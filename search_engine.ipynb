{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from time import clock\n",
    "from math import log, sqrt\n",
    "from operator import itemgetter,mul\n",
    "from string import punctuation\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "corpus = {} # the main corpus\n",
    "document_count = {}\n",
    "regex = re.compile('[%s]' % re.escape(punctuation))\n",
    "\n",
    "def load_file(path):\n",
    "    '''Load file dump and create and search indexed data structure in this\n",
    "    formart {word1:{doc_id1:count, doc_id2:count},\n",
    "             word2:{doc_id1:count, doc_id2:count} }'''\n",
    "    documents = 0\n",
    "    try:\n",
    "\n",
    "        dump_file = open(path)\n",
    "        for doc in dump_file.read().split('<doc id=\"'):\n",
    "            '''Read each document and get words'''\n",
    "            if doc[:10]:\n",
    "                curid = re.search('curid=(.*?)\" title', doc).group(1)\n",
    "                title = re.search('title=\"(.*?)\">', doc).group(1)\n",
    "                doc_id = curid + '-' + title        #Create a unique ID combining curid and title\n",
    "                if curid in document_count:\n",
    "                    continue\n",
    "                documents += 1\n",
    "                document_count[curid] = 0\n",
    "                #continue\n",
    "\n",
    "                doc = (regex.sub('', doc)).lower().split()\n",
    "                for word in doc :\n",
    "                    '''For each word in a document, count how many times it occurs'''\n",
    "                    document_count[curid] += 1\n",
    "\n",
    "                    if word in corpus:\n",
    "                        if doc_id in corpus[word]:\n",
    "                            corpus[word][doc_id] += 1\n",
    "                        else:\n",
    "                            corpus[word][doc_id] = 1\n",
    "                    else:\n",
    "                        corpus[word] = {doc_id: 1}\n",
    "\n",
    "        dump_file.close()\n",
    "\n",
    "    except (Exception) as ex:\n",
    "        print(str(ex))\n",
    "\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_idf(doc_id, term, frequency):\n",
    "    ''' tf-idf calculation'''\n",
    "    id = doc_id[:doc_id.find('-')]                                  #extract the the curid\n",
    "    tf = frequency / document_count[id]\n",
    "    idf = log((len(document_count) / len(corpus[term])), 10)\n",
    "    return tf * idf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def search(phrase):\n",
    "    '''Search process'''\n",
    "\n",
    "    if len(phrase) < 2:\n",
    "        '''Single term search'''\n",
    "        term = phrase[0]\n",
    "        if term in corpus:\n",
    "            ranking = []\n",
    "            for doc_id, frequency in corpus[term].items():\n",
    "                '''check the documents where the phrase exist return its tf-idf'''\n",
    "                ranking.append((doc_id, tf_idf(doc_id, term, frequency)))\n",
    "            return sorted(ranking, key=itemgetter(1))\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    else:\n",
    "        docs_with_terms = [] #List of documents that contain search terms\n",
    "        for term in phrase:\n",
    "            if term in corpus:\n",
    "                id = corpus[term].keys()\n",
    "                docs_with_terms.append(set((id)))\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "        #Get the intersection of the documents that contain all search terms\n",
    "        doc_intersection = dict.fromkeys(set.intersection(*docs_with_terms),0) \n",
    "        search_terms =set(phrase)\n",
    "        for document in doc_intersection:\n",
    "            for term in search_terms:\n",
    "                #Add cumulative tf-idf of all the search terms for each document\n",
    "                doc_intersection[document] +=tf_idf(document,term,corpus[term][document])                  \n",
    "        return sorted(doc_intersection.items(), key=itemgetter(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the search engine!\n",
      "type:\n",
      "     load <filename> : to load new documents\n",
      "     search <words> : to search for word(s) in the loaded documents \n",
      "     q or exit to end the program\n",
      "\n",
      "command>load wiki_dump1.txt\n",
      "Loaded 243 documents in 0.65 seconds (2.68 ms per document).\n",
      "\n",
      "command>search software \n",
      "\n",
      "Search completed in 0.17 ms.\n",
      "\n",
      "Titles and urls of matching documents:\n",
      "----------------------------------------\n",
      "Dan Bricklin                                                ->https://en.wikipedia.org/wiki?curid=8668\n",
      "Djbdns                                                      ->https://en.wikipedia.org/wiki?curid=8736\n",
      "BIND                                                        ->https://en.wikipedia.org/wiki?curid=8735\n",
      "Dia (software)                                              ->https://en.wikipedia.org/wiki?curid=9069\n",
      "Dragon 32/64                                                ->https://en.wikipedia.org/wiki?curid=8650\n",
      "Debian GNU/Hurd                                             ->https://en.wikipedia.org/wiki?curid=8780\n",
      "Dave Winer                                                  ->https://en.wikipedia.org/wiki?curid=8713\n",
      "Device driver                                               ->https://en.wikipedia.org/wiki?curid=9101\n",
      "Dhrystone                                                   ->https://en.wikipedia.org/wiki?curid=8709\n",
      "Digital compositing                                         ->https://en.wikipedia.org/wiki?curid=8858\n",
      "Deep Space 1                                                ->https://en.wikipedia.org/wiki?curid=9070\n",
      "Doctor V64                                                  ->https://en.wikipedia.org/wiki?curid=9091\n",
      "DEC Alpha                                                   ->https://en.wikipedia.org/wiki?curid=8971\n",
      "Devanagari                                                  ->https://en.wikipedia.org/wiki?curid=8968\n",
      "Digital cinema                                              ->https://en.wikipedia.org/wiki?curid=8844\n",
      "Disc jockey                                                 ->https://en.wikipedia.org/wiki?curid=8683\n",
      "Drum kit                                                    ->https://en.wikipedia.org/wiki?curid=9079\n",
      "Data General Nova                                           ->https://en.wikipedia.org/wiki?curid=8654\n",
      "Dubbing (filmmaking)                                        ->https://en.wikipedia.org/wiki?curid=8860\n",
      "Dylan (programming language)                                ->https://en.wikipedia.org/wiki?curid=8741\n",
      "Digital video                                               ->https://en.wikipedia.org/wiki?curid=8733\n",
      "Distributism                                                ->https://en.wikipedia.org/wiki?curid=8805\n",
      "Dynamical system                                            ->https://en.wikipedia.org/wiki?curid=9087\n",
      "Dalek                                                       ->https://en.wikipedia.org/wiki?curid=9140\n",
      "Derry                                                       ->https://en.wikipedia.org/wiki?curid=9055\n",
      "Distance education                                          ->https://en.wikipedia.org/wiki?curid=8997\n",
      "Debit card                                                  ->https://en.wikipedia.org/wiki?curid=9008\n",
      "\n",
      "command>load wiki_dump2.txt\n",
      "Loaded 173 documents in 0.61 seconds (3.50 ms per document).\n",
      "\n",
      "command>search Health and education implications\n",
      "\n",
      "Search completed in 0.29 ms.\n",
      "\n",
      "Titles and urls of matching documents:\n",
      "----------------------------------------\n",
      "Distance education                                          ->https://en.wikipedia.org/wiki?curid=8997\n",
      "Pseudoscience                                               ->https://en.wikipedia.org/wiki?curid=23047\n",
      "Portugal                                                    ->https://en.wikipedia.org/wiki?curid=23033\n",
      "Detroit                                                     ->https://en.wikipedia.org/wiki?curid=8687\n",
      "Discrimination                                              ->https://en.wikipedia.org/wiki?curid=8900\n",
      "Doctor (title)                                              ->https://en.wikipedia.org/wiki?curid=8881\n",
      "Plato                                                       ->https://en.wikipedia.org/wiki?curid=22954\n",
      "\n",
      "command>exit\n"
     ]
    }
   ],
   "source": [
    "def run_search():\n",
    "    '''Excute program'''\n",
    "    print('Welcome to the search engine!\\n'\n",
    "          'type:\\n'\n",
    "          '{0:<5}load <filename> : to load new documents\\n'\n",
    "          '{0:<5}search <words> : to search for word(s) in the loaded documents \\n'\n",
    "          '{0:<5}q or exit to end the program'.format(''))\n",
    "    print()\n",
    "    while True:\n",
    "        command = input('command>').lower().strip()\n",
    "\n",
    "        if len(command) > 0:\n",
    "            if command[:4] == 'load':\n",
    "                time = 0\n",
    "                start = clock()\n",
    "                num_of_docs = load_file(command[4:].strip())\n",
    "                end = clock()\n",
    "                time += end - start\n",
    "                avg =(time / num_of_docs) * 1000 if num_of_docs > 0 else 0\n",
    "                print('Loaded {0} documents in {1:.2f} seconds ({2:.2f} ms per document).'\n",
    "                      .format(num_of_docs,time, avg))\n",
    "                print()\n",
    "            elif command[:6] == 'search':\n",
    "                if len(corpus) < 1:\n",
    "                    print('The corpus is empty. Please load documents! ')\n",
    "                    continue\n",
    "                else:\n",
    "                    # remove punctuations from phrase\n",
    "                    search_phrase = (regex.sub('', command[6:])).lower().split()  \n",
    "                    timer = 0\n",
    "                    start = clock()\n",
    "                    search_result = search(search_phrase)\n",
    "                    end = clock()\n",
    "                    timer += end - start\n",
    "                    print()\n",
    "                    print('Search completed in {0:.2f} ms.'.format(timer * 1000))\n",
    "                    if search_result:\n",
    "                        print()\n",
    "                        print('Titles and urls of matching documents:')\n",
    "                        print('----------------------------------------')\n",
    "\n",
    "                        for i in range(1, len(search_result) + 1):\n",
    "                            id = search_result[-i][0]\n",
    "                            url = '->https://en.wikipedia.org/wiki?curid=' + str(id[:id.find('-')])\n",
    "                            title = id[id.find('-') + 1:]\n",
    "                            print('{0:60s}{1}'.format(title, url))\n",
    "                        print()\n",
    "                    else:\n",
    "                        print('No match for the search term. Retry!')\n",
    "\n",
    "\n",
    "            elif command[0] == 'q' or command[:4] == 'exit':\n",
    "                break\n",
    "            else:\n",
    "                print('Command not recognised. Retry!')\n",
    "        else:\n",
    "            continue\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Testing\n",
    "\n",
    "run_search()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
