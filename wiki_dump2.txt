<doc id="22623" url="https://en.wikipedia.org/wiki?curid=22623" title="Combined oral contraceptive pill">
Combined oral contraceptive pill

Combined oral contraceptive pill (COCP), often referred to as the birth control pill or colloquially as "the pill", is a birth control method that includes a combination of an estrogen (estradiol) and a progestogen (progestin). When taken by mouth every day, these pills inhibit female fertility. They were first approved for contraceptive use in the United States in 1960, and are a very popular form of birth control. They are currently used by more than 100 million women worldwide and by almost 12 million women in the United States. Use varies widely by country, age, education, and marital status. One third of women aged 16–49 in the United Kingdom currently use either the combined pill or a progestogen-only "minipill",
compared with only 1% of women in Japan.
The pill was a catalyst for the sexual revolution. World historians credit the pill as the most important contraceptive to transfer power about reproductive rights from men to women.
Medical use.
Combined oral contraceptive pills should be taken at the same time each day. If one or more tablets are forgotten for more than 12 hours, contraceptive protection will be reduced. Most brands of combined pills are packaged in one of two different packet sizes, with days marked off for a 28-day cycle. For the 21-pill packet, a pill is consumed daily for three weeks, followed by a week of no pills. For the 28-pill packet, 21 pills are taken, followed by a week of placebo or sugar pills. A woman on the pill will have a withdrawal bleed sometime during the placebo week, and is still protected from pregnancy during this week. There are also two newer combination birth control pills (Yaz 28 and Loestrin 24 Fe) that have 24 days of active hormone pills, followed by 4 days of placebo.
Placebo pills.
The placebo pills allow the user to take a pill every day; remaining in the daily habit even during the week without hormones. Placebo pills may contain an iron supplement, as iron requirements increase during menstruation.
Failure to take pills during the placebo week does not impact the effectiveness of the pill, provided that daily ingestion of active pills is resumed at the end of the week.
The withdrawal bleeding that occurs during the break from active pills was thought to be comforting, as a physical confirmation of not being pregnant. The 28-day pill package also simulates the average menstrual cycle, though the hormonal events during a pill cycle are significantly different from those of a normal ovulatory menstrual cycle. The pill suppresses the normal cycle, and the withdrawal bleeding occurs while the placebo pills are taken. The withdrawal bleeding is also predictable. Unexpected breakthrough bleeding can be a possible side effect of longer term active regimens.
No or less frequent placebos.
If the pill formulation is monophasic, it is possible to skip withdrawal bleeding and still remain protected against conception by skipping the placebo pills and starting directly with the next packet. Attempting this with bi- or tri-phasic pill formulations carries an increased risk of breakthrough bleeding and may be undesirable. It will not, however, increase the risk of getting pregnant.
Starting in 2003, women have also been able to use a three-month version of the Pill. Similar to the effect of using a constant-dosage formulation and skipping the placebo weeks for three months, Seasonale gives the benefit of less frequent periods, at the potential drawback of breakthrough bleeding. Seasonique is another version in which the placebo week every three months is replaced with a week of low-dose estrogen.
A version of the combined pill has also been packaged to completely eliminate placebo pills and withdrawal bleeds. Marketed as Anya or Lybrel, studies have shown that after seven months, 71% of users no longer had any breakthrough bleeding, the most common side effect of going longer periods of time without breaks from active pills.
Effectiveness.
The estimated probability of pregnancy during the first year of perfect use of the pill is 0.3%, and the estimated probability of pregnancy during the first year of typical use of the pill is 9%. The perfect use failure rate is based on a review of pregnancy rates in clinical trials, the typical use failure rate is based on a weighted average of estimates from the 1995 and 2002 U.S. National Surveys of Family Growth (NSFG), corrected for underreporting of abortions.
Several factors account for typical use effectiveness being lower than perfect use effectiveness:
For instance, someone using oral forms of hormonal birth control might be given incorrect information by a health care provider as to the frequency of intake, forget to take the pill one day, or simply not go to the pharmacy on time to renew the prescription.
COCPs provide effective contraception from the very first pill if started within five days of the beginning of the menstrual cycle (within five days of the first day of menstruation). If started at any other time in the menstrual cycle, COCPs provide effective contraception only after 7 consecutive days use of active pills, so a backup method of contraception must be used until active pills have been taken for 7 consecutive days. COCPs should be taken at approximately the same time every day.
Contraceptive efficacy may be impaired by: 1) missing more than one active pill in a packet, 2) delay in starting the next packet of active pills (i.e., extending the pill-free, inactive or placebo pill period beyond 7 days), 3) intestinal malabsorption of active pills due to vomiting or diarrhea, 4) drug interactions with active pills that decrease contraceptive estrogen or progestogen levels.
The effectiveness of the combined oral contraceptive pill appears to be similar whether the active pills are taken continuously for prolonged periods of time or if they are taken for 21 active days and 7 days as placebo.
Instruction for missed pills:
Non-contraceptive use.
The hormones in "the Pill" have also been used to treat other medical conditions, such as polycystic ovary syndrome (PCOS), endometriosis, amenorrhea, menstrual cramps, adenomyosis, menorrhagia (excessive menstral bleeding), menstruation-related anemia and dysmenorrhea (painful menstruation). Though extensively used for these conditions, no oral contraceptives have been approved by the U.S. FDA for those uses because of lack of convincing scientific evidence that the benefits outweigh the risks. In addition, oral contraceptives are sometimes prescribed as medication for mild or moderate acne, although none are approved by the U.S. FDA for that sole purpose. Three different oral contraceptives have been FDA approved to treat moderate acne if the person is at least 14 or 15 years old, have already begun menstruating, and need contraception. They include Ortho Tri-Cyclen, Estrostep, and YAZ. Although the pill is sometimes prescribed to induce menstruation on a regular schedule for women bothered by irregular menstrual cycles, it actually suppresses the normal menstrual cycle and then mimics a regular 28-day monthly cycle.
Women who are experiencing menstrual dysfunction due to female athlete triad are sometimes prescribed oral contraceptives as pills can create menstrual bleeding cycles. However, the condition's underlying cause is energy deficiency and should be treated by correcting the imbalance between calories eaten and calories burned by exercise. Oral contraceptives should not be used as an initial treatment for female athlete triad.
Drug interactions.
Some drugs reduce the effect of the Pill and can cause breakthrough bleeding, or increased chance of pregnancy. These include drugs such as rifampicin, barbiturates, phenytoin and carbamazepine. In addition cautions are given about broad spectrum antibiotics, such as ampicillin and doxycycline, which may cause problems "by impairing the bacterial flora responsible for recycling ethinylestradiol from the large bowel" (BNF 2003).
The traditional medicinal herb St John's Wort has also been implicated due to its upregulation of the P450 system in the liver.
Side effects.
It is generally accepted that the health risks of oral contraceptives are lower than those from pregnancy and birth, and "the health benefits of any method of contraception are far greater than any risks from the method". Some organizations have argued that comparing a contraceptive method to no method (pregnancy) is not relevant—instead, the comparison of safety should be among available methods of contraception.
Common.
Different sources note different incidences of side effects. The most common side effect is breakthrough bleeding. A 1992 French review article said that as many as 50% of new first-time users discontinue the birth control pill before the end of the first year because of the annoyance of side effects such as breakthrough bleeding and amenorrhea. One study found that women using birth control pills blinked 32% more often than those not using the contraception.
On the other hand, the pills can sometimes improve conditions such as pelvic inflammatory disease, dysmenorrhea, premenstrual syndrome, and acne, reduce symptoms of endometriosis and polycystic ovary syndrome, and decrease the risk of anemia. Use of oral contraceptives also reduces lifetime risk of ovarian cancer.
Nausea, vomiting, headache, bloating, breast tenderness, swelling of the ankles/feet (fluid retention), or weight change may occur. Vaginal bleeding between periods (spotting) or missed/irregular periods may occur, especially during the first few months of use.
Heart and blood vessels.
Combined oral contraceptives increase the risk of venous thromboembolism (including deep vein thrombosis [DVT] and pulmonary embolism [PE]). 
COC pills with more than 50 ug of estrogen increase the risk of ischemic stroke and myocardial infarction but lower doses appear safe. These risks are greatest in women with additional risk factors, such as smoking (which increases risk substantially) and long-continued use of the pill, especially in women over 35 years of age.
The overall absolute risk of venous thrombosis per 100.000 woman years in current use of combined oral contraceptives is approximately 60, compared with 30 in non-users. The risk of thromboembolism varies with different types of birth control pills; compared with combined oral contraceptives containing levonorgestrel (LNG), and with the same dose of estrogen and duration of use, the rate ratio of deep venous thrombosis for combined oral contraceptives with norethisterone is 0.98, with norgestimate 1.19, with desogestrel (DSG) 1.82, with gestodene 1.86, with drospirenone (DRSP) 1.64, and with cyproterone acetate 1.88. In comparison, venous thromboembolism occurs in 100–200 per 100.000 pregnant women every year.
One study showed more than a 600% increased risk of blood clots for women taking COCPs with drospirenone compared with non-users, compared with 360% higher for women taking birth control pills containing levonorgestrel. The U.S. Food and Drug Administration (FDA) initiated studies evaluating the health of more than 800,000 women taking COCPs and found that the risk of VTE was 93% higher for women who had been taking drospirenone COCPs for 3 months or less and 290% higher for women taking drospirenone COCPs for 7–12 months, compared with women taking other types of oral contraceptives.
Based on these studies, in 2012 the FDA updated the label for drospirenone COCPs to include a warning that contraceptives with drospirenone may have a higher risk of dangerous blood clots.
Cancer.
A systematic review in 2010 did not support an increased overall cancer risk in users of combined oral contraceptive pills, but did find a slight increase in breast cancer risk among current users, which disappears 5–10 years after use has stopped.
Protective effects.
COC decrease the risk of ovarian cancer, endometrial cancer, and colorectal cancer. Two large cohort studies published in 2010 both found a significant reduction in adjusted relative risk of ovarian and endometrial cancer mortality in ever-users of OCs compared with never-users.
The use of oral contraceptives (birth control pills) for five years or more decreases the risk of ovarian cancer in later life by 50%. Combined oral contraceptive use reduces the risk of ovarian cancer by 40% and the risk of endometrial cancer by 50% compared with never users. The risk reduction increases with duration of use, with an 80% reduction in risk for both ovarian and endometrial cancer with use for more than 10 years. The risk reduction for both ovarian and endometrial cancer persists for at least 20 years.
Increased risks.
A report by a 2005 International Agency for Research on Cancer (IARC) working group said COCs increase the risk of cancers of the breast (among current and recent users), cervix and liver (among populations at low risk of hepatitis B virus infection). 
A 2013 meta-analysis concluded that ever use of birth control pills is associated with a modest increase in the risk of breast cancer (relative risk 1.08) and a reduced risk of colorectal cancer (relative risk 0.86) and endometrial cancer (relative risk 0.57). Cervical cancer risk in those infected with human papilloma virus is increased. A similar small increase in breast cancer risk was seen in other meta analyses.
Weight.
A 2011 Cochrane systematic review found that studies of combination hormonal contraceptives showed no large difference in weight when compared with placebo or no intervention groups. The evidence was not strong enough to be certain that contraceptive methods do not cause some weight change, but no major effect was found. This review also found "that women did not stop using the pill or patch because of weight change."
Sexuality.
COCPs may increase natural vaginal lubrication. Other women experience reductions in libido while on the pill, or decreased lubrication. Some researchers question a causal link between COCP use and decreased libido; a 2007 study of 1700 women found COCP users experienced no change in sexual satisfaction. A 2005 laboratory study of genital arousal tested fourteen women before and after they began taking COCPs. The study found that women experienced a significantly wider range of arousal responses after beginning pill use; decreases and increases in measures of arousal were equally common.
A 2006 study of 124 pre-menopausal women measured sex hormone binding globulin (SHBG), including before and after discontinuation of the oral contraceptive pill. Women continuing use of oral contraceptives had SHBG levels four times higher than those who never used it, and levels remained elevated even in the group that had discontinued its use. Theoretically, an increase in SHBG may be a physiologic response to increased hormone levels, but may decrease the free levels of other hormones, such as androgens, because of the unspecificity of its sex hormone binding.
Depression.
Low levels of serotonin, a neurotransmitter in the brain, have been linked to depression. High levels of estrogen, as in first-generation COCPs, and progestin, as in some progestin-only contraceptives, have been shown to promote the lowering of brain serotonin levels by increasing the concentration of a brain enzyme that reduces serotonin. This observation, along with some small research studies have inspired speculation that the pill causes depression.
Progestin-only contraceptives are known to worsen the condition of women who are already depressed. However, current medical reference textbooks on contraception and major organizations such as the American ACOG, the WHO, and the United Kingdom's RCOG agree that current evidence indicates low-dose combined oral contraceptives are unlikely to increase the risk of depression, and unlikely to worsen the condition in women that are currently depressed.
Hypertension.
Bradykinin lowers blood pressure by causing blood vessel dilation. Certain enzymes are capable of breaking down bradykinin (Angiotensin Converting Enzyme, Aminopeptidase P). Progesterone can increase the levels of Aminopeptidase P (AP-P), thereby increasing the breakdown of bradykinin, which increases the risk of developing hypertension.
Other effects.
Other side effects associated with low-dose COCPs are leukorrhea (increased vaginal secretions), reductions in menstrual flow, mastalgia (breast tenderness), and decrease in acne. Side effects associated with older high-dose COCPs include nausea, vomiting, increases in blood pressure, and melasma (facial skin discoloration); these effects are not strongly associated with low-dose formulations.
Excess estrogen, such as from birth control pills, appears to increase cholesterol levels in bile and decrease gallbladder movement, which can lead to gallstones. Progestins found in certain formulations of oral contraceptive pills can limit the effectiveness of weight training to increase muscle mass. This effect is caused by the ability of some progestins to inhibit androgen receptors. One study claims that the pill may affect what male body odors a woman prefers, which may in turn influence her selection of partner. Use of combined oral contraceptives is associated with a reduced risk of endometriosis, giving a relative risk of endometriosis of 0.63 during active use, yet with limited quality of evidence according to a systematic review.
Combined oral contraception decreases total testosterone levels by approximately 0.5 nmol/l, free testosterone by approximately 60%, and increases the amount of sex hormone binding globulin (SHBG) by approximately 100 nmol/l. Contraceptives containing second generation progestins and/or estrogen doses of around 20 –25 mg EE were found to have less impact on SHBG concentrations.
Contraindications.
Combined oral contraceptives are generally accepted to be contraindicated in women with pre-existing cardiovascular disease, in women who have a familial tendency to form blood clots (such as familial factor V Leiden), women with severe obesity and/or hypercholesterolemia (high cholesterol level), and in smokers over age 35.
COC are also contraindicated for women with liver tumors, hepatic adenoma or severe cirrhosis of the liver, those who have migraine with aura and for those with known or suspected breast cancer. (WHO category 4).
Mechanism of action.
Combined oral contraceptive pills were developed to prevent ovulation by suppressing the release of gonadotropins. Combined hormonal contraceptives, including COCPs, inhibit follicular development and prevent ovulation as a primary mechanism of action.
Progestogen negative feedback decreases the pulse frequency of gonadotropin-releasing hormone (GnRH) release by the hypothalamus, which decreases the secretion of follicle-stimulating hormone (FSH) and greatly decreases the secretion of luteinizing hormone (LH) by the anterior pituitary. Decreased levels of FSH inhibit follicular development, preventing an increase in estradiol levels. Progestogen negative feedback and the lack of estrogen positive feedback on LH secretion prevent a mid-cycle LH surge. Inhibition of follicular development and the absence of a LH surge prevent ovulation.
Estrogen was originally included in oral contraceptives for better cycle control (to stabilize the endometrium and thereby reduce the incidence of breakthrough bleeding), but was also found to inhibit follicular development and help prevent ovulation. Estrogen negative feedback on the anterior pituitary greatly decreases the secretion of FSH, which inhibits follicular development and helps prevent ovulation.
Another primary mechanism of action of all progestogen-containing contraceptives is inhibition of sperm penetration through the cervix into the upper genital tract (uterus and fallopian tubes) by decreasing the water content and increasing the viscosity of the cervical mucus.
The estrogen and progestogen in COCPs have other effects on the reproductive system, but these have not been shown to contribute to their contraceptive efficacy:
Insufficient evidence exists on whether changes in the endometrium could actually prevent implantation. The primary mechanisms of action are so effective that the possibility of fertilization during COCP use is very small. Since pregnancy occurs despite endometrial changes when the primary mechanisms of action fail, endometrial changes are unlikely to play a significant role, if any, in the observed effectiveness of COCPs.
Formulations.
Oral contraceptives come in a variety of formulations, some containing both estrogen and progestins, and some only containing progestin. Doses of component hormones also vary among products, and some pills are monophasic (delivering the same dose of hormones each day) while others are multiphasic (doses vary each day).
COCPs have been somewhat inconsistently grouped into "generations" in the medical literature based on when they were introduced.
History.
By the 1930s, scientists had isolated and determined the structure of the steroid hormones and found that high doses of androgens, estrogens or progesterone inhibited ovulation,
but obtaining them from European pharmaceutical companies produced from animal extracts was extraordinarily expensive.
In 1939, Russell Marker, a professor of organic chemistry at Pennsylvania State University, developed a method of synthesizing progesterone from plant steroid sapogenins, initially using sarsapogenin from sarsaparilla, which proved too expensive. After three years of extensive botanical research, he discovered a much better starting material, the saponin from inedible Mexican yams ("Dioscorea mexicana" and "Dioscorea composita") found in the rain forests of Veracruz near Orizaba. The saponin could be converted in the lab to its aglycone moiety diosgenin. Unable to interest his research sponsor Parke-Davis in the commercial potential of synthesizing progesterone from Mexican yams, Marker left Penn State and in 1944 co-founded Syntex with two partners in Mexico City. When he left Syntex a year later the trade of the barbasco yam had started and the period of the heyday of the Mexican steroid industry had been started. Syntex broke the monopoly of European pharmaceutical companies on steroid hormones, reducing the price of progesterone almost 200-fold over the next eight years.
Midway through the 20th century, the stage was set for the development of a hormonal contraceptive, but pharmaceutical companies, universities and governments showed no interest in pursuing research.
Progesterone to prevent ovulation.
In early 1951, reproductive physiologist Gregory Pincus, a leader in hormone research and co-founder of the Worcester Foundation for Experimental Biology (WFEB) in Shrewsbury, Massachusetts, first met American birth control movement founder Margaret Sanger at a Manhattan dinner hosted by Abraham Stone, medical director and vice president of Planned Parenthood (PPFA), who helped Pincus obtain a small grant from PPFA to begin hormonal contraceptive research. Research started on April 25, 1951 with reproductive physiologist Min Chueh Chang repeating and extending the 1937 experiments of Makepeace "et al." that showed injections of progesterone suppressed ovulation in rabbits. In October 1951, G. D. Searle & Company refused Pincus' request to fund his hormonal contraceptive research, but retained him as a consultant and continued to provide chemical compounds to evaluate.
In March 1952, Sanger wrote a brief note mentioning Pincus' research to her longtime friend and supporter, suffragist and philanthropist Katharine Dexter McCormick, who visited the WFEB and its co-founder and old friend Hudson Hoagland in June 1952 to learn about contraceptive research there. Frustrated when research stalled from PPFA's lack of interest and meager funding, McCormick arranged a meeting at the WFEB on June 6, 1953 with Sanger and Hoagland, where she first met Pincus who committed to dramatically expand and accelerate research with McCormick providing fifty times PPFA's previous funding.
Pincus and McCormick enlisted Harvard clinical professor of gynecology John Rock, chief of gynecology at the Free Hospital for Women and an expert in the treatment of infertility, to lead clinical research with women. At a scientific conference in 1952, Pincus and Rock, who had known each other for many years, discovered they were using similar approaches to achieve opposite goals. In 1952, Rock induced a three-month anovulatory "pseudo-pregnancy" state in eighty of his infertility patients with continuous gradually increasing oral doses of estrogen (diethylstilbestrol 5–30 mg/day) and progesterone (50–300 mg/day) and within the following four months 15% became pregnant.
In 1953, at Pincus' suggestion, Rock induced a three-month anovulatory "pseudo-pregnancy" state in twenty-seven of his infertility patients with an oral 300 mg/day progesterone-only regimen for 20 days from cycle days 5–24 followed by pill-free days to produce withdrawal bleeding. This produced the same 15% pregnancy rate during the following four months without the amenorrhea of the previous continuous estrogen and progesterone regimen. But 20% of the women experienced breakthrough bleeding and in the first cycle ovulation was suppressed in only 85% of the women, indicating that even higher and more expensive oral doses of progesterone would be needed to initially consistently suppress ovulation.
Progestins to prevent ovulation.
Pincus asked his contacts at pharmaceutical companies to send him chemical compounds with progestogenic activity. Chang screened nearly 200 chemical compounds in animals and found the three most promising were Syntex's norethindrone and Searle's norethynodrel and norethandrolone.
Chemists Carl Djerassi, Luis Miramontes, and George Rosenkranz at Syntex in Mexico City had synthesized the first orally highly active progestin norethindrone in 1951. Frank B. Colton at Searle in Skokie, Illinois had synthesized the orally highly active progestins norethynodrel (an isomer of norethindrone) in 1952 and norethandrolone in 1953.
In December 1954, Rock began the first studies of the ovulation-suppressing potential of 5–50 mg doses of the three oral progestins for three months (for 21 days per cycle—days 5–25 followed by pill-free days to produce withdrawal bleeding) in fifty of his infertility patients in Brookline, Massachusetts. Norethindrone or norethynodrel 5 mg doses and all doses of norethandrolone suppressed ovulation but caused breakthrough bleeding, but 10 mg and higher doses of norethindrone or norethynodrel suppressed ovulation without breakthrough bleeding and led to a 14% pregnancy rate in the following five months. Pincus and Rock selected Searle's norethynodrel for the first contraceptive trials in women, citing its total lack of androgenicity versus Syntex's norethindrone's very slight androgenicity in animal tests.
Combined oral contraceptive.
Norethynodrel (and norethindrone) were subsequently discovered to be contaminated with a small percentage of the estrogen mestranol (an intermediate in their synthesis), with the norethynodrel in Rock's 1954–5 study containing 4–7% mestranol. When further purifying norethynodrel to contain less than 1% mestranol led to breakthrough bleeding, it was decided to intentionally incorporate 2.2% mestranol, a percentage that was not associated with breakthrough bleeding, in the first contraceptive trials in women in 1956. The norethynodrel and mestranol combination was given the proprietary name Enovid.
The first contraceptive trial of Enovid led by Celso-Ramón García and Edris Rice-Wray began in April 1956 in Río Piedras, Puerto Rico. A second contraceptive trial of Enovid (and norethindrone) led by Edward T. Tyler began in June 1956 in Los Angeles. On January 23, 1957, Searle held a symposium reviewing gynecologic and contraceptive research on Enovid through 1956 and concluded Enovid's estrogen content could be reduced by 33% to lower the incidence of estrogenic gastrointestinal side effects without significantly increasing the incidence of breakthrough bleeding.
Public availability.
United States.
On June 10, 1957, the Food and Drug Administration (FDA) approved Enovid 10 mg (9.85 mg norethynodrel and 150 µg mestranol) for menstrual disorders, based on data from its use by more than 600 women. Numerous additional contraceptive trials showed Enovid at 10, 5, and 2.5 mg doses to be highly effective. On July 23, 1959, Searle filed a supplemental application to add contraception as an approved indication for 10, 5, and 2.5 mg doses of Enovid. The FDA refused to consider the application until Searle agreed to withdraw the lower dosage forms from the application. On May 9, 1960, the FDA announced it would approve Enovid 10 mg for contraceptive use, and did so on June 23, 1960. At that point, Enovid 10 mg had been in general use for three years and, by conservative estimate, at least half a million women had used it.
Although FDA-approved for contraceptive use, Searle never marketed Enovid 10 mg as a contraceptive. Eight months later, on February 15, 1961, the FDA approved Enovid 5 mg for contraceptive use. In July 1961, Searle finally began marketing Enovid 5 mg (5 mg norethynodrel and 75 µg mestranol) to physicians as a contraceptive.
Although the FDA approved the first oral contraceptive in 1960, contraceptives were not available to married women in all states until "Griswold v. Connecticut" in 1965 and were not available to unmarried women in all states until "Eisenstadt v. Baird" in 1972.
The first published case report of a blood clot and pulmonary embolism in a woman using Enavid (Enovid 10 mg in the U.S.) at a dose of 20 mg/day did not appear until November 1961, four years after its approval, by which time it had been used by over one million women. It would take almost a decade of epidemiological studies to conclusively establish an increased risk of venous thrombosis in oral contraceptive users and an increased risk of stroke and myocardial infarction in oral contraceptive users who smoke or have high blood pressure or other cardiovascular or cerebrovascular risk factors. These risks of oral contraceptives were dramatized in the 1969 book "The Doctors' Case Against the Pill" by feminist journalist Barbara Seaman who helped arrange the 1970 Nelson Pill Hearings called by Senator Gaylord Nelson. The hearings were conducted by senators who were all men and the witnesses in the first round of hearings were all men, leading Alice Wolfson and other feminists to protest the hearings and generate media attention. Their work led to mandating the inclusion of patient package inserts with oral contraceptives to explain their possible side effects and risks to help facilitate informed consent. Today's standard dose oral contraceptives contain an estrogen dose that is one third lower than the first marketed oral contraceptive and contain lower doses of different, more potent progestins in a variety of formulations.
Australia.
The first oral contraceptive introduced outside the United States was Schering's Anovlar (norethindrone acetate 4 mg + ethinyl estradiol 50 µg) on January 1, 1961 in Australia.
Germany.
The first oral contraceptive introduced in Europe was Schering's Anovlar on June 1, 1961 in West Germany. The lower hormonal dose, still in use, was studied by the Belgian Gynaecologist Ferdinand Peeters.
Britain.
Before the mid-1960s, the United Kingdom did not require pre-marketing approval of drugs. The British Family Planning Association (FPA) through its clinics was then the primary provider of family planning services in Britain and provided only contraceptives that were on its Approved List of Contraceptives (established in 1934). In 1957, Searle began marketing Enavid (Enovid 10 mg in the U.S.) for menstrual disorders. Also in 1957, the FPA established a Council for the Investigation of Fertility Control (CIFC) to test and monitor oral contraceptives which began animal testing of oral contraceptives and in 1960 and 1961 began three large clinical trials in Birmingham, Slough, and London.
In March 1960, the Birmingham FPA began trials of norethynodrel 2.5 mg + mestranol 50 µg, but a high pregnancy rate initially occurred when the pills accidentally contained only 36 µg of mestranol—the trials were continued with norethynodrel 5 mg + mestranol 75 µg (Conovid in Britain, Enovid 5 mg in the U.S.).
In August 1960, the Slough FPA began trials of norethynodrel 2.5 mg + mestranol 100 µg (Conovid-E in Britain, Enovid-E in the U.S.).
In May 1961, the London FPA began trials of Schering's Anovlar.
In October 1961, at the recommendation of the Medical Advisory Council of its CIFC, the FPA added Searle's Conovid to its Approved List of Contraceptives.
On December 4, 1961, Enoch Powell, then Minister of Health, announced that the oral contraceptive pill Conovid could be prescribed through the NHS at a subsidized price of 2s per month.
In 1962, Schering's Anovlar and Searle's Conovid-E were added to the FPA's Approved List of Contraceptives.
France.
On December 28, 1967, the Neuwirth Law legalized contraception in France, including the pill. The pill is the most popular form of contraception in France, especially among young women. It accounts for 60% of the birth control used in France. The abortion rate has remained stable since the introduction of the pill.
Japan.
In Japan, lobbying from the Japan Medical Association prevented the Pill from being approved for general use for nearly 40 years. The higher dose "second generation" pill was approved for use in cases of gynecologic problems, but not for birth control. Two main objections raised by the association were safety concerns over long-term use of the Pill, and concerns that the Pill use would lead to diminished use of condoms and thereby potentially increase sexually transmitted infection (STI) rates.
However, when the Ministry of Health and Welfare approved Viagra's use in Japan after only six months of the application's submission, while still claiming that the Pill required more data before approval, women's groups cried foul. The Pill was subsequently approved for use in June 1999. However, the Pill has not become popular in Japan. According to estimates, only 1.3 percent of 28 million Japanese females of childbearing age use the Pill, compared with 15.6 percent in the United States. The Pill prescription guidelines the government has endorsed require Pill users to visit a doctor every three months for pelvic examinations and undergo tests for sexually transmitted diseases and uterine cancer. In the United States and Europe, in contrast, an annual or bi-annual clinic visit is standard for Pill users. However, beginning as far back as 2007, many Japanese OBGYNs have required only a yearly visit for pill users, with tri-annual visits only recommended for those who are older or at increased risk of side effects. As of 2004, condoms accounted for 80% of birth control use in Japan, and this may explain Japan's comparatively low rates of AIDS.
Society and culture.
The Pill was approved by the FDA in the early 1960s; its use spread rapidly in the late part of that decade, generating an enormous social impact. "Time" magazine placed the pill on its cover in April, 1967. In the first place, it was more effective than most previous reversible methods of birth control, giving women unprecedented control over their fertility. Its use was separate from intercourse, requiring no special preparations at the time of sexual activity that might interfere with spontaneity or sensation, and the choice to take the Pill was a private one. This combination of factors served to make the Pill immensely popular within a few years of its introduction.
Claudia Goldin, among others, argue that this new contraceptive technology was a key player in forming women's modern economic role, in that it prolonged the age at which women first married allowing them to invest in education and other forms of human capital as well as generally become more career-oriented. Soon after the birth control pill was legalized, there was a sharp increase in college attendance and graduation rates for women. From an economic point of view, the birth control pill reduced the cost of staying in school. The ability to control fertility without sacrificing sexual relationships allowed women to make long term educational and career plans.
Because the Pill was so effective, and soon so widespread, it also heightened the debate about the moral and health consequences of pre-marital sex and promiscuity. Never before had sexual activity been so divorced from reproduction. For a couple using the Pill, intercourse became purely an expression of love, or a means of physical pleasure, or both; but it was no longer a means of reproduction. While this was true of previous contraceptives, their relatively high failure rates and their less widespread use failed to emphasize this distinction as clearly as did the Pill. The spread of oral contraceptive use thus led many religious figures and institutions to debate the proper role of sexuality and its relationship to procreation. The Roman Catholic Church in particular, after studying the phenomenon of oral contraceptives, re-emphasized the stated teaching on birth control in the 1968 papal encyclical "Humanae vitae". The encyclical reiterated the established Catholic teaching that artificial contraception distorts the nature and purpose of sex.
The United States Senate began hearings on the Pill in 1970 and there were different viewpoints heard from medical professionals. Dr. Michael Newton, President of the College of Obstetricians and Gynecologists said:
"The evidence is not yet clear that these still do in fact cause cancer or related to it. The FDA Advisory Committee made comments about this, that if there wasn't enough evidence to indicate whether or not these pills were related to the development of cancer, and I think that's still thin; you have to be cautious about them, but I don't think there is clear evidence, either one way or the other, that they do or don't cause cancer."
Another physician, Dr. Roy Hertz of the Population Council, said that anyone who takes this should know of "our knowledge and ignorance in these matters" and that all women should be made aware of this so she can decide to take the Pill or not.
The Secretary of Health, Education, and Welfare at the time, Robert Finch announced the federal government had accepted a compromise warning statement which would accompany all sales of birth control pills.
At the same time, society was beginning to take note of the impact of the Pill on traditional gender roles. Women now did not have to choose between a relationship and a career; singer Loretta Lynn commented on this in her 1974 album with a song entitled "The Pill", which told the story of a married woman's use of the drug to liberate herself from her traditional role as wife and mother.
According to writer Margaret Wente, "The pill decoupled sex and marriage, and it also decoupled marriage and procreation. The purpose of marriage was mutual satisfaction, not children, and once that happened, gay marriage probably became inevitable."
Environmental impact.
A woman using COCPs excretes from her urine and feces natural estrogens, estrone (E1) and estradiol (E2), and synthetic estrogen ethinylestradiol (EE2).
These hormones can pass through water treatment plants and into rivers. Other forms of contraception, such as the contraceptive patch, use the same synthetic estrogen (EE2) that is found in COCPs, and can add to the hormonal concentration in the water when flushed down the toilet. This excretion is shown to play a role in causing endocrine disruption, which affects the sexual development and the reproduction, in wild fish populations in segments of streams contaminated by treated sewage effluents.
A study done in British rivers supported the hypothesis that the incidence and the severity of intersex wild fish populations were significantly correlated with the concentrations of the E1, E2, and EE2 in the rivers.
A review of activated sludge plant performance found estrogen removal rates varied considerably but averaged 78% for estrone, 91% for estradiol, and 76% for ethinylestradiol (estriol effluent concentrations are between those of estrone and estradiol, but estriol is a much less potent endocrine disruptor to fish).
Effluent concentrations of ethinylestradiol are lower than estradiol which are lower than estrone, but ethinylestradiol is more potent than estradiol which is more potent than estrone in the induction of intersex fish and synthesis of vitellogenin in male fish.
However, these environmental harms are outweighed by the beneficial effects of contraception as it counters human overpopulation. Numerous studies have demonstrated that increasing access to contraception, including birth control pills, can be an effective strategy for climate change mitigation as well as adaptation. According to Thomas Wire, contraception is the 'greenest technology' because of its cost-effectiveness in combating global warming — each $7 spent on family planning would reduce global carbon emissions by 1 tonne over four decades, while achieving the same result with low-carbon technologies would require $32. If all the current unmet need for contraception were met, that would reduce global carbon dioxide emissions by 34 gigatonnes between 2010 and 2050.

</doc>
<doc id="22625" url="https://en.wikipedia.org/wiki?curid=22625" title="Organized crime">
Organized crime

Organized crime is a category of transnational, national, or local groupings of highly centralized enterprises run by criminals, who intend to engage in illegal activity, most commonly for money and profit. Some criminal organizations, such as terrorist groups, are politically motivated. Sometimes criminal organizations force people to do business with them, such as when a gang extorts money from shopkeepers for so-called "protection". Gangs may become disciplined enough to be considered "organized". A criminal organization or gang can also be referred to as a mafia, mob, or crime syndicate; the network, subculture and community of criminals may be referred to as the underworld.
Other organizations—including states, militaries, police forces, and corporations—may sometimes use organized crime methods to conduct their business, but their powers derive from their status as formal social institutions. There is a tendency to distinguish organized crime from other forms of crimes, such as, white-collar crime, financial crimes, political crimes, war crime, state crimes, and treason. This distinction is not always apparent and the academic debate is ongoing. For example, in failed states that can no longer perform basic functions such as education, security, or governance, usually due to fractious violence or extreme poverty, organised crime, governance and war are often complementary to each other. The term Parliamentary Mafiocracy has been used to describe democratic countries whose political, social and economic institutions are under the control of few families and business oligarchs.
In the United States, the Organized Crime Control Act (1970) defines organized crime as "The unlawful activities of [...] a highly organized, disciplined association [...]". Criminal activity as a structured group is referred to as racketeering. In the UK, police estimate organized crime involves up to 38,000 people operating in 6,000 various groups. In addition, due to the escalating violence of Mexico's drug war, the Mexican drug cartels are considered the "greatest organized crime threat to the United States" according to a report issued by the United States Department of Justice.
Models.
Organizational.
Patron-client networks.
Patron-client networks are defined by the fluid interactions they produced crime groups operate as smaller units within the overall network, and as such tend towards valuing significant others, familiarity of social and economic environments, or tradition. These networks are usually composed of:
Bureaucratic/corporate operations.
Bureaucratic/corporate organized crime groups are defined by the general rigidity of their internal structures. Focusing more on how the operations works, succeeds, sustains itself or avoids retribution, they are generally typified by:
However, this model of operation has some flaws:
While bureaucratic operations emphasize business processes and strongly authoritarian hierarchies, these are based on enforcing power relationships rather than an overlying aim of protectionism, sustainability or growth.
Youth and street gangs.
A distinctive gang culture underpins many, but not all, organized groups; this may develop through recruiting strategies, social learning processes in the corrective system experienced by youth, family or peer involvement in crime, and the coercive actions of criminal authority figures. The term “street gang” is commonly used interchangeably with “youth gang,” referring to neighborhood or street-based youth groups that meet “gang” criteria. Miller (1992) defines a street gang as “a self-formed association of peers, united by mutual interests, with identifiable leadership and internal organization, who act collectively or as individuals to achieve specific purposes, including the conduct of illegal activity and control of a particular territory, facility, or enterprise."
"Zones of transition" are deteriorating neighborhoods with shifting populations. In such areas, conflict between groups, fighting, "turf wars", and theft promote solidarity and cohesion. Cohen (1955): working class teenagers joined gangs due to frustration of inability to achieve status and goals of the middle class; Cloward and Ohlin (1960): blocked opportunity, but unequal distribution of opportunities lead to creating different types of gangs (that is, some focused on robbery and property theft, some on fighting and conflict and some were retreatists focusing on drug taking); Spergel (1966) was one of the first criminologists to focus on "evidence-based practice" rather than intuition into gang life and culture. Klein (1971) like Spergel studied the effects on members of social workers’ interventions. More interventions actually lead to greater gang participation and solidarity and bonds between members. Downes and Rock (1988) on Parker’s analysis: strain theory applies, labeling theory (from experience with police and courts), control theory (involvement in trouble from early childhood and the eventual decision that the costs outweigh the benefits) and conflict theories. No ethnic group is more disposed to gang involvement than another, rather it is the status of being marginalized, alienated or rejected that makes some groups more vulnerable to gang formation, and this would also be accounted for in the effect of social exclusion, especially in terms of recruitment and retention. These may also be defined by age (typically youth) or peer group influences, and the permanence or consistency of their criminal activity. These groups also form their own symbolic identity or public representation which are recognizable by the community at large (include colors, symbols, patches, flags and tattoos).
Research has focused on whether the gangs have formal structures, clear hierarchies and leadership in comparison with adult groups, and whether they are rational in pursuit of their goals, though positions on structures, hierarchies and defined roles are conflicting. Some studied street gangs involved in drug dealing - finding that their structure and behavior had a degree of organizational rationality. Members saw themselves as organized criminals; gangs were formal-rational organizations, Strong organizational structures, well defined roles and rules that guided members’ behavior. Also a specified and regular means of income (i.e., drugs). Padilla (1992) agreed with the two above. However some have found these to be loose rather than well-defined and lacking persistent focus, there was relatively low cohesion, few shared goals and little organizational structure. Shared norms, value and loyalties were low, structures "chaotic", little role differentiation or clear distribution of labor. Similarly, the use of violence does not conform to the principles behind protection rackets, political intimidation and drug trafficking activities employed by those adult groups. In many cases gang members graduate from youth gangs to highly developed OC groups, with some already in contact with such syndicates and through this we see a greater propensity for imitation. Gangs and traditional criminal organizations cannot be universally linked (Decker, 1998), however there are clear benefits to both the adult and youth organization through their association. In terms of structure, no single crime group is archetypal, though in most cases there are well-defined patterns of vertical integration (where criminal groups attempt to control the supply and demand), as is the case in arms, sex and drug trafficking.
Individual difference.
Entrepreneurial.
The entrepreneurial model looks at either the individual criminal, or a smaller group of organized criminals, that capitalize off the more fluid 'group-association' of contemporary organized crime. This model conforms to social learning theory or differential association in that there are clear associations and interaction between criminals where knowledge may be shared, or values enforced, however it is argued that rational choice is not represented in this. The choice to commit a certain act, or associate with other organized crime groups, may be seen as much more of an entrepreneurial decision - contributing to the continuation of a criminal enterprise, by maximizing those aspects that protect or support their own individual gain. In this context, the role of risk is also easily understandable, however it is debatable whether the underlying motivation should be seen as true entrepreneurship or entrepreneurship as a product of some social disadvantage.
The criminal organization, much in the same way as one would assess pleasure and pain, weighs such factors as legal, social and economic risk to determine potential profit and loss from certain criminal activities. This decision-making process rises from the entrepreneurial efforts of the group's members, their motivations and the environments in which they work. Opportunism is also a key factor – the organized criminal or criminal group is likely to frequently reorder the criminal associations they maintain, the types of crimes they perpetrate, and how they function in the public arena (recruitment, reputation, etc.) in order to ensure efficiency, capitalization and protection of their interests.
Multimodel approach.
Culture and ethnicity provide an environment where trust and communication between criminals can be efficient and secure. This may ultimately lead to a competitive advantage for some groups, however it is inaccurate to adopt this as the only determinant of classification in organized crime. This categorization includes the Sicilian Mafia, Jamaican posses, Colombian drug trafficking groups, Nigerian organized crime groups, Corsican mafia, Japanese Yakuza (or Boryokudan), Korean criminal groups and ethnic Chinese criminal groups. From this perspective, organized crime is not a modern phenomenon - the construction of 17th and 18th century crime gangs fulfill all the present day criteria of criminal organizations (in opposition to the Alien Conspiracy Theory). These roamed the rural borderlands of central Europe embarking on many of the same illegal activities associated with today’s crime organizations, with the exception of money laundering.
When the French revolution created strong nation states, the criminal gangs moved to other poorly controlled regions like the Balkans and Southern Italy, where the seeds were sown for the Sicilian Mafia - the lynchpin of organized crime in the New World.
Typical activities.
Organized crime groups provide a range of illegal services and goods. Organized crime often victimize businesses through the use of extortion or theft and fraud activities like hijacking cargo trucks, robbing goods, committing bankruptcy fraud (also known as "bust-out"), insurance fraud or stock fraud (inside trading). Organized crime groups also victimize individuals by car theft (either for dismantling at "chop shops" or for export), art theft, bank robbery, burglary, jewelery theft, computer hacking, credit card fraud, economic espionage, embezzlement, identity theft, and securities fraud ("pump and dump" scam). Some organized crime groups defraud national, state, or local governments by bid rigging public projects, counterfeiting money, smuggling or manufacturing untaxed alcohol (bootlegging) or cigarettes (buttlegging), and providing immigrant workers to avoid taxes.
Organized crime groups seek out corrupt public officials in executive, law enforcement, and judicial roles so that their activities can avoid, or at least receive early warnings about, investigation and prosecution.
Activities of organized crime include loansharking of money at very high interest rates, assassination, blackmailing, bombings, bookmaking and illegal gambling, confidence tricks, copyright infringement, counterfeiting of intellectual property, fencing, kidnapping, prostitution, smuggling, drug trafficking, arms trafficking, oil smuggling, antiquities smuggling, organ trafficking, contract killing, identity document forgery, money laundering, point shaving, price fixing, illegal dumping of toxic waste, illegal trading of nuclear materials, military equipment smuggling, nuclear weapons smuggling, passport fraud, providing illegal immigration and cheap labor, people smuggling, trading in endangered species, and trafficking in human beings. Organized crime groups also do a range of business and labor racketeering activities, such as skimming casinos, insider trading, setting up monopolies in industries such as garbage collecting, construction and cement pouring, bid rigging, getting "no-show" and "no-work" jobs, political corruption and bullying.
Violence.
Assault.
The commission of violent crime may form part of a criminal organization's 'tools' used to achieve criminogenic goals (for example, its threatening, authoritative, coercive, terror-inducing, or rebellious role), due to psychosocial factors (cultural conflict, aggression, rebellion against authority, access to illicit substances, counter-cultural dynamic), or may, in and of itself, be crime rationally chosen by individual criminals and the groups they form. Assaults are used for coercive measures, to "rough up" debtors, competition or recruits, in the commission of robberies, in connection to other property offenses, and as an expression of counter-cultural authority; violence is normalized within criminal organizations (in direct opposition to mainstream society) and the locations they control. Whilst the intensity of violence is dependent on the types of crime the organization is involved in (as well as their organizational structure or cultural tradition) aggressive acts range on a spectrum from low-grade physical assaults to murder. Bodily harm and grievous bodily harm, within the context of organized crime, must be understood as indicators of intense social and cultural conflict, motivations contrary to the security of the public, and other psychosocial factors.
Murder.
Murder has evolved from the honor and vengeance killings of the Yakuza or Sicilian mafia which placed large physical and symbolic importance on the act of murder, its purposes and consequences, to a much less discriminate form of expressing power, enforcing criminal authority, achieving retribution or eliminating competition. The role of the hit man has been generally consistent throughout the history of organized crime, whether that be due to the efficiency or expediency of hiring a professional assassin or the need to distance oneself from the commission of murderous acts (making it harder to prove liability). This may include the assassination of notable figures (public, private or criminal), once again dependent on authority, retribution or competition. Revenge killings, armed robberies, violent disputes over controlled territories and offenses against members of the public must also be considered when looking at the dynamic between different criminal organizations and their (at times) conflicting needs.
Terrorism.
In addition to what is considered traditional organized crime involving direct crimes of fraud swindles, scams, racketeering and other Racketeer Influenced and Corrupt Organizations Act (RICO) predicate acts motivated for the accumulation of monetary gain, there is also non-traditional organized crime which is engaged in for political or ideological gain or acceptance. Such crime groups are often labelled terrorist groups.
There is no universally agreed, legally binding, criminal law definition of terrorism. Common definitions of terrorism refer only to those violent acts which are intended to create fear (terror), are perpetrated for a religious, political or ideological goal, deliberately target or disregard the safety of non-combatants (e.g., neutral military personnel or civilians), and are committed by non-government agencies. Some definitions also include acts of unlawful violence and war, especially crimes against humanity ("See The Nuremberg Trials"), Allied authorities deeming the German Nazi Party, its paramilitary and police organizations, and numerous associations subsidiary to the Nazi Party "criminal organizations". The use of similar tactics by criminal organizations for protection rackets or to enforce a code of silence is usually not labeled terrorism though these same actions may be labeled terrorism when done by a politically motivated group.
Notable groups include Al-Qaeda, Animal Liberation Front, Army of God, Black Liberation Army, The Covenant, The Sword, and the Arm of the Lord, Earth Liberation Front, Irish Republican Army, Kurdistan Workers' Party, Lashkar e Toiba, May 19th Communist Organization, The Order, Revolutionary Armed Forces of Colombia, Symbionese Liberation Army, Taliban, United Freedom Front and Weather Underground..
Financial crime.
Organized crime groups generate large amounts of money by activities such as drug trafficking, arms smuggling and financial crime. This is of little use to them unless they can disguise it and convert it into funds that are available for investment into legitimate enterprise. The methods they use for converting its ‘dirty’ money into ‘clean’ assets encourages corruption. Organized crime groups need to hide the money’s illegal origin. It allows for the expansion of OC groups, as the ‘laundry’ or ‘wash cycle’ operates to cover the money trail and convert proceeds of crime into usable assets. Money laundering is bad for international and domestic trade, banking reputations and for effective governments and rule of law. Accurate figures for the amounts of criminal proceeds laundered are almost impossible to calculate, and the Financial Action Task Force on Money Laundering (FATF), an intergovernmental body set up to combat money laundering, has stated that "overall it is absolutely impossible to produce a reliable estimate of the amount of money laundered and therefore the FATF does not publish any figures in this regard". However, in the US estimated figures of money laundering have been put at between $200 – $600 billion per year throughout the 1990s (US Congress Office 1995; Robinson 1996), and in 2002 this was estimated between $500 billion to $1 trillion per year (UN 2002). This would make organized crime the third largest business in world after foreign exchange and oil (Robinson 1996). The rapid growth of money laundering is due to:
Money Laundering is a three-stage process:
Means of money laundering:
The policy aim in this area is to make the financial markets transparent, and minimize the circulation of criminal money and its cost upon legitimate markets.
Remittance services
In addition to ordinary banking, however, money and other forms of value can be transferred through the use of so-called 'remittance services' which have operated for hundreds of years in non-Western societies. Originating in southeast Asia and India, users of these systems transfer funds through the use of agents who enter into agreements with each other to receive money from people in one country (such as overseas workers) and to pay money to specified relatives or friends in other countries without having to rely on conventional banking arrangements. Funds can be moved quickly, cheaply and securely between locations that often don't have established banking networks or modern forms of electronic funds transfers available. Because such systems operate outside conventional banking systems, they are known as 'alternative remittance', 'underground' or 'parallel banking' systems. They are invariably legitimate and legal in many countries, although concerns have arisen in the recent decade that they could be used to circumvent anti-money laundering and counter-terrorism financing controls that now operate across the global financial services sector. Particular risks arise from the irregular forms of record-keeping which are often employed and the possibility that the laws of those countries in which they operate may not be fully complied with. 'Alternative remittance' is only one of a number of terms used to describe the practice of transferring value, including money, from one country to another. It is generally used where value is sent through 'informal' channels, as distinct from conventional banks. Terms used in other jurisdictions include hundi, hawala, poe kuan, informal funds transfer, underground banking, parallel banking, informal funds transfer and money/value transfer. The remittance system predates modern banking and arose in various locations including China, southeast Asia and the Middle East where there was a need to move value without taking the risk of physically moving money itself. At its most basic, a remittance service involves a sender, a beneficiary and two intermediaries. The sender wishes to send a remittance to the beneficiary, often in the country of origin where the sender previously resided.
Counterfeiting.
In 2007, the OECD reported the scope of counterfeit products to include food, pharmaceuticals, pesticides, electrical components, tobacco and even household cleaning products in addition to the usual films, music, literature, games and other electrical appliances, software and fashion. A number of qualitative changes in the trade of counterfeit products:
Tax evasion.
The economic effects of organized crime have been approached from a number of both theoretical and empirical positions, however the nature of such activity allows for misrepresentation. The level of taxation taken by a nation-state, rates of unemployment, mean household incomes and level of satisfaction with government and other economic factors all contribute to the likelihood of criminals to participate in tax evasion. As most organized crime is perpetrated in the liminal state between legitimate and illegitimate markets, these economic factors must adjusted to ensure the optimal amount of taxation without promoting the practice of tax evasion. As with any other crime, technological advancements have made the commission of tax evasion easier, faster and more globalized. The ability for organized criminals to operate fraudulent financial accounts, utilize illicit offshore bank accounts, access tax havens or tax shelters, and operating goods smuggling syndicates to evade importation taxes help ensure financial sustainability, security from law enforcement, general anonymity and the continuation of their operations.
Cybercrime.
Internet fraud.
Identity theft is a form of fraud or cheating of another person's identity in which someone pretends to be someone else by assuming that person's identity, typically in order to access resources or obtain credit and other benefits in that person's name. Victims of identity theft (those whose identity has been assumed by the identity thief) can suffer adverse consequences if held accountable for the perpetrator's actions, as can organizations and individuals who are defrauded by the identity thief, and to that extent are also victims. Internet fraud refers to the actual use of Internet services to present fraudulent solicitations to prospective victims, to conduct fraudulent transactions, or to transmit the proceeds of fraud to financial institutions or to others connected with the scheme. In the context of organized crime, both may serve as means through which other criminal activity may be successfully perpetrated or as the primary goal themselves. Email fraud, advance-fee fraud, romance scams, employment scams, and other phishing scams are the most common and most widely used forms of identity theft, though with the advent of social networking fake websites, accounts and other fraudulent or deceitful activity has become commonplace.
Copyright infringement.
Copyright infringement is the unauthorized or prohibited use of works under copyright, infringing the copyright holder's exclusive rights, such as the right to reproduce or perform the copyrighted work, or to make derivative works. Whilst almost universally considered under civil procedure, the impact and intent of organized criminal operations in this area of crime has been the subject of much debate. Article 61 of the Agreement on Trade-Related Aspects of Intellectual Property Rights (TRIPs) requires that signatory countries establish criminal procedures and penalties in cases of willful trademark counterfeiting or copyright piracy on a commercial scale. More recently copyright holders have demanded that states provide criminal sanctions for all types of copyright infringement. Organized criminal groups capitalize on consumer complicity, advancements in security and anonymity technology, emerging markets and new methods of product transmission, and the consistent nature of these provides a stable financial basis for other areas of organized crime.
Cyberwarfare.
Cyberwarfare refers to politically motivated hacking to conduct sabotage and espionage. It is a form of information warfare sometimes seen as analogous to conventional warfare although this analogy is controversial for both its accuracy and its political motivation. It has been defined as activities by a nation-state to penetrate another nation's computers or networks with the intention of causing civil damage or disruption. Moreover, it acts as the "fifth domain of warfare," and William J. Lynn, U.S. Deputy Secretary of Defense, states that "as a doctrinal matter, the Pentagon has formally recognized cyberspace as a new domain in warfare . . . [which] has become just as critical to military operations as land, sea, air, and space." Cyber espionage is the practice of obtaining confidential, sensitive, proprietary or classified information from individuals, competitors, groups, or governments using illegal exploitation methods on internet, networks, software and/or computers. There is also a clear military, political, or economic motivation. Unsecured information may be intercepted and modified, making espionage possible internationally. The recently established Cyber Command is currently debating whether such activities as commercial espionage or theft of intellectual property are criminal activities or actual "breaches of national security." Furthermore, military activities that use computers and satellites for coordination are at risk of equipment disruption. Orders and communications can be intercepted or replaced. Power, water, fuel, communications, and transportation infrastructure all may be vulnerable to sabotage. According to Clarke, the civilian realm is also at risk, noting that the security breaches have already gone beyond stolen credit card numbers, and that potential targets can also include the electric power grid, trains, or the stock market.
Computer viruses.
The term "computer virus" may be used as an overarching phrase to include all types of true viruses, malware, including computer worms, Trojan horses, most rootkits, spyware, dishonest adware and other malicious and unwanted software (though all are technically unique), and proves to be quite financially lucrative for criminal organizations, offering greater opportunities for fraud and extortion whilst increasing security, secrecy and anonymity. Worms may be utilized by organized crime groups to exploit security vulnerabilities (duplicating itself automatically across other computers a given network), while a Trojan horse is a program that appears harmless but hides malicious functions (such as retrieval of stored confidential data, corruption of information, or interception of transmissions). Worms and Trojan horses, like viruses, may harm a computer system's data or performance. Applying the Internet model of organized crime, the proliferation of computer viruses and other malicious software promotes a sense of detachment between the perpetrator (whether that be the criminal organization or another individual) and the victim; this may help to explain vast increases in cyber-crime such as these for the purpose of ideological crime or terrorism. In mid July 2010, security experts discovered a malicious software program that had infiltrated factory computers and had spread to plants around the world. It is considered "the first attack on critical industrial infrastructure that sits at the foundation of modern economies," notes the "New York Times."
White-collar crime and corruption.
Corporate crime.
Corporate crime refers to crimes committed either by a corporation (i.e., a business entity having a separate legal personality from the natural persons that manage its activities), or by individuals that may be identified with a corporation or other business entity (see vicarious liability and corporate liability). Note that some forms of corporate corruption may not actually be criminal if they are not specifically illegal under a given system of laws. For example, some jurisdictions allow insider trading.
Labor Racketeering.
Labor racketeering has developed since the 1930s, affecting national and international construction, mining, energy production and transportation sectors immensely. Activity has focused on the importation of cheap or unfree labor, involvement with union and public officials (political corruption), and counterfeiting.
Political corruption.
Political corruption is the use of legislated powers by government officials for illegitimate private gain. Misuse of government power for other purposes, such as repression of political opponents and general police brutality, is not considered political corruption. Neither are illegal acts by private persons or corporations not directly involved with the government. An illegal act by an officeholder constitutes political corruption only if the act is directly related to their official duties. Forms of corruption vary, but include bribery, extortion, cronyism, nepotism, patronage, graft, and embezzlement. While corruption may facilitate criminal enterprise such as drug trafficking, money laundering, and human trafficking, it is not restricted to these activities. The activities that constitute illegal corruption differ depending on the country or jurisdiction. For instance, certain political funding practices that are legal in one place may be illegal in another. In some cases, government officials have broad or poorly defined powers, which make it difficult to distinguish between legal and illegal actions. Worldwide, bribery alone is estimated to involve over 1 trillion US dollars annually. A state of unrestrained political corruption is known as a kleptocracy, literally meaning "rule by thieves".
Drug trafficking.
Heroin: Source countries / production: three major regions known as the Golden Triangle (Burma, Laos, Thailand), Golden Crescent (Afghanistan) and Central and South America. There are suggestions that due to the continuing decline in opium production in South East Asia, traffickers may begin to look to Afghanistan as a source of heroin."
Human trafficking.
Sex trafficking.
Human trafficking for the purpose of sexual exploitation is a major cause of contemporary sexual slavery and is primarily for prostituting women and children into sex industries. Sexual slavery encompasses most, if not all, forms of forced prostitution. The terms "forced prostitution" or "enforced prostitution" appear in international and humanitarian conventions but have been insufficiently understood and inconsistently applied. "Forced prostitution" generally refers to conditions of control over a person who is coerced by another to engage in sexual activity. Official numbers of individuals in sexual slavery worldwide vary. In 2001 International Organization for Migration estimated 400,000, the Federal Bureau of Investigation estimated 700,000 and UNICEF estimated 1.75 million. The most common destinations for victims of human trafficking are Thailand, Japan, Israel, Belgium, the Netherlands, Germany, Italy, Turkey and the United States, according to a report by UNODC.
Illegal Immigration and People smuggling ('Migrant Trafficking').
"See Snakehead (gang), Coyotaje
People smuggling is defined as "the facilitation, transportation, attempted transportation or illegal entry of a person or persons across an international border, in violation of one or more countries laws, either clandestinely or through deception, such as the use of fraudulent documents". The term is understood as and often used interchangeably with migrant smuggling, which is defined by the United Nations Convention Against Transnational Organized Crime as "...the procurement, in order to obtain, directly or indirectly, a financial or other material benefit, of the illegal entry of a person into a state party of which the person is not a national". This practice has increased over the past few decades and today now accounts for a significant portion of illegal immigration in countries around the world. People smuggling generally takes place with the consent of the person or persons being smuggled, and common reasons for individuals seeking to be smuggled include employment and economic opportunity, personal and/or familial betterment, and escape from persecution or conflict.
Contemporary slavery and forced labor.
The number of slaves today remains as high as 12 million to 27 million. This is probably the smallest proportion of slaves to the rest of the world's population in history. Most are debt slaves, largely in South Asia, who are under debt bondage incurred by lenders, sometimes even for generations. It is the fastest growing criminal industry and is predicted to eventually outgrow drug trafficking.
Historical origins.
Pre-Nineteenth Century.
Today, crime is sometimes thought of as an urban phenomenon, but for most of human history it was the rural interfaces that encountered the majority of crime (bearing in mind the fact that for most of human history, rural areas were the vast majority of inhabited places). For the most part, within a village, members kept crime at very low rates; however, outsiders such as pirates, highwaymen, and bandits attacked trade routes and roads, at times severely disrupting commerce, raising costs, insurance rates and prices to the consumer. According to criminologist Paul Lunde, "Piracy and banditry were to the preindustrial world what organized crime is to modern society."
As Lunde states, "Barbarian conquerors, whether Vandals, Goths, Norsemen, Turks or Mongols are not normally thought of as organized crime groups, yet they share many features associated with thriving criminal organizations. They were for the most part non-ideological, predominantly ethnically based, used violence and intimidation, and adhered to their own codes of law." Terrorism is linked to organized crime, but has political aims rather than solely financial ones, so there is overlap but separation between terrorism and organized crime.
Twentieth century.
Donald Cressey’s Cosa Nostra model studied Mafia families exclusively and this limits his broader findings. Structures are formal and rational with allocated tasks, limits on entrance, and influence the rules established for organizational maintenance and sustainability. In this context there is a difference between organized and professional crime; there is well-defined hierarchy of roles for leaders and members, underlying rules and specific goals that determine their behavior, and these are formed as a social system, one that was rationally designed to maximize profits and to provide forbidden goods. Albini saw organized criminal behavior as consisting of networks of patrons and clients, rather than rational hierarchies or secret societies.
The networks are characterized by a loose system of power relations. Each participant is interested in furthering his own welfare. Criminal entrepreneurs are the patrons and they exchange information with their clients in order to obtain their support. Clients include members of gangs, local and national politicians, government officials and people engaged in legitimate business. People in the network may not directly be part of the core criminal organization. Furthering the approach of both Cressey and Albini, Ianni and Ianni studied Italian-American crime syndicates in New York and other cities.
Kinship is seen as the basis of organized crime rather than the structures Cressey had identified; this includes fictive godparental and affinitive ties as well as those based on blood relations, and it is the impersonal actions, not the status or affiliations of their members, that define the group. Rules of conduct and behavioral aspects of power and networks and roles include the following:
Strong family ties are derived from the traditions of southern Italy, where family rather than the church or state is the basis of social order and morality.
The “disorganized crime” and choice theses.
One of the most important trends to emerge in criminological thinking about OC in recent years is the suggestion that it is not, in a formal sense, ‘organized’ at all. Evidence includes: lack of centralized control, absence of formal lines of communication, fragmented organizational structure. It is distinctively disorganized. For example, Seattle’s crime network in the 1970s and 80s consisted of groups of businessmen, politicians and of law enforcement officers. They all had links to a national network via Meyer Lansky, who was powerful, but there was no evidence that Lansky or anyone else exercised centralized control over them.
While some crime involved well-known criminal hierarchies in the city, criminal activity was not subject to central management by these hierarchies nor by other controlling groups, nor were activities limited to a finite number of objectives. The networks of criminals involved with the crimes did not exhibit organizational cohesion. Too much emphasis had been placed on the Mafia as controlling OC. The Mafia were certainly powerful but they “were part of a heterogeneous underworld, a network characterized by complex webs of relationships." OC groups were violent and aimed at making money but because of the lack of structure and fragmentation of objectives, they were ‘disorganized’.
Further studies showed neither bureaucracy nor kinship groups are the primary structure of organized crime, rather they were in partnerships or a series of joint business ventures. Despite these conclusions, all researchers observed a degree of managerial activities among the groups they studied. All observed networks and a degree of persistence, and there may be utility in focusing on the identification of organizing roles of people and events rather than the group’s structure. There may be three main approaches to understand the organizations in terms of their roles as social systems:
Organized crime groups may be a combination of all three.
International governance approach.
International consensus on defining organized crime has become important since the 1970s due its increased prevalence and impact. e.g., UN in 1976 and EU 1998. OC is “…the large scale and complex criminal activity carried on by groups of persons, however loosely or tightly organized for the enrichment of those participating at the expense of the community and its members. It is frequently accomplished through ruthless disregard of any law, including offenses against the person and frequently in connection with political corruption.” (UN) “A criminal organization shall mean a lasting, structured association of two or more persons, acting in concert with a view to committing crimes or other offenses which are punishable by deprivation of liberty or a detention order of a maximum of at least four years or a more serious penalty, whether such crimes or offenses are an end in themselves or a means of obtaining material benefits and, if necessary, of improperly influencing the operation of public authorities.” (UE) Not all groups exhibit the same characteristics of structure. However, violence and corruption and the pursuit of multiple enterprises and continuity serve to form the essence of OC activity.
There are eleven characteristics from the European Commission and Europol pertinent to a working definition of organized crime. Six of those must be satisfied and the four in italics are mandatory. Summarized they are:
with the Convention against Transnational Organized Crime (the "Palermo Convention") having a similar definition:
Others stress the importance of power, profit and perpetuity, defining organized criminal behavior as:
Definitions need to bring together its legal and social elements. OC has widespread social, political and economic effects. It uses violence and corruption to achieve its ends: “OC when group primarily focused on illegal profits systematically commit crimes that adversely affect society and are capable of successfully shielding their activities, in particular by being willing to use physical violence or eliminate individuals by way of corruption.”
It is a mistake in using the term ‘OC’ as though it denotes a clear and well-defined phenomenon. The evidence regarding OC “shows a less well-organized, very diversified landscape of organizing criminals…the economic activities of these organizing criminals can be better described from the viewpoint of ‘crime enterprises’ than from a conceptually unclear frameworks such as “OC’.” Many of the definitions emphasize the ‘group nature’ of OC, the ‘organization’ of its members, its use of violence or corruption to achieve its goals, and its extra-jurisdictional character….OC may appear in many forms at different times and in different places. Due to the variety of definitions, there is “evident danger” in asking “what is OC?” and expecting a simple answer.
The locus of power and organized crime.
Some espouse that all organized crime operates at an international level, though there is currently no international court capable of trying offenses resulting from such activities (the International Criminal Court’s remit extends only to dealing with people accused of offenses against humanity, e.g., genocide). If a network operates primarily from one jurisdiction and carries out its illicit operations there and in some other jurisdictions it is ‘international,' though it may be appropriate to use the term ‘transnational’ only to label the activities of a major crime group that is centered in no one jurisdiction but operating in many. The understanding of organized crime has therefore progressed to combined internationalization and an understanding of social conflict into one of power, control, efficiency risk and utility, all within the context of organizational theory. The accumulation of social, economic and political power have sustained themselves as a core concerns of all criminal organizations:
Contemporary organized crime may be very different from traditional Mafia style, particularly in terms of the distribution and centralization of power, authority structures and the concept of 'control' over one's territory and organization. There is a tendency away from centralization of power and reliance upon family ties towards a fragmentation of structures and informality of relationships in crime groups. Organized crime most typically flourishes when a central government and civil society is disorganized, weak, absent or untrusted.
This may occur in a society facing periods of political, economic or social turmoil or transition, such as a change of government or a period of rapid economic development, particularly if the society lacks strong and established institutions and the rule of law. The dissolution of the Soviet Union and the Revolutions of 1989 in Eastern Europe that saw the downfall of the Communist Bloc created a breeding ground for criminal organizations.
The newest growth sectors for organized crime are identity theft and online extortion. These activities are troubling because they discourage consumers from using the Internet for e-commerce. E-commerce was supposed to level the playing ground between small and large businesses, but the growth of online organized crime is leading to the opposite effect; large businesses are able to afford more bandwidth (to resist denial-of-service attacks) and superior security. Furthermore, organized crime using the Internet is much harder to trace down for the police (even though they increasingly deploy cybercops) since most police forces and law enforcement agencies operate within a local or national jurisdiction while the Internet makes it easier for criminal organizations to operate across such boundaries without detection.
In the past criminal organizations have naturally limited themselves by their need to expand, putting them in competition with each other. This competition, often leading to violence, uses valuable resources such as manpower (either killed or sent to prison), equipment and finances. In the United States, James "Whitey" Bulger, the Irish Mob boss of the Winter Hill Gang in Boston turned informant for the Federal Bureau of Investigation (FBI). He used this position to eliminate competition and consolidate power within the city of Boston which led to the imprisonment of several senior organized crime figures including Gennaro Angiulo, underboss of the Patriarca crime family. Infighting sometimes occurs within an organization, such as the Castellamarese war of 1930–31 and the Boston Irish Mob Wars of the 1960s and 1970s.
Today criminal organizations are increasingly working together, realizing that it is better to work in cooperation rather than in competition with each other (once again, consolidating power). This has led to the rise of global criminal organizations such as Mara Salvatrucha and the 18th Street gang. The American Mafia, in addition to having links with organized crime groups in Italy such as the Camorra, the 'Ndrangheta, Sacra Corona Unita, and Sicilian Mafia, has at various times done business with the Irish Mob, Jewish-American organized crime, the Japanese Yakuza, the Russian Mafia, the Chinese Triads, and numerous black and Hispanic street gangs. The United Nations Office on Drugs and Crime estimated that organized crime groups held $322 billion in assets in 2005.
This rise in cooperation between criminal organizations has meant that law enforcement agencies are increasingly having to work together. The FBI operates an organized crime section from its headquarters in Washington, D.C. and is known to work with other national (e.g., Polizia di Stato, Russian Federal Security Service (FSB), and the Royal Canadian Mounted Police), federal (e.g., Bureau of Alcohol, Tobacco, Firearms, and Explosives, Drug Enforcement Administration, United States Marshals Service, Immigration and Customs Enforcement, United States Secret Service, and the United States Coast Guard), state (e.g., Massachusetts State Police Special Investigation Unit and the New York State Police Bureau of Criminal Investigation) and city (e.g., New York City Police Department Organized Crime Unit and the Los Angeles Police Department Special Operations Division) law enforcement agencies.
Theoretical background.
Criminal psychology.
Rational choice.
This theory treats all individuals as rational operators, committing criminal acts after consideration of all associated risks (detection and punishment) compared with the rewards of crimes (personal, financial etc.). Little emphasis is placed on the offenders’ emotional state. The role of criminal organizations in lowering the perceptions of risk and increasing the likelihood of personal benefit is prioritized by this approach, with the organizations structure, purpose, and activity being indicative of the rational choices made by criminals and their organizers.
Deterrence.
This theory sees criminal behavior as reflective of an individual, internal calculation by the criminal that the benefits associated with offending (whether financial or otherwise) outweigh the perceived risks. The perceived strength, importance or infallibility of the criminal organization is directly proportional to the types of crime committed, their intensity and arguably the level of community response. The benefits of participating in organized crime (higher financial rewards, greater socioeconomic control and influence, protection of the family or significant others, perceived freedoms from 'oppressive' laws or norms) contribute greatly to the psychology behind highly organized group offending.
Social learning.
Criminals learn through associations with one another. The success of organized crime groups is therefore dependent upon the strength of their communication and the enforcement of their value systems, the recruitment and training processes employed to sustain, build or fill gaps in criminal operations. An understanding of this theory sees close associations between criminals, imitation of superiors, and understanding of value systems, processes and authority as the main drivers behind organized crime. Interpersonal relationships define the motivations the individual develops, with the effect of family or peer criminal activity being a strong predictor of inter-generational offending. This theory also developed to include the strengths and weaknesses of reinforcement, which in the context of continuing criminal enterprises may be used to help understand propensities for certain crimes or victims, level of integration into the mainstream culture and likelihood of recidivism / success in rehabilitation.
Enterprise.
Under this theory, organized crime exists because legitimate markets leave many customers and potential customers unsatisfied. High demand for a particular good or service (e.g., drugs, prostitution, arms, slaves), low levels of risk detection and high profits lead to a conducive environment for entrepreneurial criminal groups to enter the market and profit by supplying those goods and services. For success, there must be:
Under these conditions competition is discouraged, ensuring criminal monopolies sustain profits. Legal substitution of goods or services may (by increasing competition) force the dynamic of organized criminal operations to adjust, as will deterrence measures (reducing demand), and the restriction of resources (controlling the ability to supply or produce to supply).
Differential association.
Sutherland goes further to say that deviancy is contingent on conflicting groups within society, and that such groups struggle over the means to define what is criminal or deviant within society. Criminal organizations therefore gravitate around illegal avenues of production, profit-making, protectionism or social control and attempt (by increasing their operations or membership) to make these acceptable. This also explains the propensity of criminal organizations to develop protection rackets, to coerce through the use of violence, aggression and threatening behavior (at times termed 'terrorism'). Preoccupation with methods of accumulating profit highlight the lack of legitimate means to achieve economic or social advantage, as does the organization of white-collar crime or political corruption (though it is debatable whether these are based on wealth, power or both). The ability to effect social norms and practices through political and economic influence (and the enforcement or normaliszation of criminogenic needs) may be defined by differential association theory.
Critical criminology and sociology.
Social disorganization.
Social disorganization theory is intended to be applied to neighborhood level street crime, thus the context of gang activity, loosely formed criminal associations or networks, socioeconomic demographic impacts, legitimate access to public resources, employment or education, and mobility give it relevance to organized crime. Where the upper- and lower-classes live in close proximity this can result in feelings of anger, hostility, social injustice and frustration. Criminals experience poverty; and witness affluence they are deprived of and which is virtually impossible for them to attain through conventional means. The concept of neighborhood is central to this theory, as it defines the social learning, locus of control, cultural influences and access to social opportunity experienced by criminals and the groups they form. Fear of or lack of trust in mainstream authority may also be a key contributor to social disorganization; organized crime groups replicate such figures and thus ensure control over the counter-culture. This theory has tended to view violent or anti-social behavior by gangs as reflective of their social disorganization rather than as a product or tool of their organization.
Anomie.
Sociologist Robert K. Merton believed deviance depended on society’s definition of success, and the desires of individuals to achieve success through socially defined avenues. Criminality becomes attractive when expectations of being able to fulfill goals (therefore achieving success) by legitimate means cannot be fulfilled. Criminal organizations capitalize on states of normlessness by imposing criminogenic needs and illicit avenues to achieve them. This has been used as the basis for numerous meta-theories of organized crime through its integration of social learning, cultural deviance, and criminogenic motivations. If crime is seen as a function of anomie, organized behavior produces stability, increases protection or security, and may be directly proportional to market forces as expressed by entrepreneurship- or risk-based approaches. It is the inadequate supply of legitimate opportunities that constrains the ability for the individual to pursue valued societal goals and reduces the likelihood that using legitimate opportunities will enable them to satisfy such goals (due to their position in society).
Cultural deviance.
Criminals violate the law because they belong to a unique subculture - the counter-culture - their values and norms conflicting with those of the working-, middle- or upper-classes upon which criminal laws are based. This subculture shares an alternative lifestyle, language and culture, and is generally typified by being tough, taking care of their own affairs and rejecting government authority. Role models include drug dealers, thieves and pimps, as they have achieved success and wealth not otherwise available through socially-provided opportunities. It is through modeling organized crime as a counter-cultural avenue to success that such organizations are sustained.
Alien conspiracy/queer ladder of mobility.
The alien conspiracy theory and queer ladder of mobility theories state that ethnicity and 'outsider' status (immigrants, or those not within the dominant ethnocentric groups) and their influences are thought to dictate the prevalence of organized crime in society. The alien theory posits that the contemporary structures of organized crime gained prominence during the 1860s in Sicily and that elements of the Sicilian population are responsible for the foundation of most European and North American organized crime, made up of Italian-dominated crime families. Bell's theory of the 'queer ladder of mobility' hypothesized that 'ethnic succession' (the attainment of power and control by one more marginalized ethnic group over other less marginalized groups) occurs by promoting the perpetration of criminal activities within a disenfranchised or oppressed demographic. Whilst early organized crime was dominated by the Sicilian Mafia they have been relatively substituted by the Irish Mob (early 1900s), the Aryan Brotherhood (1960s onwards), Colombian Medellin cartel and Cali cartel (mid-1970s - 1990s), and more recently the Mexican Tijuana Cartel (late 1980s onwards), the Russian Mafia (1988 onwards), Al-Qaeda (1988 onwards) and the Taliban (1994 onwards). Many argue this misinterprets and overstates the role of ethnicity in organized crime. A contradiction of this theory is that syndicates had developed long before large-scale Sicilian immigration in 1860s, with these immigrants merely joining a widespread phenomena of crime and corruption.

</doc>
<doc id="22626" url="https://en.wikipedia.org/wiki?curid=22626" title="One Foot in the Grave">
One Foot in the Grave

One Foot in the Grave is a British BBC television sitcom series written by David Renwick. There were six series and seven Christmas specials over an eleven-year period, from early 1990 to late 2000. The first five series were broadcast between January 1990 and January 1995. For the next five years, the show appeared only as Christmas specials, followed by one final series in 2000.
The series features the exploits of Victor Meldrew, played by Richard Wilson, and his long-suffering wife, Margaret, played by Annette Crosbie. The programmes invariably deal with Meldrew's battle against the problems he creates for himself. Set in a typical suburb in southern England, Victor takes involuntary early retirement. His various efforts to keep himself busy, while encountering various misfortunes and misunderstandings are the themes of the sitcom. Indoor scenes were filmed at BBC Television Centre with most exterior scenes filmed on Tresillian Way in Walkford on the Dorset/Hampshire border. Despite its traditional production, the series subverts its domestic sitcom setting with elements of black humour and surrealism.
The series was occasionally the subject of controversy for some of its darker story elements, but nevertheless received a number of awards, including the 1992 BAFTA for Best Comedy. In 2004, the series came tenth in a 2004 BBC poll to find "Britain's Best Sitcom". The programme also came 80th in the British Film Institute's 100 Greatest British Television Programmes. The series, originally shown on BBC One, is now available on DVD and is regularly repeated in the United Kingdom on Gold. Four episodes were remade for BBC Radio 2 and the series also inspired a novel released in 1992 featuring the most memorable moments from Series 1, Series 2 and the first Christmas special.
Plot.
The series features the exploits and mishaps of irascible pensioner Victor Meldrew, who after being forced to retire from his job as a security guard, finds himself at war with the world and everything in it. Meldrew, cursed with misfortune and always complaining, is married to long-suffering wife Margaret, who is often left exasperated by his many misfortunes.
Amongst other witnesses to Victor's wrath are tactless family friend Jean Warboys, and next-door couple Patrick (Victor's nemesis) and Pippa Trench. Patrick often discovers Victor in inexplicably bizarre or compromising situations, leading him to believe that he is insane. The Meldrews' neighbour on the other side, overly cheery charity worker Nick Swainey, also adds to Victor's frustration.
Although set in a traditional suburban setting, the show subverts this genre with a strong overtone of black comedy. Series One's "The Valley of Fear" is an episode which caused controversy, when Victor finds a frozen cat in his freezer. Writer David Renwick also combined farce with elements of tragedy. For example in the final episode, Victor is killed by a hit-and-run driver, and although there is no explicit reference that Victor and Margaret had children, the episode "Timeless Time" contained a reference to someone named Stuart; the strong implication being that they once had a son who had died as a child.
A number of episodes were also experimental in that they took place entirely in one setting. Such episodes include: Victor, Margaret and Mrs Warboys stuck in a traffic jam; Victor and Margaret in bed suffering insomnia; Victor left alone in the house waiting to see if he has to take part in jury service; Victor and Margaret having a long wait in their solicitor's waiting room; and Victor and Margaret trying to cope during a power cut on the hottest night of the year.
Despite Margaret's frequent exasperation with her husband's antics, the series shows that the couple have a deep affection for one another. This is demonstrated several times throughout the series.
Characters.
Main characters.
Victor Meldrew (Richard Wilson) – Victor is the main protagonist of the sitcom and finds himself constantly battling against all that life throws at him as he becomes entangled, like the pawn he is, in machiavellian plots. Renwick once pointed out in an interview that the name "Victor" was ironic, since he almost always ends up a loser. From being buried alive to being prosecuted for attacking a feisty pit bull terrier with a collection of coconut meringues, Victor tries to adjust to life after his infamous replacement by a "box" at his place of employment, but to no avail. He believes that everything is going wrong for him all the time, and he has the right to be upset because it is always someone else's fault. Victor is a tragic comedy character and sympathy is directed towards him as he becomes embroiled in complex misunderstandings, bureaucratic vanity and, at times, sheer bad luck. The audience sees a philosophical ebb to his character, however, along with a degree of optimism. Yet his polite façade collapses when events get the better of him, and a full verbal onslaught is forthcoming. "Victor-isms" include "I do not believe it!", "I don't believe it!", "Un-be-lievable!", "What in the name of bloody hell?", "In the name of sanity!". Despite his grumpy demeanor Victor isn't totally devoid of compassionin "Hearts of Darkness" he liberates elderly nursing home residents that were being mistreated by the staff and in "Descent Into The Maelstrom" he calls the incident room number and gives the location of an emotionally disturbed girl that abducted a baby and stole Margaret's pearl earrings, which resulted in the girl getting picked up by the police. However, because the girl was a friend of Margaret's and knowing she meant a lot to her, Victor never said anything. Victor has also shown a vast amount of loyalty to Margaret as, throughout their entire 38 years of lifelong marriage together, not once has the thought of infidelity ever occurred to him. In "Rearranging the Dust", Victor and Margaret recollect the days of their courtship at a party after which Victor says "You were always my first choice", which leaves Margaret stunned. In another episode, Margaret recounts the time Victor took her to the funfair and they ended up getting stuck in the hall of mirrors for over an hour. Victor had said he didn't mind as he was happy to stay there and look at all the reflections of her.
Margaret Meldrew (née Pellow) (Annette Crosbie) – Victor's long-suffering, tolerant and kind-hearted wife. Margaret tries to maintain a degree of calmness and to rise above her husband's antics. However, she is often engulfed in these follies, mishaps and confusion and often vents her anger at Victor. In early episodes, her character acts more as a comic foil to Victor's misfortunes. Examples include fearfully asking if a cat found frozen in their freezer is definitely dead and mentioning a friend who died of a terminal illness. When Victor reminds her that the woman actually fell from a cliff, Margaret retorts she only did so because "she went to the seaside to convalesce".
In later episodes, Margaret develops into a more complex character. She is shown to be fiercely protective of her marriage to Victor by becoming easily suspicious and jealous. For example, of a Dutch marionette that Victor becomes occupied with repairing in the episode "Hole in the Sky", eventually leading her to destroy it. In "The Affair of the Hollow Lady", a greengrocer (played by Barbara Windsor) develops a soft spot for Victor and tries to convince Margaret that he has been unfaithful to her. In revenge, Margaret assaults her with a pair of boxing gloves. However, Margaret herself is shown to have contemplated infidelity with a man called Ben whom she met on holiday in the episode "Warm Champagne". She decides against cheating on Victor. In this episode, she sums up her relationship with Victor by telling Ben, "He's the most sensitive person I've ever met, and that's why I love him and why I constantly want to ram his head through a television screen." She also began to develop a sense of cynicism, slowly beginning to see the world the way her husband Victor sees it. This is especially evident in "Things aren't simple anymore" where she voices that the world is "all speed and greed" and that "nobody does anything about anything". In "Rearranging the Dust", Margaret recounts the time she first chose Victor at a party and, during a power cut, "shared their bodies" in the garden. After this moment of passion, they went back inside and when the lights came back on Margaret realised that she had "grabbed hold of the wrong person".
Margaret could be said to have a catchphrase - typically a long, exasperated use of the word "God", usually when making a realisation about the reasons behind one of Victor's mishaps. These are occasionally inadvertently aided by herself in some way, such as leaving the phone off the hook or giving permission to someone to enter the Meldrews' house when she isn't there.
Jean Warboys (Doreen Mantle) – Mrs Warboys is a friend of Margaret (and a rather annoying one in Victor's eyes) who attached herself to the Meldrews, accompanying them on many of their exploits. In the early series she was married to (never seen) Chris, but eventually he left her for the private detective she had hired when she suspected him of having an affair, and they divorced.
She often bears the brunt of Victor's temper due to muddled misunderstandings and in part due to her aloof nature. One such occasion saw Victor asking her to pick up a suit of his from the dry-cleaners, only for her to return with a gorilla costume. Another occasion saw her persuading Victor to take on a dog whose owner had just died. Victor spent time building a kennel in the garden and when Mrs Warboys arrives with the dog, she forgets to mention that the dog is stuffed - much to Victor and Margaret's consternation. On another occasion she won a competition where the prize was either to earn £500 or to have a life-size waxwork model made of herself, which had to be delivered to the Meldrews' house; she chose the waxwork. As it turned out, she hated it as much as Victor and Margaret did, and the waxwork ended up in the dustbin.
Despite being friends, she has driven Margaret to distraction on several occasions. Most notably in "Only a Story", when she stayed with the Meldrew's after her flat had been flooded and drove Margaret to the point of distraction with her complaining and laziness. Jean was also shown as a somewhat absent-minded character, as she has a pet cockatiel despite having a lifelong allergy to feathers. She would often bore the Meldrews by showing them her complete collection of holiday pictures at the most unwelcome times. A running joke is her beating Victor at board-games, including Trivial Pursuit and chess, while having a conversation with someone else. Doreen Mantle described her character as "wanting to do the right thing but always finding out that it was the wrong thing".
Patrick Trench (Angus Deayton) – Patrick and his wife Pippa live next door to Victor, and often catches Victor engrossed in seemingly preposterous situations, all of which in context are perfectly innocuous. The couple's relationship with their neighbours begins badly after Victor mistakes Patrick and Pippa for distant relations when they arrive outside with three suitcasesnot realising that they are his next-door neighbours, having been on a lengthy holiday from the day Victor and Margaret moved in. Victor subsequently invites the bemused pair to stay; this and later incidents cause Patrick to suspect that Victor is quite insane, possibly bordering on malicious.
However, Patrick's rift with Victor eventually transforms him into a rather cynical character (much like Victor), and he often responds to him in similarly vindictive ways as a means of trying to settle the score. For example, writing complaints and grievances on post-it notes. This aspect of Patrick's character came to a head in the episode "The Executioner's Song" where his face temporarily morphs into that of Victor's as he looks into a mirror.
It is mentioned several times that Patrick would like to have children. After Pippa miscarries and Patrick is, so he claims, rendered infertile by a freak accident (for which he unfairly blames Victor), he adopts a dachshund called Denzil, which Pippa describes as his "baby substitute". Denzil frequently appears with Patrick through series 3-5.
Pippa Trench (née Croker) (Janine Duvitski) – Patrick's wife sought friendly relations with the Meldrews and, after a while, became good friends with Margaret. The two women usually attempt to get the men to make peace with each other at least once per series. Eventually Patrick proposes that the Trenches move house, but they soon realise that the Meldrew curse has followed them: Victor sent workmen to their home, thinking they were removal men who had initially come to the wrong house. They were in fact from a house clearance firm Margaret had employed to clear her late cousin Ursula's country mansion. The workmen consequently cleared Patrick and Pippa's house of their entire furniture and sold it for a mere four hundred and seventy five pounds. Pippa is slightly dim-witted (once described by Victor as a "gormless twerp" on an answering machine message, unaware she was listening)for example, believing Victor had murdered an elderly blind man simply because the victim had been found clutching a double-one domino in his hand, and Victor had two pimples on his nose.
New neighbours Derek and Betty McVitie replaced the Trenches for the 1997 special "Endgame", however this turned out to be their only appearances in the series and they were said to have emigrated by the penultimate episode which caused Nick Swainey to leap straight in with the offer for their old house. Series six saw the Trenches return as prominent characters, albeit living in a house some distance from the Meldrews. Despite appearing in five out of six series and three Christmas specials, neither of the Trenches ever share a scene with Mrs Warboys.
Nick Swainey (Owen Brenman) – The excessively cheerful and often oblivious Mr Swainey appeared in the first episode, encouraging Victor to join his OAPs' trip to Eastbourne, and being greeted with Victor's trademark abuse. When the Meldrews move house, they discover he is their neighbour, living on the other side of the Meldrews from the Trenches. He remains continuously optimistic; even his being told to "piss off" by Victor is laughed off. Despite this run-in he later befriends Victor, and they frequently chat in their gardens, where Victor is often surprised by Mr Swainey's activities, ranging from archery and preparing amateur dramatics props, to bizarre games he arranges for his bedridden senile mother, whom the audience never actually see. Despite his cheery demeanour, he does occasionally drop his guard, once displaying apparent depression at being nothing more than "an overgrown boy-scout". Following his mother's death, he moved house near the end of the series, but only went as far as the Trenches'/McVitie's old house, claiming he'd always wanted to live in an "end house, without leaving the area". This took Victor by surprise; he did not learn where Mr Swainey was moving to until, while reminiscing in the garden about his departure, Mr Swainey suddenly appeared from the other side.
Other characters.
Ronnie and Mildred (Gordon Peters and Barbara Ashcroft) – Ronnie and Mildred were a constantly cheerful, but incredibly boring, couple who provided yet another annoyance to the Meldrews, who dreaded any upcoming visits to them; Victor once said that he had hoped they were both dead. In "The Worst Horror of All", when the couple attempted a surprise visit, the Meldrews hid in their house to give the impression they were away on holiday, and then took the phone off the hook for several days afterwards, though these efforts to avoid them were in vain. They are referenced a number of times in the series for giving the Meldrews bizarre and always unwanted presents that are seldom opened, usually involving a garish photograph of themselves. In the final series, however it was clear that their cheerfulness was a façade and, in a particularly dark scene, Mildred hanged herself "during a game of Happy Families". The shot of Mildred's feet dangling outside the window is usually cut from pre-watershed screenings.
Alfred Meldrew (Richard Pearson) - Victor's absent-minded brother, who lives in New Zealand. During the episode "The Broken Reflection", he comes to visit after 25 years, to the disdain of Victor. Alfred is an eccentric character, often walking around with his hat on fire, and bringing over his and Victor's great-grandfather's skull. He is a clumsy character too, mistaking the table-cloth for a napkin and dropping the contents over the floor when he stands up, and breaking a mirror in the middle of the night after mistaking his own reflection for a burglar. Victor starts to warm to Alfred towards the end of his visit, but Alfred leaves early the next day after finding an unpleasant message about him that Victor had accidentally recorded on a dictaphone. He is not seen again, but keeps in touch with the Meldrews, as Victor is seen looking at some photographs Alfred had sent over in "The Trial".
Cousin Wilfred (John Rutland) – Mrs. Warboys' cousin, Wilfred, appeared twice in the series, and was considered to be a fairly boring middle-aged man. In the final series, the effects of a stroke rendered him mute, and forced him to "speak" with the aid of an electronic voice generator. His poor typing on the generator led to several misunderstandings, such as asking Victor for a "bra of soup" (as opposed to a "bar of soap") and describing a visit to his "brothel" (as opposed to "brother").
Great Aunt Joyce and Uncle Dick - Unseen characters, they are often mentioned by Victor and Margaret, as an aging and grim couple and Victor and Margaret dread having anything to do with them. Great Aunt Joyce is mentioned as having a glass eye and has the habit of knitting bizarre items (such as six-fingered gloves) for Victor. Uncle Dick has a wooden arm; in the final Comic Relief (2001) episode, it transpires that a nurse had mistakenly placed a drip in the false arm for 18 hours after a trip to hospital after trying to remove a kidney stone with a wire coat hanger.
Mimsy Berkovitz - Another unseen character, she is the local agony aunt, whom many of the characters turn to for advice. In the episode "The Secret of the Seven Sorcerers", Patrick is heard talking to her on the radio, seeking her advice on how to cope when Victor and Margaret invite him and Pippa around to dinner.
Martin Trout (Peter Cook) - A paparazzo in "One Foot in the Algarve". He manages to take a number of compromising photographs, involving a high-ranking politician. Trout compares the potential impact of the photos to the Profumo affair.On his way to sell the images, he loses the roll of film whilst arguing at a phone box with the Meldrews and subsequently pursues them across the Algarve to retrieve it. He suffers a number of disasters both related and unrelated to Victor and Margaret's own misfortunes, only to find that the film had actually fallen into the lining of his jacket and had been with him for much of his journey. He lost it in the door of the Meldrews' car. Retrieving the roll after a brief spell in hospital, Trout attempts to leave the Algarve in a taxi but is involved in a car crash.
Production.
The production of the show was in a conventional sitcom format, with episodes taped live in front of a studio audience, interposed with pre-filmed location material.
Most of the first five series of "One Foot in the Grave" were produced and directed by Susan Belbin, the exceptions being "Love and Death," which was partly directed by veteran sitcom director Sydney Lotterby, and "Starbound," for which Gareth Gwenlan (who in fact had originally commissioned the series in 1989) stepped in to direct some sequences after Belbin was taken ill. Belbin retired due to ill health afterwards, and the final series was produced by Jonathan P. Llewellyn and directed by Christine Gernon. Wilson and Renwick felt that Gernon's experience of working with Belbin on earlier series of "One Foot" as a production secretary and assistant, as well as other shows, meant that her style was similar to Belbin's, aiding the transition between directors.
"One Foot" used Bournemouth to film some exterior sequences because of its favourable climate, easy access to London, and economical benefits relative to filming in the capital. After the first series was filmed, the housenear Pokesdown, Bournemouthwhich had been used for the Meldrews' house in location sequences, changed hands and the new owners demanded nearly treble the usage fees that the previous owners had asked for. Rather than agree to this, the production team decided to find a new house, and the first episode of the second series was rewritten to have the Meldrews' house destroyed in a fire. This also gave the opportunity for a new interior set to be designed, as Belbin had been unhappy with the original set designed for the series, which she felt was too restrictive to shoot in.
Since series two, the exterior scenes of the Meldrew's home were filmed at Tresillian Way, Walkford, near New Milton in Hampshire. These later series make extensive use of specific street and garden locations in most episodes, particularly for scenes involving the Meldrew's neighbours. Most outside locations were filmed in and around Bournemouth and Christchurch. These include Richmond Hill, Undercliff Drive and Boscombe Pier, Bournemouth Town Hall, Lansdowne College, Christchurch Hospital and the former Royal Victoria Hospital (Boscombe). Later episodes, such as "Hearts of Darkness", were filmed entirely on location. Victor's death by a hit and run driver in the final episode was filmed at Shawford railway station, Hampshire. Fans left floral tributes at the site.
Over the show's history, it featured a number of notable comic actors in one-off roles. These included Susie Blake, John Bird, Tim Brooke-Taylor, Peter Cook, Diana Coupland, Phil Daniels, Edward de Souza, Hannah Gordon, Georgina Hale, Jimmy Jewel, Rula Lenska, Stephen Lewis, Brian Murphy, Christopher Ryan, Barbara Windsor and Ray Winstone. Two of Angus Deayton's former "Radio Active" and "KYTV" co-stars, Geoffrey Perkins and Michael Fenton Stevens were cast, in separate episodes, as respectively the brother and brother-in-law of Deayton's character. A few then little-known actors also appeared in one-off roles before going on to greater fame, including Lucy Davis, Joanna Scanlan, Eamonn Walker and Arabella Weir.
The show was produced with an aspect ratio of from 1990-1997. Three years later, the show returned to television for its final series, which was produced with an aspect ratio of . All episodes are of Standard Definition 576i.
Music.
The "One Foot in the Grave" theme song was written, composed and sung by Eric Idle. A longer version was produced for the special "One Foot in the Algarve", released as a single with five remixes and a karaoke version in November 1994. Idle included a live version of the song on his album "Eric Idle Sings Monty Python". It is preluded by a similar adaptation of "Bread of Heaven" to that used in the episode "The Beast in the Cage" by disgruntled car mechanics.
The music on the TV series is accompanied at the beginning and end of each episode by a tortoise.
The series also made extensive use of incidental music, composed by Ed Welch, which often hinted at a particular genre to fit the mood of the scenes, frequently incorporating well-known pieces of music such as "God Rest You Merry, Gentlemen" or "Intermezzo" from Jean Sibelius' "Karelia Suite". In the Christmas special "Endgame" during Margaret's alleged death scene, a compilation of clips from past episodes are accompanied by the song "River Runs Deep" performed by J. J. Cale. The final episode ended with a montage of some of the mishaps Victor encountered, which were mentioned in the episode – backed by "End of the Line" by the Traveling Wilburys.
Awards.
The programme received a number of prestigious awards. In 1992, it won a BAFTA as Best Comedy (Programme or Series). During its ten-year run, the series was nominated a further six times. Richard Wilson also won Best Light Entertainment Performance in 1992 and 1994, and Annette Crosbie was nominated for the same award in 1994.
The series also won the Best Television Sitcom in 1992 from the Royal Television Society and the British Comedy Award for Best Sitcom in 1992, 1995 and 2001.
In 2004, "One Foot in the Grave" came tenth in a BBC poll to find "Britain's Best Sitcom" with 31,410 votes. The programme also came 80th in the British Film Institute's 100 Greatest British Television Programmes 
Controversies.
A number of complaints were made during the series' run for its depiction of animal deaths. For example, in the episode "The Valley of Fear", a dead cat is found in the Meldrews' freezer; in another, a tortoise is roasted in a brazier. However, this was later cited as a positive feature of the programme's daring scripts in "Britain's Best Sitcom" by its advocate Rowland Rivron. The programme was censured, however, for a scene in the episode "Hearts of Darkness" in which an elderly resident is abused in an old people's home, and following complaints, the scene was slightly cut when the episode was repeated. In the DVD commentary for the episode, David Renwick stated his continued opposition to the cuts. Another controversial scene in the episode "Tales of Terror" saw the Meldrews visit Ronnie and Mildred on the understanding that Mildred had gone upstairs during a game of Happy Families and not returned; Ronnie then shows her feet hanging outside of the window, revealing that she has committed suicide. The Broadcasting Standards Commission received complaints about this scene.
When the final episode, "Things Aren't Simple Any More" originally aired on 20 November 2000 at 9pm, it coincided with the broadcast of the first jackpot winner in the UK version of "Who Wants to Be a Millionaire?", which had been filmed the Sunday before the broadcast. ITV was accused of engineering this in order to damage the final episode's expected high ratings, but was later cleared by the Independent Television Commission.
Cultural impact.
Despite gaining initially low audience ratings, by the third series, "One Foot in the Grave" was making the Top 20 ratings, with some episodes seen by more than 16 million viewers. In particular, the Christmas 1993 edition topped 20 million viewers.
Due to the series' popularity, people who constantly complain and are irritated by minor things are often compared to Victor Meldrew by the British media. Renwick disputes this usage however, claiming that Victor's reactions are entirely in proportion to the things that happen to him.
Renwick integrated some of the plots and dialogue from the series into a novel, which was first published by BBC Books in 1992. Renwick also adapted four episodes for BBC Radio 2, which first aired between 21 January 1995 and 11 February 1995. The episodes are "Alive and Buried", "In Luton Airport, No One Can Hear You Scream", "Timeless Time" and "The Beast in the Cage". They are regularly repeated on the digital speech station BBC Radio 4 Extra and are available on audio CD.
Wilson dislikes saying his character's catchphrase ("I don't believe it!") and only performs the line for charity events for a small fee. This became a joke in the actor's guest appearance as himself in the "Father Ted" episode "The Mainland", where Ted annoys him by constantly repeating his catchphrase. The situation was conceived when "Father Ted" writers Graham Linehan and Arthur Mathews sat behind Wilson at a performance of "Le Cirque du Soleil" at the Royal Albert Hall. They considered how "tasteless and wrong" it would be to lean forward to him every time that an acrobat did a stunt and yell the catchphrase, and then they realised that that's exactly what their fictional priests would do. This was also played upon when Wilson made a guest appearance on the comedy TV quiz show "Shooting Stars", in which Vic Reeves and Bob Mortimer purposefully misquoted his catchphrase by referring to him as "Richard 'I don't believe you' Wilson".
VHS and DVD releases.
All six series and specials were initially available on BBC Worldwide VHS video tapes during the late 1990s and early 2000s. The Comic Relief Shorts from 1993 and 2001 have not been released on DVD. A One Foot in the Grave Very Best Of DVD featuring five of the greatest episodes was released on 22nd October 2001 in Region 2. Then on 8 July 2004, a One Foot in the Grave Very Best Of was also released in Region 4. Each series was gradually released on DVD in Region 2 between 2004 and 2006, with a complete series 1-6 box set towards the end of 2006. A slimmer series 1-6 box set was released in 2010 in Region 2.
Foreign versions.
A German version was made of the series in 1996-97, "Mit einem Bein im Grab", directed by Thomas Nennstiel and Frank Strecker. It starred Heinz Schubert as "Viktor Bölkhoff",
Brigitte Böttrich as "Margret Bölkhoff" and Irm Hermann as "Lisbeth Albermann".
A Swedish version, "En fot i graven" was made in 2001. Produced by commercial television channel TV4, it starred Gösta Ekman as "Victor Melldrov" and Lena Söderblom as his wife. A total of 12 episodes were broadcast.
In 2006 a Dutch version was made under the title "Met één been in het graf". It starred Serge Henri Valcke as Victor Monter. The series was directed by Zdenek Kraus, who had directed the highly successful series "Toen Was Geluk Heel Gewoon" and was adapted for Dutch television by Ger Apeldoorn and Harm Edens, who also wrote Het Zonnetje in Huis. The series only lasted one season.

</doc>
<doc id="22627" url="https://en.wikipedia.org/wiki?curid=22627" title="Oscar">
Oscar

Oscar, The Oscar or OSCAR may refer to:

</doc>
<doc id="22637" url="https://en.wikipedia.org/wiki?curid=22637" title="Object Management Group">
Object Management Group

The Object Management Group (OMG) is an international, open membership, not-for-profit technology standards consortium. OMG Task Forces develop enterprise integration standards for a wide range of technologies and industries. OMG modeling standards enable visual design, execution and maintenance of software and other processes. Originally aimed at standardizing distributed object-oriented systems, the company now focuses on modeling (programs, systems and business processes) and model-based standards.
Overview.
OMG provides only specifications, and does not provide implementations. But before a specification can be accepted as a standard by OMG, the members of the winning submitter team must guarantee that they will bring a conforming product to market within a year. This is an attempt to prevent unimplemented (and unimplementable) standards.
Other private companies or open source groups are encouraged to produce conforming products and OMG is attempting to develop mechanisms to enforce true interoperability.
OMG hosts four technical meetings for its members and interested nonmembers. The Technical Meetings provide a neutral forum to discuss, develop and adopt standards that enable software interoperability for a wide range of industries including: finance, manufacturing, healthcare, robotics, software-based communications, security, government, space and more. In March 2015, the TC meeting was held in Reston, VA; in June 2015 in Berlin, Germany, in September 2015, in Cambridge, MA; and in December 2015, the meeting is La Jolla, CA.
History.
Founded in 1989 by eleven companies (including Hewlett-Packard, IBM, Sun Microsystems, Apple Computer, American Airlines and Data General), OMG's initial focus was to create a heterogeneous distributed object standard. The founding executive team included Christopher Stone and John Slitz. As of November, 2012, the leadership includes Chairman and CEO Richard Soley, President and COO Bill Hoffman and Vice President and Technical Director Andrew Watson.
Since 2000, OMG international headquarters has been located in Needham, Massachusetts. In November, 2012, the headquarters was moved from 140 Kendrick St to 109 Highland Ave.
The goal was a common portable and interoperable object model with methods and data that work using all types of development environments on all types of platforms.
In 1997, the Unified Modeling Language (UML) was added to the list of OMG adopted technologies. UML is a standardized general-purpose modeling language in the field of object-oriented software engineering.
In June 2005, the Business Process Management Initiative (BPMI.org) and OMG announced the merger of their respective Business Process Management (BPM) activities to form the Business Modeling and Integration Domain Task Force (BMI DTF).
In 2006 the Business Process Model and Notation (BPMN) was adopted as a standard by OMG.
In 2007 the Business Motivation Model (BMM) was adopted as a standard by the OMG. The BMM is a metamodel that provides a vocabulary for corporate governance and strategic planning and is particularly relevant to businesses undertaking governance, regulatory compliance, business transformation and strategic planning activities.
In 2009 OMG, together with the Software Engineering Institute at Carnegie Mellon, launched the Consortium of IT Software Quality (CISQ). CISQ brings together industry executives from Global 2000 IT organizations, system integrators, outsourcers, and package vendors to jointly address the challenge of standardizing the measurement of IT software quality and to promote a market-based ecosystem to support its deployment.
In 2011 OMG formed the Cloud Standards Customer Council. Founding sponsors included CA, IBM, Kaavo, Rackspace and Software AG. The CSCC is an OMG end user advocacy group dedicated to accelerating cloud's successful adoption, and drilling down into the standards, security and interoperability issues surrounding the transition to the cloud. The Council is not a standards organization, but will complement existing cloud standards efforts and establish a core set of client-driven requirements to ensure cloud users will have the same freedom of choice, flexibility, and openness they have with traditional IT environments. CSCC is open to all end-user organizations.
In September, 2011, the OMG Board of Directors unanimously voted to adopt the Vector Signal and Image Processing Library (VSIPL) as the latest OMG specification. Work for adopting the specification was led by Mentor Graphics' Embedded Software Division, RunTime Computing Solutions, The Mitre Corporation as well as the High Performance Embedded Computing Software Initiative (HPEC-SI). VSIPL is an application programming interface (API) defined by an open standard developed by embedded signal and image processing hardware and software vendors, academia, application developers, and government labs. VSIPL and VSIPL++ contain hundreds of functions used for common signal processing kernel and other computations. These functions include basic arithmetic, trigonometric, transcendental, signal processing, linear algebra, and image processing. The VSIPL family of libraries has been implemented by multiple vendors for a range of processor architectures, including x86, PowerPC, Cell, and NVIDIA GPUs. VSIPL and VSIPL++ are designed to achieve high performance, increase programmer productivity and maintain portability across a range of processor architectures. Additionally, VSIPL++ was designed from the start to include support for parallelism.
Late 2012 early 2013, The Object Management Group Board of Directors adopted the Automated Function Point (AFP) specification. The push for adoption was led by the Consortium for IT Software Quality (CISQ). AFP provides a standard for automating the popular Function Point measure according to the counting guidelines of the International Function Point User Group (IFPUG).
On March 27, 2014, OMG announced it would be managing the newly formed Industrial Internet Consortium (IIC). An open-membership, not-for-profit, the IIC will take the lead in establishing interoperability across industrial environments for a more connected world.
Hot Topics.
On the company's website, there is a Hot Topics page featuring a few of the different technology areas that are currently trending. As of March 17, 2015, the hot topics include: Industrial Internet of Things (IIoT), Financial Services Standards (FIBO/FIGI), Oil & Gas, Software-defined networking (SDN), Systems Engineering and Threat Modeling.
OMG Standards.
Common Object Request Broker Architecture.
At its founding, OMG set out to create the initial Common Object Request Broker Architecture (CORBA) standard which appeared in 1991. CORBA is a standard that enables software components written in multiple computer languages and running on multiple computers to work together (i.e., it supports multiple platforms). OMG has also developed a core set of standards adapting CORBA for embedded and real-time systems. Implementations of real time CORBA are widely used in control systems in ships and aircraft.
Data Distribution Service.
Data Distribution Service for real-time systems (DDS) is a specification of a publish/subscribe middleware for distributed systems created in response to the need to augment CORBA with a data-centric publish-subscribe specification.
Model Driven Architecture.
OMG evolved towards modeling standards by creating the standard for Unified Modeling Language (UML) followed by related standards for:
These together provide the foundation for Model Driven Architecture (MDA), and related set of standards, building upon the success of UML and MOF.
Systems Modeling Language (SysML), a modeling language based on UML for use in Systems Engineering, has been standardized in collaboration with INCOSE.
Significant progress has also been made in bringing the world of UML modeling and the Semantic Web together through the adoption of the "Ontology Definition Metamodel" which relates UML models in a standard way with RDF and Web Ontology Language (OWL) models.
Semantics of Business Vocabulary and Business Rules (SBVR) is a landmark for the OMG, the first OMG specification to incorporate the formal use of natural language in modeling and the first to provide explicitly a model of formal logic. Based on a fusion of linguistics, logic, and computer science, and two years in preparation, SBVR provides a way to capture specifications in natural language and represent them in formal logic so they can be machine-processed. SBVR is an integral part of MDA.
Architecture Driven Modernization.
Architecture Driven Modernization (ADM) is the reverse of MDA. ADMTF is an OMG group similar to ADTF with high potential.
Knowledge Discovery Metamodel (KDM), a common intermediate representation for existing software systems and their operating environments. Knowledge Discovery Metamodel is designed as the OMG's foundation for software modernization and software assurance. Knowledge Discovery Metamodel uses Meta-Object Facility to define an XMI interchange format between tools that work with existing software and an abstract interface for the next-generation assurance and modernization tools.
The Software Process Engineering Metamodel (SPEM) is an OMG-standard for Meta-Process Modeling.
Abstract Syntax Tree Metamodel (ASTM), a modeling language for fine grained reverse engineering.
Semantics of Business Vocabulary and Business Rules (SBVR) and KDM are designed as two parts of a unique OMG Technology Stack for software analytics related to existing software systems. KDM defines an ontology related to software artifacts and thus provides an initial formalization of the information related to a software system. SBVR is further used to formalize complex compliance rules related to the software.
Software assurance and regulatory compliance.
New activities have been initiated to address important concerns of "Regulatory Compliance" and "Software Assurance", building upon the base standards of MDA.
Certification.
OMG offers a number of professional certifications: 
In 2013, OMG Intermediate updates expected to be released in the next few months.

</doc>
<doc id="22638" url="https://en.wikipedia.org/wiki?curid=22638" title="OMG">
OMG

OMG may refer to:

</doc>
<doc id="22641" url="https://en.wikipedia.org/wiki?curid=22641" title="Oxford English Dictionary">
Oxford English Dictionary

The Oxford English Dictionary (OED), published by the Oxford University Press, is a descriptive (as opposed to prescriptive) dictionary of the English language. As well as describing English usage in its many variations throughout the world, it traces the historical development of the language, providing a comprehensive resource to scholars and academic researchers. The second edition, published in 1989, came to 21,728 pages in 20 volumes.
Although work had begun on the dictionary in 1857, it was not until 1884 that it began to be published, in unbound fascicles as work continued on the project, under the name of "A New English Dictionary on Historical Principles; Founded Mainly on the Materials Collected by The Philological Society". In 1895 the title "The Oxford English Dictionary" ("OED") was first used unofficially on the covers of the series, and in 1928 the full dictionary was republished in ten bound volumes. In 1933 the title "The Oxford English Dictionary" fully replaced the former name in all occurrences in its reprinting as twelve volumes with a one-volume supplement. More supplements came over the years until 1989, when the second edition was published. Since 2000, a third edition of the dictionary has been underway, approximately a third of which is now complete.
The first electronic version of the dictionary was made available in 1988. The online version has been available since 2000, and as of April 2014 was receiving over two million hits per month. The third edition of the dictionary will probably only appear in electronic form; the chief executive of Oxford University Press, Nigel Portwood, feels it unlikely that it will ever be printed.
Historical nature.
As a historical dictionary the "OED" explains words by showing their development, rather than merely their present-day usages. Therefore, it shows definitions in the order that the sense of the word which they define began being used, including word meanings which are no longer used. Each definition is shown with numerous short usage quotations: in each case, the first quotation shows the first recorded instance of the word that the editors are aware of, and in the case of words and senses no longer in current usage, the last quotation is the last known recorded usage. This allows the reader to get an approximate sense of the time period a particular word has been in use, and additional quotations help the reader to ascertain information about how the word is used in context, beyond any explanation the dictionary editors can provide.
The format of the "OED"'s entries has influenced numerous other historical lexicography projects. The fore-runners to the "OED" such as the early volumes of the "Deutsches Wörterbuch" had initially provided few quotations from a limited number of sources, the preference of the "OED" editors for larger groups of quite short quotations from a catholic selection of authors and publications influenced later volumes of this and other lexicographical works.
Entries and relative size.
According to the publishers, it would take a single person 120 years to "key in" the 59 million words of the "OED" second edition, 60 years to proofread them, and 540 megabytes to store them electronically. As of 30 November 2005, the "Oxford English Dictionary" contained approximately 301,100 main entries. Supplementing the entry headwords, there are 157,000 bold-type combinations and derivatives; 169,000 italicized-bold phrases and combinations; 616,500 word-forms in total, including 137,000 pronunciations; 249,300 etymologies; 577,000 cross-references; and 2,412,400 usage quotations. The dictionary's latest, complete print edition (second edition, 1989) was printed in 20 volumes, comprising 291,500 entries in 21,730 pages. The longest entry in the "OED2" was for the verb "set", which required 60,000 words to describe some 430 senses. As entries began to be revised for the "OED3" in sequence starting from M, the longest entry became "make" in 2000, then "put" in 2007, then "run" in 2011.
Despite its impressive size, the "OED" is neither the world's largest nor the earliest exhaustive dictionary of a language. The Dutch dictionary "Woordenboek der Nederlandsche Taal", which has similar aims to the "OED", is the largest, taking twice as long to complete. Another earlier large dictionary is the Grimm brothers' dictionary of the German language, begun in 1838 and completed in 1961. The first edition of the "Vocabolario degli Accademici della Crusca", which is the first great dictionary devoted to a modern European language (Italian), was published in 1612; the first edition of "Dictionnaire de l'Académie française" dates from 1694. The first edition of the official dictionary of Spanish, the "Diccionario de la lengua española" (produced, edited, and published by the Real Academia Española) was published in 1780. The Kangxi dictionary of Chinese was published in 1716.
History.
Origins.
The dictionary began as a Philological Society project of a small group of intellectuals in London (and unconnected to Oxford University): Richard Chenevix Trench, Herbert Coleridge, and Frederick Furnivall, who were dissatisfied with the then-current English dictionaries. The Society expressed interest in compiling a new dictionary as early as 1844, but it was not until June 1857 that they began, by forming an "Unregistered Words Committee" to search for words that were unlisted or poorly-defined in current dictionaries. In November, Trench's report was not a list of unregistered words; instead, it was the study "On Some Deficiencies in our English Dictionaries", which identified seven distinct shortcomings in contemporary dictionaries:
The Society ultimately realized that the number of unlisted words would be far more than the number of words in the English dictionaries of the 19th century, and shifted their idea from covering only words that were not already in English dictionaries to a larger project. Trench suggested that a new, truly "comprehensive" dictionary was needed. On 7 January 1858, the Society formally adopted the idea of a comprehensive new dictionary. Volunteer readers would be assigned particular books, copying passages illustrating word usage onto quotation slips. Later the same year, the Society agreed to the project in principle, with the title "A New English Dictionary on Historical Principles" ("NED").
Early editors.
Richard Chenevix Trench (1807–1886) played the key role in the project's first months, but his Church of England appointment as Dean of Westminster meant that he could not give the dictionary project the time it required; he withdrew, and Herbert Coleridge became the first editor.
On 12 May 1860, Coleridge's dictionary plan was published, and research started. His house was the first editorial office. He arrayed 100,000 quotation slips in a 54-pigeon-hole grid. In April 1861, the group published the first sample pages; later that month, Coleridge died of tuberculosis, aged 30.
Furnivall then became editor; he was enthusiastic and knowledgeable, yet temperamentally ill-suited for the work. Many volunteer readers eventually lost interest in the project as Furnivall failed to keep them motivated. Furthermore, many of the slips had been misplaced.
Furnivall believed that since many printed texts from earlier centuries were not readily available, it would be impossible for volunteers to efficiently locate the quotations that the dictionary needed. As a result, Furnivall founded the Early English Text Society in 1864 and the Chaucer Society in 1868 to publish old manuscripts. Furnivall's preparatory efforts, which lasted 21 years, provided numerous texts for the use and enjoyment of the general public as well as crucial sources for lexicographers, but did not actually involve compiling a dictionary. Furnivall recruited over 800 volunteers to read these texts and record quotations. While enthusiastic, the volunteers were not well trained and often made inconsistent and arbitrary selections. Ultimately, Furnivall would hand over nearly two tons of quotation slips and other materials to his successor.
In the 1870s, Furnivall unsuccessfully attempted to recruit both Henry Sweet and Henry Nicol to succeed him. He then approached James Murray, who accepted the post of editor. In the late 1870s, Furnivall and Murray met with several publishers about publishing the dictionary. In 1878, Oxford University Press agreed with Murray to proceed with the massive project; the agreement was formalized the following year. The dictionary project finally had a publisher 20 years after the idea was conceived. It would be another 50 years before the entire dictionary was complete.
Late in his editorship Murray learned that one prolific reader, W. C. Minor, was a criminal lunatic. Minor, a Yale University-trained surgeon and military officer in the American Civil War, was confined to Broadmoor Asylum for the Criminally Insane after killing a man in London. Minor invented his own quotation-tracking system, allowing him to submit slips on specific words in response to editors' requests. The story of Murray and Minor later served as the central focus of "The Surgeon of Crowthorne" (US title: "The Professor and the Madman"), a popular book about the creation of the "OED".
Oxford editors.
During the 1870s, the Philological Society was concerned with the process of publishing a dictionary with such an immense scope. Although they had pages printed by publishers, no publication agreement was reached; both the Cambridge University Press and the Oxford University Press were approached. Finally, in 1879, after two years' negotiating by Sweet, Furnivall, and Murray, the OUP agreed to publish the dictionary and to pay the editor, Murray, who was also the Philological Society president. The dictionary was to be published as interval fascicles, with the final form in four 6,400-page volumes. They hoped to finish the project in ten years.
Murray started the project, working in a corrugated iron outbuilding, the "Scriptorium", which was lined with wooden planks, book shelves, and 1,029 pigeon-holes for the quotation slips. He tracked and regathered Furnivall's collection of quotation slips, which were found to concentrate on rare, interesting words rather than common usages: for instance, there were ten times as many quotations for "abusion" as for "abuse". Through newspapers distributed to bookshops and libraries, he appealed for readers who would report "as many quotations as you can for ordinary words" and for words that were "rare, obsolete, old-fashioned, new, peculiar or used in a peculiar way". Murray had American philologist and liberal-arts-college professor Francis March manage the collection in North America; 1,000 quotation slips arrived daily to the Scriptorium, and by 1880, there were 2,500,000.
The first dictionary fascicle was published on 1 February 1884—twenty-three years after Coleridge's sample pages. The full title was "A New English Dictionary on Historical Principles; Founded Mainly on the Materials Collected by The Philological Society"; the 352-page volume, words from "A" to "Ant", cost 12s 6d. The total sales were a disappointing 4,000 copies.
The OUP saw it would take too long to complete the work with unrevised editorial arrangements. Accordingly, new assistants were hired and two new demands were made on Murray. The first was that he move from Mill Hill to Oxford; he did, in 1885. Murray had his Scriptorium re-erected on his new property.
Murray resisted the second demand: that if he could not meet schedule, he must hire a second, senior editor to work in parallel to him, outside his supervision, on words from elsewhere in the alphabet. Murray did not want to share the work, feeling he would accelerate his work pace with experience. That turned out not to be so, and Philip Gell of the OUP forced the promotion of Murray's assistant Henry Bradley (hired by Murray in 1884), who worked independently in the British Museum in London, beginning in 1888. In 1896, Bradley moved to Oxford University.
Gell continued harassing Murray and Bradley with his business concerns—containing costs and speeding production—to the point where the project's collapse seemed likely. Newspapers, particularly the "Saturday Review", reported the harassment, and public opinion backed the editors. Gell was fired, and the University reversed his cost policies. If the editors felt that the dictionary would have to grow larger, it would; it was an important work, and worth the time and money to properly finish. Neither Murray nor Bradley lived to see it. Murray died in 1915, having been responsible for words starting with "A–D", "H–K", "O–P" and "T", nearly half the finished dictionary; Bradley died in 1923, having completed "E–G", "L–M", "S–Sh", "St" and "W–We". By then two additional editors had been promoted from assistant work to independent work, continuing without much trouble. William Craigie, starting in 1901, was responsible for "N", "Q–R", "Si–Sq", "U–V" and "Wo–Wy." Whereas previously the OUP had thought London too far from Oxford, after 1925 Craigie worked on the dictionary in Chicago, where he was a professor. The fourth editor was Charles Talbut Onions, who, starting in 1914, compiled the remaining ranges, "Su–Sz", "Wh–Wo" and "X–Z". In 1919–1920 J. R. R. Tolkien was employed by the "OED", researching etymologies of the "Waggle" to "Warlock" range; later he parodied the principal editors as "The Four Wise Clerks of Oxenford" in the story "Farmer Giles of Ham".
By early 1894 a total of 11 fascicles had been published, or about one per year: four for "A–B", five for "C", and two for "E". Of these, eight were 352 pages long, while the last one in each group was shorter to end at the letter break (which would eventually become a volume break). At this point it was decided to publish the work in smaller and more frequent instalments; once every three months, beginning in 1895, there would be a fascicle of 64 pages, priced at 2s 6d. If enough material was ready, 128 or even 192 pages would be published together. This pace was maintained until World War I forced reductions in staff"." Each time enough consecutive pages were available, the same material was also published in the original larger fascicles"." Also in 1895, the title "Oxford English Dictionary" ("OED") was first used. It then appeared only on the outer covers of the fascicles; the original title was still the official one and was used everywhere else.
Completion of first edition and first supplement.
The 125th and last fascicle, covering words from "Wise" to the end of "W", was published on 19 April 1928, and the full dictionary in bound volumes followed immediately.
William Shakespeare is the most-quoted writer in the completed dictionary, with "Hamlet" his most-quoted work. George Eliot (Mary Ann Evans) is the most-quoted female writer. Collectively, the Bible is the most-quoted work (but in many different translations); the most-quoted single work is "Cursor Mundi".
Between 1928 and 1933 enough additional material had been compiled to make a one volume supplement so the dictionary was reissued as the set of 12 volumes and a one-volume supplement in 1933.
Second supplement.
In 1933 Oxford had finally put the dictionary to rest; all work ended, and the quotation slips went into storage. However, the English language continued to change, and by the time 20 years had passed, the dictionary was outdated.
There were three possible ways to update it. The cheapest would have been to leave the existing work alone and simply compile a new supplement of perhaps one or two volumes; but then anyone looking for a word or sense and unsure of its age would have to look in three different places. The most convenient choice for the user would have been for the entire dictionary to be re-edited and retypeset, with each change included in its proper alphabetical place; but this would have been the most expensive option, with perhaps 15 volumes required to be produced. The OUP chose a middle approach: combining the new material with the existing supplement to form a larger replacement supplement.
Robert Burchfield was hired in 1957 to edit the second supplement; Onions, who turned 84 that year, was still able to make some contributions as well. The work on the supplement was expected to take about seven years. It actually took 29 years, by which time the new supplement "(OEDS)" had grown to four volumes, starting with "A", "H", "O" and "Sea". They were published in 1972, 1976, 1982, and 1986 respectively, bringing the complete dictionary to 16 volumes, or 17 counting the first supplement.
Burchfield emphasized the inclusion of modern-day language, and through the supplement the dictionary was expanded to include a wealth of new words from the burgeoning fields of science and technology, as well as popular culture and colloquial speech. Burchfield said that he broadened the scope to include developments of the language in English-speaking regions beyond the United Kingdom, including North America, Australia, New Zealand, South Africa, India, Pakistan, and the Caribbean. Burchfield also removed some smaller entries that had been added to the 1933 supplement, for reasons of space; in 2012, an analysis by lexicographer Sarah Ogilvie revealed that many of these entries were in fact foreign loanwords, despite Burchfield's attempt to include more such words. The proportion was estimated from a sample calculation to amount to 17% of the foreign loan words and words from regional forms of English. Many of these had only a single recorded usage, but it ran against what was thought to be the established "OED" editorial practice and a perception that he had opened up the dictionary to 'World English'.
Second edition.
By the time the new supplement was completed, it was clear that the full text of the dictionary would now need to be computerized. Achieving this would require retyping it once, but thereafter it would always be accessible for computer searching – as well as for whatever new editions of the dictionary might be desired, starting with an integration of the supplementary volumes and the main text. Preparation for this process began in 1983, and editorial work started the following year under the administrative direction of Timothy J. Benbow, with John A. Simpson and Edmund S. C. Weiner as co-editors.
And so the "New Oxford English Dictionary (NOED)" project began. More than 120 keyboarders of the International Computaprint Corporation in Tampa, Florida, and Fort Washington, Pennsylvania, USA, started keying in over 350,000,000 characters, their work checked by 55 proof-readers in England. Retyping the text alone was not sufficient; all the information represented by the complex typography of the original dictionary had to be retained, which was done by marking up the content in SGML. A specialized search engine and display software were also needed to access it. Under a 1985 agreement, some of this software work was done at the University of Waterloo, Canada, at the "Centre for the New Oxford English Dictionary", led by Frank Tompa and Gaston Gonnet; this search technology went on to become the basis for the Open Text Corporation. Computer hardware, database and other software, development managers, and programmers for the project were donated by the British subsidiary of IBM; the colour syntax-directed editor for the project, LEXX, was written by Mike Cowlishaw of IBM. The University of Waterloo, in Canada, volunteered to design the database. A. Walton Litz, an English professor at Princeton University who served on the Oxford University Press advisory council, was quoted in "Time" as saying "I've never been associated with a project, I've never even heard of a project, that was so incredibly complicated and that met every deadline."
By 1989 the NOED project had achieved its primary goals, and the editors, working online, had successfully combined the original text, Burchfield's supplement, and a small amount of newer material, into a single unified dictionary. The word "new" was again dropped from the name, and the second edition of the "OED," or the "OED2," was published. The first edition retronymically became the "OED1".
The "OED2" was printed in 20 volumes. For the first time, there was no attempt to start them on letter boundaries, and they were made roughly equal in size. The 20 volumes started with "A", "B.B.C.", "Cham", "Creel", "Dvandva", "Follow", "Hat", "Interval", "Look", "Moul", "Ow", "Poise", "Quemadero", "Rob", "Ser", "Soot", "Su", "Thru", "Unemancipated", and "Wave".
Although the content of the "OED2" is mostly just a reorganization of the earlier corpus, the retypesetting provided an opportunity for two long-needed format changes. The headword of each entry was no longer capitalized, allowing the user to readily see those words that actually require a capital letter. Also, whereas Murray had devised his own notation for pronunciation, there being no standard available at the time, the "OED2" adopted the modern International Phonetic Alphabet. Unlike the earlier edition, all foreign alphabets except Greek were transliterated.
The British quiz show "Countdown" has awarded the leather-bound complete version to the champions of each series since its inception in 1982.
When the print version of the second edition was published in 1989, the response was enthusiastic. The author Anthony Burgess declared it "the greatest publishing event of the century", as quoted by the "Los Angeles Times". "Time" dubbed the book "a scholarly Everest", and Richard Boston, writing for "The Guardian", called it "one of the wonders of the world".
Additions series.
While the supplements, and their integration into the second edition, were a great improvement to the "OED" as a whole, it was recognized that most of the entries were still fundamentally unaltered from the first edition. Much of the information in the dictionary published in 1989 was already decades out of date: though the supplements had made good progress towards incorporating new vocabulary, many definitions contained outdated scientific theories, historical information, and moral values. Furthermore, the supplements had failed to recognize many words in the existing volumes as obsolete by the time of the second edition's publication, meaning thousands of words were marked as current despite no recent evidence of their use.
Accordingly, it was immediately recognized that work on a third edition would have to begin immediately to rectify these problems. The first attempt to produce a new edition came with the "Oxford English Dictionary Additions Series," a new set of supplements to complement the "OED2" with the intention of producing a third edition from them. Unlike the previous supplements, which appeared in alphabetical installments, the new series had a full A–Z range of entries within each individual volume, with a complete alphabetical index at the end of all words revised so far, each listed with the volume number which contained the revised entry.
However, in the end only three "Additions" volumes were published this way, two in 1993 and one in 1997, each containing about 3,000 new definitions. The possibilities of the World Wide Web and new computer technology in general meant that the processes of researching the dictionary and of publishing new and revised entries could be vastly improved. New text search databases offered vastly more material for the editors of the dictionary to work with, and with publication on the Web as a possibility, the editors could publish revised entries much more quickly and easily than ever before. A new approach was called for, and for this reason it was decided to embark on a new, complete revision of the dictionary.
Third edition.
Beginning with the launch of the first "OED Online" site in 2000, the editors of the dictionary began a major revision project to create a completely revised third edition of the dictionary ("OED3"), expected to be completed in 2037 at a projected cost of about £34 million.
Revisions were started at the letter "M", with new material appearing every three months on the "OED Online" website. The editors chose to start the revision project from the middle of the dictionary in order that the overall quality of entries be made more even, since the later entries in the "OED1" generally tended to be better than the earlier ones. However, in March 2008, the editors announced that they would alternate each quarter between moving forward in the alphabet as before and updating "key English words from across the alphabet, along with the other words which make up the alphabetical cluster surrounding them". With the relaunch of the "OED Online" website in December 2010, alphabetical revision was abandoned altogether.
The revision is expected to roughly double the dictionary in size. Apart from general updates to include information on new words and other changes in the language, the third edition brings many other improvements, including changes in formatting and stylistic conventions to make entries clearer to read and enable more thorough searches to be made by computer, more thorough etymological information, and a general change of focus away from individual words towards more general coverage of the language as a whole. While the original text drew its quotations mainly from literary sources such as novels, plays, and poetry, with additional material from newspapers and academic journals, the new edition will reference more kinds of material that were unavailable to the editors of previous editions, such as wills, inventories, account books, diaries, journals, and letters.
John Simpson was the first chief editor of the "OED3". He retired in 2013 and was replaced by Michael Proffitt, who is the eighth chief editor of the dictionary.
The production of the new edition takes full advantage of computer technology, particularly since the June 2005 inauguration of the whimsically named "Perfect All-Singing All-Dancing Editorial and Notation Application", or "Pasadena". With this XML-based system, the attention of lexicographers can be directed more to matters of content than to presentation issues such as the numbering of definitions. The new system has also simplified the use of the quotations database, and enabled staff in New York to work directly on the dictionary in the same way as their Oxford-based counterparts.
Other important computer uses include internet searches for evidence of current usage, and e-mail submissions of quotations by readers and the general public.
"Wordhunt" was a 2005 appeal to the general public for help in providing citations for 50 selected recent words, and produced antedatings for many. The results were reported in a BBC TV series, "Balderdash and Piffle". The "OED"s small army of devoted readers continue to contribute quotations: the department currently receives about 200,000 a year.
Formats.
Compact editions.
In 1971, the 13-volume "OED1" (1933) was reprinted as a two-volume, "Compact Edition", by photographically reducing each page to one-half its linear dimensions; each compact edition page held four "OED1" pages in a four-up ("4-up") format. The two volume letters were "A" and "P"; the first supplement was at the second volume's end.
The "Compact Edition" included, in a small slip-case drawer, a magnifying glass to help in reading reduced type. Many copies were inexpensively distributed through book clubs. In 1987, the second supplement was published as a third volume to the "Compact Edition". In 1991, for the "OED2", the compact edition format was re-sized to one-third of original linear dimensions, a nine-up ("9-up") format requiring greater magnification, but allowing publication of a single-volume dictionary. It was accompanied by a magnifying glass as before and "A User's Guide to the "Oxford English Dictionary"", by Donna Lee Berg. After these volumes were published, though, book club offers commonly continued to sell the two-volume 1971 "Compact Edition".
Electronic versions.
Once the text of the dictionary was digitized and online, it was also available to be published on CD-ROM. The text of the first edition was made available in 1987. Afterward, three versions of the second edition were issued. Version 1 (1992) was identical in content to the printed second edition, and the CD itself was not copy-protected. Version 2 (1999) included the OED "Additions" of 1993 and 1997.
Version 3.0 was released in 2002 with additional words from the "OED3" and software improvements. Version 3.1.1 (2007) added support for hard disk installation, so that the user does not have to insert the CD to use the dictionary. It has been reported that this version will work on operating systems other than Microsoft Windows, using emulation programs. Version 4.0 of the CD, available since June 2009, works with Windows 7 and Mac OS X (10.4 or later). This version will use the CD drive for installation, running only from the hard drive.
On 14 March 2000, the "Oxford English Dictionary Online" ("OED Online") became available to subscribers. The online database contains the entire "OED2" and is updated quarterly with revisions that will be included in the "OED3" (see above). The online edition is the most up-to-date version of the dictionary available. Whilst the "OED" web site is not optimised for mobile devices, the developers have stated that there are plans to provide an API that would enable developers to develop different interfaces for querying the "OED".
As the price for an individual to use this edition, even after a reduction in 2004, is £195 or US$295 every year, most subscribers are large organizations such as universities. Some public libraries and companies have subscribed as well, including public libraries in the United Kingdom, where access is funded by the Arts Council, and in New Zealand. Any person belonging to a library subscribing to the service is able to use the service from their own home without charge.
Relationship to other Oxford dictionaries.
The "OED"'s utility and renown as a historical dictionary have led to numerous offspring projects and other dictionaries bearing the Oxford name, though not all are directly related to the "OED" itself.
The "Shorter Oxford English Dictionary," originally started in 1902 and completed in 1933, is an abridgement of the full work that retains the historical focus, but does not include any words which were obsolete before 1700 except those used by Shakespeare, Milton, Spenser, and the King James Bible. A completely new edition was produced from the "OED2" and published in 1993, with further revisions following in 2002 and 2007.
The "Concise Oxford Dictionary" is a different work, which aims to cover current English only, without the historical focus. The original edition, mostly based on the "OED1", was edited by Francis George Fowler and Henry Watson Fowler and published in 1911, before the main work was completed. Revised editions appeared throughout the twentieth century to keep it up to date with changes in English usage.
In 1998 the "New Oxford Dictionary of English" ("NODE") was published. While also aiming to cover current English, "NODE" was not based on the "OED". Instead, it was an entirely new dictionary produced with the aid of corpus linguistics. Once "NODE" was published, a similarly brand-new edition of the "Concise Oxford Dictionary" followed, this time based on an abridgement of "NODE" rather than the "OED"; "NODE" (under the new title of the "Oxford Dictionary of English", or "ODE") continues to be principal source for Oxford's product line of current-English dictionaries, including the "New Oxford American Dictionary", with the "OED" now only serving as the basis for scholarly historical dictionaries.
Spelling.
The "OED" lists British headword spellings (e.g. "labour", "centre") with variants following ("labor", "center", etc.). For the suffix more commonly spelt "-ise" in British English, OUP policy dictates a preference for the spelling "-ize", e.g. "realize" vs "realise" and "globalization" vs "globalisation". The rationale is etymological, in that the English suffix mainly derives from the Greek suffix "-ιζειν", ("-izein"), or the Latin "-izāre". However "-ze" is also sometimes treated as an Americanism insofar as the "-ze" suffix has crept into words where it did not originally belong, as with "analyse" (British English), which is spelt "analyze" in American English.
Reception.
Criticisms.
Despite its claim of authority on the English language, the "Oxford English Dictionary" has been criticised from various angles. It has become a target precisely "because" of its massiveness, its claims to authority, and above all its influence: in his review of the 1982 supplement, University of Oxford linguist Roy Harris writes that criticising the "OED" is extremely difficult because "one is dealing not just with a dictionary but with a national institution", one that "has become, like the English monarchy, virtually immune from criticism in principle". He further notes that, while neologisms from respected "literary" authors such as Samuel Beckett and Virginia Woolf are included, usage of words in newspapers or other, less "respectable", sources hold less sway, although they may be commonly used. He writes that the "OED"'s "[b]lack-and-white lexicography is also black-and-white in that it takes upon itself to pronounce authoritatively on the rights and wrongs of usage", faulting the dictionary's prescriptive, rather than descriptive, usage. To Harris, this prescriptive classification of certain usages as "erroneous" and the complete omission of various forms and usages cumulatively represent the "social bias[es]" of the (presumably well-educated and wealthy) compilers. However, the identification of "erroneous and catachrestic" usages is being removed from third edition entries, sometimes in favour of usage notes describing the attitudes to language which have previously led to these classifications.
Harris also faults the editors' "donnish conservatism" and their adherence to prudish Victorian morals, citing as an example the non-inclusion of "various centuries-old 'four-letter words'" until 1972. However, no English dictionary included such words, for fear of possible prosecution under British obscenity laws, until after the conclusion of the "Lady Chatterley's Lover" obscenity trial in 1960. The first dictionary to include them was the "Penguin English Dictionary" of 1965.
The OED's claims of authority have also been questioned by linguists such as Pius ten Hacken, who notes that though the dictionary actively strives towards definitiveness and authority, it can only achieve those goals in a limited sense given the difficulties of defining the scope of what it includes.
Founding editor James Murray was also reluctant to include scientific terms, despite their documentation, unless he felt they were widely enough used. In 1902 he declined to add the word "radium" to the dictionary.
In contrast, Tim Bray, co-creator of Extensible Markup Language (XML), credits the "OED" as the developing inspiration of that markup language. Similarly, the author Anu Garg, founder of Wordsmith.org, has called the "Oxford English Dictionary" a "lex icon".

</doc>
<doc id="22644" url="https://en.wikipedia.org/wiki?curid=22644" title="Ottonian dynasty">
Ottonian dynasty

The Ottonian dynasty () was a Saxon dynasty of German monarchs (919–1024), named after its first Emperor Otto I, but also known as the Saxon dynasty after the family's origin in the German stem duchy of Saxony. The family itself is also sometimes known as the Liudolfings ("Liudolfinger"), after its earliest known member Count Liudolf (d. 866) and one of its primary leading-names. The Ottonian rulers were successors of the Carolingian dynasty in East Francia.
Origins.
In the 9th century, the Saxon count Liudolf held large estates on the Leine river west of the Harz mountain range and in the adjacent Eichsfeld territory of Thuringia. His ancestors probably acted as "ministeriales" in the Saxon stem duchy, which had been incorporated into the Carolingian Empire after the Saxon Wars of Charlemagne. Liudolf married Oda, a member of the Frankish House of Billung. About 852 the couple together with Bishop Altfrid of Hildesheim founded Brunshausen Abbey, which, relocated to Gandersheim, rose to a family monastery and burial ground. 
Liudolf already held the high social position of a Saxon "dux", documented by the marriage of his daughter Liutgard with Louis the Younger, son of the Carolingian king Louis the German in 869. Liudolf's sons Bruno and Otto the Illustrious ruled over large parts of Saxon Eastphalia, moreover, Otto acted as lay abbot of the Imperial abbey of Hersfeld with large estates in Thuringia. He married Hedwiga, a daughter of the Babenberg duke Henry of Franconia. Otto possibly accompanied King Arnulf on his 894 campaign to Italy; the marriage of his daughter Oda with Zwentibold, Arnulf's illegitimate son, documents the efforts of the Carolingian ruler to win the mighty Saxon dynasty over as an ally. According to the Saxon chronicler Widukind of Corvey, Otto upon the death of the last Carolingian king Louis the Child in 911 was already a candidate for the East Frankish crown, which however passed to the Franconian duke Conrad I.
Upon Otto's death in 912, his son Henry the Fowler succeeded him as Duke of Saxony. Henry had married Matilda of Ringelheim, a descendant of the legendary Saxon ruler Widukind and heiress to extended estates in Westphalia. 
Ottonian Kings and Emperors.
The Ottonian rulers of East Francia, the German kingdom and the Holy Roman Empire were:
Henry I.
Although never Emperor, Henry the Fowler was arguably the founder of the imperial dynasty. While East Francia under the rule of the last Carolingian kings was ravaged by Hungarian invasions, he rose to a "primus inter pares" among the German dukes. Elected "Rex Francorum" in May 919, Henry abandoned the claim to dominate the whole disintegrating Carolingian Empire and, unlike his predecessor Conrad I, succeeded in gaining the support of the Franconian, Bavarian, Swabian and Lotharingian dukes. In 933 he led a German army to victory over the Hungarian forces at the Battle of Riade and campaigned both the land of the Polabian Slavs and the Duchy of Bohemia. By succession regulation, he transferred the power to his second son Otto I, who acceded to an undivided heritage. 
Otto I.
Otto I, Duke of Saxony upon the death of his father in 936, was elected king within a few weeks. He continued the work of unifying all of the German tribes into a single kingdom, greatly expanding the powers of the king at the expense of the aristocracy. Through strategic marriages and personal appointments, he installed members of his own family to the kingdom's most important duchies. This, however, did not prevent his relatives from entering into civil war: both Otto's brother Duke Henry of Bavaria and his son Duke Liudolf of Swabia revolted against his rule. Otto was able to suppress their uprisings, in consequence, the various dukes, who had previously been co-equals with the king, were reduced into royal subjects under the king's authority. His decisive victory over the Magyars at the Battle of Lechfeld in 955 ended the Hungarian invasions of Europe and secured his hold over his kingdom. 
The defeat of the pagan Magyars earned King Otto the reputation as the savior of Christendom and the epithet "the Great". He transformed the Church in Germany into a kind of proprietary church and major royal power base to which he donated charity and for the creation of which his family was responsible. By 961, Otto had conquered the Kingdom of Italy, which was a troublesome inheritance that none wanted, and extended his kingdom's borders to the north, east, and south. In control of much of central and southern Europe, the patronage of Otto and his immediate successors caused a limited cultural renaissance of the arts and architecture. He confirmed the 754 Donation of Pepin and, with recourse to the concept of "translatio imperii" in succession of Charlemagne, proceeded to Rome to have himself crowned Holy Roman Emperor by Pope John XII in 962. He even reached a settlement with the Byzantine emperor John I Tzimiskes by marrying his son and heir Otto II to John's niece Theophanu. In 968 he established the Archbishopric of Magdeburg at his long-time residence.
Otto II.
Co-ruler with his father since 961 and crowned emperor in 967, Otto II ascended the throne at the age of 18. By excluding the Bavarian line of Ottonians from the line of succession, he strengthened Imperial authority and secured his own son's succession to the Imperial throne. During his reign, Otto II attempted to annex the whole of Italy into the Empire, bringing him into conflict with the Byzantine emperor and with the Saracens of the Fatimid Caliphate. His campaign against the Saracens ended in 982 with a disastrous defeat at the Battle of Stilo. Moreover in 983 Otto II experienced a Great Slav Rising against his rule. 
Otto II died in 983 at the age of 28 after a ten-year reign. Succeeded by his three-year-old son Otto III as king, his sudden death plunged the Ottonian dynasty into crisis. During her regency for Otto III, the Byzantine princess Theophanu abandoned her late husband's imperialistic policy and devoted herself entirely to furthering her own agenda in Italy. 
Otto III.
When Otto III came of age, he concentrated on securing the rule in the Italian domains, installing his confidants Bruno of Carinthia and Gerbert of Aurillac as Popes. In 1000 he made a pilgrimage to the Congress of Gniezno in Poland, establishing the Archdiocese of Gniezno and confirming the royal status of the Piast ruler Bolesław I the Brave. Expelled from Rome in 1001, Otto III died at age 21 the next year, without an opportunity to reconquer the city.
Henry II.
The childless Otto III was succeeded by Henry II, a son of Duke Henry II of Bavaria and his wife Gisela of Burgundy, thereby a member of the Bavarian line of the Ottonians. Duke of Bavaria since 995, he was crowned king on 7 June 1002. Henry II spent the first years of his rule consolidating his political power on the borders of the German kingdom. He waged several campaigns against Bolesław I of Poland and then moved successfully to Italy where he was crowned emperor by Pope Benedict VIII on 14 February 1014. He reinforced his rule by endowing and founding numeorus dioceses, such as the Bishopric of Bamberg in 1007, intertwining the secular and ecclesiastical authority over the Empire. Henry II was canonised by Pope Eugene III in 1146.
As his marriage with Cunigunde of Luxembourg remained childless, the Ottonian dynasty became extinct with the death of Henry II in 1024. The crown passed to Conrad II of the Salian dynasty, great-grandson of Liutgarde, a daughter of Otto I, and the Salian duke Conrad the Red of Lorraine. When King Rudolph III of Burgundy died without heirs on 2 February 1032, Conrad II successfully claimed also this kingship on the basis of an inheritance Emperor Henry II had extorted from the former in 1006, having invaded Burgundy to enforce his claim after Rudolph attempted to renounce it in 1016.

</doc>
<doc id="22645" url="https://en.wikipedia.org/wiki?curid=22645" title="Orkney">
Orkney

Orkney (), also known as the Orkney Islands, is an archipelago in the Northern Isles of Scotland, United Kingdom. Situated off the north coast of Great Britain, Orkney is 16 kilometres (10 mi) north of the coast of Caithness and comprises approximately 70 islands, of which 20 are inhabited.
The largest island, Mainland, often referred to as "the Mainland", has an area of 523.25 square kilometres (202 sq mi), making it the sixth-largest Scottish island and the tenth-largest island in the British Isles. The largest settlement and administrative centre is Kirkwall.
The name "Orkney" dates back to the 1st century BC or earlier, and the islands have been inhabited for at least 8,500 years. Originally occupied by Mesolithic and Neolithic tribes and then by the Picts, Orkney was invaded and forcibly annexed by Norway in 875 and settled by the Norse. The Scottish Parliament then re-annexed the earldom to the Scottish Crown in 1472, following the failed payment of a dowry for James III's bride, Margaret of Denmark. Orkney contains some of the oldest and best-preserved Neolithic sites in Europe, and the "Heart of Neolithic Orkney" is a designated UNESCO World Heritage Site.
Orkney is one of the 32 council areas of Scotland, a constituency of the Scottish Parliament, a lieutenancy area, and a former county. The local council is Orkney Islands Council, one of only three Councils in Scotland with a majority of elected members who are independents.
In addition to the Mainland, most of the islands are in two groups, the North and South Isles, all of which have an underlying geological base of Old Red Sandstone. The climate is mild and the soils are extremely fertile, most of the land being farmed. Agriculture is the most important sector of the economy. The significant wind and marine energy resources are of growing importance, and the island generates more than its total yearly electricity demand using renewables. The local people are known as Orcadians and have a distinctive Scots dialect and a rich inheritance of folklore. There is an abundance of marine and avian wildlife.
Origin of the name.
Pytheas of Massilia visited Britain – probably sometime between 322 and 285 BC – and described it as triangular in shape, with a northern tip called "Orcas".
This may have referred to Dunnet Head, from which Orkney is visible. Writing in the 1st century AD, the Roman geographer Pomponius Mela called the islands "Orcades", as did Tacitus in AD 98, claiming that his father-in-law Agricola had "discovered and subjugated the Orcades hitherto unknown" (although both Mela and Pliny had previously referred to the islands.)
Etymologists usually interpret the element "orc-" as a Pictish tribal name meaning "young pig" or "young boar".
Speakers of Old Irish referred to the islands as "Insi Orc" ("island of the pigs").
The archipelago is known as "Arcaibh" in modern [[Scottish Gaelic]], the "-aibh" representing a [[Fossilization (linguistics)|fossilized]] [[prepositional case]] ending.
[[Norsemen|Norwegian]] settlers arriving from the late 9th century re-interpreted "orc" as [[Old Norse]] "orkn" "[[pinniped|seal]]", with the added suffix "[[:wikt:Appendix:Proto-Germanic/awjō|ey]]" "island". Thus the name became "Orkneyjar" (meaning "seal islands"), later shortened to "Orkney" in English. According to the "[[Historia Norvegiæ]]", Orkney was named after an [[earl]] called Orkan.
The Norse knew [[Mainland, Orkney|Mainland Orkney]] as "Megenland" (mainland) or as "Hrossey" (horse island). The island is sometimes referred to as "Pomona" (or "Pomonia"), a name that stems from a sixteenth-century mis-translation by [[George Buchanan]] and has rarely been used locally.
History.
[[File:RingofBrodgarJM.jpg|thumb|upright|alt=Four large standing stones sit in a field of grass and heather. They are illuminated by reddish sunlight and they cast long shadows to the left. A lake and low hills lie beyond.|[[Ring of Brodgar]], on the island of [[Mainland, Orkney]]]]
Prehistory.
A charred [[hazelnut]] shell, recovered in 2007 during excavations in Tankerness on the Mainland has been dated to 6820–6660 BC indicating the presence of Mesolithic nomadic tribes. The earliest known permanent settlement is at [[Knap of Howar]], a Neolithic farmstead on the island of [[Papa Westray]], which dates from 3500 BC. The village of [[Skara Brae]], Europe's best-preserved Neolithic settlement, is believed to have been inhabited from around 3100 BC. Other remains from that era include the [[Standing Stones of Stenness]], the [[Maeshowe]] [[passage grave]], the [[Ring of Brodgar]] and other standing stones. Many of the Neolithic settlements were abandoned around 2500 BC, possibly due to changes in the climate.
During the [[Bronze Age]] fewer large stone structures were built although the great ceremonial circles continued in use as metalworking was slowly introduced to Scotland from Europe over a lengthy period. There are relatively few Orcadian sites dating from this era although there is the impressive [[Plumcake Mound]] near the Ring of Brodgar and various islands sites such as Tofts Ness on [[Sanday, Orkney|Sanday]] and the remains of two houses on [[Holm of Faray]].
Iron Age.
[[File:Midhowe Broch.jpg|thumb|left|alt=A semi-circular stone wall at left hints at the existence of a large and ancient building and to the right are the ruins of various other stone structures. In the background a low cliff divides a body of water from grassy fields.|[[Midhowe Broch]] on the west coast of [[Rousay]]]]
Excavations at Quanterness on the Mainland have revealed an [[Atlantic roundhouse]] built about 700 BC and similar finds have been made at Bu on the Mainland and Pierowall Quarry on Westray. The most impressive [[Iron Age]] structures of Orkney are the ruins of later round towers called "[[broch]]s" and their associated settlements such as the [[Broch of Burroughston]] and [[Broch of Gurness]]. The nature and origin of these buildings is a subject of ongoing debate. Other structures from this period include [[Souterrain|underground storehouses]], and [[Wheelhouse (archaeology)|aisled roundhouses]], the latter usually in association with earlier broch sites.
During the [[Ancient Rome|Roman]] invasion of Britain the "King of Orkney" was one of 11 British leaders who is said to have submitted to the Emperor [[Claudius]] in AD 43 at [[Camulodunum|Colchester]]. After the Agricolan fleet had come and gone, possibly anchoring at [[Shapinsay]], direct Roman influence seems to have been limited to trade rather than conquest.
By the late Iron Age, Orkney was part of the [[Picts|Pictish]] kingdom, and although the [[archaeological]] remains from this period are less impressive there is every reason to suppose the fertile soils and rich seas of Orkney provided the Picts with a comfortable living. The [[Dál Riata|Dalriadic]] [[Gaels]] began to influence the islands towards the close of the Pictish era, perhaps principally through the role of [[Celtic Christianity|Celtic]] [[Missionary|missionaries]], as evidenced by several islands bearing the epithet "Papa" in commemoration of these preachers. However, before the Gaelic presence could establish itself the Picts were gradually dispossessed by the [[Norsemen]] from the late 8th century onwards. The nature of this transition is controversial, and theories range from peaceful integration to [[enslavement]] and [[genocide]].
Norwegian rule.
[[File:Flateyjarbok Haraldr Halfdan.jpg|thumb|right|alt=A page from an illuminated manuscript shows two male figures. On the left a seated man wears a red crown and on the right a standing man has long fair hair. Their right hands are clasped together.|According to the "[[Orkneyinga saga|Orkneyinga Saga]]", [[Harald I of Norway|Harald Hårfagre]] (on the left) took control of Orkney in 875.]]
Both Orkney and [[Shetland]] saw a significant influx of Norwegian settlers during the late 8th and early 9th centuries. [[Viking]]s made the islands the headquarters of their [[pirate]] expeditions carried out against Norway and the coasts of mainland Scotland. In response, Norwegian king [[Harald I of Norway|Harald Hårfagre]] ("Harald Fair Hair") annexed the [[Northern Isles]], comprising Orkney and Shetland, in 875. (It is clear that this story, which appears in the "Orkneyinga Saga", is based on the later voyages of [[Magnus III of Norway|Magnus Barelegs]] and some scholars believe it to be apocryphal.) [[Rognvald Eysteinsson]] received Orkney and Shetland from Harald as an earldom as reparation for the death of his son in battle in Scotland, and then passed the earldom on to his brother [[Sigurd Eysteinsson|Sigurd the Mighty]].
However, Sigurd's line barely survived him and it was [[Torf-Einarr]], Rognvald's son by a slave, who founded a dynasty that controlled the islands for centuries after his death. He was succeeded by his son [[Thorfinn Turf-Einarsson, Earl of Orkney|Thorfinn Skull-splitter]] and during this time the deposed Norwegian King [[Eric Bloodaxe]] often used Orkney as a raiding base before being killed in 954. Thorfinn's death and presumed burial at the broch of Hoxa, on [[South Ronaldsay]], led to a long period of dynastic strife.
[[File:Peter nicolai arbo, olaf tryggvasson king.jpg|thumb|left|alt=A group of warriors in medieval garb surround two men whose postures suggest they are about to embrace. The man on the right is taller, has long fair hair and wears a bright red tunic. The man on the left his balding with short grey hair and a white beard. He wears a long brown cloak.| Artist's conception of [[Olaf I of Norway|King Olav Tryggvason]] of Norway, who forcibly Christianised Orkney. Painting by [[Peter Nicolai Arbo]].]]
Initially a pagan culture, detailed information about the return of the Christian religion to the islands of Scotland during the Norse-era is elusive. The "Orkneyinga Saga" suggests the islands were Christianised by [[Olaf I of Norway|Olav Tryggvasson]] in 995 when he stopped at [[South Walls]] on his way from Ireland to Norway. The King summoned the "[[earl|jarl]]" [[Sigurd the Stout]] and said, "I order you and all your subjects to be baptised. If you refuse, I'll have you killed on the spot and I swear I will ravage every island with fire and steel." Unsurprisingly, Sigurd agreed and the islands became Christian at a stroke, receiving their own [[Bishop of Orkney|bishop]] in the early 11th century.
[[Thorfinn Sigurdsson|Thorfinn the Mighty]] was a son of Sigurd and a grandson of [[Malcolm II of Scotland|King Máel Coluim mac Cináeda]] (Malcolm II of Scotland). Along with Sigurd's other sons he ruled Orkney during the first half of the 11th century and extended his authority over a small maritime empire stretching from [[Dublin]] to [[Shetland]]. Thorfinn died around 1065 and his sons [[Paul and Erlend Thorfinnsson|Paul and Erlend]] succeeded him, fighting at the [[Battle of Stamford Bridge]] in 1066. Paul and Erlend quarreled as adults and this dispute carried on to the next generation. The [[martyr]]dom of [[Magnus Erlendsson, Earl of Orkney|Magnus Erlendsson]], who was killed in April 1116 by his cousin [[Haakon Paulsson]], resulted in the building of [[St. Magnus Cathedral]], still today a dominating feature of Kirkwall.
[[File:Kirkwall cathedral.jpg|thumb|right|alt=A large church made from red and yellow stone with a square tower and a spire on the tower.|[[St. Magnus Cathedral|St Magnus Cathedral]] in Kirkwall]]
Unusually, from c. 1100 onwards the Norse "jarls" owed allegiance both to Norway for Orkney and to the Scottish crown through their holdings as [[Earls of Caithness]]. In 1231 the line of Norse earls, unbroken since Rognvald, ended with [[Jon Haraldsson]]'s murder in [[Thurso]]. The [[Earldom of Caithness]] was granted to [[Magnus II, Earl of Orkney|Magnus]], second son of the [[Earl of Angus]], whom [[Haakon IV of Norway]] confirmed as Earl of Orkney in 1236. In 1290, the death of the child princess [[Margaret, Maid of Norway]] in Orkney, en route to mainland Scotland, created a disputed succession that led to the [[Wars of Scottish Independence]]. In 1379 the earldom passed to the [[Clan Sinclair|Sinclair]] family, who were also barons of [[Roslin Castle|Roslin]] near [[Edinburgh]].
Evidence of the Viking presence is widespread, and includes the settlement at the [[Brough of Birsay]], the vast majority of [[Toponymy|place names]], and the [[Runic alphabet|runic]] inscriptions at Maeshowe.
Scottish rule.
[[File:James III and Margaret of Denmark.jpg|thumb|200px|left|alt=A picture on a page in an old book. A man at left wears tights and a tunic with a lion rampant design and holds a sword and scepter. A woman at right wears a dress with an heraldic design bordered with ermine and carries a thistle in one hand and a scepter in the other. They stand on a green surface over a legend in Scots that begins "James the Thrid of Nobil Memorie..." (sic) and notes that he "marrit the King of Denmark's dochter."|[[James III of Scotland|James III]] and [[Margaret of Denmark, Queen of Scotland|Margaret]], whose betrothal led to Orkney passing from Norway to Scotland.]]
In 1468 Orkney was [[pledge (law)|pledged]] by [[Christian I of Denmark|Christian I]], in his capacity as king of Norway, as security against the payment of the [[dowry]] of his daughter [[Margaret of Denmark, Queen of Scotland|Margaret]], betrothed to [[James III of Scotland]]. As the money was never paid, the connection with the crown of Scotland has become perpetual.
The history of Orkney prior to this time is largely the history of the ruling aristocracy. From now on the ordinary people emerge with greater clarity. An influx of Scottish entrepreneurs helped to create a diverse and independent community that included farmers, fishermen and merchants that called themselves "comunitas Orcadie" and who proved themselves increasingly able to defend their rights against their feudal overlords.
From at least the 16th century, boats from mainland Scotland and the [[Netherlands]] dominated the local [[herring]] fishery. There is little evidence of an Orcadian fleet until the 19th century but it grew rapidly and 700 boats were involved by the 1840s with Stronsay and then later Stromness becoming leading centres of development. [[Whitefish (fisheries term)|White fish]] never became as dominant as in other Scottish ports.
In the 17th century, Orcadians formed the overwhelming majority of employees of the [[Hudson's Bay Company]] in [[Canada]]. The harsh climate of Orkney and the Orcadian reputation for sobriety and their boat handling skills made them ideal candidates for the rigours of the Canadian north. During this period, burning [[kelp]] briefly became a mainstay of the islands' economy. For example on Shapinsay over of burned seaweed were produced per annum to make [[soda ash]], bringing in £20,000 to the local economy. The industry collapsed suddenly in 1830 after the removal of tariffs on imported [[alkali]].
Agricultural improvements beginning in the 17th century resulted in the enclosure of the commons and ultimately in the Victoria era the emergence of large and well-managed farms using a five-shift rotation system and producing high quality beef cattle.
In the 18th century [[Jacobite Risings]] Orkney was largely Jacobite in its sympathies. At the end of the 1715 rebellion, a large number of Jacobites who had fled north from mainland Scotland sought refuge on Orkney and were helped on to safety in Sweden. In 1745, the Jacobite lairds on the islands ensured that Orkney remained pro-Jacobite in outlook, and was a safe place to land supplies from Spain to aid their cause. Orkney was the last place in the British Isles that held out for the Jacobites and was not retaken by the [[Broad Bottom Ministry|British Government]] until 24 May 1746, over a month after the defeat of the main Jacobite army at [[Battle of Culloden|Culloden]].
20th century.
[[File:The altar art of the Italian chapel of Orkney - geograph.org.uk - 739607.jpg|thumb|right|The [[Italian Chapel]] on [[Lamb Holm]] was built and decorated by Italian prisoners of war working on the [[Churchill Barriers]].]]
Orkney was the site of a [[Royal Navy]] base at [[Scapa Flow]], which played a major role in [[World War I]] and [[World War II|II]]. After the [[Armistice]] in 1918, the [[German High Seas Fleet]] was transferred in its entirety to Scapa Flow to await a decision on its future. The German sailors opened the sea-cocks and scuttled all the ships. Most ships were salvaged, but the remaining wrecks are now a favoured haunt of recreational divers. One month into [[World War II]], a German [[U-boat]] sank the Royal Navy battleship [[HMS Royal Oak (08)|HMS "Royal Oak"]] in Scapa Flow. As a result, [[Churchill Barriers|barriers]] were built to close most of the access channels; these had the additional advantage of creating causeways enabling travellers to go from island to island by road instead of being obliged to rely on ferries. The causeways were constructed by Italian prisoners of war, who also constructed the ornate [[Italian Chapel]].
During World War II, the politicians of [[Quisling regime|German-occupied Norway]] asked German authorities to take over Orkney as Norway sought new opportunities for expansion.
The navy base became run down after the war, eventually closing in 1957. The problem of a declining population was significant in the post-war years, though in the last decades of the 20th century there was a recovery and life in Orkney focused on growing prosperity and the emergence of a relatively classless society. Orkney was rated as the best place to live in Scotland in both 2013 and 2014 according to the Halifax Quality of Life survey.
Overview of population trends.
In the modern era, population peaked in the mid 19th century at just over 26,000 and declined for a century thereafter to a low of fewer than 17,000 in the 1970s. Declines were particularly significant in the outlying islands, some of which remain vulnerable to ongoing losses. Although Orkney is in many ways very distinct from the other islands and archipelagos of Scotland these trends are very similar to those experienced elsewhere. The archipelago's population grew by 11% in the decade to 2011 as recorded by the [[United Kingdom Census 2011|census]]. During the same period [[List of Scottish islands|Scottish island]] populations as a whole grew by 4% to 103,702.
[[File:Orkney population chart 75.jpg]]
Geography.
[[File:Orkney Map.png|thumb|right|alt= A map of the Orkney archipelago showing main transport routes. A small island with a high elevation is at south west. At centre is the largest island, which also has low hills. Ferry routes spread out from there to the smaller islands in the north.|Map of Orkney showing main transport routes]]
Orkney is separated from the mainland of Scotland by the [[Pentland Firth]], a wide seaway between Brough Ness on the island of [[South Ronaldsay]] and [[Duncansby Head]] in [[Caithness]]. Orkney lies between 58°41′ and 59°24′ North, and 2°22′ and 3°26′ West, measuring from northeast to southwest and from east to west, and covers .
The islands are mainly low-lying except for some sharply rising sandstone hills on [[Hoy]], Mainland and Rousay and rugged cliffs on some western coasts. Nearly all of the islands have [[loch]]s, but the watercourses are merely streams draining the high land. The coastlines are indented, and the islands themselves are divided from each other by straits generally called "sounds" or "firths".
The [[Tide|tidal currents]], or "roosts" as some of them are called locally, off many of the isles are swift, with frequent whirlpools. The islands are notable for the absence of trees, which is partly accounted for by the amount of wind.
Islands.
The Mainland.
[[File:Stromness 2.jpg|thumb|alt=Stone houses crowd around a shore, the gable ends facing the water, with green hills beyond.|[[Stromness]] on the Mainland is the second largest settlement on Orkney.]]
The Mainland is the largest island of Orkney. Both of Orkney's [[burgh]]s, [[Kirkwall]] and [[Stromness]], are on this island, which is also the heart of Orkney's transportation system, with [[ferry]] and air connections to the other islands and to the outside world. The island is more densely populated (75% of Orkney's population) than the other islands and has much fertile [[Farmland (farming)|farmland]]. The Mainland is split into areas called East and West Mainland. These areas are determined by whether they lie East or West of Kirkwall. The bulk of the mainland lies West of Kirkwall, with comparatively little land lying East of Kirkwall.
West Mainland parishes are:
Stromness, Sandwick, Birsay, Harray, Stenness, Orphir, Evie, Rendall and Firth.
East Mainland Parishes are:
St Ola, Tankerness, St Andrews, Holm and Deerness.
The island is mostly low-lying (especially East Mainland) but with coastal [[cliff]]s to the north and west and two sizeable lochs: the [[Loch of Harray]] and the [[Loch of Stenness]]. The Mainland contains the remnants of numerous [[Neolithic]], [[Picts|Pictish]] and [[Viking]] constructions. Four of the main Neolithic sites are included in the [[Heart of Neolithic Orkney]] [[World Heritage Site]], inscribed in 1999.
The other islands in the group are classified as north or south of the Mainland. Exceptions are the remote islets of [[Sule Skerry]] and [[Sule Stack]], which lie west of the archipelago, but form part of Orkney for local government purposes. In island names, the [[suffix]] "a" or "ay" represents the Norse "ey", meaning "island". Those described as "[[Holm (island)|holms]]" are very small.
The North Isles.
[[File:NR sheep.jpg|thumb|right|[[North Ronaldsay (sheep)|North Ronaldsay sheep]] are a [[feral|semi-feral]] breed that has evolved to eat seaweed and their unique genetic inheritance makes them of interest to conservationists.]]
The northern group of islands is the most extensive and consists of a large number of moderately sized islands, linked to the Mainland by ferries and by air services. Farming, fishing and tourism are the main sources of income for most of the islands.
The most northerly is [[North Ronaldsay]], which lies beyond its nearest neighbour, Sanday. To the west is [[Westray]] has a population of 550. It is connected by ferry and air to [[Papa Westray]], also known as "Papay". [[Eday]] is at the centre of the [[North Isles]]. The centre of the island is [[moorland]] and the island's main industries have been peat extraction and [[limestone]] [[quarry]]ing.
[[Rousay]], [[Egilsay]] and [[Gairsay]] lie north of the west Mainland across the [[Eynhallow Sound]]. Rousay is well known for its ancient monuments, including the Quoyness [[chambered cairn]] and Egilsay has the ruins of the only round-towered church in Orkney. [[Wyre, Orkney|Wyre]] to the south east contains the site of Cubbie Roo's castle. [[Stronsay]] and [[Papa Stronsay]] lie much further to the east across the Stronsay Firth. [[Auskerry]] is south of Stronsay and has a population of only five. [[Shapinsay]] and its [[Balfour Castle]] are a short distance north of Kirkwall.
Other small uninhabited islands in the North Isles group include: [[Calf of Eday]], [[Damsay]], [[Eynhallow]], [[Faray]], [[Helliar Holm]], [[Holm of Faray]], [[Holm of Huip]], [[Holm of Papa]], [[Holm of Scockness]], [[Kili Holm]], [[Linga Holm]], [[Muckle Green Holm]], [[Rusk Holm]] and [[Sweyn Holm]].
[[File:Hoy Lighthouse RLH.jpg|thumb|upright|alt= A tall white lighthouse with a brown stripe around the parapet and dark coloured lantern sit on a rocky shore. A white wall obscures the lower floor of grey stone buildings gathered around its base.|[[Hoy Lighthouse]] on [[Graemsay]]]]
The South Isles.
The southern group of islands surrounds [[Scapa Flow]]. Hoy is the second largest of the Orkney Isles and [[Ward Hill, Hoy|Ward Hill]] at its northern end is the highest elevation in the archipelago. The [[Old Man of Hoy]] is a well-known [[Stack (geology)|seastack]]. [[Burray]] lies to the east of Scapa Flow and is linked by causeway to South Ronaldsay, which hosts the cultural events, the Festival of the Horse and the Boys' [[Ploughing Match]] on the third Saturday in August. It is also the location of the Neolithic [[Tomb of the Eagles]]. [[Graemsay]] and [[Flotta]] are both linked by ferry to the Mainland and Hoy, and the latter is known for its large oil terminal. [[South Walls]] has a 19th-century [[Martello tower]] and is connected to Hoy by the Ayre. South Ronaldsay, Burray, [[Glims Holm]], and [[Lamb Holm]] are connected by road to the Mainland by the [[Churchill Barriers]].
Uninhabited South Islands include: [[Calf of Flotta]], [[Cava (island)|Cava]], [[Copinsay]], [[Corn Holm]], [[Fara, Orkney|Fara]], [[Glims Holm]], [[Hunda]], [[Lamb Holm]], [[Rysa Little]], [[Switha]] and [[Swona]]. The [[Pentland Skerries]] lie further south, closer to the Scottish mainland.
Geology.
[[File:OldManofHoycloseJM.jpg|thumb|right|upright|alt=A tall perpendicular stack of brown rock stands in the sunlight in front of a shore with high cliffs that lie in the shadows.|The [[Old Man of Hoy]]]]
The superficial rock of Orkney is almost entirely [[Old Red Sandstone]], mostly of Middle [[Devonian]] age. As in the neighbouring mainland county of [[Caithness]], this sandstone rests upon the [[metamorphic rock|metamorphic]] rocks of the [[Moine Supergroup|Moine]] series, as may be seen on the Mainland, where a narrow strip is exposed between Stromness and Inganess, and again in the small island of [[Graemsay]]; they are represented by grey [[gneiss]] and [[granite]].
[[File:OrkneyGeologyMap.png|thumb|left|alt=A map of the geology of Orkney. Hoy to the south west is predominantly formed from Hoy/Eday Sandstones. The Mainland at centre is largely Stromness flagstones with Rousay flagstones to the east. The North and South Isles are a mixture of Eday and Rousay sandstones.|Geology of Orkney]]
The Middle Devonian is divided into three main groups. The lower part of the sequence, mostly [[Eifelian]] in age, is dominated by lacustrine beds of the lower and upper Stromness Flagstones that were deposited in [[Orcadian Basin|Lake Orcadie]]. The later Rousay flagstone formation is found throughout much of the North and South Isles and East Mainland.
The Old Man of Hoy is formed from sandstone of the uppermost Eday group that is up to thick in places. It lies unconformably upon steeply inclined flagstones, the interpretation of which is a matter of continuing debate.
The Devonian and older rocks of Orkney are cut by a series of WSW-ENE to N-S trending faults, many of which were active during deposition of the Devonian sequences. A strong [[Syncline|synclinal]] fold traverses Eday and Shapinsay, the axis trending north-south.
Middle Devonian [[basalt]]ic [[volcanic rock]]s are found on western Hoy, on Deerness in eastern Mainland and on Shapinsay. Correlation between the Hoy volcanics and the other two exposures has been proposed, but differences in chemistry means this remains uncertain. [[Lamprophyre]] [[Dike (geology)|dykes]] of Late [[Permian]] age are found throughout Orkney.
[[Glacial striation]] and the presence of [[chalk]] and [[flint]] [[Glacial erratic|erratics]] that originated from the bed of the North Sea demonstrate the influence of ice action on the [[geomorphology]] of the islands. Boulder [[clay]] is also abundant and [[moraine]]s cover substantial areas.
Climate.
Orkney has a cool temperate climate that is remarkably mild and steady for such a northerly [[latitude]], due to the influence of the [[Gulf Stream]]. The average temperature for the year is ; for winter and for summer .
The average annual rainfall varies from to . Winds are a key feature of the climate and even in summer there are almost constant breezes. In winter, there are frequent strong winds, with an average of 52 hours of gales being recorded annually.
To tourists, one of the fascinations of the islands is their "nightless" summers. On the [[Midsummer|longest day]], the sun rises at 03:00 and sets at 21:29 [[GMT]] and complete darkness is unknown. This long twilight is known in the Northern Isles as the "simmer dim". Winter nights are long. On the [[shortest day]] the sun rises at 09:05 and sets at 15:16. At this time of year the [[aurora borealis]] can occasionally be seen on the northern horizon during moderate auroral activity.
The averages table below is for largest settlement Kirkwall's weather station.
Politics.
Orkney is represented in the [[British House of Commons|House of Commons]] as part of the [[Orkney and Shetland (UK Parliament constituency)|Orkney and Shetland]] [[United Kingdom constituencies|constituency]], which elects one [[Member of Parliament]] (MP), the current incumbent being [[Alistair Carmichael]]. This seat has been held by the [[Liberal Democrats (UK)|Liberal Democrats]] or their predecessors the [[Liberal Party (UK)|Liberal Party]] since 1950, longer than any other they represent in Great Britain.
In the [[Scottish Parliament]] the [[Orkney (Scottish Parliament constituency)|Orkney]] constituency elects one [[Member of the Scottish Parliament]] (MSP) by the [[Plurality voting system|first past the post]] system. The current MSP is [[Liam McArthur]] of the Liberal Democrats. Before McArthur the MSP was [[Jim Wallace, Baron Wallace of Tankerness|Jim Wallace]], who was previously [[Deputy First Minister of Scotland|Deputy First Minister]]. Orkney is within the [[Highlands and Islands (Scottish Parliament region)|Highlands and Islands]] [[Scottish Parliament constituencies and regions|electoral region]].
[[Orkney Islands Council]] consists of 21 members, all of whom are [[Independent (politician)|independent]], that is they do not stand as representatives of a political party.
The Orkney Movement, a political party that supported devolution for Orkney from the rest of Scotland, contested the [[United Kingdom general election, 1987|1987 general election]] as the [[Orkney and Shetland Movement]] (a coalition of the Orkney movement and its equivalent for Shetland). The [[Scottish National Party]] chose not to contest the seat to give the movement a "free run". Their candidate, John Goodlad, came 4th with 3,095 votes, 14.5% of those cast, but the experiment has not been repeated.
In the [[Scottish independence referendum, 2014|2014 Scottish independence referendum]] 67.2% of voters in Orkney voted No to the question "Should Scotland be an independent country?" This was the highest % No vote in any council area in Scotland. Turnout for the referendum was at 83.7% in Orkney with 10,004 votes cast in the area against independence by comparison to 4,883 votes for independence.
Economy.
The soil of Orkney is generally very fertile and most of the land is taken up by farms, agriculture being by far the most important sector of the economy and providing employment for a quarter of the workforce. More than 90% of agricultural land is used for grazing for sheep and cattle, with cereal production utilising about 4% () and woodland occupying only .
Fishing has declined in importance, but still employed 345 individuals in 2001, about 3.5% of the islands' economically active population, the modern industry concentrating on herring, white fish, [[Homarus gammarus|lobsters]], [[crab]]s and other shellfish, and [[salmon]] fish farming.
Today, the traditional sectors of the economy export [[beef]], [[cheese]], [[whisky]], [[beer]], [[fish]] and other [[seafood]]. In recent years there has been growth in other areas including tourism, food and beverage manufacture, jewellery, knitwear, and other crafts production, construction and oil transportation through the [[Flotta]] oil terminal. Retailing accounts for 17.5% of total employment, and public services also play a significant role, employing a third of the islands' workforce.
In 2007, of the 1,420 [[VAT]] registered enterprises 55% were in agriculture, forestry and fishing, 12% in manufacturing and construction, 12% in wholesale, retail and repairs, and 5% in hotels and restaurants. A further 5% were public service related. 55% of these businesses employ between 5 and 49 people.
Power.
[[File:Pelamis at EMEC.jpg|thumb|alt=A long red tube lies in the water under dark, cloud-covered skies with black hills in the distance. |[[Pelamis wave energy converter|Pelamis]] on site at [[European Marine Energy Centre|EMEC's]] wave testing site off Billia Croo]]
Orkney has significant wind and marine energy resources, and [[Renewable energy in Scotland|renewable energy]] has recently come into prominence. Although Orkney is connected to the mainland, it generates over 100% of its net power from renewables. This comes mainly from wind turbines situated right across Orkney.
The [[European Marine Energy Centre]] (EMEC) is a [[Scottish Government]]-backed research facility that has installed a wave testing system at Billia Croo on the Orkney Mainland and a tidal power testing station on the island of Eday. At the official opening of the Eday project the site was described as "the first of its kind in the world set up to provide developers of wave and tidal energy devices with a purpose-built performance testing facility." Funding for the UK's first [[wave farm]] was announced by the [[Scottish Government]] in 2007. It will be the world's largest, with a capacity of 3 MW generated by four [[Pelamis wave energy converter|Pelamis]] machines at a cost of over £4 million. During 2007 [[Scottish and Southern Energy]] plc in conjunction with the [[University of Strathclyde]] began the implementation of a Regional Power Zone in the Orkney archipelago. This scheme (that may be the first of its kind in the world) involves "active network management" that will make better use of existing infrastructure and allow a further 15MW of new "non-firm generation" output from renewables onto the network.
Transport.
Air.
[[Highlands and Islands Airports Limited|Highland and Islands Airports]] operates the main airport in Orkney, [[Kirkwall Airport]]. [[Loganair]], a franchise of [[Flybe]], provides services to the Scottish mainland ([[Aberdeen Airport|Aberdeen]], [[Edinburgh Airport|Edinburgh]], [[Glasgow International Airport|Glasgow-International]] and [[Inverness Airport|Inverness]]), as well as to [[Sumburgh Airport]] in Shetland.
Within Orkney, the council operates airfields on most of the larger islands including [[Stronsay Airport|Stronsay]], [[Eday Airport|Eday]], [[North Ronaldsay Airport|North Ronaldsay]], [[Westray Airport|Westray]], [[Papa Westray Airport|Papa Westray]], and [[Sanday Airport|Sanday]]. Reputedly the shortest scheduled air service in the world, between the islands of Westray and Papa Westray, is scheduled at two minutes duration but can take less than one minute if the wind is in the right direction.
Ferry.
[[File:Ferry at Whale Geo pier, Westray - geograph.org.uk - 33804.jpg|thumb|right|[[MV Earl Thorfinn]] arrives at [[Westray]]. [[Orkney Ferries]] operate a fleet of inter-island ferries.]]
Ferries serve both to link Orkney to the rest of Scotland, and also to link together the various islands of the Orkney archipelago. Ferry services operate between Orkney and the Scottish mainland and Shetland on the following routes:
Inter-island ferry services connect all the inhabited islands to Orkney Mainland, and are operated by [[Orkney Ferries]], a company owned by Orkney Islands Council.
Media.
Orkney is served by a weekly local newspaper, [[The Orcadian]].
A local BBC radio station, [[BBC Radio Orkney]], the local opt-out of [[BBC Radio Scotland]], broadcasts twice daily, with local news and entertainment. Orkney also had a [[commercial radio]] station, [[The Superstation Orkney]], which broadcast to Kirkwall and parts of the mainland and also to most of [[Caithness]] until its closure in November 2014. [[Moray Firth Radio]] broadcasts throughout Orkney on AM and from an FM transmitter just outside Thurso. The [[community radio]] station Caithness FM also broadcasts to Orkney.
Festivals.
The islands are the home of several international festivals, including the [[Orkney International Science Festival]] in September, a folk festival in May and the [[St Magnus Festival|St Magnus International Arts Festival]] in June.
Language, literature and folklore.
[[File:Odin-Stone sketch.jpeg|thumb|upright|alt= A black and white line drawing of a tall standing stone that is wider at the top than the base. It has a long vertical crack on the right hand side and there is a small hole that goes right through it near the ground. A lake and hill are in the background.|The Odin Stone]]
At the beginning of recorded history the islands were inhabited by the [[Picts]], whose language was Brythonic. The [[Ogham]] script on the [[Buckquoy spindle-whorl]] is cited as evidence for the pre-Norse existence of [[Old Irish]] in Orkney.
After the Norse occupation the [[toponymy]] of Orkney became almost wholly [[West Norse]]. The Norse language evolved into the local [[Norn language|Norn]], which lingered until the end of the 18th century, when it finally died out. Norn was replaced by the [[Orcadian dialect]] of [[Insular Scots]]. This dialect is at a low ebb due to the pervasive influences of television, education and the large number of incomers. However, attempts are being made by some writers and radio presenters to revitalise its use and the distinctive sing-song [[Accent (dialect)|accent]] and many dialect words of Norse origin remain in use. The Orcadian word most frequently encountered by visitors is "peedie", meaning "small", which may derive from the French "petit".
Orkney has a rich folklore and many of the former tales concern [[Trow (folklore)|trows]], an Orcadian form of [[troll]] that draws on the islands' Scandinavian connections. Local customs in the past included marriage ceremonies at the Odin Stone that formed part of the Stones of Stenness.
The best known literary figures from modern Orkney are the poet [[Edwin Muir]], the poet and novelist [[George Mackay Brown]] and the novelist [[Eric Linklater]].
Orcadians.
[[File:The Bridge of Brodgar, Stenness, 1875. By Walter Hugh Patton (1828-1895).tif|thumb|The Bridge of Brodgar, Stenness, 1875. By Walter Hugh Patton (1828-1895).]]
An [[Orcadian]] is a native of Orkney, a term that reflects a strongly held identity with a tradition of understatement. Although the annexation of the earldom by Scotland took place over five centuries ago in 1472, most Orcadians regard themselves as Orcadians first and [[Scottish people|Scots]] second.
When an Orcadian speaks of "Scotland", they are talking about the land to the immediate south of the [[Pentland Firth]]. When an Orcadian speaks of "the mainland", they mean [[Mainland, Orkney]]. [[Tartan]], [[clans]], [[bagpipes]] and the like are traditions of the [[Scottish Highlands]] and are not a part of the islands' indigenous culture. However, at least two tartans with Orkney connections have been registered and a tartan has been designed for Sanday by one of the island's residents, and there are pipe bands in Orkney.
Native Orcadians refer to the non-native residents of the islands as "ferry loupers", a term that has been in use for nearly two centuries at least.
Natural history.
[[File:Seals hauled out by Lyrie Geo, Hoy, Orkney - geograph.org.uk - 2472901.jpg|thumb|right|upright|Seals hauled out at Lyrie Geo on [[Hoy]]. Orkney has an abundance of wildlife.]]
Orkney has an abundance of wildlife, especially of [[grey seal|grey]] and [[Harbor seal|common seals]] and seabirds such as [[Atlantic puffin|puffins]], [[kittiwake]]s, [[black guillemot|tysties]], [[raven]]s, and [[great skua|bonxies]]. Whales, dolphins, and [[European otter|otters]] are also seen around the coasts. Inland the [[Orkney vole]], a distinct subspecies of the [[common vole]], is an [[endemism|endemic]]. There are five distinct varieties, found on the islands of Sanday, Westray, Rousay, South Ronaldsay, and the Mainland, all the more remarkable as the species is absent on mainland [[Great Britain|Britain]].
The coastline is well known for its colourful flowers including [[Aster tripolium|sea aster]], [[Scilla verna|sea squill]], [[Armeria maritima|sea thrift]], [[Limonium|common sea-lavender]], [[Erica cinerea|bell]] and [[Calluna|common heather]]. The [[Primula scotica|Scottish primrose]] is found only on the coasts of Orkney and nearby Caithness and [[Sutherland]]. Although stands of trees are generally rare, a small forest named [[Happy Valley (garden)|Happy Valley]] with 700 trees and lush gardens was created from a boggy hillside near Stenness during the second half of the 20th century.
The [[North Ronaldsay sheep]] is an unusual breed of domesticated animal, subsisting largely on a diet of [[seaweed]], since they are confined to the foreshore for most of the year to conserve the limited grazing inland. The island was also a habitat for the Atlantic [[walrus]] until the mid-16th century.
The Orkney char ("[[Salvelinus inframundus]]") used to live in Heldale Water on Hoy. It has been considered [[Local extinction|locally extinct]] since 1908.
External links.
[[Category:Northern Isles]]
[[Category:Archipelagoes of Scotland]]
[[Category:Archipelagoes of the Atlantic Ocean]]
[[Category:Lieutenancy areas of Scotland]]
[[Category:Orkney| ]]
[[Category:Counties of Scotland]]
[[Category:Highlands and Islands of Scotland]]
[[Category:Regions of Scotland]]
[[Category:Former Norwegian colonies]]
[[Category:Council areas of Scotland]]
[[Category:Former Danish colonies]]
[[Category:Renewable energy in Scotland]]

</doc>
<doc id="22647" url="https://en.wikipedia.org/wiki?curid=22647" title="Hoy">
Hoy

Hoy (from Norse "Háey" meaning high island) is an island in Orkney, Scotland. With an area of it is the second largest in the archipelago after the Mainland. It is connected by a causeway called The Ayre to South Walls. Unusually, the two islands are treated as one entity by the UK census.
Description.
The dramatic coastline of Hoy greets visitors travelling to Orkney by ferry from the Scottish mainland. It has extremes of many kinds: some of the highest sea cliffs in the UK at St John's Head, which reach ; the impressive and famous sea stack, the Old Man of Hoy; some of the most northerly surviving natural woodland in the British Isles and the remote possibility that the Orkney charr ("Salvelinus inframundus"), last described in 1908, survive in Heldale Water. The most northerly Martello Towers were built to defend the area during the Napoleonic War, but were never used in combat.
The highest point in Orkney, Ward Hill, is on Hoy.
The main naval base for the British fleet Scapa Flow in both the First and Second World Wars was situated at Lyness in the south-east of the island. Some rather incongruous Art Deco structures nearby date from this period.
An unusual rock-cut tomb, the Dwarfie Stane, lies in the Rackwick valley in the north of the island. It is unique in northern Europe, bearing similarity to Neolithic or Bronze Age tombs around the Mediterranean. The tomb gets its name as it is very small and was said to be carved by dwarfs.
In Norse mythology, Hoy is the location of the never-ending battle between Hedin and Högni.
Orkney Ferries serve the island with two routes, one of which links Lyness on Hoy and Longhope on Walls with the island of Flotta and Houton on the Orkney Mainland. The other route links Moaness in Hoy to the island of Graemsay and Stromness on Orkney Mainland.
Hoy is part of the Hoy and West Mainland National Scenic Area, one of 40 in Scotland.
Wildlife.
Hoy is an Important Bird Area.
The northern part of the island is an RSPB reserve due to its importance for birdlife, particularly Great skuas and red-throated divers. It was sold to the RSPB by the Hoy Trust for a minimal amount.
Anastrepta orcadensis, a liverwort also known as Orkney Notchwort, was first discovered on Ward Hill by William Jackson Hooker in 1808.
In popular culture.
Hoy is featured prominently in the 1984 video for "Here Comes The Rain Again" by Eurythmics.

</doc>
<doc id="22648" url="https://en.wikipedia.org/wiki?curid=22648" title="Rousay">
Rousay

Rousay ( meaning Rolf's Island) is a small, hilly island about north of Orkney's Mainland, off the north coast of Scotland, and has been nicknamed "the Egypt of the north", due to its archaeological diversity and importance.
It is separated from mainland Orkney by the Eynhallow Sound, and, like its neighbours Egilsay and Wyre, can be reached by ro-ro ferry from Tingwall, on the mainland of Orkney, which takes 20–25 minutes. This service is operated by Orkney Ferries, and can take up to 95 passengers (reduced to 50 in winter), and 10 cars. The ferry links the islands of Rousay, Egilsay, and Wyre with each other, and with the mainland of Orkney.
Geography and natural history.
In the 2001 census, Rousay had a population of 212 people. Most employment opportunities are in farming, fishing or fish-farming; there are also craft businesses and some seasonal tourism-related work. There is one circular road round the island, about 14 miles (23km) long, and most arable land lies in the few hundred yards between this and the coastline. With an area of , it is the fifth largest of the Orkney Islands.
There are several freshwater lochs on the island, the biggest of which is Muckle Water.
Rousay is a 'Site of Special Scientific Interest' with notable cliff formations and wildflower colonies, and has an RSPB bird reserve. The hilliest Orkney island after Hoy, it offers good views of neighbouring islands from Blotchnifiold , and Keirfea or Knitchen (both over ).
Summertime brings visitors drawn by its natural beauty and wildlife, including Rousay's seals and otters, and by its archaeological remains, especially the cluster of important sites connected by a footpath near the western shore.
History.
The island has evidence from every stage in the history of Orkney, with a Neolithic settlement at Rinyo, Bronze Age burnt mounds, Iron Age crannogs and brochs (the highest density anywhere in Scotland: three within of coastline), Viking boat burials, remains of a medieval church and the stately home at Trumland.
Over 100 archaeological sites have been identified, but only a small fraction of them have been excavated and researched. The best known and most spectacular of the island's archaeological sites is the complex of Midhowe Broch and Midhowe Chambered Cairn. Blackhammer Chambered Cairn, Taversoe Tuick, and Yarso are also important tombs on the island.
Rousay placenames reflect its Norse heritage. 'Hrólfs-øy' or 'Hrolfsey' was based on the male name 'Hrolf' (Rolf). Hugh Marwick's work has shown the name developing from 'Rollesay' in the 14th century, through 'Rolsay' in the 15th, and 'Rowsay' in the early 16th, with the spelling 'Rousay' first recorded in 1549.
Most Rousay people have always earned their living from farming and/or fishing. In the 19th century, records show there were also tradespeople supplying the needs of a rural community: blacksmiths and joiners, shoemakers and shopkeepers, with women doing dressmaking and straw plaiting. Throughout the century, Rousay's landlords demanded high rents from crofters, many of whom were made homeless in a series of clearances along the western coast, ordered by landowner George William Traill in the 1820s and 1830s.
Traill's nephew General Sir Frederick Traill-Burroughs inherited much of the island and bought more. Traill-Burroughs built a large house at Trumland, designed by David Bryce of Edinburgh. From 1870-1883, there were a large number of improvements; the building of Trumland pier, island schools, a public market, the first steamship service, a post office, and the first resident doctor. He was known locally as "the little general" as he was a man of short stature and the poet Edwin Muir recalled in a memoir of his childhood seeing the little general walking around his estates.
Rousay's population in the mid-19th century was over 900, but emigration following land clearances reduced that to 627 by 1900, and half a century later it had fallen to 342. Depopulation accelerated, and in the next twenty years the number fell to 181, its lowest ever. From the 1970s onward new families started to settle on Rousay: most came from the south, especially from England. The population is now over 200.
The Yetnasteen stone is said to have once been a giant who revives every New Year at midnight and goes down to the Loch of Scockness to drink.
Local education.
There is a primary school, which provides education for boys and girls aged 3 to 12, and has a school roll of 24. Once a child completes his/her primary education, they must then move up to secondary school. Kirkwall Grammar School, Kirkwall, is the usual school, however, in recent years, Stromness Academy, Stromness, has been the secondary school of choice for many of the pupils.
Many of the pupils, both primary and secondary, are entitled to free school transport on the island.
Residents.
The poet Pauline Stainer spent several years on the island, and in 1999 published a collection of her poems about Rousay, "Parable Island".
Robert C. Marwick is a local author whose publications include "From My Rousay Schoolbag"; "Rousay Roots" (1995); "In Dreams We Moor" (2000) ISBN 1-899851-04-6. Marwick was born on the farm of Innister, in the Wasbister district of Rousay.
The astronomer, musician and writer, John Vetterlein first came to Rousay in 1970 and has lived on the island full-time since 1995. He established the small publishing house Spring Ast LIX in 1997, whose publications include: "Braes Woodland Diary - the First Ten Years" by Ann Chapman.
The actor Graham Fellows owns a disused church on the Orkney island, which he intends to turn into an "artists refuge".
The late artist Margaret Gardiner spent a large part of her life on Rousay and founded, in 1979 the Pier Art Gallery in Stromness.

</doc>
<doc id="22649" url="https://en.wikipedia.org/wiki?curid=22649" title="Observation">
Observation

Observation is the active acquisition of information from a primary source. In living beings, observation employs the senses. In science, observation can also involve the recording of data via the use of instruments. The term may also refer to any data collected during the scientific activity. Observations can be qualitative, that is, only the absence or presence of a property is noted, or quantitative if a numerical value is attached to the observed phenomenon by counting or measuring.
Observation in science.
The scientific method requires observations of nature to formulate and test hypotheses. It consists of these steps:
Observations play a role in the second and fifth steps of the scientific method. However the need for reproducibility requires that observations by different observers can be comparable. Human sense impressions are subjective and qualitative making them difficult to record or compare. Theed or shared by all observers, and counting how many of the standard units are comparable to the object. Measurement reduces an observation to a number which can be recorded, and two observations which result in the same number are equal within the resolution of the process.
Senses are limited, and are subject to errors in perception such as optical illusions. Scientific instruments were developed to magnify human powers of observation, such as weighing scales, clocks, telescopes, microscopes, thermometers, cameras, and tape recorders, and also translate into perceptible form events that are unobservable by human senses, such as indicator dyes, voltmeters, spectrometers, infrared cameras, oscilloscopes, interferometers, geiger counters, x-ray machines, and radio receivers.
One problem encountered throughout scientific fields is that the observation may affect the process being observed, resulting in a different outcome than if the process was unobserved. This is called the "observer effect". For example, it is not normally possible to check the air pressure in an automobile tire without letting out some of the air, thereby changing the pressure. However, in most fields of science it is possible to reduce the effects of observation to insignificance by using better instruments.
Considered as a physical process itself, all forms of observation (human or instrumental) involve amplification and are thus thermodynamically irreversible processes, increasing entropy.
Observational paradoxes.
In some specific fields of science the results of observation differ depending on factors which are not important in everyday observation. These are usually illustrated with "paradoxes" in which an event appears different when observed from two different points of view, seeming to violate "common sense".
Biases.
The human senses do not function like a video camcorder, impartially recording all observations. Human perception occurs by a complex, unconscious process of abstraction, in which certain details of the incoming sense data are noticed and remembered, and the rest forgotten. What is kept and what is thrown away depends on an internal model or representation of the world, called by psychologists a "schema", that is built up over our entire lives. The data is fitted into this schema. Later when events are remembered, memory gaps may even be filled by "plausible" data the mind makes up to fit the model; this is called "reconstructive memory". How much attention the various perceived data are given depends on an internal value system, which judges how important it is to the individual. Thus two people can view the same event and come away with entirely different perceptions of it, even disagreeing about simple facts. This is why eyewitness testimony is notoriously unreliable.
Several of the more important ways observations can be affected by human psychology are given below.
Confirmation bias.
Human observations are biased toward confirming the observer's conscious and unconscious expectations and view of the world; we "see what we expect to see". In psychology, this is called confirmation bias. Since the object of scientific research is the discovery of new phenomena, this bias can and has caused new discoveries to be overlooked. One example is the discovery of x-rays. It can also result in erroneous scientific support for widely held cultural myths, for example the scientific racism that supported ideas of racial superiority in the early 20th century. Correct scientific technique emphasizes careful recording of observations, separating experimental observations from the conclusions drawn from them, and techniques such as blind or double blind experiments, to minimize observational bias.
"Cargo cult" science.
Another bias, which has become more prevalent with the advent of "big science" and the large rewards of new discoveries, is bias in favor of the researcher's desired hypothesis or outcome; we "see what we want to see". Called pathological science and cargo cult science, this is different from deliberate falsification of results, and can happen to good-faith researchers. Researchers with a great incentive or desire for a given outcome can misinterpret or misjudge results, or even persuade themselves they have seen something they haven't. Possible examples of mistaken discoveries caused by this bias are Martian "canals", N rays, polywater, cold fusion, and perpetual motion machines. Recent decades have seen scientific scandals caused by researchers playing "fast and loose" with observational methods in order to get their pet theories published. This type of bias is rampant in pseudoscience, where correct scientific techniques are not followed. The main defense against this bias, besides correct research techniques, is peer review and repetition of the experiment, or the observation, by other researchers with no incentive to bias. For example, an emerging practice in the competitive field of biotechnology is to require the physical results of experiments, such as serums and tissue cultures, be made available to competing laboratories for independent testing.
Processing bias.
Modern scientific instruments can extensively process "observations" before they are presented to the human senses, and particularly with computerized instruments, there is sometimes a question as to where in the data processing chain "observing" ends and "drawing conclusions" begins. This has recently become an issue with digitally enhanced images published as experimental data in papers in scientific journals. The images are enhanced to bring out features that the researcher wants to emphasize, but this also has the effect of supporting the researcher's conclusions. This is a form of bias that is difficult to quantify. Some scientific journals have begun to set detailed standards for what types of image processing are allowed in research results. Computerized instruments often keep a copy of the "raw data" from sensors before processing, which is the ultimate defense against processing bias, and similarly scientific standards require preservation of the original unenhanced "raw" versions of images used as research data.
Observational bias.
An observational bias occurs when researchers only look where they think they will find positive results, or where it is easy to record observations. This is called the "streetlight effect".
Observations in philosophy.
Observation in philosophical terms is the process of filtering sensory information through the thought process. Input is received via hearing, sight, smell, taste, or touch and then analyzed through either rational or irrational thought. You "see" a parent beat their child; you "observe" that such an action is either good or bad. Deductions about what behaviors are good or bad may be based in no way on preferences about building relationships, or study of the consequences resulting from the observed behavior. With the passage of time, impressions stored in the consciousness about many related observations, together with the resulting relationships and consequences, permit the individual to build a construct about the moral implications of behavior.

</doc>
<doc id="22651" url="https://en.wikipedia.org/wiki?curid=22651" title="Oliver Conant">
Oliver Conant

Oliver Conant (born November 15, 1955) is an American actor.
Born in New York City, New York, Conant appeared as "Benji" in the 1971 coming-of-age drama "Summer of '42" and "Class of '44", appearing in both with Gary Grimes and Jerry Houser as a trio of adolescent boys.
He was also in Jean Kerr's 1973 Broadway farce "Finishing Touches", with Barbara Bel Geddes, Robert Lansing, James Woods, and others.
After a three decades or so hiatus from acting, Conant re-emerged on off and off-off Broadway stages in productions ranging from Gene Ruffini's dystopian "Homeland", Anne Fizzard's back-stage comedy "Good Opinions", and Tuvia Tenenbom's absurdist satire "Kabbalah". He serves as Producing Director for Queens Shakespeare Inc, a new classical repertory company based in Flushing, New York. Conant will be appearing in the NICU'S SPOON production of "Elizabeth Rex" in April 2008 in New York City.

</doc>
<doc id="22652" url="https://en.wikipedia.org/wiki?curid=22652" title="Oftel">
Oftel

"Oftel has been superseded as the British telecommunications regulator by Ofcom (the Office of Communications)."
The Office of Telecommunications (Oftel) ("the telecommunications regulator") was a department in the United Kingdom government, under civil service control, charged with promoting competition and maintaining the interests of consumers in the UK telecommunications market. It was set up under the Telecommunications Act 1984 after privatisation of the nationalised operator BT.
Oftel was accused by its critics of having been "captured" by BT, and of giving the dominant operator too much freedom to leverage its monopoly status in fixed line telephony into other markets such as ADSL.
On 28 December 2003 the duties of Oftel were inherited by Ofcom, which is the result of a consolidation of the British telecommunication and broadcasting regulators.
Freeserve alleged Oftel overlooked anti-competitive practices in BT's marketing of ADSL products.

</doc>
<doc id="22653" url="https://en.wikipedia.org/wiki?curid=22653" title="OCR">
OCR

OCR may refer to:

</doc>
<doc id="22654" url="https://en.wikipedia.org/wiki?curid=22654" title="Ohio-class submarine">
Ohio-class submarine

The "Ohio" class is a class of nuclear-powered submarines currently used by the United States Navy. The navy has 18 "Ohio"-class submarines: 14 ballistic missile submarines (SSBN) and four that were later converted to guided missile submarines (SSGN).
The "Ohio" class is named after the lead submarine of this class, . The 14 Trident II SSBNs together carry approximately fifty percent of the total US active inventory of strategic thermonuclear warheads. Although the Trident missiles have no pre-set targets when the submarines go on patrol, the warships, when required, are capable of quickly being assigned targets by using secure and constant radio communications links at sea, including very low frequency (VLF) systems.
All the "Ohio"-class submarines, except for , are named for U.S. states, which until that point was a tradition reserved for battleships and cruisers.
The "Ohio"-class submarines are the largest submarines ever built for the U.S. Navy. Two classes of the Russian Navy's submarines have larger total displacements: the Soviet-designed s have more than twice the total displacement, and Russia's s have roughly 25 percent greater displacement, but the "Ohio"-class boats carry more missiles than either: 24 Trident missiles per boat, versus 16 missiles for the Borei class (20 for the Borei II) and 20 for the "Typhoon" class.
Description.
The "Ohio"-class submarines were designed specifically for extended war-deterrence patrols. Each of these submarines is provided with two complete crews, called the Blue crew and the Gold crew, with each crew serving typically on 70- to 90-day deterrent patrols. To decrease the time in port for crew turnover and replenishment, three large logistics hatches have been installed to provide large-diameter resupply and repair access. These hatches allow rapid transfer of supply pallets, equipment replacement modules, and machinery components, significantly reducing the time required for replenishment and maintenance of the submarines.
The class's design allows the warship to operate for about fifteen years between major overhauls. These submarines are reported to be as quiet at their cruising speed of or more than the previous s were at , although exact information remains classified. Fire control for their Mark 48 torpedoes is carried out by Mark 118 Mod 2 system, while the Missile Fire Control (MFC) system is a Mark 98.
The "Ohio"-class submarines were constructed from sections of hull, with each four-deck section being in diameter. The sections were produced at the General Dynamics Electric Boat facility, Quonset Point, Rhode Island, and then assembled at its shipyard at Groton, Connecticut.
The US Navy has a total of 18 "Ohio"-class submarines which consist of 14 ballistic missile submarines (SSBNs), and four cruise missile submarines (SSGNs). The SSBN submarines are also known as "Trident" submarines, and provide the sea-based leg of the U.S. nuclear triad. Each SSBN submarine is armed with up to 24 Trident II submarine-launched ballistic missiles (SLBM). Each SSGN is capable of carrying 154 Tomahawk cruise missiles with either conventional or nuclear warheads, plus a complement of Harpoon missiles to be fired through their torpedo tubes.
History.
The first eight "Ohio"-class submarines were armed at first with 24 Trident I C4 SLBMs. Beginning with the ninth Trident submarine, , the remaining boats were equipped with the larger, three-stage Trident II D5 missile. The Trident I missile carries eight multiple independently targetable reentry vehicles (MIRV), while the Trident II missile carries twelve, in total delivering more destructive power than the Trident I missile and with greater accuracy. Starting with in 2000, the Navy began converting its remaining ballistic missile submarines armed with C4 missiles to carry D5 missiles. This task was completed in mid-2008.
The first eight submarines had their home ports at Bangor, Washington, to replace the submarines carrying the Polaris A3 missile that were then being decommissioned. The remaining ten submarines originally had their home ports at Kings Bay, Georgia, replacing the Poseidon and Trident Backfit submarines of the Atlantic Fleet. During the conversion of the first four submarines to SSGNs (see below), five of the submarines, , , , , and , were transferred from Kings Bay to Bangor. Further transfers occur as the strategic weapons goals of the United States change.
In 2011, "Ohio"-class submarines carried out 28 deterrent patrols. Each patrol lasts around 70 days. Four boats are on station ("hard alert") in designated patrol areas at any given time. From January to June 2014, "Pennsylvania" carried out a 140-day-long patrol, the longest to date.
SSBN/SSGN conversions.
After the end of the Cold War, plans called for to be retired in 2002, followed by three of her sister boats. However, "Ohio", , , and instead were slated for modification, to remain in service carrying conventionally armed guided missiles, and were redesignated as SSGNs.
Beginning in 2002 through 2010, 22 of the 24 diameter Trident missile tubes were modified to contain large vertical launch systems (VLS), one configuration of which may be a cluster of seven Tomahawk cruise missiles. In this configuration, the number of cruise missiles carried could be a maximum of 154, the equivalent of what is typically deployed in a surface battle group. Other payload possibilities include new generations of supersonic and hypersonic cruise missiles, and Submarine Launched Intermediate Range Ballistic Missiles (SLIRBM), unmanned air vehicles (UAVs), the ADM-160 MALD, sensors for anti-submarine warfare or intelligence, surveillance, and reconnaissance missions, countermine warfare payloads such as the AN/BLQ-11 Long Term Mine Reconnaissance System (LMRS), and the broaching universal buoyant launcher (BUBL) and stealthy affordable capsule system (SACS) specialized payload canisters.
The missile tubes also have room for stowage canisters that can extend the forward deployment time for special forces. The other two Trident tubes are converted to swimmer lockout chambers. For special operations, the Advanced SEAL Delivery System and the dry deck shelter can be mounted on the lockout chamber and the boat will be able to host up to 66 special operations sailors or Marines, such as Navy SEALs, or USMC MARSOC teams. Improved communications equipment installed during the upgrade allows the SSGNs to serve as a forward-deployed, clandestine Small Combatant Joint Command Center.
On 26 September 2002, the Navy awarded the Electric Boat company a US$442.9 million contract to begin the first phase of the SSGN submarine conversion program. Those funds covered only the initial phase of conversion for the first two boats on the schedule. Advanced procurement was funded at $355 million in fiscal year 2002, $825 million in the FY 2003 budget and, through the five-year defense budget plan, at $936 million in FY 2004, $505 million in FY 2005, and $170 million in FY 2006. Thus, the total cost to refit the four boats is just under $700 million per vessel.
In November 2002, "Ohio" entered a drydock, beginning her 36-month refueling and missile conversion overhaul. Electric Boat announced on 9 January 2006 that the conversion had been completed. The converted "Ohio" rejoined the fleet in February 2006, followed by "Florida" in April 2006. The converted "Michigan" was delivered in November 2006. The converted "Ohio" went to sea for the first time in October 2007. "Georgia" returned to the fleet in March 2008 at Kings Bay. These four SSGNs are expected to remain in service until about 2023–2026. At that point their capabilities will be replaced with Virginia Payload Module equipped s.
Replacement.
The U.S. Department of Defense anticipates a continued need for a sea-based strategic nuclear force. The first of the current "Ohio" SSBNs are expected to be retired by 2029, meaning that a platform must already be seaworthy by that time. A replacement may cost over $4 billion per unit compared to "Ohio"s $2 billion. The U.S. Navy is exploring two options. The first is a variant of the nuclear attack submarines. The second is a dedicated SSBN, either with a new hull or based on an overhaul of the current "Ohio".
With the cooperation of both Electric Boat and Newport News Shipbuilding, in 2007, the U.S. Navy began a cost control study. Then in December 2008 the U.S. Navy awarded Electric Boat a contract for the missile compartment design of the "Ohio"-class replacement, worth up to $592 million. Newport News is expected to receive close to 4% of that project. The U.S. Navy has yet to confirm an "Ohio"-class replacement program. However, in April 2009, U.S. Defense Secretary Robert M. Gates confirmed that the U.S. Navy should begin such a program in 2010. The new vessel is scheduled to enter the design phase by 2014. It is anticipated that, if a new hull design is used, the program must be initiated by 2016 in order to meet the 2029 deadline.
In popular culture.
As ballistic missile submarines, the "Ohio" class has occasionally been portrayed in fiction books and films.

</doc>
<doc id="22655" url="https://en.wikipedia.org/wiki?curid=22655" title="Ossian">
Ossian

Ossian (; Irish Gaelic/Scottish Gaelic: "Oisean") is the narrator and purported author of a cycle of epic poems published by the Scottish poet James Macpherson from 1760. Macpherson claimed to have collected word-of-mouth material in Gaelic, said to be from ancient sources, and that the work was his translation of that material. Ossian is based on Oisín, son of Finn or Fionn mac Cumhaill, anglicised to Finn McCool, a legendary bard who is a character in Irish mythology. Contemporary critics were divided in their view of the work's authenticity, but the consensus since is that Macpherson framed the poems himself, based on old folk tales he had collected, and that "Ossian" is, in the words of Thomas Curley, "the most successful literary falsehood in modern history."
The work was internationally popular, translated into all the literary languages of Europe and was influential both in the development of the Romantic movement and the Gaelic revival. "The contest over the authenticity of Macpherson's pseudo-Gaelic productions," Curley asserts, "became a seismograph of the fragile unity within restive diversity of imperial Great Britain in the age of Johnson." Macpherson's fame was crowned by his burial among the literary giants in Westminster Abbey. W.P. Ker, in the "Cambridge History of English Literature", observes that "all Macpherson's craft as a philological impostor would have been nothing without his literary skill."
The poems.
In 1760 Macpherson published the English-language text "Fragments of ancient poetry, collected in the Highlands of Scotland, and translated from the Gaelic or Erse language". Later that year, he claimed to have obtained further manuscripts and in 1761 he claimed to have found an epic on the subject of the hero Fingal, written by Ossian. The name Fingal or "Fionnghall" means "white stranger". According to Macpherson's prefatory material, his publisher, claiming that there was no market for these works except in English, required that they be translated. Macpherson published these translations during the next few years, culminating in a collected edition, "The Works of Ossian", in 1765. The most famous of these Ossianic poems was "Fingal", written in 1762.
The supposed original poems are translated into poetic prose, with short and simple sentences. The mood is epic, but there is no single narrative, although the same characters reappear. The main characters are Ossian himself, relating the stories when old and blind, his father Fingal (very loosely based on the Irish hero Fionn mac Cumhaill), his dead son Oscar (also with an Irish counterpart), and Oscar's lover Malvina (like Fiona a name invented by Macpherson), who looks after Ossian in his old age. Though the stories "are of endless battles and unhappy loves", the enemies and causes of strife are given little explanation and context.
Characters are given to killing loved ones by mistake, and dying of grief, or of joy. There is very little information given on the religion, culture or society of the characters, and buildings are hardly mentioned. The landscape "is more real than the people who inhabit it. Drowned in eternal mist, illuminated by a decrepit sun or by emphemeral meteors, it is a world of greyness." Fingal is king of a region of south-west Scotland perhaps similar to the historical kingdom of Dál Riata and the poems appear to be set around the 3rd century, with the "king of the world" mentioned being the Roman Emperor; Macpherson and his supporters detected references to Caracalla (d. 217, as "Caracul") and Carausius (d. 293, as "Caros", the "king of ships").
Reception.
The poems achieved international success. Napoleon and Diderot were great admirers, and Voltaire wrote parodies of them. Thomas Jefferson thought Ossian "the greatest Poet that has ever existed", and planned to learn Gaelic so as to read his poems in the original. They were proclaimed as a Celtic equivalent of the Classical writers such as Homer. Many writers were influenced by the works, including Walter Scott, and painters and composers chose Ossianic subjects.
One poem was translated into French in 1762, and by 1777 the whole "corpus". In the German-speaking states Michael Denis made the first full translation in 1768-69, inspiring the proto-nationalist poets Klopstock and Goethe, whose own German translation of a portion of Macpherson's work figures prominently in a climactic scene of "The Sorrows of Young Werther" (1774). Goethe's associate Johann Gottfried Herder wrote an essay titled "Extract from a correspondence about Ossian and the Songs of Ancient Peoples" (1773) in the early days of the Sturm und Drang movement.
Complete Danish translations were made in 1790, and Swedish ones in 1794-1800. In Scandinavia and Germany the Celtic nature of the setting was ignored or not understood, and Ossian was regarded as a Nordic or Germanic figure who became a symbol for nationalist aspirations. The French general Jean-Baptiste Bernadotte, who was made King Charles XIV John of Sweden and King of Norway, had already named his only son after a character from Ossian; born in 1799, he later became King Oscar I of Sweden and Norway, and was succeeded by his son Oscar II (d. 1907).
Melchiore Cesarotti was an Italian clergyman whose translation into Italian is said by many to improve on the original, and was a tireless promoter of the poems, in Vienna and Warsaw as well as Italy. It was his translation that Napoleon especially admired, and among others it influenced Ugo Foscolo who was Cesarotti's pupil in the University of Padua.
By 1800 Ossian was translated into Spanish and Russian, with Dutch following in 1805, and Polish, Czech and Hungarian in 1827-33. The poems were as much admired in Hungary as in France and Germany; Hungarian János Arany wrote "Homer and Ossian" in response, and several other Hungarian writers – Baróti Szabó, Csokonai, Sándor Kisfaludy, Kazinczy, Kölcsey, Ferenc Toldy, and Ágost Greguss, were also influenced by it.
The first partial Polish translation of Ossian was made by Ignacy Krasicki in 1793. The complete translation appeared in 1838 by Seweryn Goszczyński. The most influential Russian version of Ossian was the 1792 translation by Ermil Kostrov, who based his work on Pierre Le Tourneur's 1777 translation from the original.
The opera "Ossian, ou Les bardes" by Le Sueur was a sell-out at the Paris Opera in 1804, and transformed his career. The poems also exerted an influence on the burgeoning of Romantic music, and Franz Schubert in particular composed Lieder setting many of Ossian's poems. In 1829 Felix Mendelssohn was inspired to visit the Hebrides and composed the "Hebrides Overture", better known as "Fingal's Cave". His friend Niels Gade devoted his first published work, the concert overture "Efterklange af Ossian" ("Echoes of Ossian") written in 1840, to the same subject.
Authenticity debate.
There were immediate disputes of Macpherson's claims on both literary and political grounds. Macpherson promoted a Scottish origin for the material, and was hotly opposed by Irish historians who felt that their heritage was being appropriated. However, both Scotland and Ireland shared a common Gaelic culture during the period in which the poems are set, and some Fenian literature common in both countries was composed in Scotland.
Samuel Johnson, English author, critic, and biographer, was convinced that Macpherson was "a mountebank, a liar, and a fraud, and that the poems were forgeries". Johnson also dismissed the poems' quality. Upon being asked, "But Doctor Johnson, do you really believe that any man today could write such poetry?" he famously replied, "Yes. Many men. Many women. And many children." Johnson is cited as calling the story of Ossian "as gross an imposition as ever the world was troubled with". In support of his claim, Johnson also called Gaelic the rude speech of a barbarous people, and said there were no manuscripts in it more than 100 years old. In reply, it was proved that the Advocates' library at Edinburgh contained Gaelic manuscripts 500 years old, and one of even greater antiquity.
Scottish author Hugh Blair's 1763 "A Critical Dissertation on the Poems of Ossian" upheld the work's authenticity against Johnson's scathing criticism and from 1765 was included in every edition of "Ossian" to lend the work credibility. The work also had a timely resonance for those swept away by the emerging Romantic movement and the theory of the "noble savage", and it echoed the popularity of Burke's seminal "A Philosophical Enquiry into the Origin of Our Ideas of the Sublime and Beautiful" (1757).
In 1766 the Irish antiquarian and Gaelic scholar Charles O'Conor dismissed Ossian's authenticity in a new chapter "Remarks on Mr. Mac Pherson's translation of Fingal and Temora" that he added to the second edition of his seminal history. In 1775 he expanded his criticism in a new book, "Dissertation on the origin and antiquities of the antient Scots".
Faced with the controversy, the Committee of the Highland Society enquired after the authenticity of Macpherson's supposed original. It was because of these circumstances that the so-called Glenmasan manuscript (Adv. 72.2.3) came to light in the late 18th century, a compilation which contains the tale "Oided mac n-Uisnig". This text is a version of the Irish "Longes mac n-Uislenn" and offers a tale which bears some comparison to Macpherson's "Darthula", although it is radically different in many respects. Donald Smith cited it in his report for the Committee.
The controversy raged on into the early years of the 19th century, with disputes as to whether the poems were based on Irish sources, on sources in English, on Gaelic fragments woven into his own composition as Johnson concluded, or largely on Scots Gaelic oral traditions and manuscripts as Macpherson claimed. Defences of the authenticity of the poems continued to be made. For example, Peter Hately Waddell argued in "Ossian and the Clyde" (1875) that poems contained topographical references that could not have been known to Macpherson.
In 1952, Scottish poet Derick Thomson concluded that Macpherson had collected Scottish Gaelic ballads, employing scribes to record those that were preserved orally and collating manuscripts, but had adapted them by altering the original characters and ideas, and had introduced a great deal of his own. The modern American literature professor and translator Bernard Knox refers to the Ossian book as a forged or fake "collective bardic epic".
"The Invention of Scotland" (2008) by Hugh Trevor-Roper follows the evolution of Macpherson's versions and the work's early support by some Scottish intellectuals.
Ossian in art.
Subjects from the Ossian poems were popular in the art of northern Europe, but at rather different periods depending on the country; by the time French artists began to depict Ossian, British artists had largely dropped him. Ossian was especially popular in Danish art, but also found in Germany and the rest of Scandinavia.
Britain, Germany and Scandinavia.
British artists began to depict the Ossian poems early on, with the first major work a cycle of paintings decorating the ceiling the "Grand Hall" of Penicuik House in Midlothian, built by Sir James Clerk, who commissioned the paintings in 1772. These were by the Scottish painter Alexander Runciman and lost when the house burnt down in 1899, though drawings and etchings survive, and two pamphlets describing them were published in the 18th century. A subject from Ossian by Angelica Kauffman was shown in the Royal Academy exhibition of 1773, and Ossian was depicted in "Elysium", part of the Irish painter James Barry's "magnum opus" decorating the Royal Society of Arts, at the Adelphi Buildings in London (still "in situ").
Works on paper by Thomas Girtin and John Sell Cotman have survived, though the Ossianic landscapes by George Augustus Wallis, which the Ossian fan August Wilhelm Schlegel praised in a letter to Goethe, seem to have been lost, as has a picture by J.M.W. Turner exhibited in 1802. Henry Singleton exhibited paintings, some of which were engraved and used in editions of the poems.
A fragment by Novalis, written in 1789, refers to Ossian as an inspired, holy and poetical singer. 
The Danish painter Nicolai Abildgaard, Director of the Copenhagen Academy from 1789, painted several scenes from Ossian, as did his pupils including Asmus Jacob Carstens. His friend Joseph Anton Koch painted a number of subjects, and two large series of illustrations for the poems, which never got properly into print; like many Ossianic works by Wallis, Carstens, Krafft and others, some of these were painted in Rome, perhaps not the best place to evoke the dim northern light of the poems. In Germany the request in 1804 to produce some drawings as illustrations so excited Philipp Otto Runge that he planned a series of 100, far more than asked for, in a style heavily influenced by the linear illustrations of John Flaxman; these remain as drawings only. Many other German works are recorded, some as late as the 1840s; word of the British scepticism over the Ossian poems was evidently slow to pentetrate the continent.
France.
In France the enthusiasm of Napoleon for the poems accounts for most artistic depictions, and those by the most famous artists, but a painting exhibited in the Paris Salon in 1800 by Paul Duqueylar (now Musée Granet, Aix-en-Provence) excited "Les Barbus" ("the Bearded Ones") a group of primitivist artists including Pierre-Maurice Quays (or Quaï) who promoted living in the style of "early civilizations as described in Homer, Ossian, and the Bible". Quays is reported as saying: "Homère? Ossian? ... le soleil? la lune? Voilà la question. En vérité, je crois que je préfère la lune. C'est plus simple, plus grand, plus "primitif"". ("Homer? Ossian? ... the sun? the moon? That's the question. Truthfully I think I prefer the moon. It's more simple, more grand, more "primitive""). The same year Napoleon was planning the renovation of the Château de Malmaison as a summer palace, and though he does not seem to have suggested Ossianic subjects for his painters, two large and significant works were among those painted for the reception hall, for which six artists had been commissioned.
These were Girodet's painting of 1801–02 "Ossian receiving the Ghosts of the French Heroes", and "Ossian Evoking ghosts on the Edge of the Lora", by François Pascal Simon Gérard. Gérard's original was lost in a shipwreck after being bought by the King of Sweden after the fall of Napoleon, but survives in three replicas by the artist (a further one in Berlin was lost in 1945). One is now at Malmaison (184.5 × 194.5 cm / 72.6 × 76.6 in), and the Kunsthalle Hamburg has another (180,5 × 198,5 cm). A watercolour copy by Jean-Baptiste Isabey was placed as frontispiece to Napoleon's copy of the poems.
Duqueylar, Girodet and Gérard, like Johann Peter Krafft (above) and most of the "Barbus", were all pupils of David, and the clearly unclassical subjects of the Ossian poems were useful for emergent French Romantic painting, marking a revolt against David's Neoclassical choice of historical subject-matter. David's recorded reactions to the paintings were guarded or hostile; he said of Girodet's work: "Either Girodet is mad or I no longer know anything of the art of painting".
Girodet's painting (still at Malmaison; 192.5 x 184 cm) was a "success de scandale" when exhibited in 1802, and remains a key work in the emergence of French Romantic painting, but the specific allusions to the political situation that he intended it to carry were largely lost on the public, and overtaken by the Peace of Amiens with England, signed in 1802 between the completion and exhibition of the work. He also produced "Malvina dying in the arms of Fingal" (c. 1802), and other works.
Another pupil of David, Jean-Auguste-Dominique Ingres, was to depict Ossianic scenes over most of his long career. He made a drawing in 1809, when studying in Rome, and in 1810 or 1811 was commisissioned to make two paintings, the "Dream of Ossian" and a classical scene, to decorate the bedroom Napoleon was to occupy in the Palazzo Quirinale on a visit to Rome. In fact the visit never came off and in 1835 Ingres repurchased the work, now in poor condition.
Editions.
National Library of Scotland has 327 books and associated materials in its Ossian Collection. The collection was originally assembled by J. Norman Methven of Perth and includes different editions and translations of James MacPherson's epic poem 'Ossian', some with a map of the 'Kingdom of Connor'. It also contains secondary material relating to Ossianic poetry and the Ossian controversy. More than 200 items from the collection have been digitised. 
Further reading.
in French:

</doc>
<doc id="22656" url="https://en.wikipedia.org/wiki?curid=22656" title="Operand">
Operand

In mathematics, an operand is the object of a mathematical operation, a quantity on which an operation is performed.
Example.
The following arithmetic expression shows an example of operators and operands:
In the above example, '+' is the symbol for the operation called addition. 
The operand '3' is one of the inputs (quantities) followed by the addition operator, and the operand '6' is the other input necessary for the operation.
The result of the operation is 9. (The number '9' is also called the sum of the addends, 3 and 6.)
An operand, then, is also referred to as "one of the inputs (quantities) for an operation".
Notation.
Expressions as operands.
Operands may be complex, and may consist of expressions also made up of operators with operands.
In the above expression '(3 + 5)' is the first operand for the multiplication operator and '2' the second. The operand '(3 + 5)' is an expression in itself, which contains an addition operator, with the operands '3' and '5'.
Order of operations.
Rules of precedence affect which values form operands for which operators:
In the above expression, the multiplication operator has the higher precedence than the addition operator, so the multiplication operator has operands of '5' and '2'. The addition operator has operands of '3' and '5 × 2'.
Positioning of operands.
Depending on the mathematical notation being used the position of an operator in relation to its operand(s) may vary. In everyday usage infix notation is the most common, however other notations also exist, such as the prefix and postfix notations. These alternate notations are most common within computer science.
Below is a comparison of three different notations — all represent an addition of the numbers '1' and '2'
Infix Notation and the Order of Operation.
With infix notation, one easy mnemonic for remembering the order of operation is:
Please excuse my dear Aunt Sally.
The first letter (in boldtype) of each word in the above mnemonic stands for the following:
In a mathematical expression, the order of operation is carried out from left to right. Start with the left most value and seek the first operation to be carried out in accordance with the order specified above (i.e., start with parentheses and end with the addition/subtraction group). For example, in the expression
the first operation to be acted upon is any and all expressions found inside a parenthesis. So beginning at the left and moving to the right, find the first (and in this case, the only) parenthesis, that is, (2 + 22). Within the parenthesis itself is found the expression 22. The reader is required to find the value of 22 before going any further. The value of 22 is 4. Having found this value, the remaining expression looks like this:
The next step is to calculate the value of expression inside the parenthesis itself, that is, (2 + 4) = 6. Our expression now looks like this:
Having calculated the parenthetical part of the expression, we start over again beginning with the left most value and move right. The next order of operation (according to the rules) is exponents. Start at the left most value, that is, 4, and scan your eyes to the right and search for the first exponent you come across. The first (and only) expression we come across that is expressed with an exponent is 22. We find the value of 22, which is 4. What we have left is the expression
The next order of operation is multiplication. 4 × 4 is 16. Now our expression looks like this:
The next order of operation according to the rules is division. However, there is no division operator sign (÷) in the expression, 16 − 6. So we move on to the next order of operation, i.e., addition. But there is no addition operator sign (+) in the expression 16 − 6. So we move on to the next and final order of operation, which is subtraction.
So the correct value for our original expression, 4 × 22 − (2 + 22), is 10. 
It is important to carry out the order of operation in accordance with rules set by convention. If the reader evaluates an expression but does not follow the correct order of operation, the reader will come forth with a different value. The different value will be the incorrect value because the order of operation was not followed. The reader will arrive at the correct value for the expression if and only if each operation is carried out in the proper order.
Arity.
The number of operands of an operator is called its arity. Based on arity, operators are classified as nullary (no operands), unary (1 operand), binary (2 operands), ternary (3 operands) etc.
Computer science.
In computer programming languages, the definitions of operator and operand are almost the same as in mathematics.
In computing, an operand is the part of a computer instruction which specifies what data is to be manipulated or operated on, while at the same time representing the data itself.
A computer instruction describes an operation such as add or multiply X, while the operand (or operands, as there can be more than one) specify on which X to operate as well as the value of X.
Additionally, in assembly language, an operand is a value (an argument) on which the instruction, named by mnemonic, operates. The operand may be a processor register, a memory address, a literal constant, or a label. A simple example (in the x86 architecture) is
where the value in register operand 'AX' is to be moved into register 'DS'. Depending on the instruction, there may be zero, one, two, or more operands.

</doc>
<doc id="22657" url="https://en.wikipedia.org/wiki?curid=22657" title="Order of magnitude">
Order of magnitude

Orders of magnitude are written in powers of 10. For example, the order of magnitude of 1500 is 3, since 1500 may be written as 1.5 × 103.
Differences in order of magnitude can be measured on the logarithmic scale in "decades" (i.e., factors of ten). Examples of numbers of different magnitudes can be found at Orders of magnitude (numbers).
Uses.
Orders of magnitude are used to make approximate comparisons. If numbers differ by 1 order of magnitude, "x" is "about" ten times different in quantity than "y". If values differ by 2 orders of magnitude, they differ by a factor of about 100. Two numbers of the same order of magnitude have roughly the same scale: the larger value is less than ten times the smaller value.
The order of magnitude of a number is, intuitively speaking, the number of powers of 10 contained in the number. More precisely, the order of magnitude of a number can be defined in terms of the common logarithm, usually as the integer part of the logarithm, obtained by truncation. For example, the number 4,000,000 has a logarithm (in base 10) of 6.602; its order of magnitude is 6. When truncating, a number of this order of magnitude is between 106 and 107. In a similar example, with the phrase "He had a seven-figure income", the order of magnitude is the number of figures minus one, so it is very easily determined without a calculator to be 6. An order of magnitude is an approximate position on a logarithmic scale.
An order-of-magnitude estimate of a variable whose precise value is unknown is an estimate rounded to the nearest power of ten. For example, an order-of-magnitude estimate for a variable between about 3 billion and 30 billion (such as the human population of the Earth) is 10 billion. To round a number to its nearest order of magnitude, one rounds its logarithm to the nearest integer. Thus 4,000,000, which has a logarithm (in base 10) of 6.602, has 7 as its nearest order of magnitude, because "nearest" implies rounding rather than truncation. For a number written in scientific notation, this logarithmic rounding scale requires rounding up to the next power of ten when the multiplier is greater than the square root of ten (about 3.162). For example, the nearest order of magnitude for 1.7 × 108 is 8, whereas the nearest order of magnitude for 3.7 × 108 is 9. An order-of-magnitude estimate is sometimes also called a zeroth order approximation.
An order-of-magnitude difference between two values is a factor of 10. For example, the mass of the planet Saturn is 95 times that of Earth, so Saturn is "two orders of magnitude" more massive than Earth. Order-of-magnitude differences are called decades when measured on a logarithmic scale.
Non-decimal orders of magnitude.
Other orders of magnitude may be calculated using bases other than 10. The ancient Greeks ranked the nighttime brightness of celestial bodies by 6 levels in which each level was the fifth root of one hundred (about 2.512) as bright as the nearest weaker level of brightness, and thus the brightest level being 5 orders of magnitude brighter than the weakest indicates that it is (1001/5)5 or a factor of 100 times brighter.
The different decimal numeral systems of the world use a larger base to better envision the size of the number, and have created names for the powers of this larger base. The table shows what number the order of magnitude aim at for base 10 and for base 1,000,000. It can be seen that the order of magnitude is included in the number name in this example, because bi- means 2 and tri- means 3 (these make sense in the long scale only), and the suffix -illion tells that the base is 1,000,000. But the number names billion, trillion themselves (here with other meaning than in the first chapter) are not names of the "orders of" magnitudes, they are names of "magnitudes", that is the "numbers" 1,000,000,000,000 etc.
SI units in the table at right are used together with SI prefixes, which were devised with mainly base 1000 magnitudes in mind. The IEC standard prefixes with base 1024 were invented for use in electronic technology.
The ancient apparent magnitudes for the brightness of stars uses the base formula_1 and is reversed. The modernized version has however turned into a logarithmic scale with non-integer values.
Extremely large numbers.
For extremely large numbers, a generalized order of magnitude can be based on their double logarithm or super-logarithm. Rounding these downward to an integer gives categories between very "round numbers", rounding them to the nearest integer and applying the inverse function gives the "nearest" round number.
The double logarithm yields the categories:
(the first two mentioned, and the extension to the left, may not be very useful, they merely demonstrate how the sequence mathematically continues to the left).
The super-logarithm yields the categories:
The "midpoints" which determine which round number is nearer are in the first case:
and, depending on the interpolation method, in the second case
For extremely small numbers (in the sense of close to zero) neither method is suitable directly, but the generalized order of magnitude of the reciprocal can be considered.
Similar to the logarithmic scale one can have a double logarithmic scale (example provided here) and super-logarithmic scale. The intervals above all have the same length on them, with the "midpoints" actually midway. More generally, a point midway between two points corresponds to the generalised f-mean with "f"("x") the corresponding function log log "x" or slog "x". In the case of log log "x", this mean of two numbers (e.g. 2 and 16 giving 4) does not depend on the base of the logarithm, just like in the case of log "x" (geometric mean, 2 and 8 giving 4), but unlike in the case of log log log "x" (4 and 65536 giving 16 if the base is 2, but, otherwise).

</doc>
<doc id="22659" url="https://en.wikipedia.org/wiki?curid=22659" title="Ockham">
Ockham

Occam or Ockham may refer to:

</doc>
<doc id="22660" url="https://en.wikipedia.org/wiki?curid=22660" title="Occam (programming language)">
Occam (programming language)

occam is a concurrent programming language that builds on the communicating sequential processes (CSP) process algebra, and shares many of its features. It is named after William of Ockham of Occam's Razor fame.
occam is an imperative procedural language (such as Pascal). It was developed by David May and others at INMOS, advised by Tony Hoare, as the native programming language for their transputer microprocessors, but implementations for other platforms are available. The most widely known version is occam 2; its programming manual was written by Steven Ericsson-Zenith and others at INMOS.
Overview.
In the following examples indentation and formatting are critical for parsing the code: expressions are terminated by the end of the line, lists of expressions need to be on the same level of indentation. This feature, named the off-side rule, is also found in other languages such as Haskell and Python.
Communication between processes work through named "channels". One process outputs data to a channel via "!" while another one inputs data with "?". Input and output can not proceed until the other end is ready to accept or offer data. (In the "not proceeding" case it is often said that the process "blocks" on the channel. However, the program will neither spin nor poll; therefore terms like "wait", "hang" or "yield" may also convey the behaviour - also in the light of the fact that it will not "block" other independent processes from running.) Examples (c is a variable):
 keyboard ? c
 screen ! c
SEQ introduces a list of expressions that are evaluated sequentially. This is not implicit as it is in most other programming languages. Example:
 SEQ
 x := x + 1
 y := x * x
PAR begins a list of expressions that may be evaluated concurrently. Example:
 PAR
 p()
 q()
ALT specifies a list of "guarded" commands. The "guards" are a combination of a boolean condition and an input expression (both optional). Each guard for which the condition is true and the input channel is ready is successful. One of the successful alternatives is selected for execution. Example:
 ALT
 count1 < 100 & c1 ? data
 SEQ
 count1 := count1 + 1
 merged ! data
 count2 < 100 & c2 ? data
 SEQ
 count2 := count2 + 1
 merged ! data
 status ? request
 SEQ
 out ! count1
 out ! count2
This will read data from channels c1 or c2 (whichever is ready) and pass it into a merged channel. If countN reaches 100, reads from the corresponding channel will be disabled. A request on the status channel is answered by outputting the counts to out.
Language revisions.
occam 1.
occam 1 (released 1983) was a preliminary version of the language which borrowed from David May's work on EPL and Tony Hoare's CSP. This supported only the VAR data type, which was an integral type corresponding to the native word length of the target architecture, and arrays of only one dimension.
occam 2.
occam 2 is an extension produced by INMOS Ltd in 1987 that adds floating-point support, functions, multi-dimensional arrays and more data types such as varying sizes of integers (INT16, INT32) and bytes.
With this revision, occam became a language capable of expressing useful programs, whereas occam 1 was more suited to examining algorithms and exploring the new language (however, the occam 1 compiler was written in occam 1, so there is an existence proof that reasonably sized, useful programs could be written in occam 1, despite its limitations).
occam 2.1.
occam 2.1 was the last of the series of occam language developments contributed by INMOS. Defined in 1994, it was influenced by an earlier proposal for an occam 3 language (also referred to as "occam91" during its early development) created by Geoff Barrett at INMOS in the early 1990s. A revised Reference Manual describing occam 3 was distributed for community comment, but the language was never fully implemented in a compiler.
occam 2.1 introduced several new features to occam 2, including:
For a full list of the changes see Appendix P of the INMOS occam 2.1 Reference Manual.
occam-π.
occam-π is the common name for the occam variant implemented by later versions of KRoC, the Kent Retargetable occam Compiler. The addition of the symbol "π" (pi) to the occam name is an allusion to the fact that KRoC occam includes several ideas inspired by the pi-calculus. It contains a significant number of extensions to the occam 2.1 compiler, for example:

</doc>
<doc id="22661" url="https://en.wikipedia.org/wiki?curid=22661" title="October Revolution">
October Revolution

The October Revolution (), officially known in the Soviet literature as the Great October Socialist Revolution (), and commonly referred to as Red October, the October Uprising or the Bolshevik Revolution, was a seizure of state power instrumental in the larger Russian Revolution of 1917. It took place with an armed insurrection in Petrograd traditionally dated to 25 October 1917 (by the Julian or Old Style calendar, which corresponds to 7 November 1917 in the Gregorian or New Style calendar).
It followed and capitalized on the February Revolution of the same year, which overthrew the Tsarist autocracy and established a provisional government composed predominantly of former nobles and aristocrats. During this time, urban workers began to organize into councils (Russian: "Soviet") wherein revolutionaries criticized the provisional government and its actions. The October Revolution in Petrograd overthrew the provisional government and gave the power to the local soviets. The Bolshevik party was heavily supported by the soviets. After the Congress of Soviets, now the governing body, had its second session, it elected members of the Bolsheviks and other leftist groups such as the Left Socialist Revolutionaries to key positions within the new state of affairs. This immediately initiated the establishment of the Russian Socialist Federative Soviet Republic, the world's first self-proclaimed socialist state.
The revolution was led by the Bolsheviks, who used their influence in the Petrograd Soviet to organize the armed forces. Bolshevik Red Guards forces under the Military Revolutionary Committee began the takeover of government buildings on 24 October 1917 (O.S.). The following day, the Winter Palace (the seat of the Provisional government located in Petrograd, then capital of Russia), was captured.
The long-awaited Constituent Assembly elections were held on 12 November 1917. The Bolsheviks only won 175 seats in the 715 seat legislative body, coming in second behind the Socialist Revolutionary party, which won 370 seats. The Constituent Assembly was to first meet on 28 November 1917, but its convocation was delayed until 5 January 1918 by the Bolsheviks. On its first and only day in session, the body rejected Soviet decrees on peace and land, and was dissolved the next day by order of the Congress of Soviets.
As the revolution was not universally recognized, there followed the struggles of the Russian Civil War (1917–22) and the creation of the Soviet Union in 1922.
Etymology.
Initially, the event was referred as the "October coup" (Октябрьский переворот) or the "Uprising of 25th", as seen in contemporary documents (for example, in the first editions of Lenin's complete works). In Russian, however, "переворот" has a similar meaning to "revolution" and also means "upheaval" or "overturn", so "coup" is not necessarily the right translation. With time, the term "October Revolution" (Октябрьская революция) came into use. It is also known as the "November Revolution" having occurred in November according to the Gregorian Calendar.
The Great October Socialist Revolution (, "Velikaya Oktyabr'skaya sotsialisticheskaya revolyutsiya") was the official name for the October Revolution in the Soviet Union after the 10th anniversary of the Revolution in 1927.
Background.
The February Revolution had toppled Tsar Nicholas II of Russia, and replaced his government with the Russian Provisional Government. However, the provisional government was weak and riven by internal dissension. It continued to wage World War I, which became increasingly unpopular. A nationwide crisis developed in Russia, affecting social, economic, and political relations. Disorder in industry and transport had intensified, and difficulties in obtaining provisions had increased. Gross industrial production in 1917 had decreased by over 36 percent from what it had been in 1916. In the autumn, as much as 50 percent of all enterprises were closed down in the Urals, the Donbas, and other industrial centers, leading to mass unemployment. At the same time, the cost of living increased sharply. The real wages of the workers fell about 50 percent from what they had been in 1913. Russia's national debt in October 1917 had risen to 50 billion rubles. Of this, debts to foreign governments constituted more than 11 billion rubles. The country faced the threat of financial bankruptcy.
In September and October 1917, there were strikes by the Moscow and Petrograd workers, the miners of the Donbas, the metalworkers of the Urals, the oil workers of Baku, the textile workers of the Central Industrial Region, and the railroad workers on 44 different railway lines. In these months alone more than a million workers took part in mass strike action. Workers established control over production and distribution in many factories and plants in a social revolution.
By October 1917 there had been over four thousand peasant uprisings against landowners. When the Provisional Government sent out punitive detachments it only enraged the peasants. The garrisons in Petrograd, Moscow, and other cities, the Northern and Western fronts, and the sailors of the Baltic Fleet in September openly declared through their elected representative body Tsentrobalt that they did not recognize the authority of the Provisional Government and would not carry out any of its commands.
In a diplomatic note of 1 May, the minister of foreign affairs, Pavel Milyukov, expressed the Provisional Government's desire to carry the war against the Central Powers through "to a victorious conclusion", arousing broad indignation. On 1–4 May about 100,000 workers and soldiers of Petrograd, and after them the workers and soldiers of other cities, led by the Bolsheviks, demonstrated under banners reading "Down with the war!" and "all power to the soviets!" The mass demonstrations resulted in a crisis for the Provisional Government. 1 July saw more demonstrations, as about 500,000 workers and soldiers in Petrograd demonstrated, again demanding "all power to the soviets", "down with the war", and "down with the ten capitalist ministers". The Provisional Government opened an offensive against the Central Powers on 1 July but it soon collapsed. The news of the offensive and its collapse intensified the struggle of the workers and the soldiers. A new crisis in the Provisional Government began on 15 July.
On 16 July spontaneous demonstrations of workers and soldiers began in Petrograd, demanding that power be turned over to the soviets. The Central Committee of the Russian Social Democratic Labour Party provided leadership to the spontaneous movements. On 17 July, over 500,000 people participated in a peaceful demonstration in Petrograd, the so-called July Days. The Provisional Government, with the support of the Socialist-Revolutionary Party-Menshevik leaders of the All-Russian Executive Committee of the Soviets, ordered an armed attack against the peaceful demonstrators, murdering hundreds.
A period of repression followed. On 5–6 July attacks were made on the editorial offices and printing presses of "Pravda" and on the Palace of Kshesinskaya, where the Central Committee and the Petrograd Committee of the Bolsheviks were located. On 7 July a government decree ordering the arrest and trial of Vladimir Lenin was published. He was forced to go underground, just as he had been under the Tsarist regime. Bolsheviks began to be arrested, workers were disarmed, and revolutionary military units in Petrograd were disbanded or sent off to the front. On 12 July the Provisional Government published a law introducing the death penalty at the front. The formation of the second coalition government, with Alexander Kerensky as chairman, was completed on 24 July.
Another problem for the government centered on General Lavr Kornilov, who had been Commander-in-Chief since 18 July. In response to a Bolshevik appeal, Moscow’s working class began a protest strike of 400,000 workers. The Moscow workers were supported by strikes and protest rallies by workers in Kiev, Kharkov, Nizhny Novgorod, Ekaterinburg, and other cities.
In what became known as the Kornilov affair, Kornilov directed an army under Aleksandr Krymov to march toward Petrograd with Kerensky's agreement. Although the details remain sketchy, Kerensky appeared to become frightened by the possibility of a coup and the order was countermanded (by comparison, historian Richard Pipes has argued that the whole episode was engineered by Kerensky himself). On 27 August, feeling betrayed by the Kerensky government who had previously agreed with his views on how to restore order to Russia, Kornilov pushed on towards Petrograd. With few troops to spare on the front, Kerensky was forced to turn to the Petrograd Soviet for help. Bolsheviks, Mensheviks and Socialist Revolutionaries confronted the army and convinced them to stand down. The Bolsheviks' influence over railroad and telegraph workers also proved vital in stopping the movement of troops. The damage was already done, however. Right-wingers felt betrayed, and the left wing was resurgent.
With Kornilov defeated, the Bolsheviks' popularity with the soviets significantly increased. During and after the defeat of Kornilov, a mass turn of the soviets toward the Bolsheviks began, both in the central and local areas. On 31 August, the Petrograd Soviet of Workers and Soldiers Deputies, and on 5 September, the Moscow Soviet Workers Deputies adopted the Bolshevik resolutions on the question of power. The Bolsheviks won a majority in the Soviets of Briansk, Samara, Saratov, Tsaritsyn, Minsk, Kiev, Tashkent, and other cities.
Events.
On , the Bolsheviks' Central Committee voted 10-2 for a resolution saying that "an armed uprising is inevitable, and that the time for it is fully ripe".
On , Bolsheviks led their forces in the uprising in Petrograd (modern day Saint Petersburg), the capital of Russia, against the Kerensky Provisional Government. Leon Trotsky distributes arms to the Red Guards, which systematically captures major government facilities, key communication, installations and vantage points with little opposition. The Petrograd Garrison rebels against the Provisional Government, claiming that it is a "tool of the enemies of the people". For the most part, the revolt in Petrograd was bloodless, with the Red Guards led by Bolsheviks finally launching an assault on the poorly defended Winter Palace.
The official Soviet version of events follows: An assault led by Vladimir Lenin was launched at 9:45p.m. signaled by a blank shot from the cruiser "Aurora". (The "Aurora" was placed in Petrograd and still stands there now.) The Winter Palace was guarded by Cossacks, cadets (military students), and a Women's Battalion. It was taken at about 2a.m. The earlier date was made the official date of the Revolution, when all offices except the Winter Palace had been taken.
More contemporary research with access to government archives significantly corrects accepted Soviet edited and embellished history. The archival version shows that parties of Bolshevik operatives sent out from the Smolny by Lenin took over all critical centers of power in Petrograd in the early hours of the first night without a shot being fired. This was completed so efficiently that the takeover resembled the changing of the guard. The capture of the Winter Palace was more dramatic, with the Red Guards storming the Winter Palace at 2:10a.m. on the night of . The Cossacks deserted when the Red Guard approached, and the Cadets and the 140 volunteers of the Women's Battalion surrendered rather than resist the 40000 strong army. The "Aurora" was commandeered to then fire blanks at the palace in a symbolic act of rejection of the government. In fact the effectively unoccupied Winter Palace fell not because of acts of courage or a military barrage, but because the back door was left open, allowing the Red Guard to enter. A Red Guard named Adamovich remembered gasping as he burst into the palace, as he had never before seen such luxury and splendour. A small group broke in, got lost in the cavernous interior, and accidentally happened upon the remnants of Kerensky's provisional government in the imperial family's breakfast room. The illiterate revolutionaries then compelled those arrested to write up their own arrest papers. The Provisional Government was arrested and imprisoned in Peter and Paul Fortress after the ministers resigned to fate and surrendered without a fight, and officially overthrown. The stories of the "defense of the Winter Palace" and the heroic "Storming of the Winter Palace" came later as the creative propaganda product of Bolshevik publicists. Grandiose paintings depicting the "Women's Battalion" and photo stills taken from Sergei Eisenstein's staged film depicting the "politically correct" version of the October events in Petrograd came to be taken as truth. With the Government Petrograd Soviet now in control of government, garrison and proletariat, the Second All Russian Congress of Soviets held its opening session on the day, while Trotsky dismisses the opposing Mensheviks and the Socialist Revolutionaries (SR) from Congress.
Some sources contend that as the leader of Tsentrobalt, Pavlo Dybenko actually played an enormous role in the revolt. It is said that the ten warships that entered the city with ten thousand Baltic fleet mariners was the force that actually took the power in Petrograd and put down the Provisional Government. The same mariners then dispersed by force the elected parliament of Russia, and used machine-gun fire against protesting demonstrators in Petrograd. About a hundred demonstrators were killed, and several hundreds were wounded. Dybenko in his memoirs mentioned this event as "several shots in the air". Later, during the first hours after the taking the Winter Palace, Dybenko personally entered the Ministry of Justice and destroyed there the documents concerning the financing of the Bolshevik party by Germany. These are disputed by various sources such as Louise Bryant, who claims that news outlets in the west at the time reported that the unfortunate loss of life occurred in Moscow not Petrograd and the number was much less than is suggested above. As for the "several shots in the air", there is little evidence suggesting otherwise. The alleged action of Dybenko entering the Ministry of Justice to destroy documents as recalled by Savchenko can also be challenged. According to reports, Pavel Dybenko was in Helsingfors organizing the sailors' departures for Petrograd. From the book Radio October...On the “Krechet” in Helsingfors, radio operator Makarov hands a telegram to Pavel Dybenko with the report of the “Samson” commissar, Grigoriy Borisov: “To Tsentrobalt. Everything is calm in Petrograd. The power is in the hands of the revolutionary committee. You have to immediately get in touch with the front committee of the Northern Army in order to preserve unity of forces and stability."
Later official accounts of the revolution from the Soviet Union would depict the events in October as being far more dramatic than they actually had been. (See firsthand account by British General Knox.) This was helped by the historical reenactment, entitled "The Storming of the Winter Palace", which was staged in 1920. This reenactment, watched by 100,000 spectators, provided the model for official films made much later, which showed a huge storming of the Winter Palace and fierce fighting (See Sergei Eisenstein's ""). In reality the Bolshevik insurgents faced little or no opposition. The insurrection was timed and organized to hand state power to the Second All-Russian Congress of Soviets of Workers' and Soldiers' Deputies, which began on 25 October. After a single day of revolution eighteen people had been arrested and two had been killed.
Outcomes.
The Second Congress of Soviets consisted of 670 elected delegates; 300 were Bolshevik and nearly a hundred were Left Socialist-Revolutionaries, who also supported the overthrow of the Alexander Kerensky Government. When the fall of the Winter Palace was announced, the Congress adopted a decree transferring power to the Soviets of Workers', Soldiers' and Peasants' Deputies, thus ratifying the Revolution.
The transfer of power was not without disagreement. The center and Right wings of the Socialist Revolutionaries as well as the Mensheviks believed that Lenin and the Bolsheviks had illegally seized power and they walked out before the resolution was passed. As they exited, they were taunted by Leon Trotsky who told them "You are pitiful isolated individuals; you are bankrupts; your role is played out. Go where you belong from now on — into the dustbin of history!"
The following day, , the Congress elected a Council of People's Commissars (Sovnarkom) with Lenin as leader as the basis of a new Soviet Government, pending the convocation of a Constituent Assembly, and passed the Decree on Peace and the Decree on Land. This new government was also officially called "provisional" until the Assembly was dissolved. The Council of People's Commissars now began to arrest the leaders of opposition parties. Dozens of Constitutional Democratic Party (Kadet) leaders and members of the Constituent Assembly were imprisoned in The Peter and Paul Fortress. These were to be followed by the arrests of Socialist Revolutionary Party and Menshevik leaders.. Posters were pinned on walls and fences by the SRs describing the takeover as a "crime against the motherland and revolution". The is also strong anti-Bolshevik opposition within Petrograd.
On , the Mensheviks seize power of Georgia and declare it an independent republic. The Don Cossacks also claim control of their own government. There is strong anti-Bolshevik opposition outside of Petrograd, with Bolshevik control of country still very weak. There are also reports that the Provisional Government has not conceded defeat and are meeting with the army at the Front.
On , posters and newspapers start criticizing the actions of the Bolsheviks and refute their authority. The Executive Committee of Peasants Soviets "refutes with indignation all participation of the organised peasantry in this criminal violation of the will of the working class". Strong opposition to the Bolsheviks still continues from several important proletariat sources.
On , opposition to the Bolsheviks develops into major counter-revolutionary action. Cossacks enter Tsarskoye Selo on outskirts of Petrograd with Kerensky riding on a white horse welcomed by church bells. Kerensky gave an ultimatum to the rifle garrison to lay down weapons, which was promptly refused. They were then fired upon by Kerensky’s Cossacks, which resulted in 8 deaths. This turned soldiers in Petrograd against Kerensky because he was just like the Tsarist regime. Kerensky’s failure to assume authority over troops described by John Reed as a ‘fatal blunder’ that signalled the final death of the government.
On , the battle against the anti-Bolsheviks continues. The Red Guard fights against Cossacks at Tsarskoye Selo, with the Cossacks breaking rank and fleeing, leaving their artillery behind.
On , the Bolsheviks gain control of Moscow after a week of bitter street-fighting. Artillery had been freely used with an estimated 700 casualties. However, there is still continued support for Kerensky in the provinces.
On , there is an appeal to anti-Bolsheviks throughout Russia to join new government of the people, with the Bolsheviks gradually winning the support of the Russian people.
On , there is only minor public anti-Bolshevik sentiment; for example, the newspaper Novaya Zhizn criticises the lack of manpower and organisation of the Bolsheviks to run a party, let alone a government. Lenin confidently claims that there is "not a shadow of hesitation in the masses of Petrograd, Moscow and the rest of Russia" towards Bolshevik rule.
On 20 December 1917 the Cheka was created by the decree of Vladimir Lenin. These were the beginnings of the Bolsheviks' consolidation of power over their political opponents. The Red Terror was started in September 1918. The Jacobin Terror was an example for the Soviet Bolsheviks. Leon Trotsky has compared Lenin with Maximilien Robespierre yet in 1904.
The Decree on Land ratified the actions of the peasants who throughout Russia seized private land and redistributed it among themselves. The Bolsheviks viewed themselves as representing an alliance of workers and peasants and memorialized that understanding with the Hammer and Sickle on the flag and coat of arms of the Soviet Union.
Other decrees:
Bolshevik-led attempts to seize power in other parts of the Russian Empire were largely successful in Russia proper — although the fighting in Moscow lasted for two weeks — but they were less successful in ethnically non-Russian parts of the Empire, which had been clamoring for independence since the February Revolution. For example, the Ukrainian Rada, which had declared autonomy on 23 June 1917, created the Ukrainian People's Republic on 20 November, which was supported by the Ukrainian Congress of Soviets. This led to an armed conflict with the Bolshevik government in Petrograd and, eventually, a Ukrainian declaration of independence from Russia on 25 January 1918. In Estonia, two rival governments emerged: the Estonian Provincial Assembly proclaimed itself the supreme legal authority of Estonia on 28 November 1917 and issued the Declaration of Independence on 24 February 1918, while an Estonian Bolshevik sympathizer, Jaan Anvelt, was recognized by Lenin's government as Estonia's leader on 8 December, although forces loyal to Anvelt controlled only the capital.
The success of the October Revolution transformed the Russian state into a soviet republic. A coalition of anti-Bolshevik groups attempted to unseat the new government in the Russian Civil War from 1918 to 1922.
In an attempt to intervene in the civil war after the Bolsheviks' separate peace with the Central Powers, the Allied powers (United Kingdom, France, United States and Japan) occupied parts of the Soviet Union for over two years before finally withdrawing . The United States did not recognize the new Russian government until 1933. The European powers recognized the Soviet Union in the early 1920s and began to engage in business with it after the New Economic Policy (NEP) was implemented.
Historiography.
Few events in historical research have been as conditioned by political influences as the October Revolution. The historiography of the Revolution generally divides into three camps: the Soviet-Marxist view, the Western-Totalitarian view, and the Revisionist view.
Soviet historiography.
Soviet historiography of the October Revolution is intertwined with Soviet historical development. Many of the initial Soviet interpreters of the Revolution were themselves Bolshevik revolutionaries. After the initial wave of revolutionary narratives, Soviet historians worked within "narrow guidelines" defined by the Soviet government. The rigidity of interpretive possibilities reached its height under Joseph Stalin.
Soviet historians of the October Revolution interpreted the Revolution so as to establish the legitimacy of Marxist ideology, and also the Bolshevik regime. To establish the accuracy of Marxist ideology, Soviet historians generally described the Revolution as the product of class struggle. They maintained that the Revolution was the supreme event in a world history governed by historical laws. The Bolshevik Party is placed at the center of the Revolution, exposing the errors of both the moderate Provisional Government and the spurious "socialist" Mensheviks in the Petrograd Soviet. Guided by Vladimir Lenin's leadership and his firm grasp of scientific Marxist theory, the Party led the "logically predetermined" events of the October Revolution from beginning to end. The events were, according to these historians, logically predetermined because of the socio-economic development of Russia, where the monopoly industrial capitalism alienated the masses. In this view, the Bolshevik party took the leading role in organizing these alienated industrial workers, and thereby established the construction of the first socialist state.
Although Soviet historiography of the October Revolution stayed relatively constant until 1991, it did undergo some changes. Following Stalin’s death, historians such as E. N. Burdzhalov and P. V. Volobuev published historical research that deviated significantly from the party line in refining the doctrine that the Bolshevik victory "was predetermined by the state of Russia’s socio-economic development". These historians, who comprised the "New Directions Group", posited that the complex nature of the October Revolution "could only be explained by a multi-causal analysis, not by recourse to the mono-causality of monopoly capitalism". For them, the central actor is still the Bolshevik party, but this party triumphed "because it alone could solve the preponderance of ‘general democratic’ tasks the country faced" (such as the struggle for peace, the exploitation of landlords, and so on.)
During the late Soviet period, the opening of select Soviet archives during glasnost sparked innovative research that broke away from some aspects of Marxism–Leninism, though the key features of the orthodox Soviet view remained intact.
Western historiography.
During the Cold War, Western historiography of the October Revolution developed in direct response to the assertions of the Soviet view. The Soviet version of the October Revolution conditioned historical interpretations in the United States and the West. As a result, these Western historians exposed what they considered flaws in the Soviet view, thereby undermining the Bolsheviks' original legitimacy, as well as the precepts of Marxism.
These Western historians presented the revolution as the result of a chain of contingent accidents. Examples of these accidental and contingent factors that precipitated the Revolution include World War I's timing, chance, and the poor leadership of Tsar Nicholas II as well as liberal and moderate socialists. According to this historical interpretation, it was not popular support, but rather Bolshevik manipulation of the masses and the organization’s ruthlessness and superior structure which enabled it to survive. For these historians, the Bolsheviks’ defeat in the Constituent Assembly elections of November–December 1917 demonstrated popular opposition to the Bolsheviks’ coup, as did the scale and breadth of the Civil War.
These historians saw the organization of the Bolshevik party as proto-totalitarian. Their interpretation of the October Revolution as a violent coup organized by a proto-totalitarian party reinforced the idea that totalitarianism is an inherent part of Soviet history. For them, Stalinist totalitarianism developed as a natural progression from Leninism and the Bolshevik party’s tactics and organization.
Impact of the dissolution of the USSR on historical research.
The dissolution of the USSR had an impact on historical interpretations of the October Revolution. Since 1991, increasing access to large amounts of Soviet archival materials made it possible to re‑examine the October Revolution. Though both Western and Russian historians now have access to many of these archives, the impact of the dissolution of the USSR can be seen most clearly in the work of historians in the former USSR. While the disintegration essentially helped solidify the Western and Revisionist views, post-USSR Russian historians largely repudiated the former Soviet historical interpretation of the Revolution. As Stephen Kotkin argues, 1991 prompted "a return to political history and the apparent resurrection of totalitarianism, the interpretive view that, in different ways…revisionists sought to bury". There has additionally been the revival among some historians of the "continuity thesis", the idea that there was an uncomplicated, natural evolution from the October Revolution’s organizational structure to Stalin’s Gulags.
Legacy.
The term "Red October" (Красный Октябрь, Krasnyy Oktyabr) has also been used to describe the events of the month. This name has in turn been lent to a steel factory made notable by the Battle of Stalingrad, a Moscow sweets factory that is well known in Russia, and a fictional Soviet submarine.
"Ten Days That Shook the World", a book written by American journalist John Reed and first published in 1919, gives a firsthand exposition of the events. Reed died in 1920, shortly after the book was finished.
Dmitri Shostakovich wrote his Symphony No. 2 in B major, Op. 14 and subtitled "To October", for the 10th anniversary of the October Revolution. The choral finale of the work, "To October", is set to a text by Alexander Bezymensky, which praises Lenin and the revolution. The Symphony No. 2 was first performed by the Leningrad Philharmonic Orchestra and the Academy Capella Choir under the direction of Nikolai Malko, on 5 November 1927.
Sergei Eisenstein and Grigori Aleksandrov's film "", first released on 20 January 1928 in the USSR and on 2 November 1928 in New York City, describes and glorifies the revolution and was commissioned to commemorate the event.
7 November, the anniversary of the October Revolution, was the official national day of the Soviet Union from 1918 onward and still is a public holiday in Belarus, Kyrgyzstan, and the breakaway territory of Transnistria.
The October revolution of 1917 also marks the inception of the first communist government in Russia, and thus the first large-scale socialist state in world history. After this Russia became the Russian SFSR and later part of the USSR, which dissolved in late 1991.

</doc>
<doc id="22665" url="https://en.wikipedia.org/wiki?curid=22665" title="Opole Voivodeship">
Opole Voivodeship

Opole Voivodeship, or Opole Province ( ), is a Polish voivodeship, or province, The province's name derives from that of the region's capital and largest city, Opole. It is part of Silesia. A relatively large German minority lives in the voivodeship, with representatives in the Sejm.
Opole Voivodeship is bordered by Lower Silesian Voivodeship to the west, Greater Poland and Łódź Voivodeships to the north, Silesian Voivodeship to the east, and the Czech Republic to the south.
Opole Province's geographic location, economic potential, and its population's level of education make it an attractive business partner for other Polish regions (especially Lower Silesian and Silesian Voivodeships) and for foreign investors. Formed in 1997, the Praděd/Pradziad Euroregion has facilitated economic, cultural and tourist exchanges between the border areas of Poland and the Czech Republic.
Geography.
The voivodeship lies in southwestern Poland, the major part on the Silesian Lowland (). To the east, the region touches upon the Silesian Upland (Silesian Uplands, ) with the famous Saint Anne Mountain; the Sudetes range, the Opawskie Mountains, lies to the southwest. The Oder River cuts across the middle of the voivodeship. The northern part of the voivodeship, along the Mała Panew River, is densely forested, while the southern part consists of arable land.
History.
Opole Voivodeship was created on January 1, 1999, out of the former Opole Voivodeship and parts of Częstochowa Voivodeship, pursuant to the Polish local government reforms adopted in 1998.
Originally, the government, advised by prominent historians, had wanted to disestablish Opolskie and partition its territory between the more historically Polish regions of Lower Silesia and Silesia. The plan was that Brzeg and Namysłów, as the Western part of the region, were to be transferred to Lower Silesia, while the rest was to become, along with a part of the Częstochowa Voivodeship, an integral part of the new 'Silesian' region. However, the plans resulted in an outcry from the German minority population of Opole Voivodeship, who feared that should their region be abolished, they would lose all hope of regional representation (in the proposed Silesian Region, they would have formed a very small minority among a great number of ethnic Poles). To the surprise of many of the ethnic Germans in Opole however, the local Polish Silesian population and groups of ethnic Poles also rose up to oppose the planned reforms; this came about as a result of an overwhelming feeling of attachment to the voivodeships that were scheduled to be 'redrawn', as well as a fear of 'alienation' should one find themselves residing in a new, unfamiliar region.
The solution came in late 1999, when Olesno was, after 24 years apart, finally reunited with the Opole Voivodeship to form the new legally defined region. A historic moment came in 2006 when the town of Radłów changed its local laws to make German, alongside Polish, the district's second official language; thus becoming the first town in the region to achieve such a feat.
Demographics.
The Opole Voivodeship is the smallest region in the administrative makeup of the country in terms of both area and population. 
About 15% of the one million inhabitants of this voivodeship are ethnic Germans, which constitutes 90% of all ethnic Germans in Poland. As a result, many areas are officially bilingual in Opolskie, and the German language and culture play a significant role in education in the region. 
Tourism.
The Opole voivodeship is a green region with three large lakes: Turawskie, Nyskie, and Otmuchowskie (the latter two are connected). The Opawskie Mountains are extremely popular. The region also includes the castle in Brzeg, built during the reign of the Piast dynasty—pearl of the Silesian Renaissance, the Franciscan monastery on top of Saint Anne Mountain, as well as the medieval defence fortifications in Paczkow (referred to as the Polish Carcassonne).
The region has the warmest climate in the country.
Protected areas in Opole Voivodeship include the following three areas designated as Landscape Parks:
Transportation.
The transport route from Germany to Ukraine runs through Opole. The region has four border crossings, and direct rail connections to all important Polish cities, as well as to Frankfurt, Munich, Budapest, Kiev, and the Baltic ports.
Cities and towns.
The voivodeship contains 35 cities and towns. These are listed below in descending order of population (according to official figures for 2006):
Administrative division.
Opole Voivodeship is divided into 12 counties (powiats): 1 city county and 11 land counties. These are further divided into 71 gminas.
The counties are listed in the following table (ordering is by decreasing population).
Economy.
The Opole voivodeship is an industrial as well as an agricultural region. With respect to mineral resources, of major importance are deposits of raw materials for building: limestone (Strzelce Opolskie), marl (near Opole), marble, and basalt. The favourable climate, fertile soils, and high farming culture contribute to the development of agriculture, which is among the most productive in the country.
A total of nineteen industries are represented in the voivodeship. The most important are cement and lime, furniture, food, car manufacturing, and chemical industries. In 1997, the biggest production growth in the area was in companies producing wood and wood products, electrical equipment, machinery and appliances, as well as cellulose and paper products. In 1997, the top company in the region was Zakłady Azotowe S.A. in Kędzierzyn-Koźle, whose income was over PLN 860 million. The voivodship's economy consists of more than 53,000 businesses, mostly small and medium-sized, employing over 332,000 people. Manufacturing companies employ over 89,000 people; 95.7% of all the region's business operate in the private sector.
Universities.
There are three state-run universities in the region: the Opole University, the Opole University of Technology, and the State Medical College. All of them are based in the voivodeship's capital. Among the region's private schools, the Opole School of Management and Administration has been certified as a degree-granting institution by the Ministry of National Education.
Previous Opole voivodeships.
Opole Voivodeship was also a unit of administrative division and local government in Poland between 1975 and 1998.
Major cities and towns (population in 1995):
Opole Voivodeship (1950–1975).
This administrative region of the People's Republic of Poland (1950–1975) was created as a result of the partition of Katowice Voivodeship in 1950.

</doc>
<doc id="22666" url="https://en.wikipedia.org/wiki?curid=22666" title="Old Norse">
Old Norse

Old Norse was a North Germanic language that was spoken by inhabitants of Scandinavia and inhabitants of their overseas settlements during about the 9th to 13th centuries.
The Proto-Norse language developed into Old Norse by the 8th century, and Old Norse began to develop into the modern North Germanic languages in the mid- to late 14th century, ending the language phase known as Old Norse. These dates, however, are not absolute, since written Old Norse is found well into the 15th century.
Old Norse was divided into three dialects: Old East Norse, Old West Norse, and Old Gutnish. Old West and East Norse formed a dialect continuum, with no clear geographical boundary between them. For example, Old East Norse traits were found in eastern Norway, although Old Norwegian is classified as Old West Norse, and Old West Norse traits were found in western Sweden. Most speakers spoke Old East Norse in what is present day Denmark and Sweden. Old Gutnish, the more obscure dialectal branch, is sometimes included in the Old East Norse dialect due to geographical associations. It developed its own unique features and shared in changes to both other branches.
The 12th-century Icelandic "Gray Goose Laws" state that Swedes, Norwegians, Icelanders and Danes spoke the same language, "dǫnsk tunga" ("Danish tongue"; speakers of Old East Norse would have said "dansk tunga"). Another commonly used term with reference to West Norse, was "norrœnt mál" ("Nordic speech"). Today Old Norse has developed into the modern North Germanic languages Icelandic, Faroese, Norwegian, Danish and Swedish, of which Norwegian, Danish and Swedish retain considerable mutual intelligibility.
In some instances the term "Old Norse" refers specifically to Old West Norse.
Geographical distribution.
Old Icelandic was basically identical to Old Norwegian, and together they formed the Old West Norse dialect of Old Norse, which was also spoken in settlements in Ireland, Scotland, the Isle of Man and north-west England, and Norwegian settlements in Normandy. The Old East Norse dialect was spoken in Denmark, Sweden, settlements in Kievan Rus', eastern England, and Danish settlements in Normandy. The Old Gutnish dialect was spoken in Gotland and in various settlements in the East. In the 11th century, Old Norse was the most widely spoken European language, ranging from Vinland in the West to the Volga in the East. In Kievan Rus', it survived the longest in Novgorod, probably lasting into the 13th century there. The age of the Swedish language's presence in Finland is strongly contested (see Swedish-speaking Finns), but at latest by the time of the Second Swedish Crusade in the 13th century, Swedish settlement spread the language into the region.
Modern descendants.
The modern descendants of the Old West Norse dialect are the West Scandinavian languages of Icelandic, Faroese, Norwegian and the extinct Norn language of the Orkney and the Shetland Islands; the descendants of the Old East Norse dialect are the East Scandinavian languages of Danish and Swedish. Norwegian is descended from Old West Norse, but over the centuries it has been heavily influenced by East Norse, particularly during the Denmark–Norway union.
Among these, Icelandic and the closely related Faroese have changed the least from Old Norse in the last thousand years, although with Danish rule of the Faroe Islands, Faroese has also been influenced by Danish. Old Norse also had an influence on English dialects and Lowland Scots, which contain many Old Norse loanwords. It also influenced the development of the Norman language, and through it and to a smaller extent, that of modern French.
Various other languages, which are not closely related, have been heavily influenced by Norse, particularly the Norman dialects, Scottish Gaelic and Waterford Irish. Russian, Belarusian, Lithuanian, Finnish, Latvian and Estonian also have a number of Norse loanwords; the words "Rus" and "Russia", according to one theory, may be named after the Rus' people, a Norse tribe; "see Rus (name)", probably from present-day east-central Sweden. The current Finnish and Estonian words for Sweden are "Ruotsi" and "Rootsi", respectively.
Of the modern languages, Icelandic is the closest to Old Norse. Written modern Icelandic derives from the Old Norse phonemic writing system. Contemporary Icelandic-speakers can read Old Norse, which varies slightly in spelling as well as semantics and word order. However, pronunciation, particularly of the vowel phonemes, has changed at least as much as in the other North Germanic languages.
Faroese retains many similarities but is influenced by Danish, Norwegian, and Gaelic (Scottish and/or Irish). Although Swedish, Danish and the Norwegian languages have diverged the most, they still retain asymmetric mutual intelligibility. Speakers of modern Swedish, Norwegian and Danish can mostly understand each other without studying their neighboring languages, particularly if speaking slowly. The languages are also sufficiently similar in writing that they can mostly be understood across borders. This could be because these languages have been mutually affected by each other, as well as having a similar development influenced by Middle Low German.
Phonology.
Vowels.
The vowel phonemes mostly come in pairs of long and short. The standardized orthography marks the long vowels with an acute accent. In medieval manuscripts, it is often unmarked but sometimes marked with an accent or through gemination. All phonemes have, more or less, the expected phonetic realization.
Old Norse had nasalized versions of all nine vowel places. These occurred as allophones of the vowels before nasal consonants and in places where a nasal had followed it in an older form of the word, before it was absorbed into a neighboring sound. If the nasal was absorbed by a stressed vowel, it would also lengthen the vowel. These nasalizations also occurred in the other Germanic languages, but were not retained long. They were noted in the First Grammatical Treatise, and otherwise might have remained unknown. The First Grammarian marked these with a dot above the letter. This notation did not catch on, and would soon be obsolete. Nasal and oral vowels probably merged around the 11th century in most of Old East Norse.:3 However, the distinction still holds in Dalecarlian dialects.:4 The dots in the following vowel table separate the oral from nasal phonemes.
Note: The low/low-mid vowels may be indicated differently:
Sometime around the 13th century, Ǫ () merged with Ø or O in all dialects except Old Danish. In Icelandic, all Ǫ merged with Ø. This can be determined by their distinction within the 12th-century First Grammatical Treatise but not within the early 13th-century Prose Edda. The nasals, also noted in the First Grammatical Treatise, are assumed to have been lost by this time. See Old Icelandic for the Œ > Æ and Ę > E mergers.
Consonants.
Old Norse has six plosive phonemes. Of these is rare word-initially and and are realized as voiced fricative allophones between vowels, except in compound words (e.g. veðrabati), already in the Proto-Germanic language (e.g. "*b" > [v] between vowels). The phoneme is realized as after an "n" or another "g" and as before and . It is realized as a voiced velar fricative , by some accounts inside words, and by others between vowels (and otherwise as ). The Old East Norse /ʀ/ was an apical consonant whose position isn't precisely known, being reconstructed as a palatal sibilant:2. It descended from Proto-Germanic and eventually developed into , as it already had done in Old West Norse.
The consonant digraphs "hl", "hr", "hn" occurred word-initially. It is unclear whether they were sequences of two consonants (with the first element realised as or perhaps ), or as single voiceless sonorants , and respectively. In Old Norwegian, Old Danish and later Old Swedish the groups "hl", "hr", "hn" were reduced to plain "l", "r", "n", suggesting that they were most likely realised as voiceless sonorants by Old Norse times.
The pronunciation of "hv" is unclear, and may have been (the Proto-Germanic pronunciation), or . Unlike the other three groups above, it was retained much longer in all dialects, and never developed into a voiceless sonorant in Icelandic, but instead "hardened" to a plosive . This suggests that it was not a voiceless sonorant, but retained stronger frication.
Orthography.
Unlike Proto-Norse, which was written with the Elder Futhark, runic Old Norse was originally written with the Younger Futhark, which only had 16 letters. Because of the limited number of runes, the rune for the vowel "u" was also used for the vowels "o", "ø" and "y", and the rune for "i" was used for "e". Medieval runes came into use some time later.
As for the Latin alphabet, there was no standardized orthography in use in the Middle Ages. A modified version of the letter wynn called vend was used briefly for the sounds , , and . Long vowels were sometimes marked with acutes, but also sometimes left unmarked or geminated. The standardized Old Norse spelling was created in the 19th century, and is for the most part phonemic. The most notable deviation is that the non-phonemic difference between the voiced and the voiceless dental fricative is marked — the oldest texts as well as runic inscriptions use "þ" exclusively. Long vowels are denoted with acutes. Most other letters are written with the same glyph as the IPA phoneme, except as shown in the table below.
Accent.
Primary stress in Old Norse falls on the word stem, so that "hyrjar" would be pronounced . In compound words, secondary stress falls on the second stem (e.g. "lærisveinn", ).:1
Modern Swedish, Danish, and Norwegian have two registers reflected in differing pronunciation of the stressed syllable of words. In Swedish and Norwegian, the registers are reflected in different tones (i.e. through tonal word accent), while in Danish the difference is the presence or absence of "stød", a glottal gesture considered a kind of creaky voice that seems to have been documented by Swedish sources as early as the 16th century. What is here called "class 1" is reflected as tone 1 in Norwegian, acute accent in Swedish, and presence of "stød" in Danish, whereas "class 2" words have tone 2 in Norwegian, grave accent in Swedish, and no "stød" in Danish. No sign of any tonal system is found in Icelandic or Faroese.
Not all cognates occur in the same register classes in all three languages, partly due to language-specific restrictions on the contexts in which the two classes can occur. For example, "stød" can only occur in stressed words that have long vowels and end in a voiced consonant, whereas in Swedish and Norwegian, monosyllables can only take tone 1/acute accent. In general, however, class 1 words are those that are monosyllabic in Old Norse, while class 2 words are those that are polysyllabic. Exceptions, including minimal pairs, have arisen for various reasons:
Phonological processes.
Ablaut.
Ablaut patterns are groups of vowels which are swapped, or ablauted, in the nucleus of a word. Strong verbs ablaut the lemma's nucleus to derive the past forms of the verb. This parallels English conjugation, where, e.g., the nucleus of "sing" becomes "sang" in the past tense and "sung" in the past participle. Some verbs are derived by ablaut, as the present-in-past verbs do by consequence of being derived from the past tense forms of strong verbs.
Umlaut.
Umlaut or mutation is an assimilatory process acting on vowels preceding a vowel or semivowel of a different vowel backness. In the case of i-umlaut and ʀ-umlaut, this entails a fronting of back vowels, with retention of lip rounding. In the case of u-umlaut, this entails labialization of unrounded vowels. Umlaut is phonemic and in many situations grammatically significant as a side effect of losing the Proto-Germanic morphological suffixes whose vowels created the umlaut allophones.
Some , , , , , , , and were obtained by i-umlaut from , , , , , , , and respectively. Others were formed via ʀ-umlaut from , , , , and .
Some , , , , and all , were obtained by u-umlaut from , , , , and , respectively. See Old Icelandic for information on .
 was obtained through a simultaneous u- and i-umlaut of . It appears in words like gøra (gjǫra, geyra), from Proto-Germanic *garwijaną, and commonly in verbs with a velar consonant before the suffix like søkkva < *sankwijaną.
OEN often preserves the original value of the vowel directly preceding runic "ʀ" while OWN receives ʀ-umlaut. Compare runic OEN "glaʀ, haʀi, hrauʀ" with OWN "gler, heri" (later "héri"), "hrøyrr/hreyrr" ("glass", "hare", "pile of rocks").
U-umlaut.
U-umlaut is more common in Old West Norse in both phonemic and allophonic positions, while it only occurs sparsely in post-runic Old East Norse and even in runic Old East Norse. Compare West Old Norse "fǫður" (accusative of "faðir", father), "vǫrðr" (guardian/caretaker), "ǫrn" (eagle), "jǫrð" (in Modern Icelandic: "jörð", earth), "mjǫlk" (in Modern Icelandic: "mjólk") with Old Swedish "faður", "varðer", "örn", "jorð" and Modern Swedish "örn", "jord", "mjölk" with the latter two demonstrating the u-umlaut found in Swedish.
This is still a major difference between Swedish and Faroese and Icelandic today. Plurals of neuters do not have u-umlaut at all in Swedish, but in Faroese and Icelandic they do, for example the Faroese and Icelandic plurals of the word "land": "lond" and "lönd" in contrast to the Swedish plural "land" and other numerous examples. That also applies to almost all feminine nouns, for example the largest feminine noun group, the o-stem nouns (except the Swedish noun "jord" mentioned above), and even i-stem nouns and rootnomina, such as Old West Norse "mǫrk" ("mörk" in Icelandic) in comparison with Modern and Old Swedish "mark".
Breaking.
Vowel breaking, or fracture, caused a front vowel to be split into a semivowel-vowel sequence before a back vowel in the following syllable. While West Norse only broke "e", East Norse also broke "i". The change was blocked by a "v", "l", or "r" preceding the potentially-broken vowel.:1
Some or and or result from breaking of and respectively.
Assimilation or elision of inflectional ʀ.
When a noun, pronoun, adjective, or verb has a long vowel or diphthong in the accented syllable and its stem ends in a single -l, -n, or -s, the -r (or the elder r- or z-variant ʀ) in an ending is assimilated. When the accented vowel is short, the ending is dropped.
The nominative of the strong masculine declension and some i-stem feminine nouns uses one such -r (ʀ). "Óðin"-"r" ("Óðin"-"ʀ") becomes "Óðinn" instead of "*Óðinr" ("*Óðinʀ"), but "karl"-r ("karl"-"ʀ") remains "karl".
"Blása", to blow, has "blæss" for "you blow" instead of "*blæsr" ("*blæsʀ").
The rule is not hard and fast, with counter-examples such as "vinr", which has the synonym "vin", yet retains the unabsorbed version, and "jǫtunn", where assimilation takes place even though the root vowel, Ǫ, is short.
Words with a final r in the word stem, such as "vetr", do not add another -r, as the sounds are already the same. The effect of the dropping usually results in the lack of distinction between some forms of the noun. In the case of "vetr" the dropping renders the nominative and accusative singular and plural identical; the nominative singular and nominative and accusative plural would otherwise have been "*vetrr" ("*vintrʀ"), while the accusative singular would still have been "vetr". This is because the 3rd strong masculine declension, to which it belongs, marks the nominative singular and nominative and accusative plural, but not the accusative singular, with inflectional Rs.
Phonotactics.
Blocking of ii, uu.
"I/j" adjacent to "i", "e", their u-umlauts, and "æ" was not possible, nor "u/v" adjacent to "u", "o", their i-umlauts, and ǫ. At the beginning of words, this manifested as a dropping of the initial "i/j" or "u/v". Compare ON "orð, úlfr" with English "word, wolf". In inflections, this manifested as the dropping of the inflectional vowels. Thus, "klæði" + ᴅᴀᴛ "-i" remains "klæði", and "sjáum" in Icelandic progressed to "sjǫ́um" > "sjǫ́m" > sjám. The "jj" and "vv" of Proto-Germanic became "ggj" and "ggw" respectively in Old Norse, a change known as Holtzmann's law.
Epenthesis.
An epenthetic vowel became popular by 1200 in Old Danish, 1250 in Old Swedish and Norwegian, and 1300 in Old Icelandic. An unstressed vowel was used which varied by dialect. Old Norwegian exhibited all three: /u/ was used in West Norwegian south of Bergen, as in "aftur", "aftor" (older aptr); North of Bergen, /i/ appeared in "aftir", "after"; and East Norwegian used /a/, "after", "aftær".
Syntax.
Old Norse had a freer word order than English. Old Norse used different listing structures than the English, "a, b and c," and, "a, b or c." In those two cases, Old Norse would have, "a and b and c," or, "a and b or c."
Grammar.
Old Norse was a moderately inflected language with high levels of nominal and verbal inflection. Most of the fused morphemes are retained in modern Icelandic, especially in regard to noun case declensions, whereas modern Norwegian in comparison has moved towards more analytical word structures.
Gender.
Old Norse had three grammatical genders – masculine, feminine or neuter. Adjectives or pronouns referring to a noun must mirror the gender of that noun, so that one says, "heill maðr!" but, "heilt barn!" Like in other languages, the grammatical gender of an impersonal noun is generally unrelated to an expected natural gender of that noun. While indeed "karl", "man" is masculine, "kona", "woman", is feminine, and "hús", house, is neuter, so also are "hrafn" and "kráka", for "raven" and "crow", masculine and feminine respectively, even in reference to a female raven or a male crow.
All neuter words have identical nominative and accusative forms, and all feminine words have identical nominative and accusative plurals.
The gender of some words' plurals does not agree with that of their singulars, such as "lim" and "mund". Some words, such as "hungr", have multiple genders, evidenced by their determiners being declined in different genders within a given sentence.
Hierarchy.
Old Norse inherited the Proto-Germanic feature of having neuter as the default gender. This means that when the gender of a noun is unknown, adjectives and pronouns referencing it use the neuter gender forms, rather than the masculine or feminine. Thus, if speaking or writing to a general audience, one would say "velkomit", "well is it come," rather than "velkominn" or "velkomin", "well is [he or she] come," as one does not know whether the person hearing it is going to be male or female.
One generally sees adjectives in their neuter form when used pronominally for this reason. For words more commonly used in this way (rather than to describe a noun) one sees their neuter forms more often than their masculine or feminine. Normally the masculine form would be the most beneficial form of an adjective to learn first, given that the majority of nouns are masculine. In these cases, however, the most practical form to learn first would be the neuter.
Morphology.
Nouns, adjectives and pronouns were declined in four grammatical cases — nominative, accusative, genitive and dative, in singular and plural numbers. Adjectives and pronouns were additionally declined in three grammatical genders. Some pronouns (first and second person) could have dual number in addition to singular and plural. The genitive is used partitively, and quite often in compounds and kennings (e.g.: "Urðarbrunnr", the well of Urðr; "Lokasenna", the gibing of Loki).
There were several classes of nouns within each gender, the following is an example of the "strong" inflectional paradigms:
In addition to these examples there were the numerous "weak" noun paradigms, which had a much higher degree of syncretism between the different cases in its paradigms, i.e. they didn't have as many forms as the "strong" nouns.
A definite article was realised as a suffix, that retained an independent declension e.g. troll ("a troll") – trollit ("the troll"), hǫll (" a hall") – hǫllin ("the hall"), armr ("an arm") – armrinn ("the arm"). This definite article, however, was a separate word, and did not become attached to the noun before later stages of the Old Norse period.
Texts.
The earliest inscriptions in Old Norse are runic, from the 8th century. Runes continued to be commonly used until the 15th century and have been recorded to be in use in some form as late as the 19th century in some parts of Sweden. With the conversion to Christianity in the 11th century came the Latin alphabet. The oldest preserved texts in Old Norse in the Latin alphabet date from the middle of the 12th century. Subsequently, Old Norse became the vehicle of a large and varied body of vernacular literature, unique in medieval Europe. Most of the surviving literature was written in Iceland. Best known are the Norse sagas, the Icelanders' sagas and the mythological literature, but there also survives a large body of religious literature, translations into Old Norse of courtly romances, classical mythology, and the Old Testament, as well as instructional material, grammatical treatises and a large body of letters and official documents.
Dialects.
Most of the innovations that appeared in Old Norse spread evenly through the Old Norse area. As a result, the dialects were very similar and considered to be the same language, a language that they sometimes called the Danish tongue ("Dǫnsk tunga"), sometimes Norse language ("Norrœnt mál"), as evidenced in the following two quotes from Heimskringla by Snorri Sturluson:
"Móðir Dyggva var Drótt, dóttir Danps konungs, sonar Rígs er fyrstr var konungr kallaðr á danska tungu".
Dyggvi's mother was Drott, the daughter of king Danp, Ríg's son, who was the first to be called king in the Danish tongue.
"...stirt var honum norrœnt mál, ok kylfdi mᴊǫk til orðanna, ok hǫfðu margir menn þat mᴊǫk at spotti".
...the Norse language was hard for him, and he often fumbled for words, which amused people greatly.
However, some changes were geographically limited and so created a dialectal difference between Old West Norse and Old East Norse.
As Proto-Norse evolved into Old Norse, in the 8th century, the effects of the umlauts seem to have been very much the same over the whole Old Norse area. But in later dialects of the language a split occurred mainly between west and east as the use of umlauts began to vary. The typical umlauts (for example "fylla" from *"fullijan") were better preserved in the West due to later generalizations in the east where many instances of umlaut were removed (many archaic Eastern texts as well as eastern runic inscriptions however portray the same extent of umlauts as in later Western Old Norse).
All the while, the changes resulting in breaking (for example "hiarta" from *"hertō") were more influential in the East probably once again due to generalizations within the inflectional system. This difference was one of the greatest reasons behind the dialectalization that took place in the 9th and 10th centuries, shaping an Old West Norse dialect in Norway and the Atlantic settlements and an Old East Norse dialect in Denmark and Sweden.
Old West Norse and Old Gutnish did not take part in the monophthongization which changed "æi" ("ei") into "ē", "øy" ("ey") and "au" into "ø̄", nor did certain peripheral dialects of Swedish, as seen in modern Ostrobothnian. Another difference was that Old West Norse lost certain combinations of consonants. The combinations -"mp"-, -"nt"-, and -"nk"- were assimilated into -"pp"-, -"tt"- and -"kk"- in Old West Norse, but this phenomenon was limited in Old East Norse.
Here is a comparison between the two dialects as well as Old Gutnish. It is a transcription from one of the Funbo Runestones (U 990) meaning : "Veðr and Thane and Gunnar raised this stone after Haursi, their father. God help his spirit":
The OEN original text above is transliterated according to traditional scholarly methods, wherein u-umlaut is not regarded in runic Old East Norse. Modern studies have shown that the positions where it applies are the same as for runic Old West Norse. An alternative and probably more accurate transliteration would therefore render the text in OEN as such:
Some past participles and other words underwent i-umlaut in Old West Norse but not in Old East Norse dialects. Examples of that are Icalandic slegið/sleginn and tekið/tekinn, which in Swedish are slagit/slagen and tagit/tagen. This can also be seen in the Icelandic and Norwegian words sterkur and sterk ("strong"), which in Swedish is stark as in Old Swedish. These differences can also be seen in comparison between Norwegian and Swedish.
Old West Norse.
The combinations -mp-, -nt-, and -nk- mostly merged to -pp-, -tt- and -kk- in Old West Norse at around the 7th century, marking the first distinction between the Eastern and Western dialects.:3 The following table illustrates this (Note the influence of East-West Norse on each other) :
An early difference between Old West Norse and the other dialects was that Old West Norse had the forms "bú" ‘dwelling’, "kú" ‘cow’ (accusative) and "trú" ‘faith’ whereas Old East Norse had "bó", "kó" and "tró". Old West Norse was also characterized by the preservation of "u"-umlaut, which meant that for example Proto-Norse *"tanþu" ‘tooth’ was pronounced "tǫnn" and not "tann" as in post-runic Old East Norse; OWN "gǫ́s" and runic OEN "gǫ́s", while post-runic OEN "gás" ‘goose’.
The earliest body of text appears in runic inscriptions and in poems composed ca 900 by Þjóðólfr of Hvinir. The earliest manuscripts are from the period 1150–1200 and concern both legal, religious and historical matters. During the 12th and 13th centuries, Trøndelag and Western Norway were the most important areas of the Norwegian kingdom and they shaped Old West Norse as an archaic language with a rich set of declensions. In the body of text that has come down to us from until ca 1300, Old West Norse had little dialect variation, and Old Icelandic does not diverge much more than the Old Norwegian dialects do from each other.
Old Norwegian differentiated early from Old Icelandic by the loss of the consonant "h" in initial position before "l", "n" and "r", thus whereas Old Icelandic manuscripts might use the form "hnefi" "fist", Old Norwegian manuscripts might use "nefi".
From the late 13th century, Old Icelandic and Old Norwegian started to diverge more. After c. 1350, the Black Death and following social upheavals seem to have accelerated language changes in Norway. From the late 14th century, the language used in Norway is generally referred to as Middle Norwegian.
Old West Norse underwent a lengthening of initial vowels at some point, especially in Norwegian, so that OWN "eta" became "éta," ONW "akr" > "ákr", OIC "ek" > "ék".
Old Icelandic.
In Iceland, initial before was lost. Compare Icelandic "rangur" with Norwegian "vrangr", OEN "vrangʀ". This change is shared with Old Gutnish.
A specifically Icelandic sound, the long, u-umlauted A, spelled Ǫ́ and pronounced , developed circa the early 11th century. It was short-lived, being marked in the Grammatical Treatises and remaining until the end of the 12th century.
 merged with during the 12th century. This caused to become an independent phoneme from , and the written distinction of for from medial and final to become merely etymological.
Around the 13th century, Œ/Ǿ () merged to Æ (). Thus, pre-13th-century "grœnn" ‘green’ became modern Icelandic "grænn". The 12th-century Grágás manuscripts distinguish the vowels, and so the Codex Regius copy does as well. However, the 13th-century Codex Regius copy of the Poetic Edda probably relied on newer and/or poorer quality sources — Demonstrating either difficulty with or total lack of natural distinction, the manuscripts show separation of the two phonemes in some places, but frequently mix up the letters chosen to distinguish them in others.
Towards the end of the 13th century, Ę () merged to E ().
Old Norwegian.
Around the 11th century, Old Norwegian , , and became , , and . It is debatable whether the sequences represented a consonant cluster, , or a devoicing, .
Orthographic evidence suggests that, in a confined dialect of Old Norwegian, /ɔ/ may have been unrounded before /u/, so that u-umlaut was reversed where the "u" had not been eliminated. e.g. "ǫll", "ǫllum" > "ǫll", "allum".
Greenlandic Norse.
This dialect of Old West Norse was spoken by Icelandic colonies in Greenland. When the colonies died out around the 15th century, the dialect went with it. , and some merged to , so that Old Icelandic Þórðr becomes Tortr.
Text example.
The following text is from "Alexanders saga", an Alexander romance. The manuscript, AM 519 a 4to, is dated c. 1280. The facsimile demonstrates the sigla used by scribes to write Old Norse. Many of these were borrowed from Latin. Without familiarity with these abbreviations, the facsimile will be unreadable to many. In addition, reading the manuscript itself requires familiarity with the letterforms of the native script. The abbreviations are expanded in a version with normalized spelling like the standard normalization system's. Comparing this to the spelling of the same text in Modern Icelandic shows that, while pronunciation has changed greatly, spelling has changed little.
Old East Norse.
Old East Norse, between 800 and 1100, is in Sweden called "Runic Swedish" and in Denmark "Runic Danish". The use of "Swedish" and "Danish" is not for linguistic reasons as the differences between them are minute at best during the more ancient stages of this dialect group. Changes had a tendency to occur earlier in the Danish region and until this day many Old Danish changes have still not taken place in modern Swedish rendering Swedish as the more archaic out of the two concerning both the ancient and the modern languages, sometimes by a profound margin but in all differences are still minute. They are called "runic" because the body of text appears in runes.
Runic Old East Norse is characteristically archaic in form, especially Swedish (which is still true for modern Swedish compared to Danish). In essence it matches or surpasses the archaicness of post-runic Old West Norse which in its turn is generally more archaic than post-runic Old East Norse. While typically "Eastern" in structure, many later post-runic changes and trademarks of EON had yet to happen.
The phoneme "ʀ", which evolved during the Proto-Norse period from "z", was still clearly separated from "r" in most positions, even when being geminated, while in OWN it had already merged with "r".
Monophthongization of "æi > " and "øy, au > " started in mid-10th-century Denmark. Compare runic OEN: "fæigʀ", "gæiʀʀ", "haugʀ", "møydōmʀ", "diūʀ"; with Post-runic OEN: "fēgher", "gēr", "hø̄gher", "mø̄dōmber", "diūr"; OWN: "feigr", "geirr", "haugr", "meydómr", "dýr"; from PN *faigiaz, *gaizaz, *haugaz, *mawi- + dōmaz (maidendom; virginity), *diuza ((wild) animal).
Feminine o-stems often preserve the plural ending -aʀ while in OWN they more often merge with the feminine i-stems: (runic OEN) "*sōlaʀ", "*hafnaʀ"/"*hamnaʀ", "*vāgaʀ" while OWN "sólir", "hafnir" and "vágir" (modern Swedish "solar", "hamnar", "vågar"; suns, havens, scales; Danish has mainly lost the distinction between the two stems with both endings now being rendered as -er or -e alternatively for the o-stems).
Vice versa, masculine i-stems with the root ending in either "g" or "k" tended to shift the plural ending to that of the ja-stems while OWN kept the original: "drængiaʀ", "*ælgiaʀ" and "*bænkiaʀ" while OWN "drengir", "elgir" (elks) and "bekkir" (modern Swedish "drängar", "älgar", "bänkar").
The plural ending of ja-stems were mostly preserved while those of OWN often acquired that of the i-stems: "*bæðiaʀ", "*bækkiaʀ", "*væfiaʀ" while OWN "beðir" (beds), "bekkir", "vefir" (modern Swedish "bäddar", "bäckar", "vävar").
Old Danish.
Until the early 12th century, Old East Norse was very much a uniform dialect. It was in Denmark that the first innovations appeared that would differentiate Old Danish from Old Swedish:3 as these innovations spread north unevenly (unlike the earlier changes that spread more evenly over the East Norse area) creating a series of isoglosses going from Zealand to Svealand.
In Old Danish, merged with during the 9th century. From the 11th to 14th centuries, the unstressed vowels -"a", -"o" and -"e" (standard normalization -"a", -"u" and -"i") started to merge into -"ə", represented with the letter "e". This vowel came to be epenthetic, particularly before "-ʀ" endings. At the same time, the voiceless stop consonants "p", "t" and "k" became voiced plosives and even fricative consonants. Resulting from these innovations, Danish has "kage" (cake), "tunger" (tongues) and "gæster" (guests) whereas (Standard) Swedish has retained older forms, "kaka", "tungor" and "gäster" (OEN "kaka", "tungur", "gæstir").
Moreover, the Danish pitch accent shared with Norwegian and Swedish changed into "stød" around this time.
Old Swedish.
At the end of the 10th and early 11th century initial "h-" before "l", "n" and "r" was still preserved in the middle and northern parts of Sweden, and is sporadically still preserved in some northern dialects as "g-", e.g. "gly" (lukewarm), from "hlýʀ". The Dalecarlian dialects developed as Old Swedish dialects and as such can be considered separate languages from Swedish.
Text example.
This is an extract from "Västgötalagen", the Westrogothic law. It is the oldest text written as a manuscript found in Sweden and from the 13th century. It is contemporaneous with most of the Icelandic literature. The text marks the beginning of Old Swedish as a distinct dialect.
Dræpær maþar svænskan man eller smalenskæn, innan konongsrikis man, eigh væstgøskan, bøte firi atta ørtogher ok þrettan markær ok ænga ætar bot. […] Dræpar maþær danskan man allæ noræn man, bøte niv markum. Dræpær maþær vtlænskan man, eigh ma frid flyia or landi sinu oc j æth hans. Dræpær maþær vtlænskæn prest, bøte sva mykit firi sum hærlænskan man. Præstær skal i bondalaghum væræ. Varþær suþærman dræpin ællær ænskær maþær, ta skal bøta firi marchum fiurum þem sakinæ søkir, ok tvar marchar konongi.
If someone slays a Swede or a Smålander, a man from the kingdom, but not a West Geat, he will pay eight örtugar (20-pence coins) and thirteen marks, but no weregild. […] If someone slays a Dane or a Norwegian, he will pay nine marks. If someone slays a foreigner, he shall not be banished and have to flee to his clan. If someone slays a foreign priest, he will pay as much as for a fellow countryman. A priest counts as a freeman. If a Southerner is slain or an Englishman, he shall pay four marks to the plaintiff and two marks to the king.
Old Gutnish.
Due to Gotland's early isolation from the mainland, many features of Old Norse did not spread from or to the island, and Old Gutnish developed as an entirely separate branch from Old East and West Norse. For example, the diphthong "ai" in "aigu", "þair" and "waita" was not retroactively umlauted to "ei" as in e.g. Old Icelandic "eigu", "þeir" and "veita". Breaking was especially active in Old Gutnish, leading to forms such as "bjera" and "bjauþa", mainland "bera" and "bjúþa". Dropping of /w/ in initial /wɾ/ is shared only with Old Icelandic.
Text example.
The Gutasaga is the longest text surviving from Old Gutnish. It was written in the 13th century and dealt with the early history of the Gotlanders. This part relates to the agreement that the Gotlanders had with the Swedish king sometime before the 9th century:
So gingu gutar sielfs wiliandi vndir suia kunung þy at þair mattin frir Oc frelsir sykia suiariki j huerium staþ. vtan tull oc allar utgiftir. So aigu oc suiar sykia gutland firir vtan cornband ellar annur forbuþ. hegnan oc hielp sculdi kunungur gutum at waita. En þair wiþr þorftin. oc kallaþin. sendimen al oc kunungr oc ierl samulaiþ a gutnal þing senda. Oc latta þar taka scatt sinn. þair sendibuþar aighu friþ lysa gutum alla steþi til sykia yfir haf sum upsala kunungi til hoyrir. Oc so þair sum þan wegin aigu hinget sykia.
So, by their own will, the Gotlanders became the subjects of the Swedish king, so that they could travel freely and without risk to any location in the Swedish kingdom without toll and other fees. Likewise, the Swedes had the right to go to Gotland without corn restrictions or other prohibitions. The king was to provide protection and help, when they needed it and asked for it. The king and the jarl shall send emissaries to the Gutnish thing to receive the taxes. These emissaries shall declare free passage for the Gotlanders to all locations in the sea of the king at Uppsala (that is the Baltic Sea was under Swedish control) and likewise for everyone who wanted to travel to Gotland.
Relationship to other languages.
Relationship to English.
Old English and Old Norse were related languages. It is therefore not surprising that many words in Old Norse look familiar to English speakers (e.g., "armr" (arm), "fótr" (foot), "land" (land), "fullr" (full), "hanga" (to hang), "standa" (to stand)). This is because both English and Old Norse stem from a Proto-Germanic mother language. In addition, numerous common, everyday Old Norse words mainly of East Norse origin were adopted into the Old English language during the Viking age. A few examples of Old Norse loanwords in modern English are (English/Viking age Old East Norse):
In a simple sentence like "They are both weak" the extent of the Old Norse loanwords becomes quite clear (Old East Norse with archaic pronunciation: "Þæiʀ eʀu báðiʀ wæikiʀ" while Old English "híe syndon bégen (þá) wáce"). The words "they" and "weak" are both borrowed from Old Norse, and the word "both" might also be a borrowing, though this is disputed. While the number of loanwords adopted from the Norse was not as numerous as that of Norman French or Latin, their depth and everyday nature make them a substantial and very important part of every day English speech as they are part of the very core of the modern English vocabulary.
Words like "bull" and "Thursday" are more difficult when it comes to their origins. "Bull" may be from either Old English "bula" or Old Norse "buli", while "Thursday" may be a borrowing, or it could simply be from the Old English "Þunresdæg", which could have been influenced by the Old Norse cognate. The word "are" is from Old English "earun"/"aron", which stems back to Proto-Germanic as well as the Old Norse cognates.
Notes.
Cleasby-Vigfússon:

</doc>
<doc id="22667" url="https://en.wikipedia.org/wiki?curid=22667" title="Old English">
Old English

Old English ("Ænglisc, Anglisc, Englisc") or Anglo-Saxon is the earliest historical form of the English language, spoken in England and southern and eastern Scotland in the early Middle Ages. It was brought to Great Britain by Anglo-Saxon settlers probably in the mid 5th century, and the first Old English literary works date from the mid 7th century. After the Norman Conquest of 1066, English was replaced for a time as the language of the upper classes by Anglo-Norman, a relative of French, and Old English developed into the next historical form of English, known as Middle English.
Old English developed from a set of Anglo-Frisian or North Sea Germanic dialects originally spoken by Germanic tribes traditionally known as the Angles, Saxons, and Jutes. As the Anglo-Saxons became dominant in England, their language replaced the languages of Roman Britain: Common Brittonic, a Celtic language, and Latin, brought to Britain by Roman invasion. Old English had four main dialects, associated with particular Anglo-Saxon kingdoms: Mercian, Northumbrian, Kentish and West Saxon. It was West Saxon that formed the basis for the literary standard of the later Old English period, although the dominant forms of Middle and Modern English would develop mainly from Mercian. The speech of eastern and northern parts of England was subject to strong Old Norse influence due to Scandinavian rule and settlement beginning in the 9th century.
Old English is one of the West Germanic languages, and its closest relatives are Old Frisian and Old Saxon. Like other old Germanic languages, it is very different from Modern English and difficult for Modern English speakers to understand without study. Old English grammar is quite similar to that of modern German: nouns, adjectives, pronouns, and verbs have many inflectional endings and forms, and word order is much freer. The oldest Old English inscriptions were written using a runic system, but from about the 9th century this was replaced by a version of the Latin alphabet.
History.
Old English was not static, and its usage covered a period of 700 years, from the Anglo-Saxon settlement of Britain in the 5th century to the late 11th century, some time after the Norman invasion.
Old English is a West Germanic language, developing out of Ingvaeonic (also known as North Sea Germanic) dialects from the 5th century. It came to be spoken over most of the territory of the Anglo-Saxon kingdoms which became the Kingdom of England. This included most of present-day England, as well as part of what is now southeastern Scotland, which for several centuries belonged to the Anglo-Saxon kingdom of Northumbria. Other parts of the island – Wales and most of Scotland – continued to use Celtic languages, except in the areas of Scandinavian settlements where Old Norse was spoken. Celtic speech also remained established in certain parts of England: Medieval Cornish was spoken all over Cornwall and in adjacent parts of Devon, while Cumbric survived perhaps to the 12th century in parts of Cumbria, and Welsh may have been spoken on the English side of the Anglo-Welsh border. Norse was also widely spoken in the parts of England which fell under Danish law.
Anglo-Saxon literacy developed after Christianisation in the late 7th century. The oldest surviving text of Old English literature is "Cædmon's Hymn", composed between 658 and 680. There is a limited corpus of runic inscriptions from the 5th to 7th centuries, but the oldest coherent runic texts (notably the Franks Casket) date to the 8th century. The Old English Latin alphabet was introduced around the 9th century.
With the unification of the Anglo-Saxon kingdoms (outside the Danelaw) by Alfred the Great in the later 9th century, the language of government and literature became standardised around the West Saxon dialect (Early West Saxon). Alfred advocated education in English alongside Latin, and had many works translated into the English language; some of them, such as Pope Gregory I's treatise "Pastoral Care", appear to have been translated by Alfred himself.
A later literary standard, dating from the later 10th century, arose under the influence of Bishop Æthelwold of Winchester, and was followed by such writers as the prolific Ælfric of Eynsham ("the Grammarian"). This form of the language is known as the "Winchester standard", or more commonly as Late West Saxon. It is considered to represent the "classical" form of Old English. It retained its position of prestige until the time of the Norman Conquest, after which English ceased for a time to be of importance as a literary language.
The history of Old English can be subdivided into:
The Old English period is followed by Middle English (12th to 15th century), Early Modern English (c. 1480 to 1650) and finally Modern English (after 1650).
Dialects.
Old English should not be regarded as a single monolithic entity, just as Modern English is also not monolithic. It emerged over time out of the many dialects and languages of the colonising tribes, and it is perhaps only towards the later Anglo-Saxon period that these can be considered to have constituted a single national language. Even then, Old English continued to exhibit much local and regional variation, remnants of which remain in Modern English dialects.
The four main dialectal forms of Old English were Mercian, Northumbrian, Kentish, and West Saxon. Mercian and Northumbrian are together referred to as "Anglian".
Each of these four dialects was associated with an independent kingdom on the island. Of these, Northumbria south of the Tyne, and most of Mercia, were overrun by the Vikings during the 9th century. The portion of Mercia that was successfully defended, and all of Kent, were then integrated into Wessex under Alfred the Great.
From that time on, the West Saxon dialect (then in the form now known as Early West Saxon) became standardised as the language of government, and as the basis for the many works of literature and religious materials produced or translated from Latin in that period.
The later literary standard known as Late West Saxon (see History, above), although centred in the same region of the country, appears not to have been directly descended from Alfred's Early West Saxon. For example, the former diphthong /iy/ tended to become monophthongised to /i/ in EWS, but to /y/ in LWS.
Due to the centralisation of power and the Viking invasions, there is relatively little written record of the non-Wessex dialects after Alfred's unification. Some Mercian texts continued to be written, however, and the influence of Mercian is apparent in some of the translations produced under Alfred's programme, many of which were produced by Mercian scholars. Other dialects certainly continued to be spoken, as is evidenced by the continued variation between their successors in Middle and Modern English. In fact, what would become the standard forms of Middle English and of Modern English are descended from Mercian rather than West Saxon, while Scots developed from the Northumbrian dialect. It was once claimed that, owing to its position at the heart of the Kingdom of Wessex, the relics of Anglo-Saxon accent, idiom and vocabulary were best preserved in the dialect of Somerset.
For details of the sound differences between the dialects, see Phonological history of Old English (dialects).
Influence of other languages.
The language of the Anglo-Saxon settlers appears not to have been significantly affected by the native British Celtic languages which it largely displaced. The number of Celtic loanwords introduced into the language is very small. However, various suggestions have been made concerning possible influence that Celtic may have had on developments in English syntax in the post-Old English period, such as the regular progressive construction and analytic word order.
Old English contained a certain number of loanwords from Latin, which was the scholarly and diplomatic "lingua franca" of Western Europe. It is sometimes possible to give approximate dates for the borrowing of individual Latin words based on which patterns of sound change they have undergone. Some Latin words had already been borrowed into the Germanic languages before the ancestral Angles and Saxons left continental Europe for Britain. More entered the language when the Anglo-Saxons were converted to Christianity and Latin-speaking priests became influential. It was also through Irish Christian missionaries that the Latin alphabet was introduced and adapted for the writing of Old English, replacing the earlier runic system. Nonetheless, the largest transfer of Latin-based (mainly Old French) words into English occurred after the Norman Conquest of 1066, and thus in the Middle English rather than the Old English period.
Another source of loanwords was Old Norse, which came into contact with Old English via the Scandinavian rulers and settlers in the Danelaw from the late 9th century, and during the rule of Cnut and other Danish kings in the early 11th century. Many place-names in eastern and northern England are of Scandinavian origin. Norse borrowings are relatively rare in Old English literature, being mostly terms relating to government and administration. The literary standard, however, was based on the West Saxon dialect, away from the main area of Scandinavian influence; the impact of Norse may have been greater in the eastern and northern dialects. Certainly in Middle English texts, which are more often based on eastern dialects, a strong Norse influence becomes apparent. Modern English contains a great many, often everyday, words that were borrowed from Old Norse, and the grammatical simplification that occurred after the Old English period is also often attributed partly to Norse influence.
Phonology.
The inventory of classical Old English (Late West Saxon) surface phones, as usually reconstructed, is as follows.
The sounds enclosed in parentheses in the chart above are not considered to be phonemes:
The above system is largely similar to that of Modern English, except that (and for most speakers) have generally been lost, while the voiced affricate and fricatives (now also including ) have become independent phonemes, as has .
The mid front rounded vowels had merged into unrounded before the Late West Saxon period. During the 11th century such vowels arose again, as monophthongisations of the diphthongs , but quickly merged again with in most dialects.
The exact pronunciation of the West Saxon close diphthongs (spelt "ie") is disputed; it may have been . Other dialects may have had different systems of diphthongs; for example, Anglian dialects retained , which had merged with in West Saxon.
For more on dialectal differences, see Phonological history of Old English (dialects).
Sound changes.
Some of the principal sound changes occurring in the pre-history and history of Old English were the following:
For more details of these processes, see the main article, linked above. For sound changes before and after the Old English period, see Phonological history of English.
Grammar.
Morphology.
Unlike Modern English, Old English is a language rich in morphological diversity. It maintains several distinct cases: the nominative, accusative, genitive, dative and (vestigially) instrumental. The only remnants of this system in Modern English are in the forms of a few pronouns (such as "I/me/mine", "she/her", "who/whom/whose") and in the possessive ending "-'s", which derives from the old (masculine and neuter) genitive ending "-es". In Old English, however, nouns and their modifying words take appropriate endings depending on their case.
The modern English plural ending "-(e)s" derives from the Old English "-as", but the latter applied only to "strong" masculine nouns in the nominative and accusative cases; different plural endings were used in other instances. Besides singular and plural, the first- and second-person personal pronouns also retained dual forms, meaning "we (two)", "you (two)".
Old English nouns had grammatical gender, a feature absent in modern English, which uses only natural gender. For example, the words "sunne" ("sun"), "mōna" ("moon") and "wīf" ("woman/wife") were respectively feminine, masculine and neuter; this is reflected, among other things, in the form of the definite article used with these nouns: "sēo sunne" ("the sun"), "se mōna" ("the moon"), "þæt wīf" ("the woman/wife"). Pronoun usage could reflect either natural or grammatical gender, when those conflicted (as in the case of "wīf", a neuter noun referring to a female person).
The definite article "se" and its various forms could serve both as a definite article ("the") and a demonstrative adjective ("that"). Another demonstrative was "þes" ("this"). These words, like other adjectives, inflected for gender, number and case. Adjectives had both strong and weak sets of endings, the weak ones being used when a definite or possessive determiner was also present.
The form of the verb varies with person (first, second and third), number (singular and plural), tense (present and past), and mood (indicative, subjunctive and imperative). Old English also sometimes uses compound constructions to express other verbal aspects, the future and the passive voice; in these we see the beginnings of the compound tenses of Modern English. Old English verbs include strong verbs, which form the past tense by altering the root vowel, and weak verbs, which use a suffix such as "-de". Many modern English irregular verbs derive from Old English strong verbs, while the regular past ending "-ed" derives from the weak verb suffixes.
Syntax.
Old English syntax was similar in many ways to that of modern English. However, there were some important differences. Some were simply consequences of the greater level of nominal and verbal inflection, which meant that word order was generally freer. In addition:
Orthography.
Old English was first written in runes, using the futhorc – a rune set derived from the Germanic 24-character elder futhark, extended by five more runes used to represent Anglo-Saxon vowel sounds, and sometimes by several more additional characters. From around the 9th century, the runic system came to be supplanted by a (minuscule) half-uncial script of the Latin alphabet introduced by Irish Christian missionaries. This was replaced by insular script, a cursive and pointed version of the half-uncial script. This was used until the end of the 12th century when continental Carolingian minuscule (also known as "Caroline") replaced the insular.
The Latin alphabet of the time still lacked the letters and , and there was no as distinct from ; moreover native Old English spellings did not use , or . The remaining 20 Latin letters were supplemented by four more: ("æsc", modern "ash") and ("ðæt", now called eth or edh), which were modified Latin letters, and thorn and wynn , which are borrowings from the futhorc. A few letter pairs were used as digraphs, representing a single sound. Also used was the Tironian note (a character similar to the digit 7) for the conjunction "and", and a thorn with a crossbar through the ascender for the pronoun "þæt". Macrons over vowels were originally used not to mark long vowels (as in modern editions), but to indicate stress, or as abbreviations for a following "m" or "n".
Modern editions of Old English manuscripts generally introduce some additional conventions. The modern forms of Latin letters are used, including in place of the insular G, for long S, and others which may differ considerably from the insular script, notably , and . Macrons are used to indicate long vowels, where usually no distinction was made between long and short vowels in the originals. (In some older editions an acute accent mark was used for consistency with Old Norse conventions.) Additionally, modern editions often distinguish between velar and palatal and by placing dots above the palatals: , . The letter wynn is usually replaced with , but æsc, eth and thorn are normally retained (except when eth is replaced by thorn).
In contrast with Modern English orthography, that of Old English was reasonably regular, with a mostly predictable correspondence between letters and phonemes. There were not usually any silent letters – in the word "cniht", for example, both the and were pronounced, unlike the and in the modern "knight". The following table lists the Old English letters and digraphs together with the phonemes they represent, using the same notation as in the Phonology section above.
Doubled consonants are geminated; the geminate fricatives /, and cannot be voiced.
Literature.
Old English literature, though more abundant than literature of the continent before AD 1000 is nonetheless scant. In his supplementary article to the 1935 posthumous edition of Bright's "Anglo-Saxon Reader", Dr. James Hulbert writes:
Some of the most important surviving works of Old English literature are "Beowulf", an epic poem; the "Anglo-Saxon Chronicle", a record of early English history; the Franks Casket, an inscribed early whalebone artefact; and Cædmon's Hymn, a Christian religious poem. There are also a number of extant prose works, such as sermons and saints' lives, biblical translations, and translated Latin works of the early Church Fathers, legal documents, such as laws and wills, and practical works on grammar, medicine, and geography. Still, poetry is considered the heart of Old English literature. Nearly all Anglo-Saxon authors are anonymous, with a few exceptions, such as Bede and Cædmon.
"Beowulf".
The first example is taken from the opening lines of the epic poem "Beowulf". This passage describes how Hrothgar's legendary ancestor Scyld was found as a baby, washed ashore, and adopted by a noble family. The translation is literal and represents the original poetic word order. As such, it is not typical of Old English prose. The modern cognates of original words have been used whenever practical to give a close approximation of the feel of the original poem.
The words in brackets are implied in the Old English by noun case and the bold words in brackets are explanations of words that have slightly different meanings in a modern context. Notice how "what" is used by the poet where a word like "lo" or "behold" would be expected. This usage is similar to "what-ho!", both an expression of surprise and a call to attention.
English poetry is based on stress and alliteration. In alliteration, the first consonant in a word alliterates with the same consonant at the beginning of another word, as with Gār-Dena" and ġeār-dagum". Vowels alliterate with any other vowel, as with æþelingas" and ellen". In the text below, the letters that alliterate are bolded.
A semi-fluent translation in Modern English would be:
Lo! We have heard of majesty of the Spear-Danes, of those nation-kings in the days of yore, and how those noblemen promoted zeal. Scyld Scefing took away mead-benches from bands of enemies, from many tribes; he terrified earls. Since he was first found destitute (he gained consolation for that) he grew under the heavens, prospered in honours, until each of those who lived around him over the sea had to obey him, give him tribute. That was a good king!
The Lord's Prayer.
This text of the Lord's Prayer is presented in the standardised West Saxon literary dialect, with added macrons for vowel length, markings for probable palatalised consonants, modern punctuation, and the replacement of the letter wynn with w.
Charter of Cnut.
This is a proclamation from King Cnut the Great to his earl Thorkell the Tall and the English people written in AD 1020. Unlike the previous two examples, this text is prose rather than poetry. For ease of reading, the passage has been divided into sentences while the pilcrows represent the original division.
Revivals.
Like other historical languages, Old English has been used by scholars and enthusiasts of later periods to create texts either imitating Anglo-Saxon literature or deliberately transferring it to a different cultural context. Examples include Alistair Campbell and J. R. R. Tolkien. A number of websites devoted to Neo-Paganism and Historical re-enactment offer reference material and forums promoting the active use of Old English. By far the most ambitious project is the , but most of the Neo-Old English texts published online bear little resemblance to the historical model and are riddled with very basic grammatical mistakes.

</doc>
<doc id="22669" url="https://en.wikipedia.org/wiki?curid=22669" title="Open cluster">
Open cluster

An open cluster, also known as galactic cluster, is a group of up to a few thousand stars that were formed from the same giant molecular cloud and have roughly the same age. More than 1,100 open clusters have been discovered within the Milky Way Galaxy, and many more are thought to exist. They are loosely bound by mutual gravitational attraction and become disrupted by close encounters with other clusters and clouds of gas as they orbit the galactic center, resulting in a migration to the main body of the galaxy as well as a loss of cluster members through internal close encounters. Open clusters generally survive for a few hundred million years, with the most massive ones surviving for a few billion years. In contrast, the more massive globular clusters of stars exert a stronger gravitational attraction on their members, and can survive for longer. Open clusters have been found only in spiral and irregular galaxies, in which active star formation is occurring.
Young open clusters may still be contained within the molecular cloud from which they formed, illuminating it to create an H II region. Over time, radiation pressure from the cluster will disperse the molecular cloud. Typically, about 10% of the mass of a gas cloud will coalesce into stars before radiation pressure drives the rest of the gas away.
Open clusters are key objects in the study of stellar evolution. Because the cluster members are of similar age and chemical composition, their properties (such as distance, age, metallicity and extinction) are more easily determined than they are for isolated stars. A number of open clusters, such as the Pleiades, Hyades or the Alpha Persei Cluster are visible with the naked eye. Some others, such as the Double Cluster, are barely perceptible without instruments, while many more can be seen using binoculars or telescopes. The Wild Duck Cluster, M11, is an example.
Historical observations.
The prominent open cluster the Pleiades has been recognized as a group of stars since antiquity, while the Hyades forms part of Taurus, one of the oldest constellations. Other open clusters were noted by early astronomers as unresolved fuzzy patches of light. The Roman astronomer Ptolemy mentions the Praesepe, the Double Cluster in Perseus, and the Ptolemy Cluster, while the Persian astronomer Al-Sufi wrote of the Omicron Velorum cluster. However, it would require the invention of the telescope to resolve these nebulae into their constituent stars. Indeed, in 1603 Johann Bayer gave three of these clusters designations as if they were single stars.
The first person to use a telescope to observe the night sky and record his observations was the Italian scientist Galileo Galilei in 1609. When he turned the telescope toward some of the nebulous patches recorded by Ptolemy, he found they were not a single star, but groupings of many stars. For Praesepe, he found more than 40 stars. Where previously observers had noted only 6-7 stars in the Pleiades, he found almost 50. In his 1610 treatise "Sidereus Nuncius", Galileo Galilei wrote, "the galaxy is nothing else but a mass of innumerable stars planted together in clusters." Influenced by Galileo's work, the Sicilian astronomer Giovanni Hodierna became possibly the first astronomer to use a telescope to find previously undiscovered open clusters. In 1654, he identified the objects now designated Messier 41, Messier 47, NGC 2362 and NGC 2451.
It was realised as early as 1767 that the stars in a clusters were physically related, when the English naturalist Reverend John Michell calculated that the probability of even just one group of stars like the Pleiades being the result of a chance alignment as seen from Earth was just 1 in 496,000. Between 1774–1781, French astronomer Charles Messier published a catalogue of celestial objects that had a nebulous appearance similar to comets. This catalogue included 26 open clusters. In the 1790s, English astronomer William Herschel began an extensive study of nebulous celestial objects. He discovered that many of these features could be resolved into groupings of individual stars. Herschel conceived the idea that stars were initially scattered across space, but later became clustered together as star systems because of gravitational attraction. He divided the nebulae into eight classes, with classes VI through VIII being used to classify clusters of stars.
The number of clusters known continued to increase under the efforts of astronomers. Hundreds of open clusters were listed in the New General Catalogue, first published in 1888 by the Danish-Irish astronomer J. L. E. Dreyer, and the two supplemental Index Catalogues, published in 1896 and 1905. Telescopic observations revealed two distinct types of clusters, one of which contained thousands of stars in a regular spherical distribution and was found all across the sky but preferentially towards the centre of the Milky Way. The other type consisted of a generally sparser population of stars in a more irregular shape. These were generally found in or near the galactic plane of the Milky Way. Astronomers dubbed the former globular clusters, and the latter open clusters. Because of their location, open clusters are occasionally referred to as "galactic clusters", a term that was introduced in 1925 by the Swiss-American astronomer Robert Julius Trumpler.
Micrometer measurements of the positions of stars in clusters were made as early as 1877 by the German astronomer E. Schönfeld and further pursued by the American astronomer E. E. Barnard prior to his death in 1923. No indication of stellar motion was detected by these efforts. However, in 1918 the Dutch-American astronomer Adriaan van Maanen was able to measure the proper motion of stars in part of the Pleiades cluster by comparing photographic plates taken at different times. As astrometry became more accurate, cluster stars were found to share a common proper motion through space. By comparing the photographic plates of the Pleiades cluster taken in 1918 with images taken in 1943, van Maanen was able to identify those stars that had a proper motion similar to the mean motion of the cluster, and were therefore more likely to be members. Spectroscopic measurements revealed common radial velocities, thus showing that the clusters consist of stars bound together as a group.
The first color-magnitude diagrams of open clusters were published by Ejnar Hertzsprung in 1911, giving the plot for the Pleiades and Hyades star clusters. He continued this work on open clusters for the next twenty years. From spectroscopic data, he was able to determine the upper limit of internal motions for open clusters, and could estimate that the total mass of these objects did not exceed several hundred times the mass of the Sun. He demonstrated a relationship between the star colors and their magnitudes, and in 1929 noticed that the Hyades and Praesepe clusters had different stellar populations than the Pleiades. This would subsequently be interpreted as a difference in ages of the three clusters.
Formation.
The formation of an open cluster begins with the collapse of part of a giant molecular cloud, a cold dense cloud of gas and dust containing up to many thousands of times the mass of the Sun. These clouds have densities that vary from 102 to 106 molecules of neutral hydrogen per cm3, with star formation occurring in regions with densities above 104 molecules per cm3. Typically, only 1–10% of the cloud by volume is above the latter density. Prior to collapse, these clouds maintain their mechanical equilibrium through magnetic fields, turbulence, and rotation.
Many factors may disrupt the equilibrium of a giant molecular cloud, triggering a collapse and initiating the burst of star formation that can result in an open cluster. These include shock waves from a nearby supernova, collisions with other clouds, or gravitational interactions. Even without external triggers, regions of the cloud can reach conditions where they become unstable against collapse. The collapsing cloud region will undergo hierarchical fragmentation into ever smaller clumps, including a particularly dense form known as infrared dark clouds, eventually leading to the formation of up to several thousand stars. This star formation begins enshrouded in the collapsing cloud, blocking the protostars from sight but allowing infrared observation. In the Milky Way galaxy, the formation rate of open clusters is estimated to be one every few thousand years.
The hottest and most massive of the newly formed stars (known as OB stars) will emit intense ultraviolet radiation, which steadily ionizes the surrounding gas of the giant molecular cloud, forming an H II region. Stellar winds and radiation pressure from the massive stars begins to drive away the hot ionized gas at a velocity matching the speed of sound in the gas. After a few million years the cluster will experience its first core-collapse supernovae, which will also expel gas from the vicinity. In most cases these processes will strip the cluster of gas within ten million years and no further star formation will take place. Still, about half of the resulting protostellar objects will be left surrounded by circumstellar disks, many of which form accretion disks.
As only 30 to 40 per cent of the gas in the cloud core forms stars, the process of residual gas expulsion is highly damaging to the star formation process. All clusters thus suffer significant infant weight loss, while a large fraction undergo infant mortality. At this point, the formation of an open cluster will depend on whether the newly formed stars are gravitationally bound to each other; otherwise an unbound stellar association will result. Even when a cluster such as the Pleiades does form, it may only hold on to a third of the original stars, with the remainder becoming unbound once the gas is expelled. The young stars so released from their natal cluster become part of the Galactic field population.
Because most if not all stars form clustered, star clusters are to be viewed the fundamental building blocks of galaxies. The violent gas-expulsion events that shape and destroy many star clusters at birth leave their imprint in the morphological and kinematical structures of galaxies. Most open clusters form with at least 100 stars and a mass of 50 or more solar masses. The largest clusters can have 104 solar masses, with the massive cluster Westerlund 1 being estimated at 5 × 104 solar masses; close to that of a globular cluster. While open clusters and globular clusters form two fairly distinct groups, there may not be a great deal of difference in appearance between a very sparse globular cluster and a very rich open cluster. Some astronomers believe the two types of star clusters form via the same basic mechanism, with the difference being that the conditions that allowed the formation of the very rich globular clusters containing hundreds of thousands of stars no longer prevail in the Milky Way.
It is common for two or more separate open clusters to form out of the same molecular cloud. In the Large Magellanic Cloud, both Hodge 301 and R136 are forming from the gases of the Tarantula Nebula, while in our own galaxy, tracing back the motion through space of the Hyades and Praesepe, two prominent nearby open clusters, suggests that they formed in the same cloud about 600 million years ago. Sometimes, two clusters born at the same time will form a binary cluster. The best known example in the Milky Way is the Double Cluster of NGC 869 and NGC 884 (sometimes mistakenly called h and χ Persei; h refers to a neighboring star and χ to "both" clusters), but at least 10 more double clusters are known to exist. Many more are known in the Small and Large Magellanic Clouds—they are easier to detect in external systems than in our own galaxy because projection effects can cause unrelated clusters within the Milky Way to appear close to each other.
Morphology and classification.
Open clusters range from very sparse clusters with only a few members to large agglomerations containing thousands of stars. They usually consist of quite a distinct dense core, surrounded by a more diffuse 'corona' of cluster members. The core is typically about 3–4 light years across, with the corona extending to about 20 light years from the cluster centre. Typical star densities in the centre of a cluster are about 1.5 stars per cubic light year; the stellar density near the Sun is about 0.003 stars per cubic light year.
Open clusters are often classified according to a scheme developed by Robert Trumpler in 1930. The Trumpler scheme gives a cluster a three part designation, with a Roman numeral from I-IV indicating its concentration and detachment from the surrounding star field (from strongly to weakly concentrated), an Arabic numeral from 1 to 3 indicating the range in brightness of members (from small to large range), and "p", "m" or "r" to indication whether the cluster is poor, medium or rich in stars. An 'n' is appended if the cluster lies within nebulosity.
Under the Trumpler scheme, the Pleiades are classified as I3rn (strongly concentrated and richly populated with nebulosity present), while the nearby Hyades are classified as II3m (more dispersed, and with fewer members).
Numbers and distribution.
There are over 1,000 known open clusters in our galaxy, but the true total may be up to ten times higher than that. In spiral galaxies, open clusters are largely found in the spiral arms where gas densities are highest and so most star formation occurs, and clusters usually disperse before they have had time to travel beyond their spiral arm. Open clusters are strongly concentrated close to the galactic plane, with a scale height in our galaxy of about 180 light years, compared to a galactic radius of approximately 50,000 light years.
In irregular galaxies, open clusters may be found throughout the galaxy, although their concentration is highest where the gas density is highest. Open clusters are not seen in elliptical galaxies: star formation ceased many millions of years ago in ellipticals, and so the open clusters which were originally present have long since dispersed.
In our galaxy, the distribution of clusters depends on age, with older clusters being preferentially found at greater distances from the galactic centre, generally at substantial distances above or below the galactic plane. Tidal forces are stronger nearer the centre of the galaxy, increasing the rate of disruption of clusters, and also the giant molecular clouds which cause the disruption of clusters are concentrated towards the inner regions of the galaxy, so clusters in the inner regions of the galaxy tend to get dispersed at a younger age than their counterparts in the outer regions.
Stellar composition.
Because open clusters tend to be dispersed before most of their stars reach the end of their lives, the light from them tends to be dominated by the young, hot blue stars. These stars are the most massive, and have the shortest lives of a few tens of millions of years. The older open clusters tend to contain more yellow stars.
Some open clusters contain hot blue stars which seem to be much younger than the rest of the cluster. These blue stragglers are also observed in globular clusters, and in the very dense cores of globulars they are believed to arise when stars collide, forming a much hotter, more massive star. However, the stellar density in open clusters is much lower than that in globular clusters, and stellar collisions cannot explain the numbers of blue stragglers observed. Instead, it is thought that most of them probably originate when dynamical interactions with other stars cause a binary system to coalesce into one star.
Once they have exhausted their supply of hydrogen through nuclear fusion, medium- to low-mass stars shed their outer layers to form a planetary nebula and evolve into white dwarfs. While most clusters become dispersed before a large proportion of their members have reached the white dwarf stage, the number of white dwarfs in open clusters is still generally much lower than would be expected, given the age of the cluster and the expected initial mass distribution of the stars. One possible explanation for the lack of white dwarfs is that when a red giant expels its outer layers to become a planetary nebula, a slight asymmetry in the loss of material could give the star a 'kick' of a few kilometres per second, enough to eject it from the cluster.
Because of their high density, close encounters between stars in an open cluster are common. For a typical cluster with 1,000 stars with a 0.5 parsec half-mass radius, on average a star will have an encounter with another member every 10 million years. The rate is even higher in denser clusters. These encounters can have a significant impact on the extended circumstellar disks of material that surround many young stars. Tidal perturbations of large disks may result in the formation of massive planets and brown dwarfs, producing companions at distances of 100 AU or more from the host star.
Eventual fate.
Many open clusters are inherently unstable, with a small enough mass that the escape velocity of the system is lower than the average velocity of the constituent stars. These clusters will rapidly disperse within a few million years. In many cases, the stripping away of the gas from which the cluster formed by the radiation pressure of the hot young stars reduces the cluster mass enough to allow rapid dispersal.
Clusters that have enough mass to be gravitationally bound once the surrounding nebula has evaporated can remain distinct for many tens of millions of years, but over time internal and external processes tend also to disperse them. Internally, close encounters between stars can increase the velocity of a member beyond the escape velocity of the cluster. This results in the gradual 'evaporation' of cluster members.
Externally, about every half-billion years or so an open cluster tends to be disturbed by external factors such as passing close to or through a molecular cloud. The gravitational tidal forces generated by such an encounter tend to disrupt the cluster. Eventually, the cluster becomes a stream of stars, not close enough to be a cluster but all related and moving in similar directions at similar speeds. The timescale over which a cluster disrupts depends on its initial stellar density, with more tightly packed clusters persisting for longer. Estimated cluster half lives, after which half the original cluster members will have been lost, range from 150–800 million years, depending on the original density.
After a cluster has become gravitationally unbound, many of its constituent stars will still be moving through space on similar trajectories, in what is known as a stellar association, moving cluster, or moving group. Several of the brightest stars in the 'Plough' of Ursa Major are former members of an open cluster which now form such an association, in this case, the Ursa Major Moving Group. Eventually their slightly different relative velocities will see them scattered throughout the galaxy. A larger cluster is then known as a stream, if we discover the similar velocities and ages of otherwise unrelated stars.
Studying stellar evolution.
When a Hertzsprung-Russell diagram is plotted for an open cluster, most stars lie on the main sequence. The most massive stars have begun to evolve away from the main sequence and are becoming red giants; the position of the turn-off from the main sequence can be used to estimate the age of the cluster.
Because the stars in an open cluster are all at roughly the same distance from Earth, and were born at roughly the same time from the same raw material, the differences in apparent brightness among cluster members is due only to their mass. This makes open clusters very useful in the study of stellar evolution, because when comparing one star to another, many of the variable parameters are fixed.
The study of the abundances of lithium and beryllium in open cluster stars can give important clues about the evolution of stars and their interior structures. While hydrogen nuclei cannot fuse to form helium until the temperature reaches about 10 million K, lithium and beryllium are destroyed at temperatures of 2.5 million K and 3.5 million K respectively. This means that their abundances depend strongly on how much mixing occurs in stellar interiors. By studying their abundances in open cluster stars, variables such as age and chemical composition are fixed.
Studies have shown that the abundances of these light elements are much lower than models of stellar evolution predict. While the reason for this underabundance is not yet fully understood, one possibility is that convection in stellar interiors can 'overshoot' into regions where radiation is normally the dominant mode of energy transport.
Astronomical distance scale.
Determining the distances to astronomical objects is crucial to understanding them, but the vast majority of objects are too far away for their distances to be directly determined. Calibration of the astronomical distance scale relies on a sequence of indirect and sometimes uncertain measurements relating the closest objects, for which distances can be directly measured, to increasingly distant objects. Open clusters are a crucial step in this sequence.
The closest open clusters can have their distance measured directly by one of two methods. First, the parallax (the small change in apparent position over the course of a year caused by the Earth moving from one side of its orbit around the Sun to the other) of stars in close open clusters can be measured, like other individual stars. Clusters such as the Pleiades, Hyades and a few others within about 500 light years are close enough for this method to be viable, and results from the Hipparcos position-measuring satellite yielded accurate distances for several clusters.
The other direct method is the so-called moving cluster method. This relies on the fact that the stars of a cluster share a common motion through space. Measuring the proper motions of cluster members and plotting their apparent motions across the sky will reveal that they converge on a vanishing point. The radial velocity of cluster members can be determined from Doppler shift measurements of their spectra, and once the radial velocity, proper motion and angular distance from the cluster to its vanishing point are known, simple trigonometry will reveal the distance to the cluster. The Hyades are the best known application of this method, which reveals their distance to be 46.3 parsecs.
Once the distances to nearby clusters have been established, further techniques can extend the distance scale to more distant clusters. By matching the main sequence on the Hertzsprung-Russell diagram for a cluster at a known distance with that of a more distant cluster, the distance to the more distant cluster can be estimated. The nearest open cluster is the Hyades: the stellar association consisting of most of the Plough stars is at about half the distance of the Hyades, but is a stellar association rather than an open cluster as the stars are not gravitationally bound to each other. The most distant known open cluster in our galaxy is Berkeley 29, at a distance of about 15,000 parsecs. Open clusters are also easily detected in many of the galaxies of the Local Group.
Accurate knowledge of open cluster distances is vital for calibrating the period-luminosity relationship shown by variable stars such as cepheid stars, which allows them to be used as standard candles. These luminous stars can be detected at great distances, and are then used to extend the distance scale to nearby galaxies in the Local Group. Indeed, the open cluster designated NGC 7790 hosts three classical Cepheids. RR Lyrae variables are too old to be associated with open clusters, and are instead found in globular clusters.
Planets.
The open cluster NGC 6811 contains two known planetary systems Kepler 66 and Kepler 67.

</doc>
<doc id="22673" url="https://en.wikipedia.org/wiki?curid=22673" title="Orimulsion">
Orimulsion

Orimulsion is a registered trademark name for a bitumen-based fuel that was developed for industrial use by Intevep, the Research and Development Affiliate of Petroleos de Venezuela SA (PDVSA), following earlier collaboration on oil emulsions with BP.
Source of the bitumen.
Like coal and oil, bitumen occurs naturally and is obtained from the world's largest deposit in the Orinoco Belt in Venezuela. The deposit is estimated to be more than 1,200 billion barrels (190 billion m3) of bitumen, an amount approximately equivalent to the world's estimated proven oil reserves.
Preparation.
Raw bitumen has an extremely high viscosity and specific gravity between 8 to 10 API gravity, at ambient temperatures and is unsuitable for direct use in conventional power stations. Orimulsion is made by mixing the bitumen with about 30% fresh water and a small amount of surfactant. The result behaves similarly to fuel oil. An alcohol-based surfactant recently replaced the original phenol-based version; improving the transport properties of the fuel and eliminating the health concerns associated with the phenol group of surfactants.
Advantages.
As a fuel for electricity generation, Orimulsion has a number of attractive characteristics:
Disadvantages.
If there is a spill while shipping over water the mixture de-emulsifies and the bitumen drops out of suspension.
It is a non-Newtonian fluid, and if it is allowed to cool below 30 °C, it will 'set'. Pumping becomes impossible, and there is no way of restarting operations or the flow through the pipeline again.
Decreasing usage.
Orimulsion is currently used as a commercial boiler fuel in power plants worldwide ("e.g.", Canada, Japan, Lithuania, Italy and China). Use of fuel used to be much wider and demand was increasing. However, many of PDVSA's engineers were fired following the Venezuelan general strike of 2002–03. Orimulsion had been the pride of the PDVSA engineers, so Orimulsion fell out of favor with the key political leaders. As a result, the government is trying to "Wind Down" the Orimulsion program. The one exception is the sales of Orimulsion to China. The Venezuelan government has close ties to China, as it has with Cuba. The result is that China is still supplied with Orimulsion, while the rest of the world has either had their supplies terminated, or are still experiencing the "Wind Down" phase. Orimulsion still has excellent potential for domestic consumption.
Another reason given by current PDVSA management is that with rising crude oil prices, it has been found that mixing or diluting Orinoco bitumen (extra-heavy oil) with a lighter crude oil can make this blend more profitable as a crude oil on the world market than by selling it as Orimulsion. An example of this is the popular Merey blend (Orinoco bitumen and Mesa crude oil). ConocoPhillips along with PDVSA operate the Merey Sweeny (bpd) delayed coker, vacuum tower and related facilities at ConocoPhillips' refinery in Sweeny, Texas, U.S.A. for processing and upgrading heavy sour Merey crude oil. 
Air pollutant control technology that is commonly available can limit emissions from Orimulsion to levels considered "Best Available Control Technology", as defined by the United States Environmental Protection Agency.

</doc>
<doc id="22676" url="https://en.wikipedia.org/wiki?curid=22676" title="Oxfordian theory of Shakespeare authorship">
Oxfordian theory of Shakespeare authorship

The Oxfordian theory of Shakespeare authorship holds that Edward de Vere, 17th Earl of Oxford, wrote the plays and poems traditionally attributed to William Shakespeare. Though most literary scholars reject all alternative authorship candidates, including Oxford, popular interest in the Oxfordian theory continues. Since the 1920s, the Oxfordian theory has been the most popular alternative Shakespeare authorship theory.
The convergence of documentary evidence of the type used by academics for authorial attribution—title pages, testimony by other contemporary poets and historians, and official records—sufficiently establishes Shakespeare's authorship for the overwhelming majority of Shakespeare scholars and literary historians, and no evidence links Oxford to Shakespeare's works. Oxfordians, however, reject the historical record and often propose the conspiracy theory that the record was falsified to protect the identity of the real author, invoking the dearth of evidence for any conspiracy as evidence of its success. Scholars also note that interpreting the plays and poems as autobiographical, and then using them to construct a hypothetical author, is a method most literary specialists consider unreliable as far as attributive value.
Oxfordian arguments rely heavily on biographical allusions; adherents find correspondences between incidents and circumstances in Oxford's life and events in Shakespeare's plays, sonnets and longer poems. The case also relies on perceived parallels of language, idiom, and thought between Shakespeare's works and Oxford's own poetry and letters. Marked passages in Oxford's Bible have also been linked to biblical allusions in Shakespeare's plays. That no plays survive under Oxford's name is also important to the Oxfordian theory. Oxfordians interpret certain 16th- and 17th-century literary allusions as indicating that Oxford was one of the more prominent suppressed anonymous and/or pseudonymous writers of the day. Under this scenario, Shakespeare was either a "front man" or "play-broker" who published the plays under his own name or was merely an actor with a similar name, misidentified as the playwright since the first Shakespeare biographies of the early 1700s.
The most compelling evidence against the Oxfordian Theory is de Vere's death in 1604, since the generally accepted chronology of Shakespeare's plays places the composition of approximately twelve of the plays after that date. Oxfordian researchers respond that the annual publication of "new" or "corrected" Shakespeare plays stopped in 1604, and that the dedication to Shakespeare's Sonnets implies that the author was dead prior to their publication in 1609. Oxfordians believe the reason so many of the "late plays" show evidence of revision and collaboration is because they were completed by other playwrights after Oxford's death.
History of the Oxfordian theory.
The theory that the works of Shakespeare were in fact written by someone other than William Shakespeare dates back to the mid-nineteenth century. In 1857, the first book on the topic, "The Philosophy of the Plays of Shakspere Unfolded", by Delia Bacon, was published. Bacon proposed the first "group theory" of Shakespearian authorship, attributing the works to a committee headed by Francis Bacon and including Walter Raleigh. De Vere is mentioned once in the book, in a list of "high-born wits and poets", who were associated with Raleigh. Some commentators have interpreted this to imply that he was part of the group of authors. Throughout the 19th century Bacon was the preferred hidden author. Oxford is not known to have been mentioned again in this context.
By the beginning of the twentieth century other candidates, typically aristocrats, were put forward, most notably Roger Manners, 5th Earl of Rutland, and William Stanley, 6th Earl of Derby. Oxford's candidacy as sole author was first proposed by J. Thomas Looney in his 1920 book "Shakespeare Identified in Edward de Vere, 17th Earl of Oxford". Following earlier anti-Stratfordians, Looney argued that the known facts of Shakespeare's life did not fit the personality he ascribed to the author of the plays. Like other anti-Stratfordians before him, Looney referred to the absence of records concerning Shakespeare's education, his limited experience of the world, his allegedly poor handwriting skills (evidenced in his signatures), and the "dirt and ignorance" of Stratford at the time. Shakespeare had a petty "acquisitive disposition", he said, while the plays made heroes of free-spending figures. They also portrayed middle and lower-class people negatively, while Shakespearian heroes were typically aristocratic. Looney referred to scholars who found in the plays evidence that their author was an expert in law, widely read in ancient Latin literature, and could speak French and Italian. Looney believed that even very early works such as "Love's Labour's Lost" implied that he was already a person of "matured powers", in his forties or fifties, with wide experience of the world. Looney considered that Oxford's personality fitted that he deduced from the plays, and also identified characters in the plays as detailed portraits of Oxford's family and personal contacts. Several characters, including Hamlet and Bertram (in "All's Well that Ends Well"), were, he believed, self-portraits. Adapting arguments earlier used for Rutland and Derby, Looney fitted events in the plays to episodes in Oxford's life, including his travels to France and Italy, the settings for many plays. Oxford's death in 1604 was linked to a drop-off in the publication of Shakespeare plays. Looney declared that the late play "The Tempest" was not written by Oxford, and that others performed or published after Oxford's death were most probably left incomplete and finished by other writers, thus explaining the apparent idiosyncrasies of style found in the late Shakespeare plays. Looney also introduced the argument that the reference to the "ever-living poet" in the 1609 dedication to Shakespeare's sonnets implied that the author was dead at the time of publication.
Sigmund Freud, the novelist Marjorie Bowen, and several 20th-century celebrities found the thesis persuasive, and Oxford soon overtook Bacon as the favoured alternative candidate to Shakespeare, though academic Shakespearians mostly ignored the subject. Looney's theory attracted a number of activist followers who published books supplementing his own and added new arguments, most notably Percy Allen, Bernard M. Ward, Louis P. Bénézet and Charles Wisner Barrell. Mainstream scholar Stephen May has noted that Oxfordians of this period made genuine contributions to knowledge of Elizabethan history, citing "Ward's quite competent biography of the Earl" and "Charles Wisner Barrell's identification of Edward Vere, Oxford's illegitimate son by Anne Vavasour" as examples. In 1921, Sir George Greenwood, Looney, and others founded The Shakespeare Fellowship, an organization originally dedicated to the discussion and promotion of ecumenical anti-Stratfordian views, but which later became devoted to promoting Oxford as the true Shakespeare.
Decline and revival.
After a period of decline of the Oxfordian theory beginning with World War II, in 1952 Dorothy and Charlton Ogburn published the 1,300-page "This Star of England", which briefly revived Oxfordism. A series of critical academic books and articles, however, held in check any appreciable growth of anti-Stratfordism and Oxfordism, most notably "The Shakespeare Ciphers Examined" (1957), by William and Elizebeth Friedman, "The Poacher from Stratford" (1958), by Frank Wadsworth, "Shakespeare and His Betters" (1958), by Reginald Churchill, "The Shakespeare Claimants" (1962), by H. N. Gibson, and "Shakespeare and His Rivals: A Casebook on the Authorship Controversy" (1962), by George L. McMichael and Edgar M. Glenn. By 1968 the newsletter of The Shakespeare Oxford Society reported that "the missionary or evangelical spirit of most of our members seems to be at a low ebb, dormant, or non-existent". In 1974, membership in the society stood at 80. In 1979, the publication of an analysis of The Ashbourne portrait dealt a further blow to the movement. The painting, long claimed to be one of the portraits of Shakespeare, but considered by Barrell to be an overpaint of a portrait of the Earl of Oxford, turned out to represent neither, but rather depicted Hugh Hamersley.
Charlton Ogburn, Jr., was elected president of The Shakespeare Oxford Society in 1976 and kick-started the modern revival of the Oxfordian movement by seeking publicity through moot court trials, media debates, television, and later the Internet, including Wikipedia, methods which became standard for Oxfordian and anti-Stratfordian promoters because of their success in recruiting members of the lay public. He portrayed academic scholars as self-interested members of an "entrenched authority" that aimed to "outlaw and silence dissent in a supposedly free society", and proposed to counter their influence by portraying Oxford as a candidate on equal footing with Shakespeare. In 1985 he published his 900-page "The Mysterious William Shakespeare: the Myth and the Reality", and by framing the issue as one of fairness in the atmosphere of conspiracy that permeated America after Watergate, he used the media to circumnavigate academia and appeal directly to the public. Ogburn's efforts secured Oxford the place as the most popular alternative candidate.
Although Shakespearian experts disparaged Ogburn's methodology and his conclusions, one reviewer, Richmond Crinkley, the Folger Shakespeare Library's former director of educational programs, acknowledged the appeal of Ogburn's approach, writing that the doubts over Shakespeare, "arising early and growing rapidly", have a "simple, direct plausibility", and the dismissive attitude of established scholars only worked to encourage such doubts. Though Crinkley rejected Ogburn's thesis, calling it "less satisfactory than the unsatisfactory orthodoxy it challenges", he believed that one merit of the book lay in how it forces orthodox scholars to reexamine their concept of Shakespeare as author. Spurred by Ogburn's book, "[i]n the last decade of the twentieth century members of the Oxfordian camp gathered strength and made a fresh assault on the Shakespearean citadel, hoping finally to unseat the man from Stratford and install de Vere in his place."
The Oxfordian theory returned to wide public attention in anticipation of the late October 2011 release of Roland Emmerich's film "Anonymous". Its distributor, Sony Pictures, advertised that the film "presents a compelling portrait of Edward de Vere as the true author of Shakespeare's plays", and commissioned high school and college-level lesson plans to promote the authorship question to history and literature teachers across the United States. According to Sony Pictures, "The objective for our Anonymous program, as stated in the classroom literature, is 'to encourage critical thinking by challenging students to examine the theories about the authorship of Shakespeare's works and to formulate their own opinions.' The study guide does not state that Edward de Vere is the writer of Shakespeare's work, but it does pose the authorship question which has been debated by scholars for decades".
Variant Oxfordian theories.
Although most Oxfordians agree on the main arguments for Oxford, the theory has spawned schismatic variants that have not met with wide acceptance by all Oxfordians, although they have gained much attention.
Prince Tudor theory.
In a letter written by Looney in 1933, he mentions that Allen and Ward were "advancing certain views respecting Oxford and Queen Eliz. which appear to me extravagant & improbable, in no way strengthen Oxford’s Shakespeare claims, and are likely to bring the whole cause into ridicule." Allen and Ward believed that they had discovered that Elizabeth and Oxford were lovers and had conceived a child. Allen developed the theory in his 1934 book "Anne Cecil, Elizabeth & Oxford". He argued that the child was given the name William Hughes, who became an actor under the stage-name "William Shakespeare". He adopted the name because his father, Oxford, was already using it as a pen-name for his plays. Oxford had borrowed the name from a third Shakespeare, the man of that name from Stratford-upon-Avon, who was a law student at the time, but who was never an actor "or" a writer. Allen later changed his mind about Hughes and decided that the concealed child was the Earl of Southampton, the dedicatee of Shakespeare's narrative poems. This secret drama, which has become known as the Prince Tudor theory, was covertly represented in Oxford's plays and poems and remained hidden until Allen and Ward's discoveries. The narrative poems and sonnets had been written by Oxford for his son. "This Star of England" (1952) by Charlton and Dorothy Ogburn included arguments in support of this version of the theory. Their son, Charlton Ogburn, Jr, agreed with Looney that the theory was an impediment to the Oxfordian movement and omitted all discussion about it in his own Oxfordian works.
However, the theory was revived and expanded by Elisabeth Sears in "Shakespeare and the Tudor Rose" (2002), and Hank Whittemore in "The Monument" (2005), an analysis of Shakespeare's Sonnets which interprets the poems as a poetic history of Queen Elizabeth, Oxford, and Southampton. Paul Streitz's "Oxford: Son of Queen Elizabeth I" (2001) advances a variation on the theory: that Oxford himself was the illegitimate son of Queen Elizabeth by her stepfather, Thomas Seymour. Oxford was thus the half-brother of his own son by the queen. Streitz also believes that the queen had children by the Earl of Leicester. These were Robert Cecil, 1st Earl of Salisbury, Robert Devereux, 2nd Earl of Essex, Mary Sidney and Elizabeth Leighton.
Attribution of other works to Oxford.
As with other candidates for authorship of Shakespeare's works, Oxford's supporters have attributed numerous non-Shakespearian works to him. Looney began the process in his 1921 edition of de Vere's poetry. He suggested that de Vere was also responsible for some of the literary works credited to Arthur Golding, Anthony Munday and John Lyly. Streitz credits Oxford with the Authorized King James Version of the Bible. Two professors of linguistics have claimed that de Vere wrote not only the works of Shakespeare, but most of what is memorable in English literature during his lifetime, with such names as Edmund Spenser, Christopher Marlowe, Philip Sidney, John Lyly, George Peele, George Gascoigne, Raphael Holinshed, Robert Greene, Thomas Phaer, and Arthur Golding being among dozens of further pseudonyms of de Vere. Ramon Jiménez has credited Oxford with such plays as"The True Tragedy of Richard III" and "Edmund Ironside".
Group theories.
Group theories in which Oxford played the principal role as writer, but collaborated with others to create the Shakespeare canon, were adopted by a number of early Oxfordians. Looney himself was willing to concede that Oxford may have been assisted by his son-in-law William Stanley, 6th Earl of Derby, who perhaps wrote "The Tempest". B.M. Ward also suggested that Oxford and Derby worked together. In his later writings Percy Allen argued that Oxford led a group of writers, among whom was William Shakespeare. Group theories with Oxford as the principal author or creative "master mind" were also proposed by Gilbert Standen in "Shakespeare Authorship" (1930), Gilbert Slater in "Seven Shakespeares" (1931) and Montagu William Douglas in "Lord Oxford and the Shakespeare Group" (1952).
Case against Oxfordian theory.
Methodology of Oxfordian argument.
Specialists in Elizabethan literary history object to the methodology of Oxfordian arguments. In lieu of any evidence of the type commonly used for authorship attribution, Oxfordians discard the methods used by historians and employ other types of arguments to make their case, the most common being supposed parallels between Oxford's life and Shakespeare's works.
Another is finding cryptic allusions to Oxford's supposed play writing in other literary works of the era that to them suggest that his authorship was obvious to those "in the know". David Kathman writes that their methods are subjective and devoid of any evidential value, because they use a "double standard". Their arguments are "not taken seriously by Shakespeare scholars because they consistently distort and misrepresent the historical record", "neglect to provide necessary context" and calling some of their arguments "outright fabrication". One major evidential objection to the Oxfordian theory is Edward de Vere's 1604 death, after which a number of Shakespeare's plays are generally believed to have been written. In "The Shakespeare Claimants", a 1962 examination of the authorship question, H. N. Gibson concluded that "... on analysis the Oxfordian case appears to me a very weak one".
Mainstream objections.
Mainstream academics have often argued that the Oxford theory is based on snobbery: that anti-Stratfordians reject the idea that the son of a mere tradesman could write the plays and poems of Shakespeare. The Shakespeare Oxford Society has responded that this claim is "a substitute for reasoned responses to Oxfordian evidence and logic" and is merely an "ad hominem" attack, a charge echoed by journalists on both sides of the issue, including Michael Prescott and Joseph Sobran.
Mainstream critics further say that if William Shakespeare were a fraud instead of the true author, the number of people involved in suppressing this information would have made it highly unlikely to succeed. And citing the "testimony of contemporary writers, court records and much else" supporting Shakespeare's authorship, Columbia University professor James S. Shapiro points out the logically fatal tautology of any theory claiming that "there must have been a conspiracy to suppress the truth of de Vere's authorship" based on the idea that "the very absence of surviving evidence proves the case."
Circumstantial evidence.
While no documentary evidence connects Oxford (or any authorial candidate) to the plays of Shakespeare, Oxfordian writers, including Mark Anderson and Charlton Ogburn, say that connection is made by considerable circumstantial evidence inferred from Oxford's connections to the Elizabethan theatre and poetry scene; the participation of his family in the printing and publication of the First Folio; his relationship with the Earl of Southampton (believed by most Shakespeare scholars to have been Shakespeare's patron); as well as a number of specific incidents and circumstances of Oxford's life that Oxfordians say are depicted in the plays themselves.
Theatre connections.
Oxford was noted for his literary and theatrical patronage, garnering dedications from a wide range of authors. For much of his adult life, Oxford patronised both adult and boy acting companies, as well as performances by musicians, acrobats and performing animals, and in 1583, he was a leaseholder of the first Blackfriars Theatre in London.
Family connections.
Oxford was related to several noted literary figures. His mother, Margory Golding, was the sister of the Ovid translator Arthur Golding, and his uncle, Henry Howard, Earl of Surrey, was the inventor of the English or Shakespearian sonnet form.
The three dedicatees of Shakespeare's works (the earls of Southampton, Montgomery and Pembroke) were each proposed as husbands for the three daughters of Edward de Vere. "Venus and Adonis" and "The Rape of Lucrece" were dedicated to Southampton (whom many scholars have argued was the Fair Youth of the "Sonnets"), and the "First Folio" of Shakespeare's plays was dedicated to Montgomery (who married Susan de Vere) and Pembroke (who was once engaged to Bridget de Vere).
Oxford's Bible.
In the late 1990s, Roger A. Stritmatter conducted a study of the marked passages found in Edward de Vere's Geneva Bible, which is now owned by the Folger Shakespeare Library. The Bible contains 1,028 instances of underlined words or passages and a few hand-written annotations, most of which consist of a single word or fragment. Stritmatter believes about a quarter of the marked passages appear in Shakespeare's works as either a theme, allusion, or quotation. Stritmatter grouped the marked passages into eight themes. Arguing that the themes fitted de Vere's known interests, he proceeded to link specific themes to passages in Shakespeare. Critics have doubted that any of the underlinings or annotations in the Bible can be reliably attributed to de Vere and not the book's other owners prior to its acquisition by the Folger Shakespeare Library in 1925, as well as challenging the looseness of Stritmatter's standards for a Biblical allusion in Shakespeare's works and arguing that there is no statistical significance to the overlap.
Stratford connections.
Shakespeare's native Avon and Stratford are referred to in two prefatory poems in the 1623 First Folio, one of which refers to Shakespeare as "Swan of Avon" and another to the author's "Stratford monument". Oxfordians say the first of these phrases could refer to one of Edward de Vere's manors, Bilton Hall, near the Forest of Arden, in Rugby, on the River Avon. This view was first expressed by Charles Wisner Barrell, who argued that De Vere "kept the place as a literary hideaway where he could carry on his creative work without the interference of his father-in-law, Burghley, and other distractions of Court and city life." Oxfordians also consider it significant that the nearest town to the parish of Hackney, where de Vere later lived and was buried, was also named Stratford. Mainstream scholar Irvin Matus demonstrated that Oxford sold the Bilton house in 1580, having previously rented it out, making it unlikely that Ben Jonson's 1623 poem would identify Oxford by referring to a property he once owned, but never lived in, and sold 43 years earlier. Nor is there any evidence of a monument to Oxford in Stratford, London, or anywhere else; his widow provided for the creation of one at Hackney in her 1613 will, but there is no evidence that it was ever erected.
Oxford's annuity.
Oxfordians also believe that Rev. Dr. John Ward's 1662 diary entry stating that Shakespeare wrote two plays a year "and for that had an allowance so large that he spent at the rate of £1,000 a year" as a critical piece of evidence, since Queen Elizabeth I gave Oxford an annuity of exactly £1,000 beginning in 1586 that was continued until his death. Ogburn wrote that the annuity was granted "under mysterious circumstances", and Anderson suggests it was granted because of Oxford's writing patriotic plays for government propaganda. However, the documentary evidence indicates that the allowance was meant to relieve Oxford's embarrassed financial situation caused by the ruination of his estate.
Oxford's travels and the settings of Shakespeare's plays.
Almost half of Shakespeare's plays are set in Italy, many of them containing details of Italian laws, customs, and culture which Oxfordians believe could only have been obtained by personal experiences in Italy, and especially in Venice. The author of "The Merchant of Venice", Looney believed, "knew Italy first hand and was touched with the life and spirit of the country". This argument had earlier been used by supporters of the Earl of Rutland and the Earl of Derby as authorship candidates, both of whom had also travelled on the continent of Europe. Oxfordian William Farina refers to Shakespeare's apparent knowledge of the Jewish ghetto, Venetian architecture and laws in "The Merchant of Venice", especially the city's "notorious Alien Statute". Historical documents confirm that Oxford lived in Venice, and travelled for over a year through Italy. He disliked the country, writing in a letter to Lord Burghley dated 24 September 1575, "I am glad I have seen it, and I care not ever to see it any more". Still, he remained in Italy for another six months, leaving Venice in March 1576. According to Anderson, Oxford definitely visited Venice, Padua, Milan, Genoa, Palermo, Florence, Siena and Naples, and probably passed through Messina, Mantua and Verona, all cities used as settings by Shakespeare. In testimony before the Venetian Inquisition, Edward de Vere was said to be fluent in Italian.
However, some Shakespeare scholars say that Shakespeare gets many details of Italian life wrong, including the laws and urban geography of Venice. Kenneth Gross writes that "the play itself knows nothing about the Venetian ghetto; we get no sense of a legally separate region of Venice where Shylock must dwell." Scott McCrea describes the setting as "a nonrealistic Venice" and the laws invoked by Portia as part of the "imaginary world of the play", inconsistent with actual legal practice. Charles Ross points out that Shakespeare's Alien Statute bears little resemblance to any Italian law. For later plays such as "Othello", Shakespeare probably used Lewes Lewknor's 1599 English translation of Gasparo Contarini's "The Commonwealth and Government of Venice" for some details about Venice's laws and customs.
Shakespeare derived much of this material from John Florio, an Italian scholar living in England who was later thanked by Ben Jonson for helping him get Italian details right for his play "Volpone". Kier Elam has traced Shakespeare's Italian idioms in "Shrew" and some of the dialogue to Florio's "Second Fruits", a bilingual introduction to Italian language and culture published in 1591. Jason Lawrence believes that Shakespeare’s Italian dialogue in the play derives "almost entirely" from Florio’s "First Fruits"(1578). He also believes that Shakespeare became more proficient in reading the language as set out in Florio’s manuals, as evidenced by his increasing use of Florio and other Italian sources for writing the plays.
Oxford's education and knowledge of court life.
In 1567 Oxford was admitted to Gray's Inn, one of the Inns of Court which Justice Shallow reminisces about in "Henry IV, Part 2". Sobran observes that the Sonnets "abound not only in legal terms—more than 200—but also in elaborate legal conceits." These terms include: "allege, auditor, defects, exchequer, forfeit, heirs, impeach, lease, moiety, recompense, render, sureties," and "usage". Shakespeare also uses the legal term, "quietus" (final settlement), in Sonnet 134, the last Fair Youth sonnet.
Regarding Oxford's knowledge of court life, which Oxfordians believe is reflected throughout the plays, mainstream scholars say that any special knowledge of the aristocracy appearing in the plays can be more easily explained by Shakespeare's life-time of performances before nobility and royalty, and possibly, as Gibson theorises, "by visits to his patron's house, as Marlowe visited Walsingham."
Oxford's literary reputation.
Oxford's lyric poetry.
Some of Oxford's lyric works have survived. Stephen May, a leading authority on Oxford's poetry, attributes sixteen poems definitely and four possibly to Oxford, noting that these are probably "only a good sampling" as "both Webbe (1586) and Puttenham (1589) rank him first among the courtier poets, an eminence he probably would not have been granted, despite his reputation as a patron, by virtue of a mere handful of lyrics".
May describes Oxford as a "competent, fairly experimental poet working in the established modes of mid-century lyric verse" and his poetry as "examples of the standard varieties of mid-Elizabethan amorous lyric". In 2004, May wrote that Oxford's poetry was "one man's contribution to the rhetorical mainstream of an evolving Elizabethan poetic" and challenged readers to distinguish any of it from "the output of his mediocre mid-century contemporaries". C. S. Lewis wrote that de Vere's poetry shows "a faint talent", but is "for the most part undistinguished and verbose."
Comparisons to Shakespeare's work.
In the opinion of J. Thomas Looney, as "far as forms of versification are concerned De Vere presents just that rich variety which is so noticeable in Shakespeare; and almost all the forms he employs we find reproduced in the Shakespeare work." Oxfordian Louis P. Bénézet created the "Bénézet test", a collage of lines from Shakespeare and lines he thought were representative of Oxford, challenging non-specialists to tell the difference between the two authors. May notes that Looney compared various motifs, rhetorical devices and phrases with certain Shakespeare works to find similarities he said were "the most crucial in the piecing together of the case", but that Looney used six poems mistakenly attributed to Oxford that were actually written by Greene, Campion, and Greville for some of those "crucial" examples. Bénézet also used two lines from Greene that he thought were Oxford's, while succeeding Oxfordians, including Charles Wisner Barrell, have also misattributed poems to Oxford. "This on-going confusion of Oxford's genuine verse with that of at least three other poets," writes May, "illustrates the wholesale failure of the basic Oxfordian methodology."
According to a computerised textual comparison developed by the Claremont Shakespeare Clinic, the styles of Shakespeare and Oxford were found to be "light years apart", and the odds of Oxford having written Shakespeare were reported as "lower than the odds of getting hit by lightning". Furthermore, while the First Folio shows traces of a dialect identical to Shakespeare's, the Earl of Oxford, raised in Essex, spoke an East Anglian dialect. John Shahan and Richard Whalen, writing in "The Oxfordian" (volume IX, 2006), condemned the Claremont study, calling it "apples to oranges", and noting that the study did not compare Oxford's songs to Shakespeare's songs, did not compare a clean unconfounded sample of Oxford's poems with Shakespeare's poems, and charged that the students under Elliott and Valenza's supervision incorrectly assumed that Oxford's youthful verse was representative of his mature poetry.
Joseph Sobran's book, "Alias Shakespeare", includes Oxford's known poetry in an appendix with what he considers extensive verbal parallels with the work of Shakespeare, and he argues that Oxford's poetry is comparable in quality to some of Shakespeare's early work, such as "Titus Andronicus". Other Oxfordians say that de Vere's extant work is that of a young man and should be considered juvenilia, while May believes that all the evidence dates his surviving work to his early 20s and later.
Contemporary reception.
Four contemporary critics praise Oxford as a poet and a playwright, three of them within his lifetime:
Mainstream scholarship characterises the extravagant praise for de Vere's poetry more as a convention of flattery than honest appreciation of literary merit. Alan Nelson, de Vere's documentary biographer, writes that "[c]ontemporary observers such as Harvey, Webbe, Puttenham and Meres clearly exaggerated Oxford's talent in deference to his rank."
Perceived allusions to Oxford as a concealed writer.
Before the advent of copyright, anonymous and pseudonymous publication was a common practice in the sixteenth century publishing world, and a passage in the "Arte of English Poesie" (1589), an anonymously published work itself, mentions in passing that literary figures in the court who wrote "commendably well" circulated their poetry only among their friends, "as if it were a discredit for a gentleman to seem learned" (Book 1, Chapter 8). In another passage 23 chapters later, the author (probably George Puttenham) speaks of aristocratic writers who, if their writings were made public, would appear to be excellent. It is in this passage that Oxford appears on a list of poets.
According to Daniel Wright, these combined passages confirm that Oxford was one of the concealed writers in the Elizabethan court. Critics of this view argue that Oxford nor any other writer is not here identified as a concealed writer, but as the first in a list of "known" modern writers whose works have already been "made public", "of which number is first" Oxford, adding to the publicly acknowledged literary tradition dating back to Geoffrey Chaucer. Other critics interpret the passage to mean that the courtly writers and their works are known within courtly circles, but not to the general public. In either case, neither Oxford nor anyone else is identified as a hidden writer or one that used a pseudonym.
Oxfordians argue that at the time of the passage's composition (pre-1589), the writers referenced were not in print, and interpret Puttenham's passage (that the noblemen preferred to 'suppress' their work to avoid the discredit of appearing learned) to mean that they were 'concealed'. They cite Sir Philip Sidney, none of whose poetry was published until after his premature death, as an example. Similarly, by 1589 nothing by Greville was in print, and only one of Walter Raleigh's works had been published.
Critics point out that six of the nine poets listed had appeared in print under their own names long before 1589, including a number of Oxford's poems in printed miscellanies, and the first poem published under Oxford's name was printed in 1572, 17 years before Puttenham's book was published. Several other contemporary authors name Oxford as a poet, and Puttenham himself quotes one of Oxford's verses elsewhere in the book, referring to him by name as the author, so Oxfordians misread Puttenham.
Oxfordians also believe other texts refer to the Edward de Vere as a concealed writer. They argue that satirist John Marston's "Scourge of Villanie" (1598) contains further cryptic allusions to Oxford, named as "Mutius". Marston expert Arnold Davenport believes that Mutius is the bishop-poet Joseph Hall and that Marston is criticising Hall's satires.
There is a description of the figure of Oxford in "The Revenge of Bussy D'Ambois", a 1613 play by George Chapman, who has been suggested as the Rival Poet of Shakespeare's Sonnets. Chapman describes Oxford as "Rare and most absolute" in form and says he was "of spirit passing great / Valiant and learn’d, and liberal as the sun". He adds that he "spoke and writ sweetly" of both learned subjects and matters of state ("public weal").
Chronology of the plays and Oxford's 1604 death.
For mainstream Shakespearian scholars, the most compelling evidence against Oxford (besides the historical evidence for William Shakespeare) is his death in 1604, since the generally accepted chronology of Shakespeare's plays places the composition of approximately twelve of the plays after that date. Critics often cite "The Tempest" and "Macbeth", for example, as having been written after 1604.
The exact dates of the composition of most of Shakespeare's plays are uncertain, although David Bevington says it is a 'virtually unanimous' opinion among teachers and scholars of Shakespeare that the canon of late plays depicts an artistic journey that extends well beyond 1604. Evidence for this includes allusions to historical events and literary sources which postdate 1604, as well as Shakespeare's adaptation of his style to accommodate Jacobean literary tastes and the changing membership of the King's Men and their different venues.
Oxfordians say that the conventional composition dates for the plays were developed by mainstream scholars to fit within Shakespeare's lifetime and that no evidence exists that any plays were written after 1604. Anderson argues that all of the Jacobean plays were written before 1604, selectively citing non-Oxfordian scholars like Alfred Harbage, Karl Elze, and Andrew Cairncross to bolster his case. Anderson notes that from 1593 through 1603, the publication of new plays appeared at the rate of two per year, and whenever an inferior or pirated text was published, it was typically followed by a genuine text described on the title page as "newly augmented" or "corrected". After the publication of the Q1 and Q2 "Hamlet" in 1603, no new plays were published until 1608. Anderson observes that, "After 1604, the 'newly correct[ing]' and 'augment[ing]' stops. Once again, the Shake-speare ["sic"] enterprise appears to have shut down".
Notable silences.
Because Shakespeare lived until 1616, Oxfordians question why, if he were the author, did he not eulogise Queen Elizabeth at her death in 1603 or Henry, Prince of Wales, at his in 1612. They believe Oxford's 1604 death provides the explanation. In an age when such actions were expected, Shakespeare also failed to memorialise the coronation of James I in 1604, the marriage of Princess Elizabeth in 1612, and the investiture of Prince Charles as the new Prince of Wales in 1613.
Anderson contends that Shakespeare refers to the latest scientific discoveries and events through the end of the 16th century, but "is mute about science after de Vere’s [Oxford’s] death in 1604". He believes that the absence of any mention of the spectacular supernova of October 1604 or Kepler’s revolutionary 1609 study of planetary orbits are especially noteworthy.
The move to the Blackfriars.
Professor Jonathan Bate writes that Oxfordians cannot "provide any explanation for ... technical changes attendant on the King's Men's move to the Blackfriars theatre four years after their candidate's death ... Unlike the Globe, the Blackfriars was an indoor playhouse" and so required plays with frequent breaks in order to replace the candles it used for lighting. "The plays written after Shakespeare's company began using the Blackfriars in 1608, "Cymbeline" and "The Winter's Tale" for instance, have what most ... of the earlier plays do not have: a carefully planned five-act structure". If new Shakespearian plays were being written especially for presentation at the Blackfriars' theatre after 1608, they could not have been written by Edward de Vere.
Oxfordians argue that Oxford was well acquainted with the Blackfriars Theatre, having been a leaseholder of the venue, and note that the "assumption" that Shakespeare wrote plays for the Blackfriars is not universally accepted, citing Shakespearian scholars such as A. Nicoll who said that "all available evidence is either completely negative or else runs directly counter to such a supposition" and Harley Granville-Barker, who stated "Shakespeare did not write (except for Henry V) five-act plays at any stage of his career. The five-act structure was formalized in the First Folio, and is inauthentic".
Shakespeare's late collaborations.
Further, attribution studies have shown that certain plays in the canon were written by two or three hands, which Oxfordians believe is explained by these plays being either drafted earlier than conventionally believed, or simply revised/completed by others after Oxford's death. Shapiro calls this a 'nightmare' for Oxfordians, implying a 'jumble sale scenario' for his literary remains long after his death.
Identification of earlier works with Shakespeare plays.
Some Oxfordians have identified titles or descriptions of lost works from Oxford's lifetime that suggest a thematic similarity to a particular Shakespearian play and asserted that they were earlier versions. For example, in 1732, the antiquarian Francis Peck published in "Desiderata Curiosa" a list of documents in his possession that he intended to print someday. They included "a pleasant conceit of Vere, earl of Oxford, discontented at the rising of a mean gentleman in the English court, circa 1580." Peck never published his archives, which are now lost. To Anderson, Peck's description suggests that this conceit is "arguably an early draft of "Twelfth Night"."
Contemporary references to Shakespeare as alive or dead.
Oxfordian writers say some literary allusions imply that the playwright and poet died prior to 1609, when "Shake-Speares Sonnets" appeared with the epithet "our ever-living poet" in its dedication. They claim that the phrase "ever-living" rarely, if ever, referred to a living person, but instead was used to refer to the eternal soul of the deceased. Bacon, Derby, Neville, and William Shakespeare all lived well past the 1609 publication of the Sonnets.
However, Don Foster, in his study of Early Modern uses of the phrase "ever-living", argues that the phrase most frequently refers to God or other supernatural beings, suggesting that the dedication calls upon God to bless the living begetter (writer) of the sonnets. He states that the initials "W. H." were a misprint for "W. S." or "W. SH". Bate thinks it a misprint as well, but he thinks it "improbable" that the phrase refers to God. and suggests that the "ever-living poet" might be "a great dead English poet who had written on the great theme of poetic immortality", such as Sir Philip Sidney or Edmund Spenser.
Joseph Sobran, in "Alias Shakespeare," argued that in 1607 William Barksted, a minor poet and playwright, implies in his poem "Mirrha the Mother of Adonis" that Shakespeare was already deceased. Shakespeare scholars explain that Sobran has simply misread Barkstead’s poem, the last stanza of which is a comparison of Barkstead’s poem to Shakespeare’s "Venus and Adonis", and has mistaken the grammar also, which makes it clear that Barkstead is referring to Shakespeare’s "song" in the past tense, not Shakespeare himself. This context is obvious when the rest of the stanza is included.
Against the Oxford theory are several references to Shakespeare, later than 1604, which imply that the author was then still alive. Scholars point to a poem written circa 1620 by a student at Oxford, William Basse, that mentioned the author Shakespeare died in 1616, which is the year Shakespeare deceased and not Edward de Vere.
Dates of composition.
"The Two Gentlemen of Verona".
Tom Veal has noted that the early play "The Two Gentlemen of Verona" reveals no familiarity on the playwright's part with Italy other than "a few place names and the scarcely recondite fact that the inhabitants were Roman Catholics." For example, the play's Verona is situated on a tidal river and has a duke, and none of the characters have distinctly Italian names like in the later plays. Therefore, if the play was written by Oxford, it must have been before he visited Italy in 1575. However, the play's principal source, the Spanish "Diana Enamorada", would not be translated into French or English until 1578, meaning that someone basing a play on it that early could only have read it in the original Spanish, and there is no evidence that Oxford spoke this language. Furthermore, Veal argues, the only explanation for the verbal parallels with the English translation of 1582 would be that the translator saw the play performed and echoed it in his translation, which he describes as "not an impossible theory but far from a plausible one."
"Hamlet".
The composition date of "Hamlet" has been frequently disputed. Several surviving references indicate that a Hamlet-like play was well-known throughout the 1590s, well before the traditional period of composition (1599–1601). Most scholars refer to this lost early play as the Ur-Hamlet; the earliest reference is in 1589. A 1594 performance record of "Hamlet" appears in Philip Henslowe's diary, and Thomas Lodge wrote of it in 1596.
Oxfordian researchers believe that the play is an early version of Shakespeare's own play, and point to the fact that Shakespeare's version survives in three quite different early texts, Q1 (1603), Q2 (1604) and F (1623), suggesting the possibility that it was revised by the author over a period of many years.
"Macbeth".
Scholars contend that the composition date of "Macbeth" is one of the most overwhelming pieces of evidence against the Oxfordian position; the vast majority of critics believe the play was written in the aftermath of the Gunpowder Plot. This plot was brought to light on 5 November 1605, a year after Oxford died. In particular, scholars identify the porter's lines about "equivocation" and treason as an allusion to the trial of Henry Garnet in 1606. Oxfordians respond that the concept of "equivocation" was the subject of a 1583 tract by Queen Elizabeth's chief councillor (and Oxford's father-in-law) Lord Burghley, as well as of the 1584 "Doctrine of Equivocation" by the Spanish prelate Martín de Azpilcueta, which was disseminated across Europe and into England in the 1590s.
"Coriolanus".
Shakespearian scholar David Haley asserts that if Edward de Vere had written "Coriolanus", he "must have foreseen the Midland Revolt grain riots [of 1607] reported in Coriolanus", possible topical allusions in the play that most Shakespearians accept.
"The Tempest".
The play that can be dated within a fourteen-month period is The Tempest. This play has long been believed to have been inspired by the 1609 wreck at Bermuda, then feared by mariners as the "Isle of the Devils", of the flagship of the Virginia Company, the Sea Venture, while leading the Third Supply to relieve Jamestown in the Colony of Virginia. The Sea Venture was captained by Christopher Newport, and carried the Admiral of the company's fleet, Sir George Somers (for whom the archipelago would subsequently be named "The Somers Isles"). The survivors spent nine months in Bermuda before most completed the journey to Jamestown on 23 May 1610 aboard two new ships built from scratch. One of the survivors was the newly-appointed Governor, Sir Thomas Gates. Jamestown, then little more than a rudimentary fort, was found in such a poor condition, with the majority of the previous settlers dead or dying, that Gates and Somers decided to abandon the settlement and the continent, returning everyone to England. However, with the company believing all aboard the Sea Venture dead, a new governor, Baron De La Warr, had been sent with the Fourth Supply fleet, which arrived on 10 June 1610 as Jamestown was being abandoned.
De la Warr remained in Jamestown as Governor, while Gates returned to England (and Somers to Bermuda), arriving in September, 1610. The news of the survival of the Sea Venture's passengers and crew caused a great sensation in England. Two accounts were published: Sylvester Jordain's "A Discovery of the Barmvdas, Otherwise Called the Ile of Divels", in October, 1610, and "A True Declaration of the Estate of the Colonie in Virginia" a month later. The "True Reportory of the Wrack, and Redemption of Sir Thomas Gates Knight", an account by William Strachey dated 15 July 1610, returned to England with Gates in the form of a letter which was circulated privately until its eventual publication in 1625. Shakespeare had multiple contacts to the circle of people amongst whom the letter circled, including to Strachey. "The Tempest" shows clear evidence that he had read and relied on Jordain and especially Stratchey. The play shares premise, basic plot, and many details of the Sea Venture's wrecking and the adventures of the survivors, as well as specific details and linguistics. A detailed comparative analysis shows the "Declaration" to have been the primary source from which the play was drawn. This firmly dates the writing of the play to the months between Gates' return to England and the 1st of November, 1611.
Oxfordians have dealt with this problem in several ways. Looney expelled the play from the canon, arguing that its style and the "dreary negativism" it promoted were inconsistent with Shakespeare's "essentially positivist" soul, and so could not have been written by Oxford. Later Oxfordians have generally abandoned this argument; this has made severing the connection of the play with the wreck of the Sea Venture a priority amongst Oxfordians. A variety of attacks have been directed on the links. These include attempting to cast doubt on whether the "Declaration" travelled back to England with Gates, whether Gates travelled back to England early enough, whether the lowly Shakespeare would have had access to the lofty circles in which the "Declaration" was circulated, to understating the points of similarity between the Sea Venture wreck and the accounts of it, on the one hand, and the play on the other. Oxfordians have even claimed that the writers of the first-hand accounts of the real wreck based them on "The Tempest", or, at least, the same antiquated sources that Shakespeare, or rather Oxford, is imagined to have used exclusively, including Richard Eden's "The Decades of the New Worlde Or West India" (1555) and Desiderius Erasmus's "Naufragium"/"The Shipwreck" (1523). Alden Vaughan commented in 2008 that "[t]he argument that Shakespeare could have gotten every thematic thread, every detail of the storm, and every similarity of word and phrase from other sources stretches credulity to the limits."
"Henry VIII".
Oxfordians note that while the conventional dating for "Henry VIII" is 1610-13, the majority of 18th and 19th century scholars, including notables such as Samuel Johnson, Lewis Theobald, George Steevens, Edmond Malone, and James Halliwell-Phillipps, placed the composition of "Henry VIII" prior to 1604, as they believed Elizabeth's execution of Mary, Queen of Scots (the then king James I's mother) made any vigorous defence of the Tudors politically inappropriate in the England of James I. Though it is described as a new play by two witnesses in 1613, Oxfordians argue that this refers to the fact it was new on stage, having its first production in that year.
Oxfordian cryptology.
Although searching Shakespeare's works for encrypted clues supposedly left by the true author is associated mainly with the Baconian theory, such arguments are often made by Oxfordians as well. Early Oxfordians found many references to Oxford's family name "Vere" in the plays and poems, in supposed puns on words such as "ever" (E. Vere). "The De Vere Code", a book by English actor Jonathan Bond, the author believes that Thomas Thorpe´s 30-word dedication to the original publication of Shakespeare's Sonnets contains six simple encryptions which conclusively establish de Vere as the author of the poems. He also writes that the alleged encryptions settle the question of the identity of "the Fair Youth" as Henry Wriothesley and contain striking references to the sonnets themselves and de Vere's relationship to Sir Philip Sidney and Ben Jonson.
Similarly, a 2009 article in the Oxfordian journal "Brief Chronicles" noted that Francis Meres, in "Palladis Tamia" compares 17 named English poets to 16 named classical poets. Writing that Meres was obsessed with numerology, the authors propose that the numbers should be symmetrical, and that careful readers are meant to infer that Meres knew two of the English poets (viz., Oxford and Shakespeare) to actually be one and the same.
Parallels with the plays.
Literary scholars say that the idea that an author's work must reflect his or her life is a Modernist assumption not held by Elizabethan writers, and that biographical interpretations of literature are unreliable in attributing authorship. Further, such lists of similarities between incidents in the plays and the life of an aristocrat are flawed arguments because similar lists have been drawn up for many competing candidates, such as Francis Bacon and William Stanley, 6th Earl of Derby. Harold Love writes that "The very fact that their application has produced so many rival claimants demonstrates their unreliability," and Jonathan Bate writes that the Oxfordian biographical method "is in essence no different from the cryptogram, since Shakespeare's range of characters and plots, both familial and political, is so vast that it would be possible to find in the plays 'self-portraits' of ... anybody one cares to think of."
Despite this, Oxfordians list numerous incidents in Oxford's life that they say parallel those in many of the Shakespeare plays. Most notable among these, they say, are certain similar incidents found in Oxford's biography and "Hamlet", and "Henry IV, Part 1", which includes a well-known robbery scene with uncanny parallels to a real-life incident involving Oxford.
"Hamlet".
Most Oxfordians consider Hamlet the play most easily seen as portraying Oxford's life story, though mainstream scholars say that incidents from the lives of other contemporary figures such as King James or the Earl of Essex, fit the play just as closely, if not more so.
Hamlet's father was murdered and his mother made an "o'er-hasty marriage" less than two months later. Oxfordians see a parallel with Oxford's life, as Oxford's father died at the age of 46 on 3 August 1562, although not before making a will six days earlier, and his stepmother remarried within 15 months, although exactly when is unknown.
Another frequently-cited parallel involves Hamlet's revelation in Act IV that he was earlier taken captive by pirates. On Oxford's return from Europe in 1576, he encountered a cavalry division outside of Paris that was being led by a German duke, and his ship was hijacked by pirates who robbed him and left him stripped to his shirt, and who might have murdered him had not one of them recognised him. Anderson notes that "[n]either the encounter with Fortinbras' army nor Hamlet's brush with buccaneers appears in any of the play's sources – to the puzzlement of numerous literary critics."
Polonius.
Such speculation often identifies the character of Polonius as a caricature of Lord Burghley, Oxford's guardian from the age of 12.
In the First Quarto the character was not named Polonius, but Corambis. Ogburn writes that "Cor ambis" can be interpreted as "two-hearted" (a view not independently supported by Latinists). He says the name is a swipe "at Burghley's motto, "Cor unum, via una", or 'one heart, one way.'" Scholars suggest that it derives from the Latin phrase "crambe repetita" meaning "reheated cabbage", which was expanded in Elizabethan usage to ""Crambe bis" posita mors est" ("twice served cabbage is deadly"), which implies "a boring old man" who spouts trite rehashed ideas. Similar variants such as "Crambo" and "Corabme" appear in Latin-English dictionaries at the time.
Bed trick.
In his "Memoires" (1658), Francis Osborne writes of "the last great "Earle of Oxford", whose "Lady" was brought to his bed under the notion of his "Mistris", and from such a virtuous deceit she (Oxford's youngest daughter) is said to proceed" (p. 79).
Such a bed trick has been a dramatic convention since antiquity and was used more than 40 times by every major playwright in the Early Modern theatre era except for Ben Jonson. Thomas Middleton used it five times and Shakespeare and James Shirley used it four times. Shakespeare's use of it in "All's Well That Ends Well" and "Measure for Measure" followed his sources for the plays (stories by Boccaccio and Cinthio); nevertheless Oxfordians say that de Vere was drawn to these stories because they "paralleled his own", based on Osborne's anecdote.
Earls of Oxford in the histories.
Oxfordians claim that flattering treatment of Oxford's ancestors in Shakespeare's history plays is evidence of his authorship. Shakespeare omitted the character of the traitorous Robert de Vere, 3rd Earl of Oxford in "The Life and Death of King John", and the character of the 12th Earl of Oxford is given a much more prominent role in "Henry V" than his limited involvement in the actual history of the times would allow. The 12th Earl is given an even more prominent role in the non-Shakespearian play "The Famous Victories of Henry the fifth". Some Oxfordians argue that this was another play written by Oxford, based on the exaggerated role it gave to the 11th Earl of Oxford.
J. Thomas Looney found John de Vere, 13th Earl of Oxford is "hardly mentioned except to be praised" in "Henry VI, Part Three"; the play ahistorically depicts him participating in the Battle of Tewkesbury and being captured. Oxfordians, such as Dorothy and Charlton Ogburn, believe Shakespeare created such a role for the 13th Earl because it was the easiest way Edward de Vere could have "advertised his loyalty to the Tudor Queen" and remind her of "the historic part borne by the Earls of Oxford in defeating the usurpers and restoring the Lancastrians to power". Looney also notes that in "Richard III", when the future Henry VII appears, the same Earl of Oxford is "by his side; and it is Oxford who, as premier nobleman, replies first to the king's address to his followers".
Non-Oxfordian writers do not see any evidence of partiality for the de Vere family in the plays. Richard de Vere, 11th Earl of Oxford, who plays a prominent role in the anonymous "The Famous Victories of Henry V", does not appear in Shakespeare's "Henry V", nor is he even mentioned. In "Richard III", Oxford's reply to the king noted by Looney is a mere two lines, the only lines he speaks in the play. He has a much more prominent role in the non-Shakespearian play "The True Tragedy of Richard III". On these grounds the scholar Benjamin Griffin argues that the non-Shakespearian plays, the "Famous Victories" and "True Tragedy", are the ones connected to Oxford, possibly written for Oxford's Men. Oxfordian Charlton Ogburn Jr. argues that the role of the Earls of Oxford was played down in "Henry V" and "Richard III" to maintain Oxford's nominal anonymity. This is because "It would not do to have a performance of one of his plays at Court greeted with ill-suppressed knowing chuckles."
Oxford's finances.
In 1577 the Company of Cathay was formed to support Martin Frobisher’s hunt for the Northwest Passage, although Frobisher and his investors quickly became distracted by reports of gold at Hall’s Island. With thoughts of an impending Canadian gold-rush and trusting in the financial advice of Michael Lok, the treasurer of the company, de Vere signed a bond for £3,000 in order to invest £1,000 and to assume £2,000 worth—about half—of Lok's personal investment in the enterprise. Oxfordians say this is similar to Antonio in "The Merchant of Venice", who was indebted to Shylock for 3,000 ducats against the successful return of his vessels.
Oxfordians also note that when de Vere travelled through Venice, he borrowed 500 crowns from a Baptista Nigrone. In Padua, he borrowed from a man named Pasquino Spinola. In "The Taming of the Shrew", Kate's father is described as a man "rich in crowns." He, too, is from Padua, and his name is Baptista Minola, which Oxfordians take to be a conflation of Baptista Nigrone and Pasquino Spinola.
When the character of Antipholus of Ephesus in "The Comedy of Errors" tells his servant to go out and buy some rope, the servant (Dromio) replies, "I buy a thousand pounds a year! I buy a rope!" (Act 4, scene 1). The meaning of Dromio’s line has not been satisfactorily explained by critics, but Oxfordians say the line is somehow connected to the fact that de Vere was given a £1,000 annuity by the Queen, later continued by King James.
Marriage and affairs.
Oxfordians see Oxford's marriage to Anne Cecil, Lord Burghley's daughter, paralleled in such plays as "Hamlet", "Othello", "Cymbeline", "The Merry Wives of Windsor", "All's Well That Ends Well", "Measure for Measure", "Much Ado About Nothing", and "The Winter's Tale".
Oxford's illicit congress with Anne Vavasour resulted in an intermittent series of street battles between the Knyvet clan, led by Anne's uncle, Sir Thomas Knyvet, and Oxford’s men. As in "Romeo and Juliet", this imbroglio produced three deaths and several other injuries. The feud was finally put to an end only by the intervention of the Queen.
Oxford's criminal associations.
In May 1573, in a letter to Lord Burghley, two of Oxford's former employees accused three of Oxford's friends of attacking them on "the highway from Gravesend to Rochester." In Shakespeare's "Henry IV, Part 1", Falstaff and three roguish friends of Prince Hal also waylay unwary travellers at Gad's Hill, which is on the highway from Gravesend to Rochester. Scott McCrea says that there is little similarity between the two events, since the crime described in the letter is unlikely to have occurred near Gad's Hill and was not a robbery, but rather an attempted shooting. Mainstream writers also say that this episode derives from an earlier anonymous play, "The Famous Victories of Henry V", which was Shakespeare's source. Some Oxfordians argue that "The Famous Victories" was written by Oxford, based on the exaggerated role it gave to the 11th Earl of Oxford.
Parallels with the sonnets and poems.
In 1609, a volume of 154 linked poems was published under the title "SHAKE-SPEARES SONNETS". Oxfordians believe the title ("Shake-Speares Sonnets") suggests a finality indicating that it was a completed body of work with no further sonnets expected, and consider the differences of opinion among Shakespearian scholars as to whether the Sonnets are fictional or autobiographical to be a serious problem facing orthodox scholars. Joseph Sobran questions why Shakespeare (who lived until 1616) failed to publish a corrected and authorised edition if they are fiction, as well as why they fail to match Shakespeare's life story if they are autobiographic. According to Sobran and other researchers, the themes and personal circumstances expounded by the author of the Sonnets are remarkably similar to Oxford's biography.
The Fair Youth, the Dark Lady, and the Rival Poet.
The focus of the 154 sonnet series appears to narrate the author's relationships with three characters: the Fair Youth, the Dark Lady or Mistress, and the Rival Poet. Beginning with Looney, most Oxfordians (exceptions are Percy Allen and Louis Bénézet) believe that the "Fair Youth" referred to in the early sonnets refers to Henry Wriothesley, 3rd Earl of Southampton, Oxford's peer and prospective son-in-law. The Dark Lady is believed by some Oxfordians to be Anne Vavasour, Oxford's mistress who bore him a son out of wedlock. A case was made by the Oxfordian Peter R. Moore that the Rival Poet was Robert Devereux, Earl of Essex.
Sobran suggests that the so-called procreation sonnets were part of a campaign by Burghley to persuade Southampton to marry his granddaughter, Oxford's daughter Elizabeth de Vere, and says that it was more likely that Oxford would have participated in such a campaign than that Shakespeare would know the parties involved or presume to give advice to the nobility.
Oxfordians also assert that the tone of the poems is that of a nobleman addressing an equal rather than that of a poet addressing his patron. According to them, Sonnet 91 (which compares the Fair Youth's love to such treasures as high birth, wealth, and horses) implies that the author is in a position to make such comparisons, and the 'high birth' he refers to is his own.
Age and lameness.
Oxford was born in 1550, and was between 40 and 53 years old when he presumably would have written the sonnets. Shakespeare was born in 1564. Even though the average life expectancy of Elizabethans was short, being between 26 and 39 was not considered old. In spite of this, age and growing older are recurring themes in the Sonnets, for example, in Sonnets 138 and 37. In his later years, Oxford described himself as "lame". On several occasions, the author of the sonnets also described himself as lame, such as in Sonnets 37 and 89.
Public disgrace.
Sobran also believes "scholars have largely ignored one of the chief themes of the Sonnets: the poet's sense of disgrace ... [T]here can be no doubt that the poet is referring to something real that he expects his friends to know about; in fact, he makes clear that a wide public knows about it ... Once again the poet's situation matches Oxford's ... He has been a topic of scandal on several occasions. And his contemporaries saw the course of his life as one of decline from great wealth, honor, and promise to disgrace and ruin. This perception was underlined by enemies who accused him of every imaginable offense and perversion, charges he was apparently unable to rebut." Examples include Sonnets 29 and 112.
As early as 1576, Edward de Vere was writing about this subject in his poem "Loss of Good Name", which Steven W. May described as "a defiant lyric without precedent in English Renaissance verse."
Lost fame.
The poems "Venus and Adonis" and "Lucrece", first published in 1593 and 1594 under the name "William Shakespeare", proved highly popular for several decades – with "Venus and Adonis" published six more times before 1616, while "Lucrece" required four additional printings during this same period. By 1598, they were so famous, London poet and sonneteer Richard Barnefield wrote:
<poem>Shakespeare...
Whose "Venus" and whose "Lucrece" (sweet and chaste)
Thy name in fame's immortal Book have plac't
Live ever you, at least in Fame live ever:
Well may the Body die, but Fame dies never.</poem>
Despite such publicity, Sobran observed, "[t]he author of the Sonnets expects and hopes to be forgotten. While he is confident that his poetry will outlast marble and monument, it will immortalize his young friend, not himself. He says that his style is so distinctive and unchanging that 'every word doth almost tell my name,' implying that his name is otherwise concealed – at a time when he is publishing long poems under the name William Shakespeare. This seems to mean that he is not writing these Sonnets under that (hidden) name." Oxfordians have interpreted the phrase "every word" as a pun on the word "every", standing for "e vere" - thus telling his name. Mainstream writers respond that several sonnets literally do tell his name, containing numerous puns on the name Will[iam]; in sonnet 136 the poet directly says "thou lov'st me for my name is Will."
Based on Sonnets 81, 72, and others, Oxfordians assert that if the author expected his "name" to be "forgotten" and "buried", it would not have been the name that permanently adorned the published works themselves.
Notes.
Footnotes.
The UK and US editions of differ significantly in pagination. The citations to the book used in this article list the UK page numbers first, followed by the page numbers of the US edition in parentheses.

</doc>
<doc id="22677" url="https://en.wikipedia.org/wiki?curid=22677" title="Oxymoron">
Oxymoron

An oxymoron (usual plural oxymorons, less commonly the Latin-style oxymora) is a figure of speech that juxtaposes elements that appear to be contradictory. Oxymorons appear in a variety of contexts, including inadvertent errors (such as "ground pilot") and literary oxymorons crafted to reveal a paradox.
Types.
The most common form of oxymoron involves an adjective–noun combination of two words. For example, the following line from Tennyson's "Idylls of the King" contains two oxymorons:
Other examples of oxymorons of this kind include:
Less often seen are noun–verb combinations of two words, such as the line "The silence whistles" from Nathan Alterman's "Summer Night", or in a song title like Simon & Garfunkel's "The Sound of Silence".
Oxymorons are not always a pair of words; they can also be devised in the meaning of sentences or phrases.
Etymology.
Oxymoron is derived from the 5th century , ', which is derived from the ' "sharp, keen, pointed" and "dull, stupid, foolish", making the word itself an oxymoron. However, the combined Greek form ὀξύμωρον ("oksúmōron") does not in fact appear in the extant Greek sources.
Taxonomy.
Richard Lederer assembled a taxonomy of oxymorons in an article in "Word Ways" in 1990, running from single-word oxymorons such as "pianoforte" (literally, "soft-loud") through "doublespeak oxymorons" (deliberately intended to confuse) and "opinion oxymorons" (editorial opinions designed to provoke a laugh). In general, oxymorons can be divided into expressions that were deliberately crafted to be contradictory and those phrases that inadvertently or incidentally contain a contradiction, often as a result of a punning use of one or both words.
Apparent oxymorons.
Many oxymorons have been popularised in vernacular speech. Examples include "controlled chaos", "open secret", "organized mess", "alone in a crowd", and "accidentally on purpose".
There are also examples in which terms that are superficially contradictory are juxtaposed in such a way that there is no contradiction. Examples include "same difference", "jumbo shrimp", and "hot ice" (where "hot" means "stolen" and "ice" means "diamonds", in criminal argot).
Oxymorons as paradoxes.
Writers often use an oxymoron to call attention to an apparent contradiction. For example, Wilfred Owen's poem "The Send-off" refers to soldiers leaving for the front line, who "lined the train with faces grimly gay." The oxymoron "grimly gay" highlights the contradiction between how the soldiers feel and how they act: though they put on a brave face and act cheerfully, they feel grim.
Similarly, in Henry James' novella "The Lesson of the Master", a character is described as dressed in a manner "conventionally unconventional, suggesting a tortuous spontaneity." In this way James highlights the contradiction between the character's desire to appear spontaneous, and the efforts she makes to appear so.
One case where many oxymorons are strung together can be found in Shakespeare's "Romeo and Juliet", where Romeo declares:
Some paradoxical oxymorons become clichés:
Terms wrongly called oxymorons for rhetorical effect.
Although a true oxymoron is "something that is surprisingly true, a paradox", Garry Wills has argued that modern usage has brought a common misunderstanding that "oxymoron" is nearly synonymous with "contradiction". The introduction of this misuse, the opposite of its true meaning, has been credited to William F. Buckley.
Sometimes a pair of terms is claimed to be an oxymoron by those who hold the opinion that the two are mutually exclusive. That is, although there is no "inherent" contradiction between the terms, the speaker expresses the opinion that the two terms imply properties or characteristics that cannot occur together. Such claims may be made purely for humorous effect. Comedian George Carlin popularized many examples, such as "military intelligence", "freedom fighters", and "business ethics". Another example is the term "civil war", which is not an oxymoron, but can be claimed to be so for humorous effect, if "civil" is construed as meaning "polite" rather than "between citizens of the same state". Alternatively, such claims may reflect a genuinely held opinion or ideological position. Well-known examples include claims made against "government worker", "honest broker", "educational television", "Microsoft Works", and "working from home".
Visual and physical oxymorons.
In his book "More on Oxymoron", the artist Patrick Hughes discusses and gives examples of visual oxymorons. He writes:
Examples include waves in the sand, a fossil tree, and topiary representing something solid like an ocean liner. Hughes lists further examples of oxymoronic objects, including:
Other languages.
Oxymorons, in the sense of "single-word oxymorons" such as "pianoforte", are very common in Chinese and neighboring languages such as Japanese. Archetypal examples include 男女 (man and woman, male and female, gender), 陰陽 (yin and yang), 善悪 (good and evil, morality), formed from pairs of monosyllabic words that can each be written with a single character, and that are used to indicate couples, ranges, or the trait that these are extremes of.

</doc>
<doc id="22678" url="https://en.wikipedia.org/wiki?curid=22678" title="OSS">
OSS

OSS may refer to:

</doc>
<doc id="22679" url="https://en.wikipedia.org/wiki?curid=22679" title="Office of Strategic Services">
Office of Strategic Services

The Office of Strategic Services (OSS) was a United States intelligence agency formed during World War II. It was a wartime intelligence agency, and a predecessor of the Central Intelligence Agency (CIA). The OSS was formed to coordinate espionage activities behind enemy lines for the United States Armed Forces branches. Other OSS functions included the use of propaganda, subversion, and post-war planning.
Origin.
Prior to the formation of the OSS, American intelligence had been conducted on an ad-hoc basis by the various departments of the executive branch, including the State, Treasury, Navy, and War Departments. It had no overall direction, coordination, or control. The US Army and US Navy had separate code-breaking departments: Signals Intelligence Service and OP-20-G. (A previous code-breaking operation of the State Department, the MI-8, run by Herbert Yardley, had been shut down in 1929 by Secretary of State Henry Stimson, deeming it an inappropriate function for the diplomatic arm, because "gentlemen don't read each other's mail".) The FBI was responsible for domestic security and anti-espionage operations.
President Franklin D. Roosevelt was concerned about American intelligence deficiencies. On the suggestion of William Stephenson, the senior British intelligence officer in the western hemisphere, Roosevelt requested that William J. Donovan draft a plan for an intelligence service based on the British Secret Intelligence Service (MI6) and Special Operations Executive (SOE). Colonel Donovan was employed to evaluate the global military position to offer suggestions concerning American intelligence requirements because the U.S. did not have a central intelligence agency. After submitting his work, "Memorandum of Establishment of Service of Strategic Information," Colonel Donovan was appointed "coordinator of information" on July 11, 1941 heading the new organization known as the office of the Coordinator of Information (COI). Thereafter the organization was developed with British assistance; Donovan had responsibilities but no actual powers and the existing US agencies were skeptical if not hostile. Until some months after Pearl Harbor, the bulk of OSS intelligence came from the UK. British Security Coordination (BSC) trained the first OSS agents in Canada, until training stations were set up in the US with guidance from BSC instructors, who also provided information on how the SOE was arranged and managed. The British immediately made available their short-wave broadcasting capabilities to Europe, Africa, and the Far East and provided equipment for agents until American production was established.
The Office of Strategic Services was established by a Presidential military order issued by President Roosevelt on June 13, 1942, to collect and analyze strategic information required by the Joint Chiefs of Staff and to conduct special operations not assigned to other agencies. During the war, the OSS supplied policymakers with facts and estimates, but the OSS never had jurisdiction over all foreign intelligence activities. The FBI was left responsible for intelligence work in Latin America, and the Army and Navy continued to develop and rely on their own sources of intelligence.
Activities.
For the duration of World War II, the Office of Strategic Services was conducting multiple activities and missions, including collecting intelligence by spying, performing acts of sabotage, waging propaganda war, organizing and coordinating anti-Nazi resistance groups in Europe, providing military training for anti-Japanese guerrilla movement in Asia, among other things. At the height of its influence during WWII, the OSS employed almost 24,000 people.
From 1943–1945, the OSS played a major role in training Kuomintang troops in China and Burma, and recruited Kachin, and other indigenous irregular forces for sabotage as well as guides for Allied forces in Burma fighting the Japanese Army. Among other activities, the OSS helped arm, train and supply resistance movements, including Mao Zedong's Red Army in China and the Viet Minh in French Indochina, in areas occupied by the Axis powers during World War II. OSS officer Archimedes Patti played a central role in OSS operations in French Indochina and met frequently with Ho Chi Minh in 1945.
In the "40th Bomb Group Association Memories Issue # 14 March 1987 Date of event: Summer of 1944 to early Spring, 1945 Date written: September, 1986 Written by: Louis Jones":
The Dixie Mission in China was composed of approximately 20 people, including two OSS officers.
One of the greatest accomplishments of the OSS during World War II was its penetration of Nazi Germany by OSS operatives. The OSS was responsible for training German and Austrian individuals for missions inside Germany. Some of these agents included exiled communists and Socialist party members, labor activists, anti-Nazi prisoners-of-war, and German and Jewish refugees. The OSS also recruited and ran one of the war's most important spies, the German diplomat Fritz Kolbe.
In 1943, the Office of Strategic Services set up operations in Istanbul. Turkey, as a neutral country during the Second World War, was a place where both the Axis and Allied powers had spy networks. The railroads connecting central Asia with Europe as well as Turkey's close proximity to the Balkan states placed it at a crossroads of intelligence gathering. The goal of the OSS Istanbul operation called Project Net-1 was to infiltrate and extenuate subversive action in the old Ottoman and Austro-Hungarian Empires.
Head of operations at OSS Istanbul was a banker from Chicago named Lanning "Packy" Macfarland who maintained the cover story as a banker for the American lend-lease program. Macfarland hired Alfred Schwarz, a Czechoslovakian engineer and businessman who came to be known as "Dogwood" and ended up establishing the Dogwood information chain. Dogwood in turn hired a personal assistant named Walter Arndt and established himself as an employee of the Istanbul Western Electrik Kompani. Through Schwartz and Arndt the OSS was able to infiltrate anti-fascist groups in Austria, Hungary and Germany. Schwartz was able to convince Romanian, Bulgarian, Hungarian and Swiss diplomatic couriers to smuggle American intelligence information into these territories and establish contact with elements antagonistic to the Nazis and their collaborators. Couriers and agents memorized information and produced analytical reports; when they were not able to memorize effectively they recorded information on microfilm and hid it in their shoes or hollowed pencils. Through this process information about the Nazi regime made its way to Macfarland and the OSS in Istanbul and eventually to Washington.
While the OSS "Dogwood-chain" produced a lot of information, its reliability was increasingly questioned by British intelligence. Eventually by May 1944 through collaboration between the OSS, British intelligence, Cairo and Washington the entire Dogwood-chain was found to be unreliable and dangerous. Planting phony information into the OSS was intended to misdirect the resources of the Allies. Schwartz's Dogwood-chain, which was the largest American intelligence gathering tool in occupied territory, was shortly thereafter shut down.
The OSS purchased Soviet code and cipher material (or Finnish information on them) from émigré Finnish army officers in late 1944. Secretary of State Edward Stettinius, Jr., protested that this violated an agreement President Roosevelt made with the Soviet Union not to interfere with Soviet cipher traffic from the United States. General Donovan might have copied the papers before returning them the following January, but there is no record of Arlington Hall's receiving them, and CIA and NSA archives have no surviving copies. This codebook was in fact used as part of the Venona decryption effort, which helped uncover large-scale Soviet espionage in North America.
Weapons and gadgets.
The OSS espionage and sabotage operations produced a steady demand for highly specialized equipment. After realizing that, General Donovan invited experts, organized workshops and funded labs that formed a core of the later established Research & Development Branch. Boston chemist Stanley P. Lovell became its first head, and Donovan humorously called him—"his Professor Moriarty". Throughout the war years, the OSS Research & Development was successfully adapting Allied weapons and espionage equipment, and producing its own line of novel spy tools and gadgets, including: silenced pistols, lightweight sub-machine guns, "Beano" grenades that exploded upon impact, explosives disguised as lumps of coal ("Black Joe") or bags of Chinese flour ("Aunt Jemima"), acetone time delay fuses for limpet mines, compasses hidden in uniform buttons, playing cards that concealed maps, a 16mm Kodak camera in the shape of a matchbox, tasteless poison tablets ("K" and "L" pills), and cigarettes laced with tetrahydrocannabinol acetate (an extract of Indian hemp) to induce uncontrollable chattiness, among others. In addition, innovative communication equipment was developed, such as wiretap gadgets, electronic beacons for locating agents, and the "Joan-Eleanor" portable radio system that made possible for operatives on the ground to establish secure contact with a plane that was preparing to land or drop cargo. The OSS Research & Development also printed fake German and Japanese-issued identification cards, various passes, ration cards and counterfeit money.
On August 28, 1943, Stanley Lovell was asked to make a presentation in front of a not very friendly audience of the Joint Chiefs of Staff, since the U.S. top brass were largely skeptical of all OSS plans beyond collecting military intelligence and were ready to split the OSS between the Army and the Navy. While explaining the purpose and mission of his department and introducing various gadgets and tools, he reportedly casually dropped into a waste basket the Hedy, a panic-inducing type of a device in a shape of a firecracker, which shortly produced a loud shrieking sound followed by a deafening boom. The presentation was interrupted and did not resume since everyone in the room fled. In reality, the Hedy, jokingly named after Hollywood movie star Hedy Lamarr for her ability to distract men, saved lives of some trapped OSS operatives.
Not all projects worked. Some ideas were odd , such as producing pathogenic synthetic goat dung in PROJECT Capricious (1942) to spread anthrax by using flies among German troops in Spanish Morocco to prevent Spain from joining the Axis powers. Donovan was not informed about PROJECT Capricious due to its uttermost secrecy, the Germans eventually evacuated and Operation Capricious was aborted. There were also ideas to introduce estrogen into Hitler's food to deprive him of his trademark mustache and—recognizable by all Germans—baritone voice. A more deadly plot included hiding a capsule with mustard gas in flowers to cause blindness among Nazi generals inside the German High Command Headquarters. All in all, Stanley Lovell worked hard to level the playing field for the OSS in the WWII arena of espionage, and was later quoted saying, "It was my policy to consider any method whatever that might aid the war, however unorthodox or untried".
In 1939, a young physician named Christian J. Lambertsen developed an oxygen rebreather set (the Lambertsen Amphibious Respiratory Unit) and demonstrated it to the OSS—after already being rejected by the U.S. Navy—in a pool at a hotel in Washington D.C. in 1942 The OSS not only bought into the concept, they hired Lambertsen to lead the program and build up the dive element for the organization. His responsibilities included training and developing methods of combining self-contained diving and swimmer delivery including the Lambertsen Amphibious Respiratory Unit for the OSS "Operational Swimmer Group". Growing involvement of the OSS with coastal infiltration and water-based sabotage eventually led to creation of the OSS Maritime Unit.
Dissolution into other agencies.
After victory in Europe in May 1945, the OSS was better able to concentrate on operations in Japan. Soon Japan surrendered, ending the Pacific Theater of Operations in World War II.
A month later, on September 20, 1945, President Truman signed Executive Order 9621, terminating the OSS. His Order became effective October 1, 1945. In the days following, the functions of the OSS were split between the Department of State and the Department of War. The State Department received the Research and Analysis Branch of OSS which was renamed the Interim Research and Intelligence Service or IRIS, headed by U.S. Army Colonel Alfred McCormack. Later it was renamed the Bureau of Intelligence and Research by the State Department.
The War Department took over the Secret Intelligence (SI) and Counter-Espionage (X-2) Branches, which were then housed in a new unit created for this purpose—the Strategic Services Unit (SSU). The Secretary of War appointed Brigadier General John Magruder (formerly Donovan's Deputy Director for Intelligence in OSS) as the new SSU director. He oversaw the liquidation of the OSS yet, more importantly, he managed the institutional preservation of its clandestine intelligence capability.
In January 1946, President Truman created the Central Intelligence Group (CIG), which was the direct precursor to the CIA. SSU assets, which now constituted a streamlined "nucleus" of clandestine intelligence, were transferred to the CIG in mid-1946 and reconstituted as the Office of Special Operations (OSO). The National Security Act of 1947 established the United States's first permanent peacetime intelligence agency, the Central Intelligence Agency, which then took up OSS functions. The direct descendant of the paramilitary component of the OSS is the CIA Special Activities Division.
Facilities.
Prince William Forest Park (then known as Chopawamsic Recreational Demonstration Area) was the site of an OSS training camp that operated from 1942 to 1945. Area "C", consisting of approximately , was used extensively for communications training, whereas Area "A" was used for training some of the OGs. Catoctin Mountain Park, now the location of Camp David, was the site of OSS training Area "B." Congressional Country Club (Area F) in Bethesda, MD was the primary OSS training facility.
The London branch of the OSS, its first overseas facility, was at 70 Grosvenor Street, W1. 
The Facilities of the Catalina Island Marine Institute at Toyon Bay on Santa Catalina Island, Calif., are composed (in part) of a former OSS survival training camp.
The National Park Service commissioned a study of OSS National Park training facilities by Professor John Chambers of Rutgers University.
At Camp X, at Ajax, near Oshawa, Ontario, Canada, an "assassination and elimination" training program was operated by the British Special Operations Executive such as William E. Fairbairn and Eric A. Sykes. Many members of the US Office of Strategic Services also were trained there. It was dubbed "the school of mayhem and murder" by George Hunter White who trained at the facility in the 1950s.
Personnel.
The names of all OSS personnel and documents of their OSS service, previously a closely guarded secret, were released by the US National Archives on August 14, 2008. Among the 24,000 names were those of Julia Child, Ralph Bunche, Arthur Goldberg, Saul K. Padover, Arthur Schlesinger, Jr., Bruce Sundlun, Rene Joyeuse and John Ford. The 750,000 pages in the 35,000 personnel files include applications of people who were not recruited or hired, as well as the service records of those who were.
Major League Baseball player Moe Berg was recruited by the OSS in 1943 because of his language skills, assigned to the Secret Intelligence branch, and took part in missions in the Caribbean, South America, France, England, Norway, Italy, and the Balkans. Later, Berg was briefed in nuclear physics, and sent to Zürich, Switzerland posing as a Swiss physics student, with the mission of attending a lecture at the Technische Hochschule by Germany's top nuclear scientist, Werner Heisenberg. His orders were to kill the scientist if he determined that the Germans were far along in their efforts to build an atomic weapon; he found that the scientist was not a threat. Berg was awarded the Presidential Medal of Freedom, but declined to accept it as he was forbidden from saying what he had done to receive the award. He is the only former Major League Baseball player whose baseball card is displayed at CIA headquarters.
One of the forefathers of today's commandos was Navy Lieutenant Jack Taylor. He was sequestered by the OSS early in the war and had a long career behind enemy lines.
Taro and Mitsu Yashima, both Japanese political dissidents who were imprisoned in Japan for protesting its regime, worked for the OSS in psychological warfare against the Japanese Empire.
In popular culture.
Films
Television
Literature
Comics
Video games
References.
Notes
Bibliography

</doc>
<doc id="22680" url="https://en.wikipedia.org/wiki?curid=22680" title="Oda Nobunaga">
Oda Nobunaga

 was a powerful samurai warlord of Japan in the late 16th century who initiated the unification of Japan near the end of the Warring States period. He lived a life of continuous military conquest, eventually conquering a third of Japan before his death in a 1582 coup d'état. His successors were Toyotomi Hideyoshi, a loyal Oda supporter who was the first to unify all of Japan and was thus the first ruler of the whole country since the Ōnin War, and later Tokugawa Ieyasu, who was to consolidate his rule under a shogunate, which ruled Japan until the Meiji Restoration in 1868.
Oda Nobunaga is remembered in Japan as one of the most brutal figures of the Warring States period and was recognized as one of Japan's greatest rulers. He was the first of three unifiers during the Warring States period, followed by Toyotomi Hideyoshi and Tokugawa Ieyasu. Nobunaga was well on his way to the complete conquest and unification of Japan when Akechi Mitsuhide, one of his generals, forced Nobunaga to commit seppuku (suicide) in Honnō-ji in Kyoto (It is actually unknown if he was forced to commit suicide or if he died in the attack). Akechi Mitsuhide quickly declared himself master over Nobunaga's domains, but was quickly defeated by Toyotomi Hideyoshi.
Early years.
Oda Nobunaga was born on June 23, 1534, in the Owari domain, and was given the childhood name of . He was the second son of Oda Nobuhide, a deputy "shugo" (military governor) with land holdings in Owari Province. He is said to have been born in Nagoya Castle, although this is subject to debate. Through his childhood and early teenage years, he was well known for his bizarre behavior and received the name of . He was known to run around with other youths from the area, without any regard to his own rank in society. With the introduction of firearms into Japan, though, he became known for his fondness of tanegashima firearms.
Unification of Owari Province.
In 1551, Oda Nobuhide died unexpectedly. Nobunaga was said to have acted outrageously during his funeral, throwing ceremonial incense at the altar. This convinced many Oda retainers of Nobunaga's mediocrity and lack of discipline. Alienated, they then began to side with his soft-spoken and well-mannered brother, Nobuyuki. Hirate Masahide, a valuable mentor and retainer to Nobunaga, was ashamed by Nobunaga's behavior and performed "seppuku". This had a huge effect on Nobunaga, who later built a temple to honor Masahide.
Succession dispute.
Though Nobunaga was Nobuhide's legitimate successor, the Oda clan was divided into many factions, and the clan was technically under the control of Owari's "shugo", Shiba Yoshimune. Oda Nobutomo, the deceased Nobuhide's brother and deputy to the "shugo", used the weak Yoshimune as his puppet and challenged Nobunaga's place as Owari's new ruler. Nobutomo murdered Yoshimune when it was discovered that he supported and attempted to aid Nobunaga.
Nobunaga persuaded Oda Nobumitsu, a younger brother of Nobuhide, to join his side and, with Nobumitsu's help, slew Nobutomo in Kiyosu Castle, which later became Nobunaga's place of residence for over ten years. Taking advantage of the position of Shiba Yoshikane, Yoshimune's son, as the rightful "shugo", Nobunaga forged an alliance with the Imagawa clan of Suruga Province and the Kira clan of Mikawa Province, as both clans had the same "shugo" and would have no excuse to decline. This also ensured that the Imagawa clan would have to stop attacking Owari's borders.
Though Nobuyuki and his supporters were still at large, Nobunaga brought an army to Mino Province to aid Saitō Dōsan after Dōsan's son, Saitō Yoshitatsu, turned against him. The campaign failed, as Dōsan was killed, and Yoshitatsu became the new master of Mino in 1556.
Elimination of Nobuyuki.
A few months later Nobuyuki, with support from Shibata Katsuie and Hayashi Hidesada, rebelled against Nobunaga. The conspirators were defeated at the Battle of Inō, but were pardoned after the intervention of Tsuchida Gozen, the birth mother of Nobunaga and Nobuyuki. The next year, Nobuyuki again planned to rebel. Nobunaga was informed of this by Shibata Katsuie, then faked illness to get close to Nobuyuki and assassinated him in Kiyosu Castle.
By 1559, Nobunaga had eliminated all opposition within the clan and Owari Province. He continued to use Shiba Yoshikane as a pretext to make peace with other daimyo, though it was later discovered that Yoshikane had secretly corresponded with the Kira and Imagawa clans, attempting to oust Nobunaga and restore the Shiba clan's place. Nobunaga eventually cast him out, voiding alliances created in the Shiba clan's name.
Rise to Power.
Battle of Okehazama.
In 1560, Imagawa Yoshimoto gathered an army of 40,000 men and started his march toward Kyoto, with the pretext of aiding the frail Ashikaga shogunate. The Matsudaira clan of Mikawa Province also joined Yoshimoto's forces. Against this, the Oda clan could rally an army of only 3,000, and the forces needed to be split up to defend various border forts. Under such circumstances, Nobunaga was said to have performed his favorite Atsumori dance at Kiyosu Castle, before riding off with only a few attendants to pray. Due to the sheer imbalance in the forces available to the two clans the night before, Shibata Katsuie had tried in vain to change Nobunaga's mind about a frontal attack; he kept reminding Nobunaga of the joint army's lack of manpower compared to Imagawa's numerous soldiers. Hayashi Hidesada, the remaining advisor from Nobuhide's days, even argued for surrender without fighting, using the same reasoning as Katsuie.
Nobunaga's scouts reported that Yoshimoto was resting at the narrow gorge of Dengaku-hazama, ideal for a surprise attack, and that the Imagawa army were celebrating their victories while Yoshimoto viewed the heads. Nobunaga moved towards Imagawa's camp, and set up a position some distance away. An array of flags and dummy troops made of straw and spare helmets gave the impression of a large host, while the real Oda army hurried round in a rapid march to get behind Yoshimoto's camp. The heat gave way to a terrific thunderstorm. As the Imagawa samurai sheltered from the rain Nobunaga deployed his troops, and when the storm ceased they charged down upon the enemy in the gorge, so suddenly that Yoshimoto thought a brawl had broken out among his men, only realizing it was an attack when two samurai charged up. One aimed a spear at him, which Yoshimoto deflected with his sword, but the second swung his blade and cut off Imagawa's head.
Rapidly weakening in the wake of this battle, the Imagawa clan no longer exerted control over the Matsudaira clan. In 1561, an alliance was forged between Oda Nobunaga and Matsudaira Motoyasu (who would become Tokugawa Ieyasu), despite the decades-old hostility between the two clans. Tradition dates this battle as the first time that Nobunaga noticed the talents of the sandal-bearer who would eventually become Toyotomi Hideyoshi.
Siege of Inabayama Castle.
In Mino, Saitō Yoshitatsu died suddenly of illness in 1561, and was succeeded by his son, Saitō Tatsuoki. Tatsuoki, however, was young and much less effective as a ruler and military strategist compared to his father and grandfather. Taking advantage of this situation, Nobunaga moved his base to Komaki Castle and started his campaign in Mino. By convincing Saitō retainers to abandon their incompetent and foolish master, Nobunaga weakened the Saitō clan significantly, eventually mounting a final attack in 1567. Nobunaga captured Inabayama Castle and sent Tatsuoki into exile.
After taking possession of the castle, Nobunaga changed the name of both the castle and the surrounding town to Gifu. Remains of Nobunaga's residence in Gifu can be found today in Gifu Park. Naming it after the legendary Mount Qi (岐山 "Qi" in Standard Chinese) in China, on which the Zhou dynasty started, Nobunaga revealed his ambition to conquer the whole of Japan. He also started using a new personal seal that read "Tenka Fubu" (天下布武), which means "All the world by force of arms". In 1564, Nobunaga had his sister, Oichi, marry Azai Nagamasa, a daimyo in northern Ōmi Province. This would later help pave the way to Kyoto.
Campaign in Kyoto.
In 1568, Ashikaga Yoshiaki went to Gifu to ask Nobunaga to start a campaign toward Kyoto. Yoshiaki was the brother of the murdered thirteenth shogun of the Ashikaga shogunate, Yoshiteru, and wanted revenge against the killers who had already set up a puppet shogun, Ashikaga Yoshihide. Nobunaga agreed to install Yoshiaki as the new shogun and, grasping the opportunity to enter Kyoto, started his campaign. An obstacle in southern Ōmi Province, however, was the Rokkaku clan. Led by Rokkaku Yoshikata, the clan refused to recognize Yoshiaki as shogun and was ready to go to war. In response, Nobunaga launched a rapid attack, driving the Rokkaku clan out of their castles.
Within a short amount of time, Nobunaga had reached Kyoto and driven the Miyoshi clan out of the city. Yoshiaki was made the 15th shogun of the Ashikaga shogunate. Nobunaga refused the post of "Kanrei" (the Shogunal deputy), and eventually began to restrict the powers of the shogun, making it clear that he intended to use him as a façade to justify his future conquests. Yoshiaki, however, was not pleased about being a puppet and secretly corresponded with various daimyo, forging an anti-Nobunaga alliance.
Campaign against Rival Daimyo.
Battle of Anegawa.
The Asakura clan was particularly disdainful of the Oda clan's increasing power because, historically, the Oda clan had been subordinate to the Asakura clan. Furthermore, Asakura Yoshikage had also protected Ashikaga Yoshiaki, but had not been willing to march toward Kyoto. Thus, the Asakura clan also despised Nobunaga the most for his success.
When Nobunaga launched a campaign into the Asakura clan's domain, Azai Nagamasa, to whom Oichi was married, broke the alliance with Oda to honor the Azai-Asakura alliance which had lasted for generations. With the help of Ikko rebels, the anti-Nobunaga alliance sprang into full force, taking a heavy toll on the Oda clan. At the Battle of Anegawa, Tokugawa Ieyasu joined forces with Nobunaga and defeated the combined forces of the Asakura and Azai clans.
The Enryaku-ji monastery on Mt. Hiei, with its "sōhei" (warrior monks) of the Tendai school who aided the anti-Nobunaga group by helping Azai-Asakura alliance, was an issue for Nobunaga since the monastery was so close to his base of power. Nobunaga attacked Enryaku-ji and razed it in 1571, killing between 3,000 and 4,000 men, women and children in the process. The temple was admired as a significant cultural symbol at the time. 
Siege of Nagashima and Ishiyama Hongan-ji.
During the siege of Nagashima, Nobunaga suffered tremendous losses, including the death of a couple of his brothers, to the Ikkō-ikki resistance, a coalition of peasant farmers, monks, Shinto priests, and local nobles that opposed samurai rule. The siege finally ended when Nobunaga surrounded the enemy complex and set fire to it, killing tens of thousands of non-combatants, including women and children. He later succeeded in taking their main stronghold at Ishiyama Hongan-ji after an 11-year siege that ended with its surrender.
Battle of Nagashino.
One of the strongest rulers in the anti-Nobunaga alliance was Takeda Shingen, in spite of his generally peaceful relationship and a nominal alliance with the Oda clan. In 1572, at the urgings of the shogun, Shingen decided to make a drive for the capital starting with invading Tokugawa territory. Tied down on the Western front, Nobunaga sent lackluster aid to Ieyasu, who suffered defeat at the Battle of Mikatagahara in 1573. However, after the battle, Tokugawa's forces launched night raids and convinced Takeda of an imminent counter-attack, thus saving the vulnerable Tokugawa with the bluff. This would play a pivotal role in Tokugawa's philosophy of strategic patience in his campaigns with Oda Nobunaga. Shortly thereafter, the Takeda forces retreated after Shingen died of illness in 1573. This was a relief for Nobunaga because he could now focus on Yoshiaki, who had openly declared hostility more than once, despite the imperial court's intervention. Nobunaga was able to defeat Yoshiaki's forces and send him into exile, bringing the Ashikaga shogunate to an end in the same year.
Also in 1573, Nobunaga successfully destroyed the Asakura and Azai clans, leading Azai Nagamasa to send Oichi back to Nobunaga and commit suicide. With Nagashima's destruction in 1574, the only threat to Nobunaga was the Takeda clan, now led by Takeda Katsuyori.
At the decisive Battle of Nagashino, the combined forces of Nobunaga and Tokugawa Ieyasu devastated the Takeda clan with the strategic use of arquebuses. Nobunaga compensated for the arquebus' slow reloading time by arranging the arquebusiers in three lines. After each line fired, it would duck and reload as the next line fired. The bullets were able to pierce the Takeda cavalry armor, who were pushed back and killed by incoming fire. From there, Nobunaga continued his expansion, sending Shibata Katsuie and Maeda Toshiie to the north and Akechi Mitsuhide to Tamba Province.
Surrender of Ishiyama Hongan-ji.
In 1574 Nobunaga accepted the title of "kuge" (court noble), then in 1577 he was given the title of "udaijin" (or Minister of the Right), the third highest position in the Imperial court.
The Oda clan's siege of Ishiyama Hongan-ji in Osaka made some progress, but the Mori clan of the Chūgoku region broke the naval blockade and started sending supplies into the strongly fortified complex by sea. As a result, in 1577, Hashiba Hideyoshi was ordered to expand west to confront the Mori clan.
However, Uesugi Kenshin, said to be the greatest general of his time since the demise of Takeda Shingen, took part in the second anti-Nobunaga alliance. Following his conquest of neighboring forces, the two sides clashed during the Battle of Tedorigawa which resulted in a decisive Uesugi victory. It was around this time that Uesugi forces began preparations to march on Kyoto.
Due to his defeat, Nobunaga's expansion in Noto, Kaga, and Etchū Province area stagnated. But Kenshin, who prepared to move his armies again after the battle, died from a possible cerebral hemorrhage before moving them. After Kenshin's death and much confusion among his successors, Nobunaga started his campaign again on this area.
Nobunaga forced the Ishiyama Hongan-ji to surrender in 1580 and destroyed the Takeda clan in 1582. Nobunaga's administration was at its height of power and he was about to launch invasions into Echigo Province and Shikoku.
Coup at Honnō-ji and death.
In 1582, Nobunaga's former sandal bearer Hashiba Hideyoshi invaded Bitchu Province, laying siege to Takamatsu Castle. The castle was vital to the Mori clan, and losing it would leave the Mori home domain vulnerable. Led by Mōri Terumoto, reinforcements arrived outside Takamatsu Castle, and the two sides came to a standstill. Hideyoshi asked for reinforcements from Nobunaga.
It has often been argued that Hideyoshi had no need for reinforcements, but asked Nobunaga anyway for various reasons. Most believe that Hideyoshi, envied and hated by fellow generals for his swift rise from a lowly footman to a top general under Oda Nobunaga, wanted to give the credit for taking Takamatsu to Nobunaga so as to humble himself in front of other Oda vassals.
In any case, Nobunaga ordered Niwa Nagahide to prepare for an invasion of Shikoku, and Akechi Mitsuhide to assist Hideyoshi. En route to Chūgoku region, Nobunaga stayed at Honnō-ji, a temple in Kyoto. Since Nobunaga would not expect an attack in the middle of his firmly-controlled territories, he was guarded by only a few dozen personal servants and bodyguards. His son Nobutada stayed at Myōkaku-ji, a temple on the grounds of Nijō Palace, the forerunner to Nijō Castle.
Mitsuhide chose that time to attack. On June 21, 1582, Mitsuhide took a unit of his men and surrounded the Honnō-ji while sending another unit of Akechi troops to assault Myōkaku-ji, initiating a full coup d'état. At Honnō-ji, Nobunaga's small entourage was soon overwhelmed and as the Akechi troops closed in on the burning temple where Nobunaga had been residing, he decided to commit seppuku in one of the inner rooms. Unknown to Nobunaga, his son Nobutada died in the fighting before the temple where he was staying. At Honnō-ji, only his young page, Mori Ranmaru, remained at his master's side; he was still in his teens. Ranmaru's loyalty and devotion to his lord were widely known and praised during the Edo period. He attended to Nobunaga as he sought a moment of peace to carry out his last act, then Ranmaru likewise killed himself in the same way.
The cause of Mitsuhide's "betrayal" is controversial. It has been proposed that Mitsuhide may have heard a rumor that Nobunaga would transfer Mitsuhide's fief to the page, Mori Ranmaru, with whom Nobunaga is alleged to have been in a ritualized homosexual relationship, a form of patronage, known as "shudō". Other motives include revenge for Nobunaga's numerous insults and derisive treatment of Mitsuhide, or Mitsuhide's jealousy as Nobunaga had shown greater favor toward another vassal, Hashiba Hideyoshi. Another possible motive is for revenge as Akechi Mitsuhide's mother (or perhaps aunt) was killed because Nobunaga had gone against a peace treaty that he had previously agreed to.
In 1579, Nobunaga captured Yakami Castle from Hatano Hideharu by promising Hideharu peace terms. This accomplished Mitsuhide's goal, although Nobunaga betrayed the peace agreement and had Hideharu executed. According to several stories, this displeased the Hatano family, and a short while later several of Hideharu's retainers murdered Akechi Mitsuhide's mother (or aunt). The situation was fueled through several public insults Nobunaga had directed at Mitsuhide that even drew the attention of some Western observers. However, Mitsuhide's actual motive for attacking Nobunaga at Honnō-ji is not known.
Just eleven days after the coup at Honnō temple, Mitsuhide was killed at the Battle of Yamazaki and his army was defeated by Hashiba Hideyoshi, who eventually became heir to Nobunaga's legacy. He is more widely known as Toyotomi Hideyoshi. At the time of Nobunaga's death, he was in control of more than half of the provinces in Japan, the majority of which were in the Kyoto region.
Nobunaga, Hideyoshi, and Ieyasu.
Toyotomi Hideyoshi, who unified Japan in 1590, and Tokugawa Ieyasu, who founded the Tokugawa Shogunate in 1603, were loyal followers of Nobunaga. These two were able to build a unified Japan on the basis of Nobunaga's previous achievements. There was a saying: "Nobunaga pounds the national rice cake, Hideyoshi kneads it, and in the end Ieyasu sits down and eats it."
Hideyoshi was brought up from a nameless peasant to be one of Nobunaga's top generals. When he became a grand minister in 1586, he created a law that the samurai caste became codified as permanent and heritable, and that non-samurai were forbidden to carry weapons, thereby ending the social mobility of Japan from which he himself had benefited. He was even said to divert rivers to flood enemy villages and clans. These restrictions lasted until the dissolution of the Edo Shogunate by the Meiji Restoration revolutionaries. Hideyoshi secured his claim as the rightful successor of Nobunaga by defeating Akechi Mitsuhide within a month of Nobunaga's death.
It is important to note that the distinction between samurai and non-samurai was so obscure that during the 16th century, most male adults in any social class (even small farmers) belonged to at least one military organization of their own and served in wars before and during Hideyoshi's rule. It can be said that an "all against all" situation continued for a century. The authorized samurai families after the 17th century were those that chose to follow Nobunaga, Hideyoshi and Ieyasu. Large battles occurred during the change between regimes and a number of defeated samurai were destroyed, became ronin or were absorbed into the general populace.
Ieyasu had shared his childhood with Nobunaga as a hostage of the Oda clan. Though there were a number of battles between him and the Oda clan, Ieyasu eventually switched sides and became one of Nobunaga's strongest allies.
Policies.
Militarily, Nobunaga changed the way war was fought in Japan. He developed, implemented, and expanded the use of long pikes, firearms and castle fortifications in accordance with the expanded mass battles of the period. The firearms that were introduced by the Portuguese had allowed the establishment of firearm brigades in the army. Once the two important musket factories in Sakai City and Omi province were conquered, it gave Nobunaga superior firepower over his enemies. Nobunaga also instituted a specialized warrior class system and appointed his retainers and subjects to positions based on ability, not wholly based on name, rank, or family relationship as in prior periods. Retainers were also given land on the basis of rice output, not land size. Nobunaga's organizational system in particular was later used and extensively developed by his ally Tokugawa Ieyasu in the forming of the Tokugawa shogunate in Edo.
Nobunaga's dominance and brilliance was not restricted to the battlefield, for he also was a keen businessman and understood the principles of microeconomics and macroeconomics. First, in order to modernize the economy from an agricultural base to a manufacture and service base, castle towns were developed as the center and basis of local economies. Roads were also made within his domain between castle towns to not only facilitate trade, but also to move armies great distances in short timespans. International trade was also expanded beyond China and the Korean peninsula, while "nanban" (southern barbarian) trade with Europe, the Philippines, Siam, and Indonesia was also started.
Nobunaga also instituted policies as a way to stimulate business and the overall economy through the use of a free market system. These policies abolished and prohibited monopolies and opened once closed and privileged unions, associations and guilds, which he saw as impediments to commerce. Even though these policies provided a major boost to the economy, it was still heavily dependent on daimyos' support. Copies of his original proclamations can be found in Entoku-ji in the city of Gifu. He also developed tax exemptions and established laws to regulate and ease the borrowing of debt.
Culture.
As Nobunaga conquered Japan and amassed a great amount of wealth, he progressively supported the arts for which he always had an interest, but which he later and gradually more importantly used as a display of his power and prestige. He built extensive gardens and castles which were themselves great works of art. Azuchi Castle on the shores of Lake Biwa is said to have been the greatest castle in the history of Japan, covered with gold and statues on the outside and decorated with standing screen, sliding door, wall, and ceiling paintings made by his subject Kanō Eitoku on the inside. During this time, Nobunaga's subject and tea master Sen no Rikyū established the Japanese tea ceremony which Nobunaga popularized and used originally as a way to talk politics and business. The beginnings of modern kabuki were started and later fully developed in the early Edo period.
Additionally, Nobunaga was very interested in European culture which was still very new to Japan. He collected pieces of Western art as well as arms and armor, and he is considered to be among the first Japanese people in recorded history to wear European clothes. He also became the patron of the Jesuit missionaries in Japan and supported the establishment of the first Christian church in Kyoto in 1576, although he remained an adamant atheist and never converted to Christianity. During a visit by the Jesuits in March 1581, Nobunaga's interest was piqued by a slave in the service of a Jesuit inspector of missions, and it was requested that he be left in Nobunaga's service. This slave, later called by the Japanese name Yasuke, was highly favored by Nobunaga and fought in the final battle at Honnō-ji. During that time, the persecution of Buddhists was motivated mostly by separating politics from religion. Though it was not fully realized under Nobunaga's rule, he attempted to create a public, rational political authority. The concepts brought up during this change had the potential to radically change society in Japan. The new ideas that came forth were either incorporated into common discourses without changing it fundamentally, built upon at a later time, or opened up new options in the later Tokugawa era that were expanded on.
Family.
Depending upon the source, Oda Nobunaga and the entire Oda clan are descendents of either the Fujiwara clan or the Taira clan (specifically, Taira no Shigemori's branch). His lineage can be directly traced to his great-great-grandfather, Oda Hisanaga, who was followed by Oda Toshisada, Oda Nobusada, Oda Nobuhide and Nobunaga himself.
Immediate family.
Nobunaga was the eldest legitimate son of Nobuhide, a minor warlord from Owari Province, and Tsuchida Gozen, who was also the mother to three of his brothers (Nobuyuki, Nobukane and Hidetaka) and two of his sisters (Oinu and Oichi).
Descendants.
Nobunaga married Nōhime, the daughter of Saitō Dōsan, as a matter of political strategy; however, she was unable to give birth to children and was considered to be barren. It was his concubines Kitsuno and Lady Saka who bore his children. Kitsuno gave birth to Nobunaga's eldest son, Nobutada. Nobutada's son, Oda Hidenobu, became ruler of the Oda clan after the deaths of Nobunaga and Nobutada. His son Oda Nobuhide was a Christian, and took the baptismal name Peter; he was adopted by Toyotomi Hideyoshi and commissioned chamberlain.
Other relatives.
One of Nobunaga's younger sisters, Oichi, gave birth to three daughters. These three nieces of Nobunaga became involved with important historical figures. Chacha (also known as Lady Yodo), the eldest, became the mistress of Toyotomi Hideyoshi. O-Hatsu married Kyōgoku Takatsugu. The youngest, O-go, married the son of Tokugawa Ieyasu, Tokugawa Hidetada (the second shogun of the Tokugawa shogunate). O-go's daughter Senhime married her cousin Toyotomi Hideyori, Lady Yodo's son.
Nobunaga's nephew was Tsuda Nobusumi, the son of Nobuyuki. Nobusumi married Akechi Mitsuhide's daughter, and was killed after the Honnō-ji coup by Nobunaga's third son, Nobutaka, who suspected him of being involved in the plot.
Later descendants.
Nobunari Oda, a retired figure skater, claims to be a 17th generation direct descendant of Nobunaga. The ex-monk celebrity Mudō Oda also claims descent from the Sengoku period warlord, but his claims have not been verified.
In popular culture.
Nobunaga appears frequently within fiction and continues to be portrayed in many other anime, manga, video games, and cinematic films. Many depictions show him as villainous or even demonic in nature, though some portray him in a more positive light. The latter type of works include Akira Kurosawa's film "Kagemusha", which portrays Nobunaga as energetic, athletic and respectful towards his enemies. The film "Goemon" portrays him as a saintly mentor of Ishikawa Goemon. Nobunaga is a central character in Eiji Yoshikawa's historical novel "Taiko Ki", where he is a firm but benevolent lord. Nobunaga is also portrayed in a heroic light in some video games such as "Kessen III", "Ninja Gaiden II" and the "Warriors Orochi" series.
By contrast, the novel and anime series "Yōtōden" portrays Nobunaga as a literal demon in addition to a power-mad warlord. In the novel "The Samurai's Tale" by Erik Christian Haugaard, he is portrayed as an antagonist "known for his merciless cruelty". He is portrayed as evil or megalomaniacal in some anime and manga series including "Samurai Deeper Kyo" and "Flame of Recca". Nobunaga is portrayed as evil, villainous, bloodthirsty, and/or demonic in many video games such as "Ninja Master's", "Sengoku", "Maplestory", "" and "Atlantica Online", and the video game series "Onimusha", "Samurai Warriors", "Sengoku Basara" (and its anime adaptation) and "Soulcalibur".
There are also numerous examples of his portrayal in a more neutral or historic framework, especially in the Taiga dramas shown on television in Japan. Oda Nobunaga appears in the manga series "Tail of the Moon", "Kacchu no Senshi Gamu", and Tsuji Kunio's historical fiction "The Signore: Shogun of the Warring States". Historical representations in video games (mostly Western-made strategy titles) include ', ', "Throne of Darkness", the eponymous "Nobunaga's Ambition" series, as well as "Civilization V" and "". Kamenashi Kazuya of the Japanese pop group KAT-TUN wrote and performed a song titled "1582" which is written from the perspective of Mori Ranmaru at the Incident at Honnouji.
There are also more fictive portrayals, in which the figure of Nobunaga influences a story or inspires a characterization. In James Clavell's novel "Shōgun", the character Goroda is a pastiche of Nobunaga. In the film "Sengoku Jieitai 1549" Nobunaga is killed by time-travellers. Nobunaga also appears as a major character in the eroge "Sengoku Rance" and is a playable character in "Pokémon Conquest". In the anime "", in "Sengoku Collection", and the light novel and anime series "The Ambition of Oda Nobuna", he is depicted as a female character. He is the main character of the stage action and anime adaptation of "Nobunaga the Fool".
In the Japanese tokusatsu, "Kamen Rider Ghost", the spirit of Nobunaga helps Makoto Fukami/Kamen Rider Specter, transform into his warlord rifle wielding Nobunaga Damashii form.

</doc>
<doc id="22684" url="https://en.wikipedia.org/wiki?curid=22684" title="Otto Wilhelm Hermann von Abich">
Otto Wilhelm Hermann von Abich

Otto Wilhelm Hermann von Abich (December 11, 1806 – July 1, 1886) was a German mineralogist and geologist. Full member of St Petersburg Academy of Sciences (hon. member since 1866).
Biography.
He was born at Berlin and educated at the local university. His earliest scientific work is related to spinels and other minerals. Later he made special studies of fumaroles, of the mineral deposits around volcanic vents, and of the structure of volcanoes. In 1842 he was appointed professor of mineralogy in the university of Dorpat (Tartu), and henceforth gave attention to the geology and mineralogy of the Russian Empire. Residing for some time at Tiflis, he investigated the geology of the Armenian Highland (this term was introduced by Abich) and Caucasus. In 1844 and 1845 he ascended Ararat volcano several times, studied the geological event of 1840 that was centered on Ararat (Akori village). In 1877 he retired to Vienna, where he died. The mineral Abichite was named after him.
Publications.
The following are listed in Chisholm, 1, p. 62:

</doc>
<doc id="22685" url="https://en.wikipedia.org/wiki?curid=22685" title="Organization of the Communist Party of the Soviet Union">
Organization of the Communist Party of the Soviet Union

The organization of the Communist Party of the Soviet Union was based on the principles of democratic centralism.
The governing body of the Communist Party of the Soviet Union (CPSU) was the Party Congress which initially met annually but whose meetings became less frequent, particularly under Joseph Stalin. Party Congresses would elect a Central Committee which, in turn, would elect a Politburo. Under Stalin the most powerful position in the party became the General Secretary who was elected by the Politburo. In 1952 the title of "General Secretary" became "First Secretary" and the "Politburo" became the "Presidium" before reverting to their former names under Leonid Brezhnev in 1966.
In theory, supreme power in the party was invested in the Party Congress. However, in practice the power structure became reversed and, particularly after the death of Lenin, supreme power became the domain of the General Secretary.
Higher levels.
In the late Soviet Union the CPSU incorporated the communist parties of the 15 constituent republics (the communist branch of the Russian SFSR was established in 1990). Before 1990 the communist party organization in Russian oblasts, autonomous republics and some other major administrative units were subordinated directly to the CPSU Central Committee.
Lower levels.
At lower levels, the organizational hierarchy was managed by Party Committees, or partkoms (партком). A partkom was headed by the elected "partkom bureau secretary" ("partkom secretary", секретарь парткома). At enterprises, institutions, kolkhozes, etc., they were called as such, i.e., "partkoms". At higher levels the Committees were abbreviated accordingly: obkoms (обком) at oblast (zone) levels (known earlier as gubkoms (губком) for guberniyas), "raikoms" (райком) at raion (district) levels (known earlier as ukoms (уком) for uyezds), gorkom (горком) at city levels, etc.
The same terminology ("raikom", etc.) was used in the organizational structure of Komsomol.
The bottom level of the Party was the primary party organization (первичная партийная организация) or party cell (партийная ячейка). It was created within any organizational entity of any kind where there were at least three communists. The management of a cell was called party bureau/partbureau (партийное бюро, партбюро). A partbureau was headed by the elected bureau secretary (секретарь партбюро).
At smaller party cells, secretaries were regular employees of the corresponding plant/hospital/school/etc. Sufficiently large party organizations were usually headed by an exempt secretary, who drew his salary from the Party money.

</doc>
<doc id="22686" url="https://en.wikipedia.org/wiki?curid=22686" title="Oromo people">
Oromo people

The Oromo people (; ; "’Oromo") are an ethnic group inhabiting Ethiopia, northern Kenya, and parts of Somalia. With around 25 million members, they constitute the single largest ethnicity in Ethiopia and the wider Horn of Africa, at approximately 35% of Ethiopia's population according to the 2007 census. Oromos speak the Oromo language as a mother tongue (also called "Afaan Oromoo" and "Oromiffa"), which is part of the Cushitic branch of the Afro-Asiatic family. The name was given as "Ilm’ Orma" ("Sons of Men" or an eponymous 'Orma') in the 19th century; the present form is probably an obsolete plural of the same word "orma" ("person, stranger").
Origins.
Oromos are the largest Cushitic-speaking group of people living in Northeast Africa. Available information suggests that they have existed as a community in the Horn of Africa for several millennia (Prouty et al., 1981).
While further research is needed to precisely comprehend their origins, the Oromo are believed to have originally adhered to a pastoralist/nomadic and/or semi-agriculturalist lifestyle. Many historians agree that some Oromo clans (Bale) have lived in the southern tip of present-day Ethiopia for over a millennium. They suggest that a Great trade-influenced Oromo population movement brought most Oromos to present-day central and western Ethiopia in the 16th and 17th centuries. Historical maps of the ancient Aksum/Abyssinian Empire and Adal/Somali empires indicate that Oromo people are newcomers to most of modern-day central Ethiopia.
Recent history.
Historically, Afaan Oromo-speaking people used their own "Gadaa" system of governance. Oromos also had a number of independent kingdoms, which they shared with the Sidama. Among these were the Gibe region kingdoms of Gera, Gomma, Garo, Gumma, Jimma and Limmu-Ennarea, as well as the kingdom of Jiren.
Historically, both peaceful and violent competition and integration between Oromos and other neighboring ethnicities such as the Amhara, Sidama and the Somali had an impact on politics within the Oromo community. The northern expansion of the Oromos such as the Yejju and, in particular the Arsi, to ethnic Somali and Sidama territories mirrored the southern expansion of Amharas, and helped influence contemporary ethnic politics in Ethiopia. Also the great Somali expansion from the Ogaden plains west towards the Juba river led to conflicts with the Oromo. In some areas, Oromos and Somalis were in competition for fertile territory and natural resources. Additionally, Eastern Oromos, who had adopted Islam, were along with Somalis and Afars part of the Muslim Adal Sultanate, which under Imam Ahmad ibn Ibrihim al-Ghazi led a conquest of the Christian Abyssinian Empire.
Historian Richard Pankhurst stated that before the coming of European powers and the creation of centralized Ethiopia, the area presently known as Ethiopia, Eritrea and Somalia:
Constituted a galaxy of states and polities, each moving in its own orbit, but significantly affecting, and affected by, the other entities in the constellation. Each ruler kept a watchful eye on his neighbors but would often exchange gifts and courtesies with them unless actually at war. Dynastic marriages were made whenever practicable, though these only occasionally crossed barriers of religion. Commerce, on the other hand, made little distinction between faith, and trade routes linked traditionalist, Christian and Muslim localities. Ethnic and linguistic communities remained largely distinct, but there was much cross-fertilization of cultures. This was true not only off the Ethiopian highlands and the Red Sea coastlands, but also further south along the Somali-Oromo frontier where later nineteenth century travelers reported the existence of bilingual trading communities.
In the first decades of the 19th century, three Oromo monarchies, Enarya, Goma and Guma, rose to prominence. The collective area was known as Galla-land and comprised most of central and southern Ethiopia, including lands now held by other ethnic regions. In the general view of Oromo people's role in Ethiopia, Ras Gobana Dacche is a famous Oromo figure who led the development of modern Ethiopia and the political and miliatary incorporation of more territories into Ethiopian borders. Gobana under the authority of Menelik II incorporated several Oromo territories into a centralized Ethiopian state. Some contemporary ethno-nationalist Oromo political groups refer to Gobana in a negative light. Though, before military integration; present day Ethiopia, Eritrea, and parts of Somalia were previously and extensively linked commercially by local, long-distance and trans-frontier trade routes. These commercial routes connected Bonga, Jimma, Seqa, Assandabo, Gojjam, Begemder, Maramma, Massawa, Soddo, Shewa, Harar, Zeila and Berbera. Some Oromo writers believe that the Oromo Ras Gobena and the Amhara Menelik II were the first two people in Ethiopia with the concept of national boundary that brought various different ethno-linguistic communities under a politically and militarily centralized rule.
"The two most important historical figures who signify the introduction of the concepts of national boundary and sovereignty in Ethiopia are Emperor Menelik II and Ras Gobana Dachi, who used guns manufactured in Europe to bring a large swath of Biyas (regions/nations) under a centralized rule."
Ethnically mixed Ethiopians with Oromo background made up a little percentage of Ethiopian generals and leaders. The Wollo Oromo (particularly the Raya Oromo and Yejju Oromo) were early Oromo holders of power among the increasingly mixed Ethiopian state. The later north-to-south movement of central power in Ethiopia led to Oromos in Shewa holding power in Ethiopia together with the Shewan Amhara.
"In terms of descent, the group that became politically dominant in Shewa – and Subsequently in Ethiopia – was a mixture of Amhara and Oromo; in terms of language, religion and cultural practices, it was Amhara."
Nonetheless, in many cases Oromo became part of the Ethiopian nobility without losing their identity. Both ethnically mixed Oromos and those with full Oromo descent held high leadership positions in Ethiopia. Notably Iyasu V was the designated but uncrowned Emperor of Ethiopia (1913–1916), while Haile Selassie I was the crowned and generally acknowledged Emperor of Ethiopia from 1930 to 1974. Both these Ethiopian Emperors are ethnically mixed, with Oromo parents and lineages. Haile Selassie's mother was paternally of Oromo descent and maternally of Gurage heritage, while his father was paternally Oromo and maternally Amhara. He consequently would have been considered Oromo in a patrilineal society, and would have been viewed as Gurage in a matrilineal one. However, in the main, Haile Selassie was regarded as Amhara: his paternal grandmother's royal lineage, through which he was able to ascend to the Imperial throne.
By the 1880s, Sahle Selassie, king of Shewa (the later Emperor Menelik II) allied with Ras Gobena's Shewan Oromo militia to expand his kingdom to the South and East, expanding into areas that hadn't been held together since the invasion of Ahmed Gragn. Another famous leader of Ethiopia with Oromo descent was Ras Makonnen Woldemikael Gudessa, the governor of Harar who served as the top general in the First Italo–Ethiopian War, playing a key role at the Battle of Adwa. He is the father of Ethiopian Emperor Haile Selassie I.
In 1973, Oromo discontent with their position led to the formation of the Oromo Liberation Front (OLF), which began political agitation in the Oromo areas. Also in 1973 there was a catastrophic famine in which over one quarter of a million people died from starvation before the government recognised the disaster and permitted relief measures. The majority who died were Oromos and Amharas from Wollo, Afars and Tigrayans. There were strikes and demonstrations in Addis Ababa in 1974; and in February of that year, Haile Selassie’s government was replaced by the Derg, a military junta led by Mengistu Haile Mariam; but the Council was still Amhara-dominated, with only 25 non-Amhara members out of 125. In 1975 the government declared all rural land State-owned, and announced the end of the tenancy system. However, much of the benefit of this reform was counteracted by compulsive collectivization, State farms and forced resettlement programmes.
In December 2009, a 96-page report titled "Human Rights in Ethiopia: Through the Eyes of the Oromo Diaspora", compiled by the Advocates for Human Rights, documented human rights violations against the Oromo in Ethiopia under three successive regimes: the Abyssinian Empire under Haile Selassie, the Marxist Derg and the current Ethiopian government of the Ethiopian People’s Revolutionary Democratic Front (EPRDF), dominated by members of the Tigray People’s Liberation Front (TPLF) and which was accused to have arrested approximately 20,000 suspected OLF members, to have driven most OLF leadership into exile, and to have effectively neutralized the OLF as a political force in Ethiopia.
According to the Office of the United Nations High Commissioner for Human Rights, the Oromia Support Group (OSG) recorded 594 extra-judicial killings of Oromos by Ethiopian government security forces and 43 disappearances in custody between 2005 and August 2008.
Demographics.
The Oromo people are the largest ethnic grouping in Ethiopia, which has a total of 74 ethnically diverse language groups. About 95% are settled agriculturalists and nomadic pastoralists, practising archaic farming methods and living at subsistence level. A few live in the urban centres.
Oromos today are mainly concentrated in the Oromia region in central Ethiopia, which is the largest region in the country in terms of both population and size. Group members also have a notable presence in northern Kenya.
Language.
The Oromo speak the Oromo language as a mother tongue (also known as "Afaan Oromoo" and "Oromiffa"). It belongs to the Cushitic branch of the Afro-Asiatic family.
According to "Ethnologue", there are around 40,467,900 Oromo speakers worldwide.
The Oromo language is divided into four main linguistic varieties: Borana-Arsi-Guji Oromo, Eastern Oromo, Orma and West Central Oromo.
Modern writing systems used to transcribe Oromo include the Latin script. The Ethiopic script had previously been used by Oromo communities in west-central Ethiopia up until the 1990s. Additionally, the Sapalo script was historically used to write Oromo. It was invented by the Oromo scholar Sheikh Bakri Sapalo (also known by his birth name, Abubaker Usman Odaa) during the 1950s. The Arabic script has also traditionally been used in areas with Muslim populations.
Subgroups.
The Oromo are divided into two major branches that break down into an assortment of clan families. From west to east. The Borana Oromo, also called the Boran, are a pastoralist group living in southern Ethiopia (Oromia) and northern Kenya. The Boran inhabit the former provinces of Shewa, Welega, Illubabor, Kafa, Jimma, Sidamo, northern and northeastern Kenya, and some parts of Somalia.
Barentu/Barentoo or (older) Baraytuma is the other moiety of the Oromo people. The Barentu Oromo inhabit the eastern parts of the Oromia Region in the Zones of Mirab Hararghe or West Hararghe, Arsi Zone, Bale Zone, Debub Mirab Shewa Zone or South West Shewa, Dire Dawa region, the Jijiga Zone of the Somali Region, Administrative Zone 3 of the Afar Region, Oromia Zone of the Amhara Region, and are also found in the Raya Azebo woreda in the Tigray Region.
Society and culture.
Gadaa.
Oromo society was traditionally structured in accordance with "Gadaa", a social stratification system partially based on an eight-year cycle of age sets. However, over the centuries, the age sets grew out-of-alignment with the actual ages of their members, and some time in the 19th century, another age set system was instituted. Under gadaa, every eight years, the Oromo would hold a popular assembly called the "Gumi Gayo", where laws were established for the following eight years. A democratically elected leader, the "Abba Gada", presided over the system for an eight-year term. Gadaa is no longer in wide practice but remains influential.
In a short article, Geoffrey W. Arnott described an Oromo rite of passage in which young men run over the backs of bulls surrounded by the village community.
Religion.
Waaq (also Waq or Waaqa) is the name of God in the traditional Oromo religion, which only about 3% of the population of Oromia follows today, those who do usually living in the Borena Zone.
In the 2007 Ethiopian census in the 88% Oromo region of Oromia, 47.5% were Muslims, 30.5% Orthodox Christians, 17.7% Protestant Christian, 3.3% Traditional. Protestant Christianity is the fastest growing religion inside the Oromo community. In urban areas of Oromia, Orthodox Christianity constitute 51.2% of the population, followed by Islam 29.9% and Protestants 17.5%. But adherence to traditional practices and rituals is still common among many Oromo people regardless of religious background.
Calendar.
It is believed that the Oromo developed their own calendar around 300 BCE. The Oromo calendar is a lunar-stellar calendrical system, relying on astronomical observations of the moon in conjunction with seven particular stars or constellations. Borana Months (Stars/Lunar Phases) are Bittottessa (iangulum), Camsa (Pleiades), Bufa (Aldebarran), Waxabajjii (Belletrix), Obora Gudda (Central Orion-Saiph), Obora Dikka (Sirius), Birra (full moon), Cikawa (gibbous moon), Sadasaa (quarter moon), Abrasa (large crescent), Ammaji (medium crescent), and Gurrandhala (small crescent).
Current.
Most Oromos do not have political unity today due to their historical roles in the Ethiopian state and the region, the spread out movement of different Oromo clans, and the differing religions inside the Oromo nation. Accordingly, Oromos played major roles in all three main political movements in Ethiopia (centralist, federalist and secessionist) during the 19th and 20th century. In addition to holding high powers during the centralist government and the monarchy, the Raya Oromos in Tigray played a major role in the revolt inside the Tigray regional state, known as "Weyane" revolt, challenging Emperor Haile Selassie I's rule in the 1940s. Simultaneously, both federalist and secessionist political forces developed inside the Oromo community.
Presently, a number of ethnic based political organizations have been formed to promote the interests of the Oromo. The first was the Mecha and Tulama Self-Help Association founded in January 1963, but was disbanded by the government after several increasingly tense confrontations in November, 1966. Later groups include the Oromo Liberation Front (OLF), Oromo Federalist Democratic Movement (OFDM), the United Liberation Forces of Oromia (ULFO), the Islamic Front for the Liberation of Oromia (IFLO), the Oromia Liberation Council (OLC), the Oromo National Congress (ONC, recently changed to OPC) and others. Another group, the Oromo People's Democratic Organization (OPDO), is one of the four parties that form the ruling Ethiopian People's Revolutionary Democratic Front (EPRDF) coalition. However, these Oromo groups do not act in unity: the ONC, for example, was part of the United Ethiopian Democratic Forces coalition that challenged the EPRDF in the Ethiopian general elections of 2005.
A number of these groups seek to create an independent Oromo nation, some using armed force. Meanwhile, the ruling OPDO and several opposition political parties in the Ethiopian parliament believe in the unity of the country which has 80 different ethnicities. But most Oromo opposition parties in Ethiopia condemn the economic and political inequalities in the country. Progress has been very slow with the Oromia International Bank just recently established in 2008 though Oromo owned Awash International Bank started early in the 1990s and with the first private Afaan Oromoo newspaper in Ethiopia, Jimma Times, also known as Yeroo, recently established. Though the "Jimma Times" – Yeroo newspaper has faced a lot of harassment and persecution from the Ethiopian government since its beginning. Abuse of Oromo media is widespread in Ethiopia and reflective of the general oppression Oromos face in the country. University departments in Ethiopia did not establish curriculum in Afaan Oromo until the late 1990s.
Various human rights organizations have publicized the government persecution of Oromos in Ethiopia for decades. In 2008, OFDM opposition party condemned the government's indirect role in the death of hundreds of Oromos in western Ethiopia. According to Amnesty International, "between 2011 and 2014, at least 5000 Oromos have been arrested based on their actual or suspected peaceful opposition to the government. These include thousands of peaceful protestors and hundreds of opposition political party members. The government anticipates a high level of opposition in Oromia, and signs of dissent are sought out and regularly, sometimes pre-emptively, suppressed. In numerous cases, actual or suspected dissenters have been detained without charge or trial, killed by security services during protests, arrests and in detention."

</doc>
<doc id="22687" url="https://en.wikipedia.org/wiki?curid=22687" title="Oral history">
Oral history

Oral history is the collection and study of historical information about individuals, families, important events, or everyday life using audiotapes, videotapes, or transcriptions of planned interviews. These interviews are conducted with people who participated in or observed past events and whose memories and perceptions of these are to be preserved as an aural record for future generations. Oral history strives to obtain information from different perspectives and most of these cannot be found in written sources. "Oral history" also refers to information gathered in this manner and to a written work (published or unpublished) based on such data, often preserved in archives and large libraries.
The term is sometimes used in a more general sense to refer to any information about past events that people who experienced them tell anybody else, but professional historians usually consider this to be oral tradition. However, as the Columbia Encyclopedia explains: 
Primitive societies have long relied on oral tradition to preserve a record of the past in the absence of written histories. In Western society, the use of oral material goes back to the early Greek historians Herodotus and Thucydides, both of whom made extensive use of oral reports from witnesses. The modern concept of oral history was developed in the 1940s by Allan Nevins and his associates at Columbia University.
In modern times.
Oral history has become an international movement in historical research. Oral historians in different countries have approached the collection, analysis, and dissemination of oral history in different modes. However, it should also be noted that there are many ways of creating oral histories and carrying out the study of oral history even within individual national contexts.
In the words of the "Columbia Encyclopedia": 
The discipline came into its own in the 1960s and early 70s when inexpensive tape recorders were available to document such rising social movements as civil rights, feminism, and anti–Vietnam War protest. Authors such as Studs Terkel, Alex Haley, and Oscar Lewis have employed oral history in their books, many of which are largely based on interviews. In another important example of the genre, a massive archive covering the oral history of American music has been compiled at the Yale School of Music. By the end of the 20th cent. oral history had become a respected discipline in many colleges and universities. At that time the Italian historian Alessandro Portelli and his associates began to study the role that memory itself, whether accurate or faulty, plays in the themes and structures of oral history. Their published work has since become standard material in the field, and many oral historians now include in their research the study of the subjective memory of the persons they interview.
In the United Kingdom.
Since the early 1970s, oral history in Britain has grown from being a method in folklore studies (see for example the work of the School of Scottish Studies in the 1950s) to becoming a key component in community histories. Oral history continues to be an important means by which non-academics can actively participate in the compilation and study of history. However, practitioners across a wide range of academic disciplines have also developed the method into a way of recording, understanding, and archiving narrated memories. Influences have included women's history and labour history.
In Britain the Oral History Society has played a key role in facilitating and developing the use of oral history. A more complete account of the history of oral history in Britain and Northern Ireland can be found at "Making Oral History" on the Institute of Historical Research's website.
During 1998 and 1999, forty BBC local radio stations recorded personal oral histories from a broad cross-section of the population for the series The Century Speaks. The result was 640 half-hour radio documentaries, broadcast in the final weeks of the millennium, and one of the largest single oral history collections in Europe, the Millennium Memory Bank (MMB). The interview based recordings are held by the British Library Sound Archive in the oral history collection.
In one of the largest memory project anywhere, The BBC in 2003-6 invited its audiences to send in recollections of the homefront in the Second World War. It put 47,000 of the recollections online, along with 15,000 photographs.
In the United States.
Elite studies.
In 1948, Allan Nevins, a Columbia University historian, established the Columbia Oral History Research Office, now known as the Columbia Center for Oral History, with a mission of recording, transcribing, and preserving oral history interviews. The Regional Oral History Office was founded in 1954 as a division of the University of California, Berkeley's Bancroft Library. In 1967, American oral historians founded the Oral History Association, and British oral historians founded the Oral History Society in 1969. There are now numerous national organizations and an International Oral History Association, which hold workshops and conferences and publish newsletters and journals devoted to oral history theory and practices.
Oral history began with a focus on national leaders in the United States, but has expanded to include groups representing the entire population. In Britain, the influence of 'history from below' and interviewing people who had been 'hidden from history' was more influential. However, in both countries elite oral history has emerged as an important strand. Scientists, for example, have been covered in numerous oral history projects. Doel (2003) discusses the use of oral interviews by scholars as primary sources, He lists major oral history projects in the history of science begun after 1950. Oral histories, he concludes, can augment the biographies of scientists and help spotlight how their social origins influenced their research. Doel acknowledges the common concerns historians have regarding the validity of oral history accounts. He identifies studies that used oral histories successfully to provide critical and unique insight into otherwise obscure subjects, such as the role scientists played in shaping US policy after World War II. Interviews furthermore can provide road maps for researching archives, and can even serve as a fail-safe resource when written documents have been lost or destroyed. Roger D. Launius (2003) shows the huge size and complexity of the National Aeronautics and Space Administration (NASA) oral history program since 1959. NASA systematically documented its operations through oral histories. They can help to explore broader issues regarding the evolution of a major federal agency. The collection consists primarily of oral histories conducted by scholars working on books about the agency. Since 1996, however, the collection has also included oral histories of senior NASA administrators and officials, astronauts, and project managers, part of a broader project to document the lives of key agency individuals. Launius emphasizes efforts to include such less-well-known groups within the agency as the Astrobiology Program, and to collect the oral histories of women in NASA.
Folklore roots and ordinary people.
Contemporary oral history involves recording or transcribing eyewitness accounts of historical events. Some anthropologists started collecting recordings (at first especially of Native American folklore) on phonograph cylinders in the late 19th century. In the 1930s, the Federal Writers' Project—part of the Works Progress Administration (WPA)—sent out interviewers to collect accounts from various groups, including surviving witnesses of the Civil War, slavery, and other major historical events. The Library of Congress also began recording traditional American music and folklore onto acetate discs. With the development of audio tape recordings after World War II, the task of oral historians became easier.
In 1946, David P. Boder, a professor of psychology at the Illinois Institute of Technology in Chicago, traveled to Europe to record long interviews with "displaced persons"—most of them Holocaust survivors. Using the first device capable of capturing hours of audio—the wire recorder—Boder came back with the first recorded Holocaust testimonials and in all likelihood the first recorded oral histories of significant length.
Many state and local historical societies have oral history programs. Sinclair Kopp (2002) report on the Oregon Historical Society's program. It began in 1976 with the hiring of Charles Digregorio, who had studied at Columbia with Nevins. Thousands of sound recordings, reel-to-reel tapes, transcriptions, and radio broadcasts have made it one of the largest collections of oral history on the Pacific Coast. In addition to political figures and prominent businessmen, the Oregon Historical Society has done interviews with minorities, women, farmers, and other ordinary citizens, who have contributed extraordinary stories reflecting the state's cultural and social heritage. Hill (2004) encourages oral history projects in high school courses. She demonstrates a lesson plan that encourages the study of local community history through interviews. By studying grassroots activism and the lived experiences of its participants, her high school students came to appreciate how African Americans worked to end Jim Crow laws in the 1950s.
Naison (2005) describes the Bronx African I AM BLACK MAN American History Project, an oral community history project developed by the Bronx County Historical Society. Its goal was to document the histories of black working- and middle-class residents of the South Bronx neighborhood of Morrisania in New York City since the 1940s.
In post-dictatorships.
Belarus oral history.
, since the government-run historiography in modern Belarus almost fully excludes repression during the epoch when Belarus was part of the Soviet Union, only private initiatives cover these aspects. Citizens' groups in Belarus use the methods of oral history and record narrative interviews on video: the Virtual Museum of Soviet Repression in Belarus presents a full Virtual museum with intense use of oral history. The Belarusian Oral History Archive project also provides material based on oral history recordings.
Czech oral history.
Czech oral history (likewise the oral history applied in others so called post communist countries) did not experience that building period in 1960s and 1970s, partly at the beginning in 1980s, where in the world is spoken about social movement more than a method. With knowledge of the thing I can say that this development was in its beginning probably necessary and well- founded. Understandable (in its beginning) was also some political activism. In 1970s and 1980s in Czech Republic (similarly in other countries of so-called socialist block) was OH absolutely unknown. History and historians did not know about it. Isolate attempts to invite witnesses for scientific project ended without accomplishment (ideological task, guiltlessness of method, imperfect technique, etc.). Hypothetically, if the OH had been discovered earlier for Czech historians, it could have acted positive and surely combative activist role (as A. Freund. P. Thomson and many others speak about it) like in other authoritative regimes. It could have aimed at enquiry of proscribe groups: dissent or prisoners of conscience. To cognate research or any other allusion about just mentioned groups of fellow – citizen was until 1989 totally avoided by communist historiography. Oral History was for the first time used in the mid 1990s but we can speak about some kind of progress for past six years, as Sean Field speaks about it, when it has transformed from disregard and criticized to possibly respect. In the first years of 21st century one can even speak about boom of Oral History in the Czech republic. In 2000, The Oral History Center (COH) at the Institute of Contemporary History, Academy of Sciences, Czech Republic (AV ČR) was established. Next year, in 2001, was created association Post Bellum.
Projects.
"Students in the Period of the Fall of Communism - Life Stories", published as the book "One Hundred Student Revolutions" by M. Vaněk and M. Otáhal (1999), was funded by the Grant Agency AV ČR. The project "Political Elites and Dissidents during the Period of So-called Normalization - Historical Interviews" was funded by the GA ČR and resulted in two publications: Victors? Vanquished (2005), a two-volume collection of 50 exemplary interviews; and a compilation of original interpretive essays entitled The Powerful?! or Helpless?! These publications demonstrate that oral history can contribute greatly to our understanding of many interesting fields in human lives and history itself, such as the motives behind the dissidents' activities, the formation of opposition groups, communication between dissidents and state representatives and the emergence of ex-communist elites and their decision-making processes. "An Investigation into Czech Society during the 'Normalization' Era: Biographic Narratives of Workers and the Intelligentsia" (funded by the Grant Agency AV ČR). The book of interpretations (called "Ordinary People...?!") (2009). All oral history centers in the Czech Republic emphasize educational activities (seminars, lectures, conferences), archiving and maintaining interview collections, and providing consultations to those interested in the method.
Post Bellum is a non-profit organization founded in 2001 by a group of historians and journalists interested in increasing the knowledge of people regarding events that occurred in the 20th Century within the Czech Republic and surrounding European countries. Post Bellum has collected thousands of witness accounts by conducting interviews with people who lived through significant periods in history. Their documentation project created in 2008, Memory of Nation, is the biggest oral history project in the Czech Republic. They are working together with Czech Radio and Institute for the Study of Totalitarian Regimes.
In Italy.
Alessandro Portelli is an Italian oral historian. He is known for his work which compared workers' experiences in Harlan County, Kentucky and Terni, Italy. Other oral historians have drawn on Portelli's analysis of memory, identity, and the construction of history.
In Spain.
Because of repression during the Franco dictatorship (1939–75), the development of oral history in Spain was quite limited until the 1970s. It became well-developed in the early 1980s, and often had a focus on the Civil War years (1936–39), especially regarding the losers whose stories had been suppressed. The field was based at the University of Barcelona. Professor Mercedes Vilanova was a leading exponent, and combined it with her interest in quantification and social history. The Barcelona group sought to integrate oral sources with traditional written sources to create mainstream, not ghettoized, historical interpretations. They sought to give a public voice to neglected groups, such as women, illiterates, political leftists, and ethnic minorities.
Methods.
Historians, folklorists, anthropologists, sociologists, journalists, linguists, and many others employ some form of interviewing in their research. Although multi-disciplinary, oral historians have promoted common ethics and standards of practice, most importantly the attaining of the "informed consent" of those being interviewed. Usually this is achieved through a deed of gift, which also establishes copyright ownership that is critical for publication and archival preservation.
Oral historians generally prefer to ask open-ended questions and avoid leading questions that encourage people to say what they think the interviewer wants them to say. Some interviews are "life reviews," conducted with people at the end of their careers. Other interviews focus on a specific period or a specific event in people's lives, such as in the case of war veterans or survivors of a hurricane.
Feldstein (2004) considers oral history to be akin to journalism, Both are committed to uncovering truths and compiling narratives about people, places, and events. Felstein says each could benefit from adopting techniques from the other. Journalism could benefit by emulating the exhaustive and nuanced research methodologies used by oral historians. The practice of oral historians could be enhanced by utilizing the more sophisticated interviewing techniques employed by journalists, in particular, the use of adversarial encounters as a tactic for obtaining information from a respondent.
The first oral history archives focused on interviews with prominent politicians, diplomats, military officers, and business leaders. By the 1960s and '70s, influenced by the rise of new social history, interviewing began to be employed more often when historians investigated history from below. Whatever the field or focus of a project, oral historians attempt to record the memories of many different people when researching a given event. Interviewing a single person provides a single perspective. Individuals may misremember events or distort their account for personal reasons. By interviewing widely, oral historians seek points of agreement among many different sources, and also record the complexity of the issues. The nature of memory—both individual and community—is as much a part of the practice of oral history as are the stories collected.
Legal interpretation and relationship to historical truth.
In 1997 the Supreme Court of Canada, in the "Delgamuukw v. British Columbia" trial, ruled that oral histories were just as important as written testimony. Of oral histories, it said "that they are tangential to the ultimate purpose of the fact-finding process at trial – the determination of the historical truth."
Writers who use oral history have often discussed its relationship to historical truth. Gilda O'Neill writes in "Lost Voices", an oral history of East End hop-pickers: "I began to worry. Were the women's, and my, memories true or were they just stories? I realised that I had no 'innocent' sources of evidence - facts. I had, instead, the stories and their tellers' reasons for remembering in their own particular ways.' Duncan Barrett, one of the co-authors of "The Sugar Girls" describes some of the perils of relying on oral history accounts: "On two occasions, it became clear that a subject was trying to mislead us about what happened – telling a self-deprecating story in one interview, and then presenting a different, and more flattering, version of events when we tried to follow it up. [...] often our interviewees were keen to persuade us of a certain interpretation of the past, supporting broad, sweeping comments about historical change with specific stories from their lives." Alessandro Portelli argues that oral history is valuable nevertheless: "it tells us less about events as such than about their meaning [...] the unique and precious element which oral sources force upon the historian [...] is the speaker's subjectivity."
Regarding the accuracy of oral history, Jean-Loup Gassend concludes in the book "Autopsy of a Battle" "I found that each witness account can be broken down into two parts: 1) descriptions of events that the witness participated in directly, and 2) descriptions of events that the witness did not actually participate in, but that he heard about from other sources. The distinction between these two parts of a witness account is of the highest importance. I noted that concerning events that the witnesses participated in, the information provided was surprisingly reliable, as was confirmed by comparison with other sources. The imprecision or mistakes usually concerned numbers, ranks, and dates, the first two tending to become inflated with time. Concerning events that the witness had not participated in personally, the information was only as reliable as whatever the source of information had been (various rumors); that is to say, it was often very unreliable and I usually discarded such information."
Organization.
National and international organizations promote scholarship in the field. The "Oral History Review" is a scholarly journal begun in 1974. The "Oral History Journal" in Britain was established two years before the "Review". H-ORALHIST is an H-Net Discussion Network established in 1996, based on an earlier listserv, OHA-L, developed by Terry Birdwhistell of the University of Kentucky. It works by email and knits together an international network of researchers interested in creating and using oral history. Its daily email reach 3400 subscribers with discussions of current projects, teaching methods, and the state of historiography in the field. H-ORALHIST is especially interested in methods of teaching oral history to graduate and undergraduate students in diverse settings. H-ORALHIST publishes syllabi, outlines, handouts, bibliographies, tables of contents of journals, guides to term papers, listings of new sources, library catalogs and archives, and reports on new software, datasets, and other materials. H-ORALHIST posts announcements of conferences, fellowships, and jobs. It also carries information about new books and commissions book reviews.

</doc>
<doc id="22689" url="https://en.wikipedia.org/wiki?curid=22689" title="Oncogene">
Oncogene

An oncogene is a gene that has the potential to cause cancer. In tumor cells, they are often mutated or expressed at high levels.
Most normal cells will undergo a programmed form of rapid cell death (apoptosis) when critical functions are altered. Activated oncogenes can cause those cells designated for apoptosis to survive and proliferate instead. Most oncogenes require an additional step, such as mutations in another gene, or environmental factors, such as viral infection, to cause cancer. Since the 1970s, dozens of oncogenes have been identified in human cancer. Many cancer drugs target the proteins encoded by oncogenes.
History.
The first theory of oncogenes was given by Danish physicist Niels Henrik Arley (1938-40 scientific private secretary for Niels Bohr. 1947-53 head of Copenhagen University geophysics research) at around 1950, but was rejected by contemporaries as nonsense. Later on the term "oncogene" was rediscovered in 1969 by National Cancer Institute scientists, George Todaro and Robert Heubner.
The first confirmed oncogene was discovered in 1970 and was termed src (pronounced "sarc" as in "sarcoma"). Src was in fact first discovered as an oncogene in a chicken retrovirus. Experiments performed by Dr. G. Steve Martin of the University of California, Berkeley demonstrated that the Src was indeed the oncogene of the virus. The first nucleotide sequence of v-src was sequenced in 1980 by A.P. Czernilofsky et al.
In 1976 Drs. Dominique Stehelin, J. Michael Bishop and Harold E. Varmus of the University of California, San Francisco demonstrated that oncogenes were activated proto-oncogenes, found in many organisms including humans. For this discovery, proving Todaro and Heubner's "oncogene theory", Bishop and Varmus were awarded the Nobel Prize in Physiology or Medicine in 1989.
Oncoproteins are any proteins coded by an oncogene and they play an important role in the regulation or synthesis of proteins linked to tumorigenic cell growth. Some oncoproteins are accepted and used as tumor markers
Proto-oncogene.
A proto-oncogene is a normal gene that can become an oncogene due to mutations or increased expression. The resultant protein encoded by an oncogene is termed oncoprotein. Proto-oncogenes code for proteins that help to regulate cell growth and differentiation. Proto-oncogenes are often involved in signal transduction and execution of mitogenic signals, usually through their protein products. Upon "activation", a proto-oncogene (or its product) becomes a tumor-inducing agent, an oncogene. Examples of proto-oncogenes include RAS, WNT, MYC, ERK, and TRK. The MYC gene is implicated in Burkitt's Lymphoma, which starts when a chromosomal translocation moves an enhancer sequence within the vicinity of the MYC gene. The MYC gene codes for widely used transcription factors. When the enhancer sequence is wrongly placed, these transcription factors are produced at much higher rates. Another example of an oncogene is the Bcr-Abl gene found on the Philadelphia Chromosome, a piece of genetic material seen in Chronic Myelogenous Leukemia caused by the translocation of pieces from chromosomes 9 and 22. Bcr-Abl codes for a receptor tyrosine kinase, which is constitutively active, leading to uncontrolled cell proliferation. (More information about the Philadelphia Chromosome below)
Activation.
The proto-oncogene can become an oncogene by a relatively small modification of its original function. There are three basic methods of activation:
The expression of oncogenes can be regulated by microRNAs (miRNAs), small RNAs 21-25 nucleotides in length that control gene expression by downregulating them. Mutations in such microRNAs (known as oncomirs) can lead to activation of oncogenes. Antisense messenger RNAs could theoretically be used to block the effects of oncogenes.
Classification.
There are several systems for classifying oncogenes, but there is not yet a widely accepted standard. They are sometimes grouped both spatially (moving from outside the cell inwards) and chronologically (parallelling the "normal" process of signal transduction). There are several categories that are commonly used:
More detailed information for the above Table:

</doc>
<doc id="22691" url="https://en.wikipedia.org/wiki?curid=22691" title="Orthogonal frequency-division multiplexing">
Orthogonal frequency-division multiplexing

Orthogonal frequency-division multiplexing (OFDM) is a method of encoding digital data on multiple carrier frequencies. OFDM has developed into a popular scheme for wideband digital communication, used in applications such as digital television and audio broadcasting, DSL Internet access, wireless networks, powerline networks, and 4G mobile communications.
OFDM is a frequency-division multiplexing (FDM) scheme used as a digital multi-carrier modulation method. A large number of closely spaced orthogonal sub-carrier signals are used to carry data on several parallel data streams or channels. Each sub-carrier is modulated with a conventional modulation scheme (such as quadrature amplitude modulation or phase-shift keying) at a low symbol rate, maintaining total data rates similar to conventional "single-carrier" modulation schemes in the same bandwidth.
The primary advantage of OFDM over single-carrier schemes is its ability to cope with severe channel conditions (for example, attenuation of high frequencies in a long copper wire, narrowband interference and frequency-selective fading due to multipath) without complex equalization filters. Channel equalization is simplified because OFDM may be viewed as using many slowly modulated narrowband signals rather than one rapidly modulated wideband signal. The low symbol rate makes the use of a guard interval between symbols affordable, making it possible to eliminate intersymbol interference (ISI) and utilize echoes and time-spreading (on analogue TV these are visible as ghosting and blurring, respectively) to achieve a diversity gain, i.e. a signal-to-noise ratio improvement. This mechanism also facilitates the design of single frequency networks (SFNs), where several adjacent transmitters send the same signal simultaneously at the same frequency, as the signals from multiple distant transmitters may be combined constructively, rather than interfering as would typically occur in a traditional single-carrier system.
Example of applications.
The following list is a summary of existing OFDM based standards and products. For further details, see the Usage section at the end of the article.
Wireless.
The OFDM based multiple access technology OFDMA is also used in several 4G and pre-4G cellular networks and mobile broadband standards:
Key features.
The advantages and disadvantages listed below are further discussed in the Characteristics and principles of operation section below.
Characteristics and principles of operation.
Orthogonality.
Conceptually, OFDM is a specialized FDM, the additional constraint being: all the carrier signals are orthogonal to each other.
In OFDM, the sub-carrier frequencies are chosen so that the sub-carriers are orthogonal to each other, meaning that cross-talk between the sub-channels is eliminated and inter-carrier guard bands are not required. This greatly simplifies the design of both the transmitter and the receiver; unlike conventional FDM, a separate filter for each sub-channel is not required.
The orthogonality requires that the sub-carrier spacing is formula_1 Hertz, where "T"U seconds is the useful symbol duration (the receiver side window size), and "k" is a positive integer, typically equal to 1. Therefore, with "N" sub-carriers, the total passband bandwidth will be "B" ≈ "N"·Δ"f" (Hz).
The orthogonality also allows high spectral efficiency, with a total symbol rate near the Nyquist rate for the equivalent baseband signal (i.e. near half the Nyquist rate for the double-side band physical passband signal). Almost the whole available frequency band can be utilized. OFDM generally has a nearly 'white' spectrum, giving it benign electromagnetic interference properties with respect to other co-channel users.
OFDM requires very accurate frequency synchronization between the receiver and the transmitter; with frequency deviation the sub-carriers will no longer be orthogonal, causing "inter-carrier interference" (ICI) (i.e., cross-talk between the sub-carriers). Frequency offsets are typically caused by mismatched transmitter and receiver oscillators, or by Doppler shift due to movement. While Doppler shift alone may be compensated for by the receiver, the situation is worsened when combined with multipath, as reflections will appear at various frequency offsets, which is much harder to correct. This effect typically worsens as speed increases, and is an important factor limiting the use of OFDM in high-speed vehicles. In order to mitigate ICI in such scenarios, one can shape each sub-carrier in order to minimize the interference resulting in a non-orthogonal subcarriers overlapping. For example, a low-complexity scheme referred to as WCP-OFDM () consists in using short filters at the transmitter output in order to perform a potentially non-rectangular pulse shaping and a near perfect reconstruction using a single-tap per subcarrier equalization. Other ICI suppression techniques usually increase drastically the receiver complexity.
Implementation using the FFT algorithm.
The orthogonality allows for efficient modulator and demodulator implementation using the FFT algorithm on the receiver side, and inverse FFT on the sender side. Although the principles and some of the benefits have been known since the 1960s, OFDM is popular for wideband communications today by way of low-cost digital signal processing components that can efficiently calculate the FFT.
The time to compute the inverse-FFT or FFT transform has to take less than the time for each symbol., which for example for DVB-T means the computation has to be done in or less.
For an -point FFT this may be approximated to:
The computational demand approximately scales linearly with FFT size so a double size FFT needs double the amount of time and vice versa.
As a comparison an Intel Pentium III CPU at 1.266 GHz is able to calculate a FFT in using FFTW. Intel Pentium M at 1.6 GHz does it in Intel Core Duo at 3.0 GHz does it in .
Guard interval for elimination of intersymbol interference.
One key principle of OFDM is that since low symbol rate modulation schemes (i.e., where the symbols are relatively long compared to the channel time characteristics) suffer less from intersymbol interference caused by multipath propagation, it is advantageous to transmit a number of low-rate streams in parallel instead of a single high-rate stream. Since the duration of each symbol is long, it is feasible to insert a guard interval between the OFDM symbols, thus eliminating the intersymbol interference.
The guard interval also eliminates the need for a pulse-shaping filter, and it reduces the sensitivity to time synchronization problems.
The cyclic prefix, which is transmitted during the guard interval, consists of the end of the OFDM symbol copied into the guard interval, and the guard interval is transmitted followed by the OFDM symbol. The reason that the guard interval consists of a copy of the end of the OFDM symbol is so that the receiver will integrate over an integer number of sinusoid cycles for each of the multipaths when it performs OFDM demodulation with the FFT. In some standards such as Ultrawideband, in the interest of transmitted power, cyclic prefix is skipped and nothing is sent during the guard interval. The receiver will then have to mimic the cyclic prefix functionality by copying the end part of the OFDM symbol and adding it to the beginning portion.
Simplified equalization.
The effects of frequency-selective channel conditions, for example fading caused by multipath propagation, can be considered as constant (flat) over an OFDM sub-channel if the sub-channel is sufficiently narrow-banded (i.e., if the number of sub-channels is sufficiently large). This makes frequency domain equalization possible at the receiver, which is far simpler than the time-domain equalization used in conventional single-carrier modulation. In OFDM, the equalizer only has to multiply each detected sub-carrier (each Fourier coefficient) in each OFDM symbol by a constant complex number, or a rarely changed value.
If differential modulation such as DPSK or DQPSK is applied to each sub-carrier, equalization can be completely omitted, since these non-coherent schemes are insensitive to slowly changing amplitude and phase distortion.
In a sense, improvements in FIR equalization using FFTs or partial FFTs leads mathematically closer to OFDM, but the OFDM technique is easier to understand and implement, and the sub-channels can be independently adapted in other ways than varying equalization coefficients, such as switching between different QAM constellation patterns and error-correction schemes to match individual sub-channel noise and interference characteristics.
Some of the sub-carriers in some of the OFDM symbols may carry pilot signals for measurement of the channel conditions (i.e., the equalizer gain and phase shift for each sub-carrier). Pilot signals and training symbols (preambles) may also be used for time synchronization (to avoid intersymbol interference, ISI) and frequency synchronization (to avoid inter-carrier interference, ICI, caused by Doppler shift).
OFDM was initially used for wired and stationary wireless communications. However, with an increasing number of applications operating in highly mobile environments, the effect of dispersive fading caused by a combination of multi-path propagation and doppler shift is more significant. Over the last decade, research has been done on how to equalize OFDM transmission over doubly selective channels.
Channel coding and interleaving.
OFDM is invariably used in conjunction with channel coding (forward error correction), and almost always uses frequency and/or time interleaving.
Frequency (subcarrier) interleaving increases resistance to frequency-selective channel conditions such as fading. For example, when a part of the channel bandwidth fades, frequency interleaving ensures that the bit errors that would result from those subcarriers in the faded part of the bandwidth are spread out in the bit-stream rather than being concentrated. Similarly, time interleaving ensures that bits that are originally close together in the bit-stream are transmitted far apart in time, thus mitigating against severe fading as would happen when travelling at high speed.
However, time interleaving is of little benefit in slowly fading channels, such as for stationary reception, and frequency interleaving offers little to no benefit for narrowband channels that suffer from flat-fading (where the whole channel bandwidth fades at the same time).
The reason why interleaving is used on OFDM is to attempt to spread the errors out in the bit-stream that is presented to the error correction decoder, because when such decoders are presented with a high concentration of errors the decoder is unable to correct all the bit errors, and a burst of uncorrected errors occurs. A similar design of audio data encoding makes compact disc (CD) playback robust.
A classical type of error correction coding used with OFDM-based systems is convolutional coding, often concatenated with Reed-Solomon coding. Usually, additional interleaving (on top of the time and frequency interleaving mentioned above) in between the two layers of coding is implemented. The choice for Reed-Solomon coding as the outer error correction code is based on the observation that the Viterbi decoder used for inner convolutional decoding produces short error bursts when there is a high concentration of errors, and Reed-Solomon codes are inherently well-suited to correcting bursts of errors.
Newer systems, however, usually now adopt near-optimal types of error correction codes that use the turbo decoding principle, where the decoder iterates towards the desired solution. Examples of such error correction coding types include turbo codes and LDPC codes, which perform close to the Shannon limit for the Additive White Gaussian Noise (AWGN) channel. Some systems that have implemented these codes have concatenated them with either Reed-Solomon (for example on the MediaFLO system) or BCH codes (on the DVB-S2 system) to improve upon an error floor inherent to these codes at high signal-to-noise ratios.
Adaptive transmission.
The resilience to severe channel conditions can be further enhanced if information about the channel is sent over a return-channel. Based on this feedback information, adaptive modulation, channel coding and power allocation may be applied across all sub-carriers, or individually to each sub-carrier. In the latter case, if a particular range of frequencies suffers from interference or attenuation, the carriers within that range can be disabled or made to run slower by applying more robust modulation or error coding to those sub-carriers.
The term "discrete multitone modulation" ("DMT") denotes OFDM based communication systems that adapt the transmission to the channel conditions individually for each sub-carrier, by means of so-called "bit-loading". Examples are ADSL and VDSL.
The upstream and downstream speeds can be varied by allocating either more or fewer carriers for each purpose. Some forms of rate-adaptive DSL use this feature in real time, so that the bitrate is adapted to the co-channel interference and bandwidth is allocated to whichever subscriber needs it most.
OFDM extended with multiple access.
OFDM in its primary form is considered as a digital modulation technique, and not a multi-user channel access method, since it is utilized for transferring one bit stream over one communication channel using one sequence of OFDM symbols. However, OFDM can be combined with multiple access using time, frequency or coding separation of the users.
In orthogonal frequency-division multiple access (OFDMA), frequency-division multiple access is achieved by assigning different OFDM sub-channels to different users. OFDMA supports differentiated quality of service by assigning different number of sub-carriers to different users in a similar fashion as in CDMA, and thus complex packet scheduling or Media Access Control schemes can be avoided. OFDMA is used in:
OFDMA is also a candidate access method for the IEEE 802.22 "Wireless Regional Area Networks" (WRAN). The project aims at designing the first cognitive radio based standard operating in the VHF-low UHF spectrum (TV spectrum).
In Multi-carrier code division multiple access (MC-CDMA), also known as OFDM-CDMA, OFDM is combined with CDMA spread spectrum communication for coding separation of the users. Co-channel interference can be mitigated, meaning that manual fixed channel allocation (FCA) frequency planning is simplified, or complex dynamic channel allocation (DCA) schemes are avoided.
Space diversity.
In OFDM based wide area broadcasting, receivers can benefit from receiving signals from several spatially dispersed transmitters simultaneously, since transmitters will only destructively interfere with each other on a limited number of sub-carriers, whereas in general they will actually reinforce coverage over a wide area. This is very beneficial in many countries, as it permits the operation of national single-frequency networks (SFN), where many transmitters send the same signal simultaneously over the same channel frequency. SFNs utilise the available spectrum more effectively than conventional multi-frequency broadcast networks (MFN), where program content is replicated on different carrier frequencies. SFNs also result in a diversity gain in receivers situated midway between the transmitters. The coverage area is increased and the outage probability decreased in comparison to an MFN, due to increased received signal strength averaged over all sub-carriers.
Although the guard interval only contains redundant data, which means that it reduces the capacity, some OFDM-based systems, such as some of the broadcasting systems, deliberately use a long guard interval in order to allow the transmitters to be spaced farther apart in an SFN, and longer guard intervals allow larger SFN cell-sizes. A rule of thumb for the maximum distance between transmitters in an SFN is equal to the distance a signal travels during the guard interval — for instance, a guard interval of 200 microseconds would allow transmitters to be spaced 60 km apart.
A "single frequency network" is a form of transmitter macrodiversity. The concept can be further utilized in "dynamic single-frequency networks" (DSFN), where the SFN grouping is changed from timeslot to timeslot.
OFDM may be combined with other forms of space diversity, for example antenna arrays and MIMO channels. This is done in the IEEE802.11 Wireless LAN standard.
Linear transmitter power amplifier.
An OFDM signal exhibits a high peak-to-average power ratio (PAPR) because the independent phases of the sub-carriers mean that they will often combine constructively. Handling this high PAPR requires:
Any non-linearity in the signal chain will cause intermodulation distortion that
The linearity requirement is demanding, especially for transmitter RF output circuitry where amplifiers are often designed to be non-linear in order to minimise power consumption. In practical OFDM systems a small amount of peak clipping is allowed to limit the PAPR in a judicious trade-off against the above consequences. However, the transmitter output filter which is required to reduce out-of-band spurs to legal levels has the effect of restoring peak levels that were clipped, so clipping is not an effective way to reduce PAPR.
Although the spectral efficiency of OFDM is attractive for both terrestrial and space communications, the high PAPR requirements have so far limited OFDM applications to terrestrial systems.
The crest factor CF (in dB) for an OFDM system with n uncorrelated sub-carriers is
 CF = 10 log ( n ) + CFc ...
where CFc is the crest factor (in dB) for each sub-carrier.
(CFc is 3.01 dB for the sine waves used for BPSK and QPSK modulation).
For example, the DVB-T signal in 2K mode is composed of 1705 sub-carriers that are each QPSK-modulated, giving a crest factor of 35.32 dB.
Many crest factor reduction techniques have been developed.
The dynamic range required for an FM receiver is while DAB only require
about As a comparison, each extra bit per sample increases the dynamic range with 
Efficiency comparison between single carrier and multicarrier.
The performance of any communication system can be measured in terms of its power efficiency and bandwidth efficiency.
The power efficiency describes the ability of communication system to preserve bit error rate (BER) of the transmitted signal at low power levels.
Bandwidth efficiency reflects how efficiently the allocated bandwidth is utilized and is defined as the throughput data rate per Hertz in a given bandwidth.
If the large number of subcarriers are used, the bandwidth efficiency of multicarrier system such as OFDM with using optical fiber channel is defined as
Factor 2 is because of two polarization states in the fiber.
where formula_7 is the symbol rate in giga symbol per second (Gsps), and formula_8 is the bandwidth of OFDM signal.
There is saving of bandwidth by using Multicarrier modulation with orthogonal frequency division multiplexing . So the bandwidth for multicarrier system is less in comparison with single carrier system and hence bandwidth efficiency of multicarrier system is larger than single carrier system.
There is only 1 dBm increase in receiver power, but we get 76.7% improvement in bandwidth efficiency with using multicarrier transmission technique.
Idealized system model.
This section describes a simple idealized OFDM system model suitable for a time-invariant AWGN channel.
Transmitter.
An OFDM carrier signal is the sum of a number of orthogonal sub-carriers, with baseband data on each sub-carrier being independently modulated commonly using some type of quadrature amplitude modulation (QAM) or phase-shift keying (PSK). This composite baseband signal is typically used to modulate a main RF carrier.
formula_9 is a serial stream of binary digits. By inverse multiplexing, these are first demultiplexed into formula_10 parallel streams, and each one mapped to a (possibly complex) symbol stream using some modulation constellation (QAM, PSK, etc.). Note that the constellations may be different, so some streams may carry a higher bit-rate than others.
An inverse FFT is computed on each set of symbols, giving a set of complex time-domain samples. These samples are then quadrature-mixed to passband in the standard way. The real and imaginary components are first converted to the analogue domain using digital-to-analogue converters (DACs); the analogue signals are then used to modulate cosine and sine waves at the carrier frequency, formula_11, respectively. These signals are then summed to give the transmission signal, formula_12.
Receiver.
The receiver picks up the signal formula_13, which is then quadrature-mixed down to baseband using cosine and sine waves at the carrier frequency. This also creates signals centered on formula_14, so low-pass filters are used to reject these. The baseband signals are then sampled and digitised using analog-to-digital converters (ADCs), and a forward FFT is used to convert back to the frequency domain.
This returns formula_10 parallel streams, each of which is converted to a binary stream using an appropriate symbol detector. These streams are then re-combined into a serial stream, formula_16, which is an estimate of the original binary stream at the transmitter.
Mathematical description.
If formula_10 sub-carriers are used, and each sub-carrier is modulated using formula_18 alternative symbols, the OFDM symbol alphabet consists of formula_19 combined symbols.
The low-pass equivalent OFDM signal is expressed as:
where formula_21 are the data symbols, formula_10 is the number of sub-carriers, and formula_23 is the OFDM symbol time. The sub-carrier spacing of formula_24 makes them orthogonal over each symbol period; this property is expressed as:
where formula_26 denotes the complex conjugate operator and formula_27 is the Kronecker delta.
To avoid intersymbol interference in multipath fading channels, a guard interval of length formula_28 is inserted prior to the OFDM block. During this interval, a "cyclic prefix" is transmitted such that the signal in the interval formula_29 equals the signal in the interval formula_30. The OFDM signal with cyclic prefix is thus:
The low-pass signal above can be either real or complex-valued. Real-valued low-pass equivalent signals are typically transmitted at baseband—wireline applications such as DSL use this approach. For wireless applications, the low-pass signal is typically complex-valued; in which case, the transmitted signal is up-converted to a carrier frequency formula_11. In general, the transmitted signal can be represented as:
Usage.
OFDM is used in:
OFDM system comparison table.
Key features of some common OFDM based systems are presented in the following table.
ADSL.
OFDM is used in ADSL connections that follow the ANSI T1.413 and G.dmt (ITU G.992.1) standards, where it is called "discrete multitone modulation" (DMT). DSL achieves high-speed data connections on existing copper wires. OFDM is also used in the successor standards ADSL2, ADSL2+, VDSL, VDSL2, and G.fast. ADSL2 uses variable sub-carrier modulation, ranging from BPSK to 32768QAM (in ADSL terminology this is referred to as bit-loading, or bit per tone, 1 to 15 bits per sub-carrier).
Long copper wires suffer from attenuation at high frequencies. The fact that OFDM can cope with this frequency selective attenuation and with narrow-band interference are the main reasons it is frequently used in applications such as ADSL modems. However, DSL cannot be used on every copper pair; interference may become significant if more than 25% of phone lines coming into a central office are used for DSL.
Powerline Technology.
OFDM is used by many powerline devices to extend digital connections through power wiring. Adaptive modulation is particularly important with such a noisy channel as electrical wiring. Some medium speed smart metering modems, "Prime" and "G3" use OFDM at modest frequencies (30–100 kHz)with modest numbers of channels (several hundred) in order to overcome the intersymbol interference in the power line environment.
The IEEE 1901 standards include two incompatible physical layers that both use OFDM. The ITU-T G.hn standard, which provides high-speed local area networking over existing home wiring (power lines, phone lines and coaxial cables) is based on a PHY layer that specifies OFDM with adaptive modulation and a Low-Density Parity-Check (LDPC) FEC code.
Wireless local area networks (LAN) and metropolitan area networks (MAN).
OFDM is extensively used in wireless LAN and MAN applications, including IEEE 802.11a/g/n and WiMAX.
IEEE 802.11a/g/n, operating in the 2.4 and 5 GHz bands, specifies per-stream airside data rates ranging from 6 to 54 Mbit/s. If both devices can utilize "HT mode" (added with 802.11n), the top 20 MHz per-stream rate is increased to 72.2 Mbit/s, with the option of data rates between 13.5 and 150 Mbit/s using a 40 MHz channel. Four different modulation schemes are used: BPSK, QPSK, 16-QAM, and 64-QAM, along with a set of error correcting rates (1/2–5/6). The multitude of choices allows the system to adapt the optimum data rate for the current signal conditions.
Wireless personal area networks (PAN).
OFDM is also now being used in the WiMedia/Ecma-368 standard for high-speed wireless personal area networks in the 3.1–10.6 GHz ultrawideband spectrum (see MultiBand-OFDM).
Terrestrial digital radio and television broadcasting.
Much of Europe and Asia has adopted OFDM for terrestrial broadcasting of digital television (DVB-T, DVB-H and T-DMB) and radio (EUREKA 147 DAB, Digital Radio Mondiale, HD Radio and T-DMB).
DVB-T.
By Directive of the European Commission, all television services transmitted to viewers in the European Community must use a transmission system that has been standardized by a recognized European standardization body, and such a standard has been developed and codified by the DVB Project, "Digital Video Broadcasting (DVB); Framing structure, channel coding and modulation for digital terrestrial television". Customarily referred to as DVB-T, the standard calls for the exclusive use of COFDM for modulation. DVB-T is now widely used in Europe and elsewhere for terrestrial digital TV.
SDARS.
The ground segments of the Digital Audio Radio Service (SDARS) systems used by XM Satellite Radio and Sirius Satellite Radio are transmitted using Coded OFDM (COFDM). The word "coded" comes from the use of forward error correction (FEC).
COFDM vs VSB.
The question of the relative technical merits of COFDM versus 8VSB for terrestrial digital television has been a subject of some controversy, especially between European and North American technologists and regulators. The United States has rejected several proposals to adopt the COFDM based DVB-T system for its digital television services, and has instead opted for 8VSB (vestigial sideband modulation) operation.
One of the major benefits provided by COFDM is in rendering radio broadcasts relatively immune to multipath distortion and signal fading due to atmospheric conditions or passing aircraft. Proponents of COFDM argue it resists multipath far better than 8VSB. Early 8VSB DTV (digital television) receivers often had difficulty receiving a signal. Also, COFDM allows single-frequency networks, which is not possible with 8VSB.
However, newer 8VSB receivers are far better at dealing with multipath, hence the difference in performance may diminish with advances in equalizer design.
Digital radio.
COFDM is also used for other radio standards, for Digital Audio Broadcasting (DAB), the standard for digital audio broadcasting at VHF frequencies, for Digital Radio Mondiale (DRM), the standard for digital broadcasting at shortwave and medium wave frequencies (below 30 MHz) and for DRM+ a more recently introduced standard for digital audio broadcasting at VHF frequencies. (30 to 174 MHz)
The USA again uses an alternate standard, a proprietary system developed by iBiquity dubbed "HD Radio". However, it uses COFDM as the underlying broadcast technology to add digital audio to AM (medium wave) and FM broadcasts.
Both Digital Radio Mondiale and HD Radio are classified as in-band on-channel systems, unlike Eureka 147 (DAB: Digital Audio Broadcasting) which uses separate VHF or UHF frequency bands instead.
BST-OFDM used in ISDB.
The "band-segmented transmission orthogonal frequency division multiplexing" ("BST-OFDM") system proposed for Japan (in the ISDB-T, ISDB-TSB, and ISDB-C broadcasting systems) improves upon COFDM by exploiting the fact that some OFDM carriers may be modulated differently from others within the same multiplex. Some forms of COFDM already offer this kind of hierarchical modulation, though BST-OFDM is intended to make it more flexible. The 6 MHz television channel may therefore be "segmented", with different segments being modulated differently and used for different services.
It is possible, for example, to send an audio service on a segment that includes a segment composed of a number of carriers, a data service on another segment and a television service on yet another segment—all within the same 6 MHz television channel. Furthermore, these may be modulated with different parameters so that, for example, the audio and data services could be optimized for mobile reception, while the television service is optimized for stationary reception in a high-multipath environment.
Ultra-wideband.
Ultra-wideband (UWB) wireless personal area network technology may also utilise OFDM, such as in Multiband OFDM (MB-OFDM). This UWB specification is advocated by the WiMedia Alliance (formerly by both the Multiband OFDM Alliance [MBOA] and the WiMedia Alliance, but the two have now merged), and is one of the competing UWB radio interfaces.
FLASH-OFDM.
"Fast low-latency access with seamless handoff orthogonal frequency division multiplexing" (Flash-OFDM), also referred to as F-OFDM, was based on OFDM and also specified higher protocol layers. It was developed by Flarion, and purchased by Qualcomm in January 2006. Flash-OFDM was marketed as a packet-switched cellular bearer, to compete with GSM and 3G networks. As an example, 450 MHz frequency bands previously used by NMT-450 and C-Net C450 (both 1G analogue networks, now mostly decommissioned) in Europe are being licensed to Flash-OFDM operators.
In Finland, the license holder Digita began deployment of a nationwide "@450" wireless network in parts of the country since April 2007. It was purchased by Datame in 2011. In February 2012 Datame announced they would upgrade the 450 MHz network to competing CDMA2000 technology.
Slovak Telekom in Slovakia offers Flash-OFDM connections with a maximum downstream speed of 5.3 Mbit/s, and a maximum upstream speed of 1.8 Mbit/s, with a coverage of over 70 percent of Slovak population. The Flash-OFDM network is due to be switched off in the majority of Slovakia from 30 September 2015.
T-Mobile Germany uses Flash-OFDM to backhaul Wi-Fi HotSpots on the Deutsche Bahn's ICE high speed trains.
American wireless carrier Nextel Communications field tested wireless broadband network technologies including Flash-OFDM in 2005. Sprint purchased the carrier in 2006 and decided to deploy the mobile version of WiMAX, which is based on Scalable Orthogonal Frequency Division Multiple Access (SOFDMA) technology.
Citizens Telephone Cooperative launched a mobile broadband service based on Flash-OFDM technology to subscribers in parts of Virginia in March 2006. The maximum speed available was 1.5 Mbit/s. The service was discontinued on April 30, 2009.
Digiweb Ltd. launched a mobile broadband network using Flash-OFDM technology at 872 MHz in July 2007 in Ireland and Digiweb also owns a national 872 MHz license in Norway. Voice handsets are not yet available as of November 2007. The deployment is live in a small area north of Dublin only.
Butler Networks operates a Flash-OFDM network in Denmark at 872 MHz.
In Netherlands, KPN-telecom will start a pilot around July 2007.

</doc>
<doc id="22693" url="https://en.wikipedia.org/wiki?curid=22693" title="Operator overloading">
Operator overloading

In programming, operator overloading—less commonly known as operator ad hoc polymorphism—is a specific case of polymorphism, where different operators have different implementations depending on their arguments. Operator overloading is generally defined by the language, the programmer, or both.
Motivation.
Operator overloading is syntactic sugar, and is used because it allows the developer to program using notation closer to the target domain and allows user-defined types a similar level of syntactic support as types built into the language. It is common, for example, in scientific computing, where it allows computational representations of mathematical objects to be manipulated with the same syntax as on paper.
Operator overloading does not change the expressive power of a language (with functions), as it can be emulated using function calls; for example, consider variables codice_1 of some user-defined type, such as matrices:
 a + b * c
In a language that supports operator overloading, and with the usual assumption that the '*' operator has higher precedence than '+' operator, this is a concise way of writing:
 add (a, multiply (b,c))
However, the former syntax reflects common mathematical usage.
Examples.
In this case, the addition operator is overloaded to allow addition on a user-defined type "Time" (in C++):
Addition is a binary operation, which means it has two operands. In C++, the arguments being passed are the operands, and the codice_2 object is the returned value.
The operation could also be defined as a class method, replacing codice_3 by the hidden codice_4 argument; however this forces the left operand to be of type codice_5:
Note that a unary operator defined as a class method would receive no apparent argument (it only works from codice_4):
Less than(<) operator is often overloaded to sort a structure or class.
Since "multi" was used, the function gets added to the list of multidispatch candidates, and "+" is only overloaded for the case where the type constraints in the function signature are met.
While the capacity for overloading includes +, *, >=, the postfix and term i, and so on, it also allows for overloading various brace operators: "[x, y]", "x[ y ]", "x{ y }", and "x( y )".

</doc>
<doc id="22700" url="https://en.wikipedia.org/wiki?curid=22700" title="Omphalos hypothesis">
Omphalos hypothesis

The Omphalos hypothesis is the argument that God created the world recently (in the last ten thousand years, in keeping with Flood geology), but complete with signs of great age. It was named after the title of an 1857 book, "Omphalos" by Philip Henry Gosse, in which Gosse argued that in order for the world to be "functional", God must have created the Earth with mountains and canyons, trees with growth rings, Adam and Eve with hair, fingernails, and navels ("omphalos" is Greek for "navel"), and that therefore "no" evidence that we can see of the presumed age of the earth and universe can be taken as reliable. The idea saw some revival in the 20th century by some creationists, who extended the argument to light that appears to originate in far-off stars and galaxies (although other creationists reject this explanation). Many creationists believe that Adam and Eve had no navels, and that the trees in the Garden of Eden had no growth rings.
Support.
Chateaubriand wrote in his 1802 book, "Génie du christianisme" (Part I Book IV Chapter V): "God might have created, and doubtless did create, the world with all the marks of antiquity and completeness which it now exhibits." Rabbi Dovid Gottlieb supports a similar position, arguing further that the evidence for an old universe is strong: "The bones, artifacts, partially decayed radium, potassium-argon, uranium, the red-shifted light from space, etc.– all of it points to a greater age which nevertheless is not true."
Creationists still argue the same way. For instance, John D. Morris, president of the Institute for Creation Research talks about the "appearance of age":
He does not extend this idea to the geological record, preferring to believe that it was all created in the Flood, but others such as Gerald E. Aardsma go further, with his idea of "virtual history". This appears to suggest that events after the creation have changed the "virtual history" we now see, including the fossils:
The past president of the Missouri Association for Creation has said:
Criticisms.
When did false history begin?
Though Gosse's original Omphalos hypothesis specifies a popular creation story, others have proposed that the idea does not preclude creation as recently as five minutes ago, including memories of times before this created "in situ". This idea is sometimes called "Last Thursdayism" by its opponents, as in "the world might as well have been created last Thursday."
The concept is both unverifiable and unfalsifiable through any conceivable scientific method—in other words, it is impossible even "in principle" to subject it to any form of test by reference to any empirical data because the empirical data themselves are considered to have been arbitrarily created to look the way they do at every observable level of detail.
A deceptive creator.
From a religious viewpoint, it can be interpreted as God having 'created a fake,' such as illusions of light in space of stellar explosions (supernovae) that never really happened, or volcanic mountains that were never really volcanoes in the first place and that never actually experienced erosion.
This conception has therefore drawn harsh rebuke from some theologians. Reverend Canon Brian Hebblethwaite, for example, preached against Bertrand Russell's Five minute hypothesis:
The basis for Hebblethwaite's objection, however, is the presumption of a God that would not deceive us about our very humanity - an unprovable presumption that the Omphalos hypothesis rejects at the outset. Hebblethwaite also suggests that God necessarily had to create certain elements of the Universe in combination with the creation of man:
In a rebuttal of the claim that God might have implanted a false history of the age of the Universe in order to test our faith in the truth of the Torah, Rabbi Natan Slifkin, an author whose works have been banned by several Haredi rabbis for going against the tenets of the Talmud, writes:
Gosse, however, did not assert that God deceived us, only that any act of creation of human, animal or plant would "at the instant of its creation present indubitable evidences of a previous history" in far more subtle, microscopic and unavoidable ways than the presence or absence of hair or navels. He presented it not as an hypothesis but as a law or logical necessity: any created organism must be "from the first marked with the records of a previous being". The alternative, he argued, would be a created earth in which trees (larger than saplings) would exhibit no seasonal growth rings.
A consistent creator.
Some Jewish commentaries on the age of the Universe delve into the Omphalos hypothesis. In particular, rabbi Natan Slifkin writes:
Other formulations.
Five-minute hypothesis.
The five-minute hypothesis is a skeptical hypothesis put forth by the philosopher Bertrand Russell that proposes that the universe sprang into existence five minutes ago from nothing, with human memory and all other signs of history included. It is a commonly used example of how one may maintain extreme philosophical skepticism with regards to memory.
Borges's "Tlön, Uqbar, Orbis Tertius".
Jorge Luis Borges, in his 1940 work, "Tlön, Uqbar, Orbis Tertius", describes a fictional world in which some essentially follow as a religious belief a philosophy much like Russell's discussion on the logical extreme of Gosse's theory:
Borges had earlier written a short essay, "The Creation and P. H. Gosse" that explored the rejection of Gosse's "Omphalos". Borges argued that its unpopularity stemmed from Gosse's explicit (if inadvertent) outlining of what Borges characterized as absurdities in the Genesis story.
Last Thursdayism.
Last Thursdayism is a similar response to omphalism which posits that, by the same logic, the world might have been created last Thursday (or by implication, on any other given date and time), but with the appearance of age: people's memories, history books, fossils, light already on the way from distant stars, and so forth. It is aimed at the logic point that when this logic is permitted, it can be used to prove any "fixed date creation" schema. The first known reference is on November 2, 1992, in a Usenet post titled "Last Thursdayism proven!", responding to an apocalyptic prediction:
It developed on talk.origins into a satiric parody religion with a catechism; other postings started the "heretical" splinter groups Last Wednesdayism and Last Fridayism. Another version, claiming not to be a parody, incorporates ideas from solipsism.

</doc>
<doc id="22702" url="https://en.wikipedia.org/wiki?curid=22702" title="Origen">
Origen

Origen (; , "Ōrigénēs"), or Origen Adamantius (, "Ōrigénēs Adamántios"; 184/185 – 253/254), was a scholar and early Christian theologian who was born and spent the first half of his career in Alexandria. He was a prolific writer in multiple branches of theology, including textual criticism, biblical exegesis and hermeneutics, philosophical theology, preaching, and spirituality written in Greek.
Unlike many church fathers, he was never canonized as a saint because some of his teachings directly contradicted the teachings attributed to the apostles, notably the Apostles Paul and John. His teachings on the pre-existence of souls, the final reconciliation of all creatures, including perhaps even the devil (the apokatastasis), and the subordination of God the Son to God the Father, were extremely controversial.
Etymology.
Origen's Greek name "Ōrigénēs" () probably means "child of Horus" (from , "Horus", and , "born"). His nickname or cognomen "Adamantios" () derives from Greek "adámas" (), which means "adamant", "unalterable", "unbreakable", "unconquerable", "diamond". He acquired it because of his severe ascetical practices.
Life.
Early years.
Origen was born in Alexandria to Christian parents. He was educated by his father, Leonides of Alexandria, who gave him a standard Hellenistic education, but also had him study the Christian scriptures. The name of his mother is unknown.
In 202, Origen's father was martyred in the outbreak of the persecution during the reign of Septimius Severus. A story reported by Eusebius has it that Origen wished to follow him in martyrdom, but was prevented only by his mother hiding his clothes. The death of Leonides left the family of nine impoverished when their property was confiscated. Origen, however, was taken under the protection of a woman of wealth and standing; but as her household already included a heretic named Paul, the strictly orthodox Origen seems to have remained with her only a short time.
Eusebius, our chief witness to Origen's life, says that in 203 Origen revived the Catechetical School of Alexandria where Clement of Alexandria had once taught but had apparently been driven out during the persecution under Severus. Many modern scholars, however, doubt that Clement's school had been an official ecclesiastical institution as Origen's was and thus deny continuity between the two. But the persecution still raged, and the young teacher visited imprisoned Christians, attended the courts, and comforted the condemned, himself preserved from persecution because the persecution was probably limited only to converts to Christianity. His fame and the number of his pupils increased rapidly, so that Bishop Demetrius of Alexandria, made him restrict himself to instruction in Christian doctrine alone.
Asceticism and castration.
Origen, to be entirely independent, sold his library for a sum which netted him a daily income of 4 obols, on which he lived by exercising the utmost frugality. Teaching throughout the day, he devoted the greater part of the night to the study of the Bible and lived a life of rigid asceticism.
Eusebius reported that Origen, following literally, castrated himself. This story was accepted during the Middle Ages and was cited by Peter Abelard in his letters to Heloise. Edward Gibbon, in his "History of the Decline and Fall of the Roman Empire", also accepts this story as true. During the past century, scholars have often questioned this, surmising that this may have been a rumor circulated by his detractors. Henry Chadwick points out that, while the story may be true, it seems unlikely, given that Origen's exposition of Matthew 19:12 "strongly deplored any literal interpretation of the words". However, many noted historians, such as Peter Brown and William Placher, continue to find no reason to deny the truth of Eusebius' claims.
Travels.
During the reign of emperor Caracalla, about 211–212, Origen paid a brief visit to Rome, but the relative laxity during the pontificate of Zephyrinus seems to have disillusioned him, and on his return to Alexandria he resumed his teaching with zeal increased by the contrast. But the school had far outgrown the strength of a single man; the catechumens pressed eagerly for elementary instruction, and the baptized sought for interpretation of the Bible. Under these circumstances, Origen entrusted the teaching of the catechumens to Heraclas, the brother of the martyr Plutarch, his first pupil.
His own interests became more and more centered in exegesis, and he accordingly studied Hebrew, though there is no certain knowledge concerning his instructor in that language. From about this period (212–213) dates Origen's acquaintance with Ambrose of Alexandria, whom he was instrumental in converting from Valentinianism to orthodoxy. Later (about 218) Ambrose, a man of wealth, made a formal agreement with Origen to promulgate his writings, and all the subsequent works of Origen (except his sermons, which were not expressly prepared for publication) were dedicated to Ambrose.
In 213 or 214, Origen visited Arabia at the request of the prefect, who wished to have an interview with him; and Origen accordingly spent a brief time in Petra, after which he returned to Alexandria. In the following year, a popular uprising at Alexandria caused Caracalla to let his soldiers plunder the city, shut the schools, and expel all foreigners. The latter measure caused Ambrose to take refuge in Caesarea, where he seems to have made his permanent home; and Origen left Egypt, apparently going with Ambrose to Caesarea, where he spent some time. Here, in conformity with local usage based on Jewish custom, Origen, though not ordained, preached and interpreted the scriptures at the request of the bishops Alexander of Jerusalem and Theoctistus of Caesarea. When, however, the confusion in Alexandria subsided, Demetrius recalled Origen, probably in 216.
Of Origen's activity during the next decade little is known, but it was probably devoted to teaching and writing. The latter was rendered the more easy for him by Ambrose, who provided him with more than seven stenographers to take dictation in relays, as many scribes to prepare long-hand copies, and a number of girls to multiply the copies. At the request of Ambrose, he now began a huge commentary on the "Bible", beginning with John, and continuing with Genesis, Psalms 1–25, and Lamentations, besides brief exegeses of selected texts (forming the ten books of his "Stromateis"), two books on the resurrection, and the work "On First Principles".
Conflict with Demetrius and removal to Caesarea.
Demetrius, the bishop of Alexandria, at first supported Origen but later opposed him, disputing his ordination in another diocese (Caesarea Maritima in Palestine). This ecclesiastical turmoil eventually caused Origen to move to Caesarea, a move which he characterized as divine deliverance from Egypt akin to that the ancient Hebrews received. About 230, Origen entered on the fateful journey which was to compel him to give up his work at Alexandria and embittered the next years of his life. Sent to Greece on some ecclesiastical mission, he paid a visit to Caesarea, where he was heartily welcomed and was ordained a priest, that no further cause for criticism might be given Demetrius, who had strongly disapproved his preaching before ordination while at Caesarea. But Demetrius, taking this well-meant act as an infringement of his rights, was furious, for not only was Origen under his jurisdiction as bishop of Alexandria, but, if Eastern sources may be believed, Demetrius had been the first to introduce episcopal ordination in Egypt. The metropolitan accordingly convened a synod of bishops and presbyters which banished Origen from Alexandria, while a second synod declared his ordination invalid.
Origen accordingly fled from Alexandria in 231–2, and made his permanent home in Caesarea in Palestine, where his friend Theoctistus was bishop. A series of attacks on him seems to have emanated from Alexandria, whether for his self-castration (a capital crime in Roman law) or for alleged heterodoxy is unknown; but at all events these fulminations were heeded only at Rome, while Palestine, Phoenicia, Arabia, and Achaia paid no attention to them. At Alexandria, Heraclas became head of Origen's school, and shortly afterward, on the death of Demetrius, was consecrated bishop.
During this time at Caesarea in Palestine (232–5), he resumed work on the "Commentary on John", composing at least books 6-10, wrote the treatise "On Prayer", and, some time in the first half of the year 235, composed his "Exhortation to Martyrdom". Eusebius reports that he was summoned from there to Antioch at the behest of the empress mother Julia Avita Mamaea "to discuss Christian philosophy and doctrine with her." Approximately three years after his arrival in Caesarea in Palestine, Origen's life as a scholar was again interrupted by the persecution of Maximinus Thrax (235-8). He took refuge at Caesarea in Cappadocia. At Caesarea, Origen was joyfully received and was the guest of Firmilian, bishop of Caesarea in Cappadocia.
After the death of Maximinus, Origen resumed his life in Caesarea of Palestine. Little is known of the last twenty years of Origen's life. He founded a school where Gregory Thaumaturgus, later bishop of Pontus, was one of the pupils. He preached regularly on Wednesdays and Fridays, and later daily. He taught dialectics, physics, ethics, and metaphysics. He evidently, however, developed an extraordinary literary productivity, broken by occasional journeys; one of which, to Athens during some unknown year, was of sufficient length to allow him time for research.
After his return from Athens, he succeeded in converting Beryllus, bishop of Bostra, from his adoptionistic (i.e., belief that Jesus was born human and only became divine after his baptism) views to the orthodox faith; yet in these very years (about 240) probably occurred the attacks on Origen's own orthodoxy which compelled him to defend himself in writing to Pope Fabian and many bishops. Neither the source nor the object of these attacks is known, though the latter may have been connected with Novatianism (a strict refusal to accept Christians who had denied their faith under persecution).
After his conversion of Beryllus, however, his aid was frequently invoked against heresies. Thus, when the doctrine was promulgated in Arabia that the soul died and decayed with the body, being restored to life only at the resurrection (see soul sleep), appeal was made to Origen, who journeyed to Arabia, and successfully battled this doctrine.
There was second outbreak of the Antonine Plague, which at its height in 251 to 266 took the lives of 5,000 a day in Rome. This time it was called the Plague of Cyprian. Emperor Decius, believing the plague to be a product of magic, caused by the failure of Christians to recognize him as Divine, began Christian persecutions. This time Origen did not escape the Decian persecution. Eusebius recounted how Origen suffered "bodily tortures and torments under the iron collar and in the dungeon; and how for many days with his feet stretched four spaces in the stocks" Though he did not die while being tortured, he died three years later due to injuries sustained at the age of 69. A later legend, recounted by Jerome and numerous itineraries, places his death and burial at Tyre, but to this little value can be attached.
Works.
Origen excelled in multiple branches of theological scholarship. For instance, he was the greatest textual critic of the early Church, directing the production of the massive "Hexapla" ("Sixfold"), an Old Testament in six columns: Hebrew, Hebrew in Greek characters, the Septuagint, and the Greek versions of Theodotion, Aquila of Sinope, and Symmachus. This was an immense and complex word-for-word comparison of the Greek Septuagint with the original Hebrew Scriptures and with those other Greek translations. He was one of the greatest biblical scholars of the early Church, having written commentaries on most of the books of the Bible, though few are extant. He interpreted scripture both literally and allegorically. Origen was largely responsible for the collection of usage information regarding the texts which became the New Testament. The information used to create the late-fourth-century Easter Letter, which declared accepted Christian writings, was probably based on the "Ecclesiastical History" [HE] of Eusebius of Caesarea, wherein he uses the information passed on to him by Origen to create both his list at HE 3:25 and Origen’s list at HE 6:25. Eusebius got his information about what texts were accepted by the third-century churches throughout the known world, a great deal of which Origen knew of firsthand from his extensive travels, from the library and writings of Origen. In fact, Origen would have possibly included in his list of "inspired writings" other texts which were kept out by the likes of Eusebius, including the Epistle of Barnabas, Shepherd of Hermas, and 1 Clement. "Origen is not the originator of the idea of biblical canon, but he certainly gives the philosophical and literary-interpretative underpinnings for the whole notion." As a theologian, in "De principiis" ("On First Principles"), he articulated one of the first philosophical expositions of Christian doctrine. Having been educated in classical and philosophical studies, some of his teachings were influenced by and engaged with aspects of Neo-Pythagorean, Neo-Platonist, and other strains of contemporary philosophical thought. An ordained priest in Palestine, he has left posterity numerous homilies on various books of the Bible. Finally, he has also been regarded as a spiritual master for such works as "An Exhortation to Martyrdom" and "On Prayer".
In 2012, 29 unpublished homilies by Origen were discovered in the Bavarian State Library. This text can be found online.
Exegetical writings.
According to Epiphanius, Origen wrote about 6,000 works ("i.e.", rolls or chapters). A list was given by Eusebius in his lost "Life of Pamphilus", which was apparently known to Jerome. These fall into four classes: textual criticism; exegesis; systematic, practical, and apologetic theology; and letters; besides certain spurious works.
By far the most important work of Origen on textual criticism was the "Hexapla", a comparative study of various translations of the Old Testament.
The full text of the "Hexapla" is no longer extant. Some portions were discovered in Milan indicating that at least some individual parts existed much longer than was previously thought. The "Hexapla" has been referred to by later manuscripts and authors, and represented the precursor to the parallel bible.
The "Tetrapla" was an abbreviation of the "Hexapla" in which Origen placed only the translations (Aquila, Symmachus, Theodotion, and the Septuagint) in parallels.
He was likewise keenly conscious of the textual difficulties in the manuscripts of the New Testament, although he never wrote definitely on this subject. In his exegetical writings he frequently alludes to the variant readings, but his habit of making rough citations in his dictation, the verification being left to the scribes, renders it impossible to deduce his text from his commentaries.
The exegetical writings of Origen fall into three classes:
Jerome states that there were scholia on Leviticus, Psalms i.-xv., Ecclesiastes, Isaiah, and part of John. The "Stromateis" were of a similar character, and the margin of "Codex Athous Laura", 184, contains citations from this work on Rom. 9:23; I Cor. 6:14, 7:31, 34, 9:20-21, 10:9, besides a few other fragments.
Homilies on almost the entire Bible were prepared by Origen. There are 205, and possibly 279, homilies of Origen that are extant either in Greek or in Latin translations. The homilies preserved are on Genesis (16), Exodus (13), Leviticus (16), Numbers (28), Joshua (26), Judges (9), I Sam. (2), Psalms 36-38 (9), Canticles (2), Isaiah (9), Jeremiah (7 Greek, 2 Latin, 12 Greek and Latin), Ezekiel (14), and Luke (39). The homilies were preached in the church at Caesarea, with the exception of the two on 1 Samuel which were delivered in Jerusalem. Nautin has argued that they were all preached in a three-year liturgical cycle some time between 238 and 244, preceding the "Commentary on the Song of Songs", where Origen refers to homilies on Judges, Exodus, Numbers, and a work on Leviticus.
It is not improbable that Origen gave no attention to supervising the publication of his homilies, for only by such a hypothesis can the numerous evidences of carelessness in diction be explained. The exegesis of the homilies was simpler than that of the scientific commentaries, but nevertheless demanded no mean degree of intelligence from the auditor. Origen's chief aim was the practical exposition of the text, verse by verse; and while in such books as Leviticus and Numbers he sought to allegorize, the wealth of material in the prophets seldom rendered it necessary for him to seek meanings deeper than the surface afforded.
On June 11, 2012, the Bavarian National Library announced the discovery by philologist Marina Molin Pradel of unknown original texts of homilies by Origenes in a twelfth-century Greek manuscript. The attribution to Origen has been confirmed by experts like Prof. Lorenzo Perrone of the Bologna University.
Extant commentaries of Origen.
The object of Origen's commentaries was to give an exegesis that discriminated strictly against historical significance, in favour of a "hidden" spiritual truth. At the same time, he neglected neither philological nor geographical, historical nor antiquarian material, to all of which he devoted numerous excursus.
In his commentary on John he constantly considered the exegesis of the Valentinian Heracleon (probably at the insistence of Ambrose), and in many other places he implied or expressly cited Gnostic views and refuted them.
Unfortunately, only meagre fragments of the commentaries have survived. Three commentaries on New Testament books survive in large measure. Of the 32 books in the "Commentary on John", only nine have been preserved. The "Commentary on Romans" is extant only in the abbreviated Latin translation of Rufinus, though some Greek fragments also exist. The eight books preserved of the "Commentary on Matthew" (Books 10-17) cover Matthew 13.36-22.33. There also exists a Latin translation of the commentary by an unknown translator which covers Matthew 16.13-27.66. One commentary on a book of the Old Testament, the "Commentary on the Song of Songs", has also been preserved in part, in a Latin translation of Rufinus.
Fragments of some other commentaries survive. Citations in Origen's Philocalia include fragments of the third book of the commentary on Genesis. There is also Ps. i, iv.1, the small commentary on Canticles, and the second book of the large commentary on the same, the twentieth book of the commentary on Ezekiel, and the commentary on Hosea. Of the non-extant commentaries, there is limited evidence of their arrangement.
Dogmatic, practical, and apologetic writings.
Study of "On First Principles" has occupied centre stage in studies of Origen since the fourth century. It is perhaps written for his more advanced pupils at Alexandria and probably composed between 212 and 215. It is extant only in the free translation of Rufinus of 397, except for fragments (books 3.1 and 4.1-3) preserved in "Origen's Philocalia", and smaller citations in Justinian's letter to Mennas.
In the first book the author considers God, the Logos, the Holy Ghost, reason, and the angels; in the second the world and man (including the incarnation of the Logos, the soul, free will, and eschatology); in the third, the doctrine of sin and redemption; and in the fourth, the scriptures; the whole being concluded with a résumé of the entire system. The work is noteworthy as the first endeavor to present Christianity as a complete theory of the universe, and was designed to remove the difficulties felt by many Christians concerning the essential basis of their faith.
Between 232-235, while in Caesarea in Palestine, Origen wrote "On Prayer". This is preserved entire in Greek. After an introduction on the object, necessity, and advantage of prayer, ends with an exegesis of the Lord's Prayer, concluding with remarks on the position, place, and attitude to be assumed during prayer, as well as on the classes of prayer.
"On Martyrdom", or the "Exhortation to Martyrdom", also preserved entire in Greek, was written some time after the beginning of the persecution of Maximinus in the first half of 235. In it, Origen warns against any trifling with idolatry and emphasizes the duty of suffering martyrdom manfully; while in the second part he explains the meaning of martyrdom.
"Against Celsus" (Greek: Κατὰ Κέλσου; Latin: "Contra Celsum"), preserved entire in Greek, was Origen's last treatise, written about 248. Ambrose had requested that Origen provide an answer to a book entitled "The True Doctrine" which attacked Christianity, and had been written some time in the second century by an unknown Middle Platonic philosopher named Celsus. In "Against Celsus", Origen drew freely on the Greek philosophers and poets as well as the Bible to provide a rational basis for holding the Christian faith.
The papyri discovered at Tura in 1941 contained the Greek text of two previously unknown works of Origen. Neither work can be dated precisely, though both were probably written after the persecution of Maximinus in 235. One is "On the Pascha". The other is "Dialogue of Origen with Heraclides and the Bishops with him concerning the Father and the Son and the soul".
Lost works include two books on the resurrection, written before "On First Principles", and also two dialogues on the same theme dedicated to Ambrose.
Eusebius had a collection of more than one hundred letters of Origen, and the list of Jerome speaks of several books of his epistles. Except for a few fragments, only three letters have been preserved. The first, partly preserved in the Latin translation of Rufinus, is addressed to friends in Alexandria. The second is a short letter to Gregory Thaumaturgus, preserved in the "Philocalia". The third is an epistle to Sextus Julius Africanus, extant in Greek, replying to a letter from Africanus (also extant), and defending the authenticity of the Greek additions to the book of Daniel.
Forgeries of the writings of Origen made in his lifetime are discussed by Rufinus in "De adulteratione librorum Origenis". The "Dialogus de recta in Deum fide", the "Philosophumena" attributed to Hippolytus of Rome, and the "Commentary on Job" by Julian the Arian have also been ascribed to him.
Views.
Philosophical and religious.
Origen, reportedly trained in the school of Clement and by his father, has long been considered essentially a Platonist with occasional traces of Stoic philosophy. Patristic scholar Mark J Edwards has argued that many of Origen's positions are more properly Aristotelian than strictly Platonic (for instance, his philosophical anthropology). Nonetheless, he was thus a pronounced idealist, as one regarding all things temporal and material as insignificant and indifferent, the only real and eternal things being comprised in the idea. He therefore regards as the purely ideal center of this spiritual and eternal world, God, the pure reason, whose creative powers call into being the world with matter as the necessary substratum.
Origen's cosmology is complicated and controverted, but he seems to have held to a hypothesis of the preexistence of souls. Before the known world was created by God, he created a great number of spiritual intelligences. At first devoted to the contemplation and love of their creator, almost all of these intelligences eventually grew bored of contemplating God, and their love for him cooled off. Those whose love for God diminished the most became demons. Those whose love diminished moderately became human souls, eventually to be incarnated in fleshly bodies. Those whose love diminished the least became angels. One, however, who remained perfectly devoted to God became, through love, one with the Word (Logos) of God. The Logos eventually took flesh and was born of the Virgin Mary, becoming the God-man Jesus Christ. The diverse conditions in which human beings are born is actually dependent upon what their souls did in this pre-existent state. Thus what seems unfair, some being born poor and others wealthy, some sick and others healthy, and so forth, is, Origen insists, actually in a by-product of the free-will of souls. Thus, material creation is at least implicitly of a lesser ontological category than the immaterial, or spiritual, and the heavy material bodies that man assumes after the fall will eventually be cast off. Origen, however, still insisted on a bodily resurrection, but in contrast to Athenagoras, who believed that earthly bodies would be precisely reconstituted in the hereafter, Origen argued that Paul's notion of a flourishing spiritual body is more appropriate.
He was a rigid adherent of scripture, making no statement without adducing some scriptural basis. To him the scriptures were divinely inspired, as was proved both by the fulfillment of prophecy and by the immediate impression which the scriptures made on those who read them. Since the divine Logos spoke in the scriptures, they were an organic whole and on every occasion he combatted the Gnostic tenet of the inferiority of the Old Testament.
In his exegesis, Origen sought to discover the deeper meaning implied in the scriptures. One of his chief methods was the translation of proper names, which enabled him, like Philo, to find a deep meaning even in every event of history (see hermeneutics), but at the same time he insisted on an exact grammatical interpretation of the text as the basis of all exegesis.
A strict adherent of the Church, Origen yet distinguished sharply between the ideal and the empirical Church, representing "a double church of men and angels", or, in Platonic phraseology, the lower church and its celestial ideal. The ideal Church alone was the Church of Christ, scattered over all the earth; the other provided also a shelter for sinners. Holding that the Church, as being in possession of the mysteries, affords the only means of salvation, he was indifferent to her external organization, although he spoke sometimes of the office-bearers as the pillars of the Church, and of their heavy duties and responsibilities.
More important to him was the idea borrowed from Plato of the grand division between the great human multitude, capable of sensual vision only, and those who know how to comprehend the hidden meaning of scripture and the diverse mysteries, church organization being for the former only.
It is doubtful whether Origen possessed an obligatory creed; at any rate, such a confession of faith was not a norm like the inspired word of scripture. The reason, illumined by the divine Logos, which is able to search the secret depths of the divine nature, remains as the only source of knowledge.
Theological and dogmatic.
Origen's conception of God the Father is apophatic—a perfect unity, invisible and incorporeal, transcending all things material, and therefore inconceivable and incomprehensible. He is likewise unchangeable, and transcends space and time. But his power is limited by his goodness, justice, and wisdom; and, though entirely free from necessity, his goodness and omnipotence constrained him to reveal himself.
This revelation, the external self-emanation of God, is expressed by Origen in various ways, the Logos being only one of many. Revelation was the first creation of God (cf. Prov. viii. 22), in order to afford creative mediation between God and the world, such mediation being necessary, because God, as changeless unity, could not be the source of a multitudinous creation.
The Logos is the rational creative principle that permeates the universe. Since God eternally manifests himself, the Logos is likewise eternal. He forms a bridge between the created and uncreated, and only through him, as the visible representative of divine wisdom, can the inconceivable and incorporeal God be known. Creation came into existence only through the Logos, and God's nearest approach to the world is the command to create. While the Logos is substantially a unity, he comprehends a multiplicity of concepts, so that Origen terms him, in Platonic fashion, "essence of essences" and "idea of ideas".
The defense of the unity of God against the Gnostics led Origen to maintain the subordination of the Logos to God, and the doctrine of the eternal generation is later. Origen distinctly emphasized the independence of the Logos as well as the distinction from the being and substance of God. The term "of the same substance with the Father" was not employed. The Logos (and the Holy Spirit also) however, does share in the divinity of God. He is an image, a reflex of God, in which God communicates his divinity, as light radiating from the sun. Origen taught that, though the Son was subordinate and less than the Father in power, substance, and rank, the relation of the Son to the Father had no beginning, and that the Son was "eternally generated".
The Logos doctrine and cosmology.
The activity of the Logos was conceived by Origen in Platonic fashion, as the world soul, wherein God manifested his omnipotence. His first creative act was the divine spirit, as an independent existence; and partial reflexes of the Logos were the created rational beings, who, as they had to revert to the perfect God as their background, must likewise be perfect; yet their perfection, unlike in kind with that of God, the Logos, and the divine spirit, had to be attained. The freedom of the will is an essential fact of the reason, notwithstanding the foreknowledge of God. The Logos, eternally creative, forms an endless series of finite, comprehensible worlds, which are mutually alternative. Combining the Stoic doctrine of a universe without beginning with the biblical doctrine of the beginning and the end of the world, he conceived of the visible world as the stages of an eternal cosmic process, affording also an explanation of the diversity of human fortunes, rewards, and punishments. The material world, which at first had no place in this eternal spiritual progression, was due to the fall of the spirits from God, the first being the serpent, who was imprisoned in matter and body. The ultimate aim of God in the creation of matter out of nothing was not punishment, but the upraising of the fallen spirits. Man's accidental being is rooted in transitory matter, but his higher nature is formed in the image of the Creator. The soul is divided into the rational and the irrational, the latter being material and transitory, while the former, incorporeal and immaterial, possesses freedom of the will and the power to reascend to purer life. The strong ethical import of this cosmic process can not remain unnoticed. The return to original being through divine reason is the object of the entire cosmic process. Through the worlds which follow each other in eternal succession, the spirits are able to return to Paradise. God so ordered the universe that all individual acts work together toward one cosmic end which culminates in himself. Likewise as to Origen's anthropology, man conceived in the image of God is able by imitating God in good works to become like God, if he first recognizes his own weakness and trusts all to the divine goodness. He is aided by guardian angels, but more especially by the Logos who operates through saints and prophets in proportion to the constitution of these and man's capacity.
Christology.
The culmination of this gradual revelation is the universal revelation of Christ. In Christ, God, hitherto manifest only as the Lord, appeared as the Father. The incarnation of the Logos, moreover, was necessary since otherwise he would not be intelligible to sensual man; but the indwelling of the Logos remained a mystery, which could be represented only by the analogy of his indwelling in the saints; nor could Origen fully explain it. He speaks of a "remarkable body", and in his opinion that the mortal body of Jesus was transformed by God into an ethereal and divine body, Origen approximated the Docetism that he otherwise abhorred. His concept of the soul of Jesus is likewise uncertain and wavering. He proposes the question whether it was not originally perfect with God but, emanating from him, at his command assumed a material body. As he conceived matter as merely the universal limit of created spirits, so would it be impossible to state in what form the two were combined. He dismissed the solution by referring it to the mystery of the divine governance of the universe. More logically did he declare the material nature of the world to be merely an episode in the spiritual process of development, whose end should be the annihilation of all matter and return to God, who should again be all in all. The doctrine of the resurrection of the body he upholds by the explanation that the Logos maintains the unity of man's existence by ever changing his body into new forms, thus preserving the unity and identity of personality in harmony with the tenet of an endless cosmic process. Origen's concept of the Logos allowed him to make no definite statement on the redemptive work of Jesus. Since sin was ultimately only negative as a lack of pure knowledge, the activity of Jesus was essentially example and instruction, and his human life was only incidental as contrasted with the immanent cosmic activity of the Logos. Origen regarded the death of Jesus as a sacrifice, paralleling it with other cases of self-sacrifice for the general good. On this, Origen's accord with the teachings of the Church was merely superficial.
Eschatology.
His idealizing tendency to consider the spiritual alone as real, fundamental to his entire system, led him to combat the "rude" or "crude" Chiliasm (see Christian eschatology) of a sensual beyond. His position on the literal resurrection of physical bodies is difficult, but in both the "Contra Celsum" and "On First Principles", Origen affirms some form of bodily resurrection, but eschews the notion that earthly bodies will be raised, on account of their gross materiality. Origen believes that all spirits will be finally rescued and glorified, each in the form of its individual life, in order to serve a new epoch of the world when sensuous matter disappears of itself. Yet he constrained himself from breaking entirely with the distinct celestial hopes and representations of Paradise prevalent in the Church. He represents a progressive purification of souls, until, cleansed of all clouds of evil, they should know the truth and God as the Son knew him, see God face to face, and attain a full possession of the Holy Spirit and union with God. The means of attainment of this end were described by Origen in different ways, the most important of which was his concept of a purifying fire which should cleanse the world of evil and thus lead to cosmic renovation. By a further spiritualization Origen could call God himself this consuming fire. In proportion as the souls were freed from sin and ignorance, the material world was to pass away, until, after endless eons, at the final end, God should be all in all, and the worlds and spirits should return to a knowledge of God; in Greek this is called Apokatastasis.
Character.
In Origen the Christian Church had its first theologian. His teaching was not merely theoretical, but was also imbued with an intense ethical power. To the multitude to whom his instruction was beyond grasp, he left mediating images and symbols, as well as the final goal of attainment. In Origen Christianity blended with the pagan philosophy in which lived the desire for truth and the longing after God. Origen had many admirers and followers, one in particular, Dionysius of Alexandria, who caused controversy throughout Libya in 259 due to his theology in regards to the unity of the trinity. Three centuries later his very name was stricken from the books of the Church; yet in the monasteries of the Greeks his influence still lived on, as the spiritual father of Greek monasticism.
Origen's influence on the later church.
Anathemas (544, 553).
While Patriarch Mennas of Constantinople condemned Origen and a form of apocatastasis at the Synod of Constantinople (543); experts are divided whether the Second Council of Constantinople (the Fifth Ecumenical Council) in 553 ratified the condemnation authentically as "It is [only] certain that the council opened on 5 May, 553, in spite of the protestations of Pope Vigilius, who though at Constantinople refused to attend it, and that in the eight conciliary sessions (from 5 May to 2 June), the Acts of which we possess, only the question of the Three Chapters is treated." Many heteroclite views became associated with Origen, and the 15 anathemas attributed to the council condemn a form of apocatastasis along with the pre-existence of the soul, animism (a heterodox Christology), and a denial of real and lasting resurrection of the body. Some authorities believe these anathemas belong to an earlier local synod. The anathema against Origen in his person, declaring him (among others) a heretic, reads as follows:
As a result of this condemnation, the writings of Origen supporting his teachings in these areas were destroyed. They were either destroyed outright, or translated with the appropriate adjustments to eliminate conflict with orthodox Christian doctrine. Therefore, little direct evidence remains to fully confirm or disprove Origen's support of the nine points of anathema against him.
The Fifth Ecumenical Council addressed what was called "The Three Chapters" and opposed a form of Origenism which truly had nothing to do with Origen and Origenist views. In fact, Popes Vigilius (537–555), Pelagius I (556–61), Pelagius II (579–90), and Gregory the Great (590–604) were only aware that the Fifth Council specifically dealt with the Three Chapters and make no mention of Origenism or Universalism, nor spoke as if they knew of its condemnation - even though Gregory the Great opposed the belief of universalism.
The Emperor Justinian denied apocatastasis, making it the ninth of the ten doctrines in his edict against Origen in 545, and later that year, the doctrine was the fourteenth of the fifteen at the council in Constantinople that condemned Origen.
Origen in the 1970s.
In "Reincarnation in Christianity" (1978), theosophist Geddes MacGregor asserts that Origen believed in reincarnation and taught about it, but that his texts written about the subject have been destroyed.
Origen wrote about the Greeks' transmigration of the soul, with which he may or may not have agreed. Many theologians share the notion that Origen's extant works from Latin translations (not from the original Greek) confirm he did not believe in reincarnation. He was cognizant of the concept of transmigration ("metensomatosis" transformation, and loses what it once was, the human soul will not be what it was) from Greek philosophy, but it is repeatedly stated that this concept is not a part of the Christian teaching or scripture. A translation of his "Commentary on the Gospel of Matthew", which stems from a 6th-century Latin translation, reads: "In this place [when Jesus said Elijah was come and referred to John the Baptist] it does not appear to me that by Elijah the soul is spoken of, lest I fall into the doctrine of transmigration, which is foreign to the Church of God, and not handed down by the apostles, nor anywhere set forth in the scriptures" (ibid., 13:1:46–53). Conversely in Origen's "Against Celsus", he argues that the teaching of the resurrection does not come from the doctrine of reincarnation, yet contradictorily claims to know that the soul transmigrates from body to body:
There is evidence that Origen's writing was mistranslated from Greek into Latin due to religious bias, and that he taught reincarnation in his lifetime. One of the epistles written by St. Jerome, "To Avitus" (Letter 124; "Ad Avitum", Epistula CXXIV), asserts that Origen's "On First Principles" (Greek: Περὶ Ἀρχῶν; Latin: "De Principiis")
was mistranscribed from Greek into Latin:
St. Jerome writes about Origen in "To Avitus", conveying the impression that Origen was a heretic like Arius. Concerning Origen's "On First Principles", St. Jerome warns Avitus "that there are countless things in the book to be abhorred, and that, as the Lord says, you will have to walk among scorpions and serpents". Further, in "To Avitus" (Letter 124), St. Jerome writes about "convincing proof" that Origen teaches reincarnation in the original version of the book:
St. Jerome further elaborates Origen's ideas in "To Avitus":
St. Jerome adds to this:
The original text of Origen's "On First Principles" (Greek: Περὶ Ἀρχῶν) has almost completely disappeared. It remains extant as "De Principiis" in fragments translated into Latin by St. Jerome reportedly in good faith, and in the more complete, though "not very reliable Latin translation of Rufinus".
Today.
Origen is regarded by the Catholic Church as a Church Father, but not a saint.
His thought on the Old Testament was an important link in the development of the medieval system of typology. 

</doc>
<doc id="22703" url="https://en.wikipedia.org/wiki?curid=22703" title="Oliver Hazard Perry-class frigate">
Oliver Hazard Perry-class frigate

The "Oliver Hazard Perry" class is a class of guided missile frigates named after the American Commodore Oliver Hazard Perry, the hero of the naval Battle of Lake Erie. Also known as the "Perry" or FFG-7 class, the warships were designed in the United States in the mid-1970s as general-purpose escort vessels inexpensive enough to be bought in large quantities to replace World War II-era destroyers and complement 1960s-era s. In Admiral Zumwalt's "high low fleet plan", the FFG-7s were the low capability ships with the Spruance destroyers serving as the high capability ships. Intended to protect amphibious landing forces, supply and replenishment groups, and merchant convoys from aircraft and submarines, they also later were part of battleship-centric surface action groups and aircraft carrier battle groups/strike groups. Fifty-five ships were built in the United States: 51 for the United States Navy and four for the Royal Australian Navy (RAN). In addition, eight were built in Taiwan, six in Spain, and two in Australia for their navies. Former U.S. Navy warships of this class have been sold or donated to the navies of Bahrain, Egypt, Poland, Pakistan, and Turkey.
The U.S. Navy built 51 of the "Oliver Hazard Perry" frigates, with the first going into service in 1977. The last, the USS Simpson (FFG-56) was decommissioned on Sept. 29, 2015. The retired vessels were either mothballed or transferred to other navies for continued service. Some of the U.S. Navy's frigates, such as USS "Duncan" (14.6 years in service) had fairly short careers, while a few lasted as long as 30+ years in active U.S. service, and some lasting even longer after being sold or donated to other navies.
Design and construction.
The ships were designed by the Bath Iron Works shipyard in Maine in partnership with the New York-based naval architects Gibbs & Cox.
The "Oliver Hazard Perry"-class ships were produced in long "short-hull" (Flight I) and long "long-hull" (Flight III) variants. The long-hull ships (FFG 8, 28, 29, 32, 33, and 36-61) carry the larger SH-60 Seahawk LAMPS III helicopters, while the short-hulled warships carry the smaller and less-capable SH-2 Seasprite LAMPS I. Aside from the lengths of their hulls, the principal difference between the versions is the location of the aft capstan: on long-hull ships, it sits a step below the level of the flight deck in order to provide clearance for the tail rotor of the longer Seahawk helicopters. The long-hull ships also carry the RAST (Recovery Assist Securing and Traversing) system for the Seahawk, a hook, cable, and winch system that can reel in a Seahawk from a hovering flight, expanding the ship's pitch-and-roll range in which flight operations are permitted. The FFG 8, 29, 32, and 33 were built as "short-hull" warships but were later modified into "long-hull" warships. "Oliver Hazard Perry"-class frigates were the second class of surface ship (after the s) in the US Navy to be built with gas turbine propulsion. The gas turbine propulsion plant was more automated than other Navy propulsion plants at the time and could be centrally monitored and controlled from a remote engineering control center away from the engines. The gas turbine propulsion plants also allowed the ship's speed to be controlled directly from the bridge via a throttle control, a first for the US Navy.
American shipyards constructed "Oliver Hazard Perry"-class ships for the U.S. Navy and the Royal Australian Navy (RAN). Early American-built Australian ships were originally built as the "short-hull" version, but they were modified during the 1980s to the "long-hull" design. Shipyards in Australia, Spain, and Taiwan have produced several warships of the "long-hull" design for their navies.
Although the per-ship costs rose greatly over the period of production, all 51 ships planned for the U.S. Navy were built. Some "Oliver Hazard Perry"-class warships are planned to remain in American service for years, but some of the older ships have been decommissioned and some scrapped. Others of these decommissioned ships have been transferred to the navies of other countries, including Bahrain, Egypt, Poland, Pakistan, and Turkey. Several of these have replaced old Second World War-built American destroyers that had been given to those countries.
During the design phase of the "Oliver Hazard Perry" class, head of the Royal Corps of Naval Constructors, R.J. Daniels, was invited by an old friend, US Chief of the Bureau of Ships, Adm Robert C Gooding, to advise upon the use of variable-pitch propellers in the class. During the course of this conversation, Daniels warned Gooding against the use of aluminium in the superstructure of the FFG-7 class as he believed it would lead to structural weaknesses. A number of ships subsequently developed structural cracks, including a fissure in USS "Duncan", before the problems were remedied.
The "Oliver Hazard Perry"-class frigates were designed primarily as anti-aircraft and anti-submarine warfare guided-missile warships intended to provide open-ocean escort of amphibious warfare ships and merchant ship convoys in moderate threat environments in a potential war with the Soviet Union and the Warsaw Pact countries. They could also provide air defense against 1970s- and 1980s-era aircraft and anti-ship missiles. These warships are equipped to escort and protect aircraft carrier battle groups, amphibious landing groups, underway replenishment groups, and merchant ship convoys. They can conduct independent operations to perform such tasks as surveillance of illegal drug smugglers, maritime interception operations, and exercises with other nations.
The addition of the Naval Tactical Data System, LAMPS helicopters, and the Tactical Towed Array System (TACTAS) gave these warships a combat capability far beyond the original expectations. They are well-suited for the littoral regions and most war-at-sea scenarios.
Notable combat actions.
"Oliver Hazard Perry"-class frigates made worldwide news during the 1980s. Despite being small, these frigates were shown to be extremely durable. During the Iran–Iraq War, on 17 May 1987, was attacked by an Iraqi warplane. Struck by two Exocet anti-ship missiles, thirty-seven U.S. Navy sailors died in the deadly prelude to the American Operation Earnest Will, the reflagging and escorting of oil tankers through the Persian Gulf and the Straits of Hormuz.
Less than a year later, on 14 April 1988, was nearly sunk by an Iranian mine. No lives were lost, but 10 sailors were evacuated from the warship for medical treatment. The crew of "Samuel B. Roberts" battled fire and flooding for two days, ultimately managing to save the ship. The U.S. Navy retaliated four days later with Operation Praying Mantis, a one-day attack on Iranian oil platforms being used as bases for raids on merchant shipping. Those had included bases for the minelaying operations that damaged "Samuel B. Roberts". Both frigates were repaired in American shipyards and returned to full service. "Stark" was decommissioned in 1999, and scrapped in 2006.
On April 18, 1988, was accompanying the cruiser and frigate when they came under attack from the Iranian gunboat which fired a U.S. made Harpoon missile at the ships. With "Simpson" having the only clear shot, the frigate fired an SM-1 standard missile which struck "Joshan". "Simpson" fired three more SM-1s, and with later naval fire from "Wainwright", sunk the Iranian vessel.
Modifications.
United States.
The U.S. Navy and Royal Australian Navy have modified their remaining "Perry"s to reduce their operating costs, replacing Detroit Diesel Company 16V149TI electrical generators with Caterpillar, Inc.- 3512B diesel engines.
In mid-2000, the U.S.Navy removed the frigates' Mk 13 single-arm missile launchers and magazines because the primary missile, the Standard SM-1MR, became outmoded.
The "zone-defense" anti-aircraft warfare (AAW) capability has vanished, and all that remains is a "point-defense" type of anti-air warfare (AAW) armament. It would supposedly have been too costly to refit the Standard Missile SM-1MR missiles, which had little ability to bring down sea-skimming missiles. Another reason is to allow more SM-1MRs to go to American allies that operate "Perry"s, such as Poland, Spain, Australia, Turkey, and Taiwan.
The loss of the launchers also stripped the frigates of their Harpoon anti-ship missiles. However, their Seahawk helicopters can carry the much shorter-range Penguin and Hellfire anti-ship missiles.
The last nine ships of the class have new remotely operated 25 mm Mk 38 Mod 2 Naval Gun Systems installed on platforms over the old MK 13 launcher magazine.
As of 2002, the U.S. Navy updated the remaining active "Oliver Hazard Perry"-class warships' Phalanx CIWS to the "Block 1B" capability, which allowed the Mk 15 20 mm Phalanx gun to shoot at fast-moving surface craft and helicopters. They were also to be fitted with the Mk 53 DLS "Nulka" missile decoy system, which will be better than the presently-equipped chaff (SRBOC, Super Rapid Blooming Offboard Chaff) and flares at guarding against anti-ship missiles. It had been planned to outfit the remaining ships with one 32-cell RIM-116 Rolling Airframe Missile launcher at the location of the former Mk-13, but this did not occur.
On May 11, 2009, the first International Frigate Working Group met in Mayport Naval Station to discuss maintenance, obsolescence and logistics issues regarding "Oliver Hazard Perry"-class ships of the U.S. and foreign navies.
On June 16, 2009, Vice Admiral Barry McCullough turned down the suggestion of then-U.S. Senator Mel Martinez (R-FL) to keep the "Perry"s in service, citing their worn-out and maxed-out condition. However, U.S. Representative Ander Crenshaw (R-FL) and former U.S. Representative Gene Taylor (D-MS) took up the cause to retain the vessels.
The "Oliver Hazard Perry"-class frigates were to eventually be replaced by Littoral Combat Ships by 2019. However, the worn out frigates were being retired faster than the LCSs are being built, which may lead to a gap in United States Southern Command mission coverage. According to Navy deactivation plans, all "Oliver Hazard Perry"-class frigates will be retired by October 2015. "Simpson" was the last to be retired, on 29 September 2015, leaving the Navy devoid of frigates for the first time since 1943. The ships will either be made available for sale to foreign navies or dismantled. "Perry"-class frigate retirement was accelerated by budget pressures, which will lead to the remaining 11 ships being replaced by only eight LCS hulls. With the timeline LCS mission packages will come online unknown, there is uncertainty if they will be able to perform the frigates' counter-narcotics and anti-submarine roles when they are gone. The Navy is looking into Military Sealift Command to see if the Joint High Speed Vessel, Mobile Landing Platform, and other auxiliary ships could handle low-end missions that the frigates performed.
The U.S. Coast Guard is harvesting weapons systems components from decommissioned Navy "Perry"-class frigates to save money. Harvesting components from four decommissioned frigates results in more than $24 million in cost savings, which increases with parts from more decommissioned frigates. Equipment including Mk 75, 76 mm/62 caliber gun mounts, gun control panels, barrels, launchers, junction boxes, and other components will be returned to service aboard s to extend their service lives into the 2030s.
Australia.
Australia is spending A$1.46bn to upgrade Royal Australian Navy (RAN) guided-missile frigates, including equipping them to fire the SM-2 version of the Standard missile, adding an eight-cell Mk-41 vertical launch system for Evolved Sea Sparrow missiles, and installing better air-search radars and long-range sonar.
The first of the upgraded frigates, , returned to the RAN fleet in 2005. Each of the four frigates to be upgraded have the work at the Garden Island shipyard in Sydney, Australia, with the modernizations lasting between 18 months and two years. These frigates are planned to be replaced starting in 2013 by three new "Hobart"-class air warfare destroyers equipped with the AEGIS combat system. However, the third of those destroyers will not be commissioned until 2017, at the earliest.
The cost will be partly offset, in the short run, by the decommissioning and disposal of the two older frigates. was decommissioned on 12 November 2005 at naval base in Western Australia and was decommissioned at that same naval base on 20 January 2008.
Turkey.
The Turkish Navy had commenced the modernization of its s with the GENESIS (Gemi Entegre Savaş İdare Sistemi) combat management system in 2007. The first GENESIS upgraded ship was delivered in 2007, and the last delivery is scheduled for 2011. The "short-hull" "Oliver Hazard Perry"-class frigates that are currently part of the Turkish Navy were modified with the ASIST landing platform system at the Gölcük Naval Shipyard, so that they can accommodate the S-70B Seahawk helicopters. Turkey is planning to add one eight-cell Mk 41 Vertical Launching System (VLS) for the Evolved Sea Sparrow missile, to be installed forward of the present Mk 13 missile launchers, similar to the case in the modernization program of the Australian "Adelaide"-class frigates. TCG "Gediz" was the first ship in the class to receive the Mk 41 VLS installation.
There are also plans for new components to be installed that are being developed for the Milgem-class warships ("Ada"-class corvettes and F-100-class frigates) of the Turkish Navy. These include modern Three-dimensional and X-band radars developed by Aselsan and Turkish-made hull-mounted sonars. One of the G-class frigates will also be used as a test-bed for Turkey's 6,000+ ton AAW frigates that are currently being designed by the Turkish Naval Institute.
Related legislation.
On April 7, 2014, the United States House of Representatives voted to pass the Taiwan Relations Act Affirmation and Naval Vessel Transfer Act of 2014 (H.R. 3470; 113th Congress), a bill that would allow eight more "Perry" frigates to be transferred to foreign countries. The bill would authorize the President to transfer and to Mexico, and and to Thailand. The bill would also authorize the President to sell four units (, , , and ) to the Taipei Economic and Cultural Representative Office of the United States (which is the Taiwan agency designated pursuant to the Taiwan Relations Act) for about $10 million each.

</doc>
<doc id="22705" url="https://en.wikipedia.org/wiki?curid=22705" title="Ottawa Senators">
Ottawa Senators

The Ottawa Senators () are a professional ice hockey team based in Ottawa, Ontario, Canada. They are members of the Atlantic Division of the Eastern Conference of the National Hockey League (NHL). The Senators play their home games at the 19,153 seat (20,500 capacity) Canadian Tire Centre which opened in 1996.
Founded and established by Ottawa real estate developer Bruce Firestone, the team is the second NHL franchise to use the Ottawa Senators name. The original Ottawa Senators, founded in 1883, had a famed history, winning 11 Stanley Cups and playing in the NHL from 1917 until 1934. On December 6, 1990, after a two-year public campaign by Firestone, the NHL awarded a new franchise, which began play in the 1992–93 season. The current team owner is Eugene Melnyk, and in 2014, the club was valued by "Forbes" magazine at $400 million.
The team has had success, qualifying for the Stanley Cup playoffs in 15 of the past 18 seasons, winning four division titles, the Presidents' Trophy in 2003 and appearing in the 2007 Stanley Cup Finals. The success has been reflected in attendance as the club has been regularly represented in the top half in attendance in the NHL.
History.
Ottawa had been home to the original Senators, a founding NHL franchise and 11-time Stanley Cup champions. After the NHL expanded to the United States in the late 1920s, the original Senators' eventual financial losses forced the franchise to move to St. Louis in 1934 operating as the Eagles while a Senators senior amateur team took over the Senators' place in Ottawa. The NHL team was unsuccessful in St. Louis, and planned to return to Ottawa, but the NHL decided instead to suspend the franchise and transfer the players to other NHL teams.
Fifty-four years later, after the NHL announced plans to expand, Ottawa real estate developer Bruce Firestone decided along with colleagues Cyril Leeder and Randy Sexton that Ottawa was now able to support an NHL franchise, and the group proceeded to put a bid together. His firm, Terrace Investments, did not have the liquid assets to finance the expansion fee and the team, but the group conceived a strategy to leverage a land development. In 1989, after finding a suitable site on farmland just west of Ottawa in Kanata on which to construct a new arena, Terrace announced its intention to win a franchise and launched a successful "Bring Back the Senators" campaign to both woo the public and persuade the NHL that the city could support an NHL franchise. Public support was high and the group would secure over 11,000 season ticket pledges. On December 12, 1990, the NHL approved a new franchise for Firestone's group, to start play in the 1992–93 season.
1992–96: First seasons.
The new team hired former NHL player Mel Bridgman, who had no previous NHL management experience, as its first general manager in 1992. The team was initially interested in hiring former Jack Adams Award winner Brian Sutter as its first head coach, but Sutter came with a high price tag and was reluctant to be a part of an expansion team. When Sutter was eventually signed to coach the Boston Bruins, Ottawa signed Rick Bowness, the man Sutter replaced in Boston. The new Senators played their first game on October 8, 1992, in the Ottawa Civic Centre against the Montreal Canadiens with lots of pre-game spectacle. The Senators defeated the Canadiens 5–3 in one of the few highlights that season. Following the initial excitement of the opening night victory, the club floundered badly and eventually tied the San Jose Sharks for the worst record in the league, winning only 10 games with 70 losses and four ties for 24 points, three points better than the NHL record for futility. The Senators had aimed low and considered the 1992–93 season a small success, as Firestone had set a goal for the season of not setting a new NHL record for fewest points in a season. The long term plan was to finish low in the standings for its first few years in order to secure high draft picks and eventually contend for the Stanley Cup.
Bridgman was fired after one season and Team President Randy Sexton took over the general manager duties. Firestone himself soon left the team and Rod Bryden emerged as the new owner. The strategy of aiming low and securing a high draft position did not change. The Senators finished last overall for the next three seasons. Although 1993 first overall draft choice Alexandre Daigle wound up being one of the greatest draft busts in NHL history, they chose Radek Bonk in 1994, Bryan Berard (traded for Wade Redden) in 1995, Chris Phillips in 1996 and Marian Hossa in 1997, all of whom would become solid NHL players and formed a strong core of players in years to come. Alexei Yashin, the team's first-ever draft selection from 1992, emerged as one of the NHL's brightest young stars. The team traded many of their better veteran players of the era, including 1992–93 leading scorer Norm Maciver and fan favourites Mike Peluso and Bob Kudelski in an effort to stockpile prospects and draft picks.
As the 1995–96 season began, star centre Alexei Yashin refused to honour his contract and did not play. In December, after three straight last-place finishes and a team which was ridiculed throughout the league, fans began to grow restless waiting for the team's long term plan to yield results, and arena attendance began to decline. Rick Bowness was fired in late 1995 and was replaced by the Prince Edward Island Senators' head coach Dave Allison. Allison would fare no better than his predecessor, and the team would stumble to a 2–22–3 record under him. Sexton himself was fired and replaced by Pierre Gauthier, the former assistant GM of Anaheim. Before the end of January 1996, Gauthier had resolved the team's most pressing issues by settling star player Alexei Yashin's contract dispute, and hiring the highly regarded Jacques Martin as head coach. While Ottawa finished last overall once again, the 1995–96 season ended with renewed optimism, due in part to the upgraded management and coaching, and also to the emergence of an unheralded rookie from Sweden named Daniel Alfredsson, who would win the Calder Memorial Trophy as NHL Rookie of the Year in 1996.
1996–2004: Jacques Martin era.
Martin would impose a "strong defence first" philosophy that led to the team qualifying for the playoffs every season that he coached, but he was criticized for the team's lack of success in the playoffs, notably losing four straight series against the provincial rival Toronto Maple Leafs. Martin outlasted several general managers and a change in ownership.
In 1996–97, his first season, the club qualified for the playoffs in the last game of the season, and nearly defeated the Buffalo Sabres in the first round. In 1997–98, the club finished with their first winning record and upset the heavily favoured New Jersey Devils to win their first playoff series. In 1998–99, the Senators jumped from fourteenth overall in the previous season to third, with 103 points—the first 100-point season in club history, only to be swept in the first round. In 1999–2000 despite the holdout of team captain Alexei Yashin, Martin guided the team to the playoffs, only to lose to the Maple Leafs in the first Battle of Ontario series. Yashin returned for 2000–01 and the team improved to win their division and place second in the Eastern Conference. Yashin played poorly in another first round playoff loss and on the day of the 2001 NHL Entry Draft, he was traded to the New York Islanders in exchange for Zdeno Chara, Bill Muckalt and the second overall selection in the draft, which Ottawa used to select centre Jason Spezza.
The 2001–02 Senators regular season points total dropped, but in the playoffs, they upset the Philadelphia Flyers for the franchise's second playoff series win. Yet the Sens would lose in game seven of the second round of the playoffs. Despite speculation that Martin would be fired, it was GM Marshall Johnston who left, retiring from the team, replaced by John Muckler, the Senators' first with previous GM experience.
In 2002–03 off-ice problems dominated the headlines, as the Senators filed for bankruptcy in mid-season, but continued play after getting emergency financing. Despite the off-ice problems, Ottawa had an outstanding season, placing first overall in the NHL to win the Presidents' Trophy. In the playoffs, they came within one game of making it into the finals. Prior to the 2003–04 season, pharmaceutical billionaire Eugene Melnyk would purchase the club to bring financial stability. Martin would guide the team to another good regular season but again would lose in the first round of the playoffs, leading to Martin's dismissal as management felt that a new coach was required for playoff success.
2004–present: Bryan Murray era.
After the playoff loss, owner Melnyk promised that changes were coming and they came quickly. In June 2004, Anaheim Ducks GM Bryan Murray of nearby Shawville, became head coach. That summer, the team also made substantial personnel changes, trading long-time players Patrick Lalime and Radek Bonk, and signing free agent goaltender Dominik Hasek. The team would not be able to show its new lineup for a year, as the 2004–05 NHL lockout intervened and most players played in Europe or in the minors. In a final change, just before the 2005–06 season, the team traded long-time player Marian Hossa for Dany Heatley.
The media predicted the Senators to be Stanley Cup contenders in 2005–06, as they had a strong core of players returning, played in an up-tempo style fitting the new rule changes and Hasek was expected to provide top-notch goaltending. The team rushed out of the gate, winning 19 of the first 22 games, in the end winning 52 games and 113 points, placing first in the conference, and second overall. The newly formed 'CASH' line of Alfredsson, Spezza and newly acquired Dany Heatley established itself as one of the league's top offensive lines. Hasek played well until he was injured during the 2006 Winter Olympics, forcing the team to enter the playoffs with rookie netminder Ray Emery as their starter. Without Hasek, the club bowed out in a second round loss to the Buffalo Sabres.
2006–07: Trip to the Stanley Cup finals.
In 2006–07, the Senators reached the Stanley Cup Finals after qualifying for the playoffs in nine consecutive seasons. The Senators had a high turn-over of personnel and the disappointment of 2006 to overcome and started the season poorly. Trade rumours swirled around Daniel Alfredsson for most of the last months of 2006. The team lifted itself out of last place in the division to nearly catch the Buffalo Sabres by season's end, placing fourth in the Eastern Conference. The team finished with 105 points, their fourth straight 100-point season and sixth in the last eight. In the playoffs, Ottawa continued its good play. Led by the 'CASH' line, goaltender Ray Emery, and the strong defence of Chris Phillips and Anton Volchenkov, the club defeated the Pittsburgh Penguins, the second-ranked New Jersey Devils and the top-ranked Buffalo Sabres to advance to the Stanley Cup Finals.
The 2006–07 Senators thus became the first Ottawa team to be in the Stanley Cup final since 1927 and the city was swept up in the excitement. Businesses along all of the main streets posted large hand-drawn "Go Sens Go" signs, residents put up large displays in front of their homes or decorated their cars. A large Ottawa Senators flag was draped on the City Hall, along with a large video screen showing the games. A six-storey likeness of Daniel Alfredsson was hung on the Corel building. Rallies were held outside of City Hall, car rallies of decorated cars paraded through town and a section of downtown, dubbed the "Sens Mile," was closed off to traffic during and after games for fans to congregate.
In the Final, the Senators now faced the Anaheim Ducks, considered a favourite since the start of the season, a team the Senators had last played in 2006, and a team known for its strong defence. The Ducks won the first two games in Anaheim 3–2 and 1–0. Returning home, the Senators won game three 5–3, but lost game four 3–2. The Ducks won game five 6–2 in Anaheim to clinch the series. The Ducks had played outstanding defence, shutting down the 'CASH' line, forcing Murray to split up the line. The Ducks scored timely goals and Ducks' goaltender Jean-Sebastien Giguere out-played Emery.
2007–11: A team in decline.
In the off-season after the Stanley Cup Final, Bryan Murray's contract was expiring, while GM John Muckler had one season remaining, at which he was expected to retire. Murray, who had previously been at GM for other NHL clubs, was expected to take over the GM position, although no public timetable was given. Owner Melnyk decided to offer Muckler another position in the organization and give the GM position to Murray. Muckler declined the offer and was relieved from his position. Melnyk publicly justified the move, saying that he expected to lose Murray if his contract ran out. Murray then elevated John Paddock, the assistant coach, to head coach of the Senators. Under Paddock, the team came out to a record start to the 2007–08 season. However, team play declined to a .500 level and the team looked to be falling out of the playoffs. Paddock was fired by Murray, who took over coaching on an interim basis. The club managed to qualify for the playoffs by a tie-breaker, but was swept in the first round of the playoffs to the Pittsburgh Penguins. In June, the club bought-out goaltender Ray Emery, who had become notorious for off-ice events in Ottawa and lateness to several team practices.
For 2008–09, Murray hired Craig Hartsburg to coach the Senators. Under Hartsburg's style, the Senators struggled and played under .500. Uneven goaltending with Martin Gerber and Alex Auld meant the team played cautiously to protect the goaltender. Murray's patience ran out in February 2009 with the team well out of playoff contention and Hartsburg was fired, although he had two years left on his contract, and the team also had Paddock under contract. Cory Clouston was elevated from the Binghamton coaching position. The team played above .500 under Clouston and rookie goaltender Brian Elliott, who had been promoted from Binghamton. Gerber was waived from the team at the trading deadline and the team traded for goaltender Pascal Leclaire, although he would not play due to injury. The team failed to make the playoffs for the first time in 12 seasons. Auld would be traded in the off-season to make room. Clouston's coaching had caused a rift with top player Dany Heatley (although unspecified "personal issues" were also noted by Heatley) and after Clouston was given a contract to continue coaching, Heatley made a trade demand and was traded just before the start of the 2009–10 season.
In 2009–10, the Senators were a .500 team until January, when the team went on a team-record 11-game winning streak. The streak propelled the team to the top of the Northeast Division standings and a top-three placing for the playoffs. The team was unable to hold off the Sabres for the division lead, but qualified for the playoffs in the fifth position. For the third season in four, the Senators played off against the Pittsburgh Penguins in the first round. A highlight for the Senators was winning a triple-overtime fifth game in Pittsburgh, but the team was unable to win a playoff game on home ice, losing the series in six games.
2011–present: Rebuilding.
The Senators had a much poorer than expected 2010–2011 campaign, resulting in constant rumours of a shakeup right through until December. The rumours were heightened in January after the team went on a lengthy losing streak. January was a dismal month for the Senators, winning only one game all month. Media speculated on the imminent firing of Clouston, Murray or both. Owner Melynk cleared the air in an article in the January 22, 2011 edition of the "Ottawa Sun." Melnyk stated that he would not fire either Clouston or Murray, but that he had given up on this season and was in the process of developing a plan for the future. On Monday, January 24, the "Globe and Mail" reported that the plan included hiring a new general manager before the June entry draft and that Murray would be retained as an advisor to the team. A decision on whether to retain Clouston would be made by the new general manager. The article by Roy MacGregor, a long-time reporter of the Ottawa Senators, stated that former assistant coach Pierre McGuire had already been interviewed. Murray, in a press conference that day, stated that he wished to stay on as the team's general manager. He also stated that Melnyk was allowing him to continue as general manager without restraint. Murray said that the players were now to be judged by their play until the February 28 trade deadline. Murray would attempt to move "a couple, at least" of the players for draft picks or prospects at that time if the Senators remained out of playoff contention. At the time of Murray's comments the team was eight games under .500 and 14 points out of a playoff position after 49 games.
Murray started with the trading of Mike Fisher to the Nashville Predators in exchange for a first round pick in the 2011 draft. Fisher already had a home in Nashville with new wife Carrie Underwood. The trading of Fisher, a fan favourite in Ottawa, lead to a small anti-Underwood backlash in the city with the banning of her songs from the play lists of some local radio stations. Murray next traded Chris Kelly, another veteran, to the Boston Bruins for a second round pick in the 2011 draft. A few days later, pending unrestricted free agent Jarkko Ruutu was sent to the Anaheim Ducks in exchange for a sixth round pick in 2011. A swap of goaltenders was made with the Colorado Avalanche which brought Craig Anderson to Ottawa in exchange for Brian Elliott. Both goalies were having sub-par seasons prior to the trade. Under-achieving forward Alex Kovalev was traded to the Pittsburgh Penguins for a seventh round draft pick. On trade deadline day, Ottawa picked up goaltender Curtis McElhinney on waivers and traded Chris Campoli with a seventh round pick to the Chicago Blackhawks for a second round pick and Ryan Potulny. Goaltender Anderson played very well down the stretch for Ottawa, and the team quickly signed the soon-to-be unrestricted free agent to a four-year contract. After media speculation on the future of Murray within the organization, Murray was re-signed as general manager on April 8 to a three-year extension. On April 9, Head Coach Cory Clouston and assistants Greg Carvel and Brad Lauer were dismissed from their positions. Murray said that the decision was made based on the fact that the team entered the season believing it was a contender, but finished with a 32–40–10 record. Former Detroit Red Wings' assistant coach Paul MacLean was hired as Clouston's replacement on June 14, 2011.
As the 2011–12 season began, many hockey writers and commentators were convinced that the Senators would finish at or near the bottom of the NHL standings. In the midst of rebuilding, the Ottawa lineup contained many rookies and inexperienced players. The team struggled out of the gate, losing five of their first six games before a reversal of fortunes saw them win six games in a row. In December 2011, the team acquired forward Kyle Turris from the Phoenix Coyotes in exchange for David Rundblad and a draft pick. The team improved its play afterwards and moved into a playoff position before the All-Star Game. For the first time in Senators' history, the All-Star Game was held in Ottawa, and it was considered a great success. Five Senators were voted in or named to the event, including Daniel Alfredsson, who was named captain of one team. The team continued its playoff push after the break. After starting goalie Craig Anderson injured his hand in a kitchen accident at home, the Senators called up Robin Lehner from Binghamton and acquired highly regarded goaltender Ben Bishop from the St. Louis Blues. While Anderson recovered, the team continued its solid play. On April 1, 2012, the Senators defeated the New York Islanders 5–1, officially ensuring a playoff position. The team finished as the eighth seed in the Eastern Conference, drawing a first round playoff matchup against the Conference champion New York Rangers. Ultimately, Ottawa lost the series in seven games.
The next season, Ottawa would be challenged to repeat the success they had in 2011–12, due to long-term injuries to key players such as Erik Karlsson, Jason Spezza, Milan Michalek and Craig Anderson. Despite these injuries, the Senators would finish seventh in the Eastern Conference and head coach Paul MacLean would go on to win the Jack Adams Award as the NHL's coach of the year. Ottawa would play the second-seeded Montreal Canadiens in the first round of the playoffs, eventually winning in five games, blowing out Montreal 6–1 in games three and five. The Senators would advance to play the top-seeded Pittsburgh Penguins in the second round, this time losing in five games. During the off-season, the Senators traded veteran defenceman Sergei Gonchar to the Dallas Stars for a sixth round pick in the 2013 draft. July 5, 2013, would be a day of mixed emotions for the city and fans, as long-time captain Daniel Alfredsson signed a one-year contract with the Detroit Red Wings, leaving Ottawa after 17 seasons with the Senators and 14 as captain. The signing shocked numerous fans across the city and many within the Senators organization. The day finished optimistically however, as Murray acquired star forward Bobby Ryan from the Anaheim Ducks in exchange for forwards Jakob Silfverberg, Stefan Noesen and a first round pick in the 2014 draft. The hope was that Ryan would be the guy to play on the top line with Jason Spezza after Alfredsson's departure. Murray would also sign free agent forward Clarke MacArthur to a two-year contract that same day and would sign free agent defenceman Joe Corvo to a one-year contract three days later on July 8, 2013.
For the 2013–14 NHL season, the league realigned and Ottawa was assigned to the new Atlantic Division along with the rest of the old Northeast Division, with the additions of the Columbus Blue Jackets and Detroit Red Wings, formerly of the Western Conference. The re-alignment brought increased competition to qualify for the playoffs, as there were now 16 teams in the Eastern Conference fighting for eight playoff spots. The season began with a changing of leadership, as on September 14, 2013, the Ottawa Senators named Jason Spezza their eighth captain in franchise history. While new addition Clarke MacArthur had a career year, Ryan and Spezza struggled to find chemistry, and Ryan was moved to a line with MacArthur and Kyle Turris, where he fared much better. Bobby Ryan also ran into injury problems during the season, and while there were times where Joe Corvo played solidly, he eventually lost his place in the lineup. The club struggled on defence, as shots and goals against numbers increased from the previous season. The club was a sub .500 team much of the season, or only a few games above and never was in a playoff position all season. At the trade deadline, Murray traded for flashy right winger Ales Hemsky from the Edmonton Oilers, quickly finding success on a line with Spezza and Michalek. The club, however, was eliminated from playoff contention in the last week of the season. At the end of the season, the club failed to come to terms on a new contract with Hemsky and captain Jason Spezza requested a trade out of Ottawa. At the 2014 NHL Entry Draft, a potential trade to the Nashville Predators was negotiated by Murray but rejected by Spezza, as the Predators were one of the teams on his limited no-trade list. A deal with the Dallas Stars was eventually reached, and Spezza was sent, along with Ludwig Karlsson, in exchange for Alex Chiasson, Nick Paul, Alex Guptill and a 2015 second-round pick. During the off-season, the club signed free agent forward David Legwand to a two-year, $6 million contract.
At the beginning of the 2014–15 season, defenceman Erik Karlsson was named the franchise's ninth captain, with the club also re-signing Bobby Ryan to a seven-year extension. After firing head coach Paul MacLean after 27 games with an 11-11-5 record and replacing him with Dave Cameron, the Senators would win 32 of their last 55 games. Goaltender Andrew Hammond would compile a record of 20-1-2, a goals against average of 1.79, and a save percentage of .941 to get the team back into playoff position. The Senators later became the first team in modern NHL history to overcome a 14-point deficit at any juncture of the season to qualify for the playoffs. However, the Senators lost to the Canadiens in six games in the first round of the playoffs.
Home rinks.
Ottawa Civic Centre.
The new Senators' first home arena was the Ottawa Civic Centre, located on Bank Street, where they played from the 1992-93 season to January of the 1995-96 season. They played their first home game on October 8, 1992 against the Montreal Canadiens with lots of pre-game spectacle. The Senators would defeat the Canadiens 5–3 in one of few highlights that season. Montreal would eventually finish the season as Stanley Cup champions. Following the initial excitement of the opening night victory, the club floundered badly and would eventually tie with the San Jose Sharks for the worst record in the league, finishing with only 10 wins, 70 losses and 4 ties for 24 points, three points better than the NHL record for futility.
Canadian Tire Centre.
As part of its bid to land a NHL franchise for Ottawa, Terrace Corporation unveiled the original proposal for the arena development at a press conference in September 1989. The proposal included a hotel and 20,500 seat arena, named The Palladium on , surrounded by a mini-city, named "West Terrace." The site itself, of farmland, on the western border of Kanata, had been acquired in May 1989 by Terrace. Rezoning approval was granted by the Board on August 28, 1991, with conditions. The conditions imposed by the board included a scaling down of the arena to 18,500 seats, a moratorium on development outside the initial arena site, and that the cost of the highway interchange with highway 417 be paid by Terrace. A two-year period was used seeking financing for the site and interchange by Terrace Corporation. The corporation received a $6 million grant from the federal government, but needed to borrow to pay for the rest of the costs of construction. A ground-breaking ceremony was held in June 1992 but actual construction did not start until July 7, 1994. Actual construction took 18 months, finishing in January 1996.
The newly built Palladium opened on January 15, 1996 with a concert by Canadian rocker Bryan Adams. The Senators played their first game in their new arena two days later, falling 3-0 to the Montreal Canadiens. On February 17, 1996, the name 'Palladium' was changed to the 'Corel Centre' when Corel Corporation, an Ottawa software company, signed a 10-year deal for the naming rights.
When mortgage holder Covanta Energy (the former Ogden Entertainment) went into receivership in 2001, Terrace was expected to pay off the entire debt. The ownership was not able to refinance the arena, eventually leading Terrace itself to declare bankruptcy in 2003. However, on August 26, 2003, billionaire businessman Eugene Melnyk finalized the purchase of the Senators and the arena. The arena and club became solely owned by Melnyk through a new company, Capital Sports Properties.
In 2004, the ownership applied to expand its seating. In December 2004, the City of Ottawa amended its by-laws and in 2005, the venue was allowed to increase its seating capacity to 19,153 and total attendance capacity to 20,500 when including standing room.
On January 19, 2006, the arena became known as 'Scotiabank Place' after reaching a new 15-year naming agreement with Canadian bank Scotiabank on January 11, 2006. Scotiabank had been an advertising partner with the club for several years and took over the naming after Corel declined to renew its naming agreement with the Senators, but continued as an advertising sponsor.
On June 18, 2013, the Ottawa Senators announced a new marketing agreement with Canadian Tire, and as a result, the arena was renamed the Canadian Tire Centre on July 1, 2013.
Team identity.
Logo and jersey design.
The team colours are red, black and white, with added trim of gold. The team's away jersey is mostly white with red and black trim, while the home jersey is red, with white and black trim. The club logo is officially the head of a Roman general, a member of the Senate of the Roman Republic, projecting from a gold circle. The original, unveiled on May 23, 1991, described the general as a "centurion figure, strong and prominent" according to its designer, Tony Milchard.
The current jersey design was unveiled on August 22, 2007, in conjunction with the league-wide adoption of the "Rbk EDGE" jerseys by Reebok for the 2007–08 season. The jersey incorporates the original Senators' 'O' logo as a shoulder patch. At the same time, the team updated its logos, and switched their usage. The primary logo, which according to team owner Eugene Melnyk, "represents strength and determination" is an update of the old secondary logo. The old primary logo has become the team's secondary logo and only appears on Senators' merchandise.
In 2011, the Senators introduced their current third jersey design. Mostly black, the jersey incorporated horizontal striping intended to be reminiscent of the original Senators' 'barber-pole' designs. Shield-type patches were added to the shoulders. The design of the shield-type patches was intended to be similar to the shield patches that the original Senators added to their jerseys after each Stanley Cup championship win. The patches spell the team name, one in English, and one in French. The design was a collaborative effort between the Senators and a fan in Gatineau, Quebec who had been circulating a version of it on the internet since 2009.
Attendance and revenues.
On April 18, 2008, the club announced its final attendance figures for 2007–08. The club had 40 sell-outs out of 41 home dates, a total attendance of 812,665 during the regular season, placing the club third in attendance in the NHL. The number of sell-outs and the total attendance were both club records. The previous attendance records were set during the 2005–06 with a season total of 798,453 and 33 sell-outs. In 2006–07 regular season attendance was 794,271, with 31 sell-outs out of 41 home dates or an average attendance of 19,372. In the 2007 playoffs, the Senators played 9 games with 9 sell-outs and an attendance of 181,272 for an average of 20,141, the highest in team history.
On November 29, 2011, a "Forbes" magazine report valued the Ottawa Senators Hockey Club at $201 million, (17th highest in NHL). The valuation was based on $27 million for the sport, $70 million for the arena, $80 million for the market and $25 million for the brand. For 2010–11, the club had an operating income of $2.8 million on revenues of $100 million. The gate receipts for the 2010–11 season were $46 million and player expenses were $57 million. The operating income followed two years where the team posted a loss. Forbes estimates that the organization has a debt/value ratio of 65%, including arena debt. Eugene Melnyk bought the team for $92 million in 2003. A November 2014 report by Forbes valued the Senators at $400 million, 16th highest in the NHL.
Arena entertainment.
At many home games the fans are entertained both outside and inside Canadian Tire Centre with a myriad of talent – live music, rock bands, giveaways and promotions. The live music includes the traditional Scottish music of the 'Sons of Scotland Pipe Band' of Ottawa along with highland dancers. Before and during games, entertainment is provided by Spartacat, the official mascot of the Senators, an anthropomorphic lion. He made his debut on the Senators' opening night: October 8, 1992. Anthems are usually sung by former Ontario Provincial Police Constable Lyndon Slewidge. Slewidge sings the "bilingual" version of "O Canada" containing both English and French words. The Senators have their own theme song "Ottawa Senators Theme Song" which is played as the team comes on the ice and is also used in Sens TV web videos. It was composed locally in Ottawa.
Sens Army.
The fans of the Senators are known as the "Sens Army". Like most hockey fanatics, they are known to dress up for games; some in Roman legionary clothing. For the 2006–2007 playoff run, more fans than ever before would wear red, and fan activities included 'Red Rallies' of decorated cars, fan rallies at Ottawa City Hall Plaza and the 'Sens Mile' along Elgin Street where fans would congregate.
Sens Mile.
Much like the Red Mile in Calgary during the Flames' 2004 cup run and the Copper Kilometer in Edmonton during the Oilers' 2006 cup run, Ottawa Senators fans took to the streets to celebrate their team's success during the 2006–07 playoffs. The idea to have a 'Sens Mile' on the downtown Elgin Street, a street with numerous restaurants and pubs, began as a grassroots campaign on Facebook by Ottawa residents before Game 4 of the Ottawa-Buffalo Eastern Conference Final series. After the Game 5 win, Ottawa residents closed the street to traffic for a spontaneous celebration. The City of Ottawa then closed Elgin Street for each game of the Final.
Broadcasting and media.
On television, Senators games not broadcast by the league's national broadcast partners are televised by TSN5 within the Ottawa River valley and Eastern Ontario (portions are shared with the Toronto Maple Leafs, along with Quebec, the Maritime provinces and Newfoundland and Labrador. Senators games were previously broadcast by Sportsnet East. On January 29, 2014, the team announced a new, 12-year regional broadcasting deal with Bell Media to take effect in the 2014-15 season, which will see CFGO maintain radio coverage, and see TSN (English) and RDS (French) gain regional television rights to Senators games not broadcast nationally by Sportsnet (who will take over national NHL rights beginning in the same season), TVA Sports, or "Hockey Night in Canada". The deal will also expand Bell Canada's role as a team sponsor.
In April 2014, Dean Brown, who had called play-by-play for Senators games the team's inception, stated that it was "extremely unlikely" that he would move to TSN and continue his role. He noted that the network already had four commentators among its personalities—including his colour commentator Gord Miller, and fellow TSN personalities Chris Cuthbert, Rod Black, and Paul Romanuk (who was, however, picked up by Rogers for its national NHL coverage in June 2014), who were likely candidates to serve as the new voices of the Senators. However, Brown and TSN mended fences, and Brown is still the Senators' voice as of the 2015-16 season.
On radio, all home and away games are broadcast on a five-station network stretching across Eastern Ontario, and including one American station, WQTK in Ogdensburg, New York. The flagship radio station is CFGO "TSN Radio 1200" in Ottawa. Radio broadcasts on CFGO began in 1997–98; the contract has since been extended through the 2025-2026 season through an extensive rights deal with the station's current owner, Bell Media.
During the 2006–07 and 2007–08 seasons, several games were only available in video on pay-per-view or at local movie theatres in the Ottawa area. The "Sens TV" service was suspended indefinitely as of September 24, 2008.
The Senators' organization operates predominantly in English, but provides services for its francophone fans as well. The Senators' web site is in both languages. Arena announcements and press releases are in both languages. The Senators' ticket agency "CapitalTickets.ca" operates in English and French. The French-language cable television channels TVA Sports and RDS broadcast a selection of Senators games. On the RDS network, Félix Séguin and former Senators goaltender Patrick Lalime are the announcers, starting in the 2011–12 season. The TVA Sports broadcast team consists of Michel Langevin, Yvon Pedneault and Enrico Ciccone. The Senators are broadcast on radio in French through Intersport Production and CJFO Unique FM in Ottawa. Nicolas St. Pierre provides play-by-play, with Alain Sanscartier as colour commentator.
Players and personnel.
General managers.
Source: "Ottawa Senators 2009–10 Media Guide", p. 206.
Team record.
Statistics and records are current after the 2014–15 season, except where noted.
Season-by-season record.
"For the full season-by-season history, see List of Ottawa Senators seasons"
Team scoring leaders.
These are the top-ten regular season point-scorers in franchise history, post-1992, after the 2014–15 season:
"Note: Pos = Position; GP = Games Played; G = Goals; A = Assists; Pts = Points; P/G = Points per game average;
°= "current NHL player"
Totals contain only games played for Ottawa.
Source: Former players: Ottawa Senators, Active players: Hockeydb
NHL awards and trophies.
Presidents' Trophy
Prince of Wales Trophy
Calder Memorial Trophy
NHL Plus-Minus Award
Jack Adams Award
James Norris Memorial Trophy
King Clancy Memorial Trophy
Mark Messier Leadership Award
NHL All-Rookie Team
NHL First All-Star Team
NHL Second All-Star Team
Team records.
Source: Ottawa Senators.

</doc>
<doc id="22706" url="https://en.wikipedia.org/wiki?curid=22706" title="Orchestra">
Orchestra

An orchestra ( or ; ) is a large instrumental ensemble used in classical music that contains sections of string (violin, viola, cello and double bass), brass, woodwind, and percussion instruments. Other instruments such as the piano and celesta may sometimes be grouped into a fifth section such as a keyboard section or may stand alone, as may the concert harp and, for 20th and 21st century compositions, electric and electronic instruments. The term "orchestra" derives from the Greek ὀρχήστρα, the name for the area in front of an ancient Greek stage reserved for the Greek chorus. The orchestra grew by accretion throughout the 18th and 19th centuries, but changed very little in composition during the course of the 20th century.
A smaller-sized orchestra for this time period (of about fifty musicians or fewer) is called a chamber orchestra. A full-size orchestra (about 70-100 musicians) may sometimes be called a symphony orchestra or philharmonic orchestra; these modifiers do not necessarily indicate any strict difference in either the instrumental constitution or role of the orchestra, but can be useful to distinguish different ensembles based in the same city (for instance, the London Symphony Orchestra and the London Philharmonic Orchestra). A symphony orchestra will usually have over eighty musicians on its roster, in some cases over a hundred, but the actual number of musicians employed in a particular performance may vary according to the work being played and the size of the venue. A leading chamber orchestra might employ as many as fifty musicians; some are much smaller than that. The term concert orchestra may sometimes be used (e.g., BBC Concert Orchestra; RTÉ Concert Orchestra)—no distinction is made on size of orchestra by use of this term, although their use is generally distinguished as for live concert. As such they are commonly chamber orchestras. There are several types of amateur orchestras, including school orchestras, youth orchestras and community orchestras.
Orchestras are usually led by a conductor who directs the performance by way of visible gestures. The conductor unifies the orchestra, sets the tempo and shapes the sound of the ensemble. Orchestras play a wide range of repertoire, including symphonies, overtures, concertos, and music for operas and ballets.
Instrumentation.
The typical symphony orchestra consists of four groups of related musical instruments called the woodwinds, brass, percussion, and strings (violin, viola, cello and double bass). Other instruments such as the piano and celesta may sometimes be grouped into a fifth section such as a keyboard section or may stand alone, as may the concert harp and electric and electronic instruments. The orchestra, depending on the size, contains almost all of the standard instruments in each group. In the history of the orchestra, its instrumentation has been expanded over time, often agreed to have been standardized by the classical period and Ludwig van Beethoven's influence on the classical model. In the 20th century, new repertory demands expanded the instrumentation of the orchestra, resulting in a flexible use of the classical model instruments in various combinations.
Beethoven's influence.
The so-called "standard complement" of double winds and brass in the orchestra from the first half of the 19th century is generally attributed to the forces called for by Beethoven. The exceptions to this are his Symphony No. 4, Violin Concerto, and Piano Concerto No. 4, which each specify a single flute. The composer's instrumentation almost always included paired flutes, oboes, clarinets, bassoons, horns and trumpets. Beethoven carefully calculated the expansion of this particular timbral "palette" in Symphonies 3, 5, 6, and 9 for an innovative effect. The third horn in the "Eroica" Symphony arrives to provide not only some harmonic flexibility, but also the effect of "choral" brass in the Trio. Piccolo, contrabassoon, and trombones add to the triumphal finale of his Symphony No. 5. A piccolo and a pair of trombones help deliver storm and sunshine in the Sixth. The Ninth asks for a second pair of horns, for reasons similar to the "Eroica" (four horns has since become standard); Beethoven's use of piccolo, contrabassoon, trombones, and untuned percussion—plus chorus and vocal soloists—in his finale, are his earliest suggestion that the timbral boundaries of symphony might be expanded for good. For several decades after his departure, symphonic instrumentation was faithful to Beethoven's well-established model, with few exceptions.
Expanded instrumentation.
Apart from the core orchestral complement, various other instruments are called for occasionally. These include the classical guitar, heckelphone, flugelhorn, cornet, harpsichord, and organ. Saxophones, for example, appear in some 19th- through 21st-century scores. While appearing only as featured solo instruments in some works, for example Maurice Ravel's orchestration of Modest Mussorgsky's "Pictures at an Exhibition" and Sergei Rachmaninoff's "Symphonic Dances", the saxophone is included in other works, such as Ravel's "Boléro", Sergei Prokofiev's Romeo and Juliet Suites 1 and 2, Vaughan Williams' Symphonies No.6 and 9 and William Walton's "Belshazzar's Feast", and many other works as a member of the orchestral ensemble. The euphonium is featured in a few late Romantic and 20th-century works, usually playing parts marked "tenor tuba", including Gustav Holst's "The Planets", and Richard Strauss's "Ein Heldenleben". The Wagner tuba, a modified member of the horn family, appears in Richard Wagner's cycle "Der Ring des Nibelungen" and several other works by Strauss, Béla Bartók, and others; it has a prominent role in Anton Bruckner's "Symphony No. 7 in E Major". Cornets appear in Pyotr Ilyich Tchaikovsky's ballet "Swan Lake", Claude Debussy's "La Mer", and several orchestral works by Hector Berlioz. Unless these instruments are played by members doubling on another instrument (for example, a trombone player changing to euphonium for a certain passage), orchestras will use freelance musicians to augment their regular rosters.
The 20th-century orchestra was far more flexible than its predecessors. In Beethoven's and Felix Mendelssohn's time, the orchestra was composed of a fairly standard core of instruments which was very rarely modified. As time progressed, and as the Romantic period saw changes in accepted modification with composers such as Berlioz and Mahler, the 20th century saw that instrumentation could practically be hand-picked by the composer. Today, however, the modern orchestra has generally been considered standardized with the modern instrumentation listed below.
With this history in mind, the orchestra can be seen to have a general evolution as outlined below. The first is a Baroque orchestra, the second is a typical classical orchestra (i.e. Beethoven/Joseph Haydn), the third is typical of an early/mid-Romantic (i.e. Franz Schubert/Hector Berlioz/Robert Schumann), late-Romantic/early 20th century (i.e. Wagner/Brahms/Mahler/Igor Stravinsky), to the common complement of a present-day modern orchestras (i.e. John Adams/Samuel Barber/Aaron Copland/Philip Glass/Krzysztof Penderecki).
Organization.
Among the instrument groups and within each group of instruments, there is a generally accepted hierarchy. Every instrumental group (or section) has a principal who is generally responsible for leading the group and playing orchestral solos. The violins are divided into two groups, first violin and second violin, with the second violins playing with lower registers than the first violins.
The principal first violin is called the concertmaster (or "leader" in the UK) and is not only considered the leader of the string section, but the second-in-command of the entire orchestra, behind only the conductor. The concertmaster leads the pre-concert tuning and handles musical aspects of orchestra management, such as determining the bowings for the violins or for all of the string section. The concertmaster usually sits to the conductor's left, closest to the audience. In some U.S. and British orchestras, the concertmaster comes on stage after the rest of the orchestra is seated, takes a bow, and receives applause before the conductor (and the soloists, if there are any) appear on stage.
The principal trombone is considered the leader of the low brass section, while the principal trumpet is generally considered the leader of the entire brass section. While the oboe often provides the tuning note for the orchestra (due to 300-year-old convention), no principal is the leader of the woodwind section though in woodwind ensembles, often the flute is leader. Instead, each principal confers with the others as equals in the case of musical differences of opinion. The horn, while technically a brass instrument, often acts in the role of both woodwind and brass. Most sections also have an assistant principal (or co-principal or associate principal), or in the case of the first violins, an assistant concertmaster, who often plays a tutti part in addition to replacing the principal in his or her absence. Principal, co-principal and assistant principal players are paid a higher salary than regular orchestra members playing the same instrument.
A section string player plays in unison with the rest of the section, except in the case of divided ("divisi") parts, where upper and lower parts in the music are often assigned to "outside" (nearer the audience) and "inside" seated players. Where a solo part is called for in a string section, the section leader invariably plays that part. The section leader (or principal) of a string section is also responsible for determining the bowings, often based on the bowings set out by the concertmaster. In some cases, the principal of a string section may use a slightly different bowing than the Concertmaster, to accommodate the requirements of playing their instrument (e.g., the double bass section). Principals of a string section will also lead entrances for their section, typically by lifting the bow before the entrance, to ensure the section plays together. Tutti wind and brass players generally play a unique but non-solo part. Section percussionists play parts assigned to them by the principal percussionist. 
In modern times, the musicians are usually directed by a conductor, although early orchestras did not have one, giving this role instead to the concertmaster or the harpsichordist playing the continuo. Some modern orchestras also do without conductors, particularly smaller orchestras and those specializing in historically accurate (so-called "period") performances of baroque and earlier music.
The most frequently performed repertoire for a symphony orchestra is Western classical music or opera. However, orchestras are used sometimes in popular music (e.g., to accompany a rock or pop band in a concert), extensively in film music, and increasingly often in video game music. Orchestras are also used in the symphonic metal genre. The term "orchestra" can also be applied to a jazz ensemble, for example in the performance of big band music.
Selection and appointment of members.
All members of a professional orchestra must audition for positions in the ensemble. Performers typically play one or more solo pieces of the auditionee's choice, such as a movement of a concerto, and a variety of excerpts from the orchestral literature that are advertised in the audition poster (so the auditionees can prepare). The excerpts are typically the most technically challenging parts and solos from the orchestral literature. Orchestral auditions are typically held in front of a panel that includes the conductor, the Concertmaster, the Principal player of the section for which the auditionee is applying and possibly other principal players and regular orchestra members.
The most promising candidates from the first round of auditions are invited to return for a second or third round of auditions, which allows the conductor and the panel to compare the best candidates. Performers may be asked to sight read orchestral music. The final stage of the audition process in some orchestras is a "test week", in which the performer plays with the orchestra for a week or two, which allows the conductor and principal players to see if the individual can function well in an actual rehearsal and performance setting.
There are a range of different employment arrangements. The most sought-after positions are permanent, tenured positions in the orchestra. Orchestras also hire musicians on contracts, ranging in length from a single concert to a full season or more. Contract performers may be hired for individual concerts when the orchestra is doing an exceptionally large late-Romantic era orchestral work, or to substitute for a permanent member who is sick. A professional musician who is hired to perform for a single concert is sometimes called a "sub". Some contract musicians may be hired to replace permanent members for the period that the permanent member is on parental leave or disability leave.
Working conditions and concert preparation.
Orchestral musicians typically sit to rehearse and play, although some musicians such as percussionists and double bassists may stand. Musicians rehearse under the direction of the conductor for several rehearsals. For particularly challenging pieces, sectional rehearsals may be held (e.g., the viola section or the brass section). In addition to the preparation that takes place during rehearsals, orchestral musicians are expected to prepare their individual parts by practicing them. Some rehearsals are held in large rehearsal halls or rooms. The final rehearsal, called the dress rehearsal, is held on the stage where the orchestra is performing, so that the conductor can hear the balance of instrument sections and the sound in the performance hall. 
The concerts are typically held on a stage in a large auditorium in an arts centre or opera house, although orchestras may also play in churches or outdoor stages. Once a conductor and orchestra have prepared a symphony program in rehearsal, the program may be played once, twice, or for a larger number of performances. The latter approach is typically used during a concert tour or for an extended run of an opera or other presentation. During tours, musicians have to travel, stay in hotels and adapt to changing performance venues.During performances, orchestra members typically wear formal evening wear, such as black tuxedos for men and black evening gowns or pantsuits for women.
In the US and Canada, many professional orchestral musicians are members are members of a union, the American Federation of Musicians. Unions negotiate working conditions such as the length of rehearsals and breaks and overtime pay. In each orchestra, an orchestra member serves as a union steward, to ensure that the conditions of work are respected. Union stewards may also sit in during auditions, to ensure the fairness of the process.
Gender of ensembles.
Historically, major professional orchestras have been mostly or entirely composed of male musicians. The first women members hired in professional orchestras have been harpists. The Vienna Philharmonic, for example, did not accept women to permanent membership until 1997, far later than comparable orchestras (the other orchestras ranked among the world’s top five by "Gramophone" in 2008). The last major orchestra to appoint a woman to a permanent position was the Berlin Philharmonic. In February 1996, the Vienna Philharmonic's principal flute, Dieter Flury, told "Westdeutscher Rundfunk" that accepting women would be "gambling with the emotional unity () that this organism currently has". In April 1996, the orchestra’s press secretary wrote that "compensating for the expected leaves of absence" of maternity leave would be a problem.
In 1997, the Vienna Philharmonic was "facing protests during a [US] tour" by the National Organization for Women and the International Alliance for Women in Music. Finally, "after being held up to increasing ridicule even in socially conservative Austria, members of the orchestra gathered [on 28 February 1997] in an extraordinary meeting on the eve of their departure and agreed to admit a woman, Anna Lelkes, as harpist." As of 2013, the orchestra has six female members; one of them, violinist Albena Danailova became one of the orchestra’s concertmasters in 2008, the first woman to hold that position.In 2012, women still made up just 6% of the orchestra's membership. VPO president Clemens Hellsberg said the VPO now uses completely screened blind auditions.
In 2013, an article in "Mother Jones" stated that while "[m]any prestigious orchestras have significant female membership—women outnumber men in the New York Philharmonic's violin section—and several renowned ensembles, including the National Symphony Orchestra, the Detroit Symphony, and the Minnesota Symphony, are led by women violinists", the double bass, brass, and percussion sections of major orchestras "...are still predominantly male."A 2014 BBC article stated that the "...introduction of ‘blind’ auditions, where a prospective instrumentalist performs behind a screen so that the judging panel can exercise no gender or racial prejudice, has seen the gender balance of traditionally male-dominated symphony orchestras gradually shift."
Amateur ensembles.
There are also a variety of amateur orchestras:
Repertoire.
Orchestras play a wide range of repertoire ranging from 17th century dance suites to 21st century symphonies. Orchestras have become synonymous with the symphony, an extended musical composition in Western classical music that typically contains multiple movements. Symphonies are notated in a musical score, which contains all the instrument parts. The conductor uses the score to study the symphony before rehearsals and decide on their interpretation (e.g., tempos, articulation, phrasing, etc.), and to follow the music during rehearsals and concerts. Orchestral musicians play from parts which contain just the notated music for their instrument. A small number of symphonies also contain vocal parts (e.g., Beethoven's Ninth Symphony). 
Orchestras also perform overtures, a term originally applied to the instrumental introduction to an opera. During the early Romantic era, composers such as Beethoven and Mendelssohn began to use the term to refer to independent, self-existing instrumental, programmatic works that presaged genres such as the symphonic poem, a form devised by Franz Liszt in several works that began as dramatic overtures. These were "at first undoubtedly intended to be played at the head of a programme". In the 1850s the concert overture began to be supplanted by the symphonic poem. 
Orchestras also play with instrumental soloists in concertos. During concertos, the orchestra plays an accompaniment role to the soloist (e.g., a solo violinist or pianist) and, at times, introduces musical themes or interludes while the soloist is not playing. Orchestras also play during operas, ballets, some musical theatre works and some choral works (both sacred works such as Masses and secular works). In operas and ballets, the orchestra accompanies the singers and dancers, respectively, and plays overtures and interludes where the melodies played by the orchestra take centre stage. The orchestral repertoire also includes a range of other pieces, such as Baroque dance suites, symphonic dances and suites of film music.
History.
Early history.
The first orchestras were made up of small groups of musicians that gathered for festivals, holidays, or funerals. It was not until the 11th century that families of instruments started to appear with differences in tones and octaves. True modern orchestras started in the late 16th century when composers started writing music for instrumental groups. In the 15th and 16th centuries in Italy the households of nobles had musicians to provide music for dancing and the court, however with the emergence of the theatre, particularly opera, in the early 17th century, music was increasingly written for groups of players in combination, which is the origin of orchestral playing. Opera originated in Italy, and Germany eagerly followed. Dresden, Munich and Hamburg successively built opera houses. At the end of the 17th century opera flourished in England under Henry Purcell, and in France under Lully, who with the collaboration of Molière also greatly raised the status of the entertainments known as ballets, interspersed with instrumental and vocal music.
In the 17th century and early 18th century, instrumental groups were taken from all of the available talent. A composer such as Johann Sebastian Bach had control over almost all of the musical resources of a town, whereas Handel would hire the best musicians available. This placed a premium on being able to rewrite music for whichever singers or musicians were best suited for a performance — Handel produced different versions of the "Messiah" oratorio almost every year.
As nobility began to build retreats away from towns, they began to hire musicians to form permanent ensembles. Composers such as the young Joseph Haydn would then have a fixed body of instrumentalists to work with. At the same time, traveling virtuoso performers such as the young Wolfgang Amadeus Mozart would write concerti that showed off their skills, and they would travel from town to town, arranging concerts along the way. The aristocratic orchestras worked together over long periods, making it possible for ensemble playing to improve with practice.
Mannheim school.
This change, from civic music making where the composer had some degree of time or control, to smaller court music making and one-off performance, placed a premium on music that was easy to learn, often with little or no rehearsal. The results were changes in musical style and emphasis on new techniques. Mannheim had one of the most famous orchestras of that time, where notated dynamics and phrasing, previously quite rare, became standard (see Mannheim school). It also attended a change in musical style from the complex counterpoint of the baroque period, to an emphasis on clear melody, homophonic textures, short phrases, and frequent cadences: a style that would later be defined as classical.
Throughout the late 18th century composers would continue to have to assemble musicians for a performance, often called an "Academy", which would, naturally, feature their own compositions. In 1781, however, the Leipzig Gewandhaus Orchestra was organized from the merchants concert society, and it began a trend towards the formation of civic orchestras that would accelerate into the 19th century. In 1815, Boston's Handel and Haydn Society was founded, in 1842 the New York Philharmonic and the Vienna Philharmonic were formed, and in 1858, the Hallé Orchestra was formed in Manchester. There had long been standing bodies of musicians around operas, but not for concert music: this situation changed in the early 19th century as part of the increasing emphasis in the composition of symphonies and other purely instrumental forms. This was encouraged by composer critics such as E. T. A. Hoffmann who declared that instrumental music was the "purest form" of music. The creation of standing orchestras also resulted in a professional framework where musicians could rehearse and perform the same works repeatedly, leading to the concept of a repertoire in instrumental music.
Performance standards.
In the 1830s, conductor François Antoine Habeneck, began rehearsing a selected group of musicians in order to perform the symphonies of Beethoven, which had not been heard in their entirety in Paris. He developed techniques of rehearsing the strings separately, notating specifics of performance, and other techniques of cuing entrances that were spread across Europe. His rival and friend Hector Berlioz would adopt many of these innovations in his touring of Europe.
Instrumental craftsmanship.
The invention of the piston and rotary valve by Heinrich Stölzel and Friedrich Blühmel, both Silesians, in 1815, was the first in a series of innovations, including the development of modern keywork for the flute by Theobald Boehm and the innovations of Adolphe Sax in the woodwinds. These advances would lead Hector Berlioz to write a landmark book on instrumentation, which was the first systematic treatise on the use of instrumental sound as an expressive element of music.
The effect of the invention of valves for the brass was felt almost immediately: instrument-makers throughout Europe strove together to foster the use of these newly refined instruments and continuing their perfection; and the orchestra was before long enriched by a new family of valved instruments, variously known as tubas, or euphoniums and bombardons, having a chromatic scale and a full sonorous tone of great beauty and immense volume, forming a magnificent bass. This also made possible a more uniform playing of notes or intonation, which would lead to a more and more "smooth" orchestral sound that would peak in the 1950s with Eugene Ormandy and the Philadelphia Orchestra and the conducting of Herbert von Karajan with the Berlin Philharmonic.
During this transition period, which gradually eased the performance of more demanding "natural" brass writing, many composers (notably Wagner and Berlioz) still "notated" brass parts for the older "natural" instruments. This practice made it possible for players still using natural horns, for instance, to perform from the same parts as those now playing valved instruments. However, over time, use of the valved instruments became standard, indeed universal, until the revival of older instruments in the contemporary movement towards authentic performance (sometimes known as "historically informed performance").
At the time of the invention of the valved brass, the pit orchestra of most operetta composers seems to have been modest. An example is Sullivan's use of two flutes, one oboe, two clarinets, one bassoon, two horns, two cornets (a piston), two trombones, drums and strings.
During this time of invention, winds and brass were expanded, and had an increasingly easy time playing in tune with each other: particularly the ability for composers to score for large masses of wind and brass that previously had been impractical. Works such as the "Requiem" of Hector Berlioz would have been impossible to perform just a few decades earlier, with its demanding writing for twenty woodwinds, as well as four gigantic brass ensembles each including around four trumpets, four trombones, and two tubas.
Wagner's influence.
The next major expansion of symphonic practice came from Richard Wagner's Bayreuth orchestra, founded to accompany his musical dramas. Wagner's works for the stage were scored with unprecedented scope and complexity: indeed, his score to "Das Rheingold" calls for six harps. Thus, Wagner envisioned an ever-more-demanding role for the conductor of the theatre orchestra, as he elaborated in his influential work "On Conducting". This brought about a revolution in orchestral composition, and set the style for orchestral performance for the next eighty years. Wagner's theories re-examined the importance of tempo, dynamics, bowing of string instruments and the role of principals in the orchestra. Conductors who studied his methods would go on to be influential themselves.
20th century orchestra.
As the early 20th century dawned, symphony orchestras were larger, better funded, and better trained than ever before; consequently, composers could compose larger and more ambitious works. The influence of Gustav Mahler was particularly innovational; in his later symphonies, such as the mammoth Symphony No. 8, Mahler pushes the furthest boundaries of orchestral size, employing huge forces. By the late Romantic era, orchestras could support the most enormous forms of symphonic expression, with huge string sections, massive brass sections and an expanded range of percussion instruments. With the recording era beginning, the standards of performance were pushed to a new level, because a recorded symphony could be listened to closely and even minor errors in intonation or ensemble, which might not be noticeable in a live performance, could be heard by critics. As recording technologies improved over the 20th and 21st centuries, eventually small errors in a recording could be "fixed" by audio editing or overdubbing. Some older conductors and composers could remember a time when simply "getting through" the music as best as possible was the standard. Combined with the wider audience made possible by recording, this led to a renewed focus on particular star conductors and on a high standard of orchestral execution. After sound was added to silent film, the lush sound of a full orchestra became a key component of popular film scores.
Counter-revolution.
In the 1920s and 1930s, economic as well as artistic considerations led to the formation of smaller concert societies, particularly those dedicated to the performance of music of the avant-garde, including Igor Stravinsky and Arnold Schoenberg. This tendency to start festival orchestras or dedicated groups would also be pursued in the creation of summer musical festivals, and orchestras for the performance of smaller works. Among the most influential of these was the Academy of St Martin in the Fields under the baton of Sir Neville Marriner.
With the advent of the early music movement, smaller orchestras where players worked on execution of works in styles derived from the study of older treatises on playing became common. These include the Orchestra of the Age of Enlightenment, the London Classical Players under the direction of Sir Roger Norrington and the Academy of Ancient Music under Christopher Hogwood, among others.
Recent trends in the United States.
In the United States, the late 20th century saw a crisis of funding and support for orchestras. The size and cost of a symphony orchestra, compared to the size of the base of supporters, became an issue that struck at the core of the institution. Few orchestras could fill auditoriums, and the time-honored season-subscription system became increasingly anachronistic, as more and more listeners would buy tickets on an ad hoc basis for individual events. Orchestral endowments and—more centrally to the daily operation of American orchestras—orchestral donors have seen investment portfolios shrink or produce lower yields, reducing the ability of donors to contribute; further, there has been a trend toward donors finding other social causes more compelling. Also, while government funding is less central to American than European orchestras, cuts in such funding are still significant for American ensembles. Finally, the drastic falling-off of revenues from recording, tied to no small extent to changes in the recording industry itself, began a period of change that has yet to reach its conclusion.
U.S. orchestras that have gone into Chapter 11 bankruptcy include the Philadelphia Orchestra (in April 2011), and the Louisville Orchestra, in December 2010; orchestras that have gone into Chapter 7 bankruptcy and have ceased operations include the Northwest Chamber Orchestra in 2006, the Honolulu Orchestra in March 2011, the New Mexico Symphony Orchestra in April 2011, and the Syracuse Symphony in June 2011. The Festival of Orchestras in Orlando, Florida ceased operations at the end of March, 2011.
One source of financial difficulties that received notice and criticism was high salaries for music directors of US orchestras, which led several high-profile conductors to take pay cuts in recent years. Music administrators such as Michael Tilson Thomas and Esa-Pekka Salonen argued that new music, new means of presenting it, and a renewed relationship with the community could revitalize the symphony orchestra. The American critic Greg Sandow has argued in detail that orchestras must revise their approach to music, performance, the concert experience, marketing, public relations, community involvement, and presentation to bring them in line with the expectations of 21st-century audiences immersed in popular culture.
It is not uncommon for contemporary composers to use unconventional instruments, including various synthesizers, to achieve desired effects. Many, however, find more conventional orchestral configuration to provide better possibilities for color and depth. Composers like John Adams often employ Romantic-size orchestras, as in Adams' opera "Nixon in China"; Philip Glass and others may be more free, yet still identify size-boundaries. Glass in particular has recently turned to conventional orchestras in works like the "Concerto for Cello and Orchestra" and the Violin Concerto No. 2.
Along with a decrease in funding, some U.S. orchestras have reduced their overall personnel, as well as the number of players appearing in performances. The reduced numbers in performance are usually confined to the string section, since the numbers here have traditionally been flexible (as multiple players typically play from the same part).
Conductorless orchestras.
The post-revolutionary symphony orchestra Persimfans was formed in the Soviet Union in 1922. The unusual aspect of the orchestra was that, believing that in the ideal Marxist state all people are equal, its members felt that there was no need to be led by the dictatorial baton of a conductor; instead they were led by a committee. Although it was a partial success, the principal difficulty with the concept was in changing tempo. The orchestra survived for ten years before Stalin's cultural politics effectively forced it into disbandment by draining away its funding.
Some ensembles, such as the Orpheus Chamber Orchestra, based in New York City, have had more success, although decisions are likely to be deferred to some sense of leadership within the ensemble (for example, the principal wind and string players). Others have returned to the tradition of a principal player, usually a violinist, being the artistic director and running rehearsals (such as the Australian Chamber Orchestra, Amsterdam Sinfonietta & Candida Thompson and the New Century Chamber Orchestra).
Multiple conductors.
The techniques of polystylism and polytempo music have recently led a few composers to write music where multiple orchestras perform simultaneously. These trends have brought about the phenomenon of polyconductor music, wherein separate sub-conductors conduct each group of musicians. Usually, one principal conductor conducts the sub-conductors, thereby shaping the overall performance. Some pieces are enormously complex in this regard, such as Evgeni Kostitsyn's Third Symphony, which calls for nine conductors.
Charles Ives often used two conductors, one for example to simulate a marching band coming through his piece. "Realizations for Symphonic Band" includes one example from Ives. Benjamin Britten's War Requiem is also an important example of the repertoire for more than one conductor.
One of the best examples in the late century orchestral music is Karlheinz Stockhausen's "Gruppen", for three orchestras placed around the audience. This way, the sound masses could be spacialized, as in an electroacoustic work. "Gruppen" was premiered in Cologne, in 1958, conducted by Stockhausen, Bruno Maderna and Pierre Boulez. Recently, it was performed by Simon Rattle, John Carewe and Daniel Harding.
Other meanings of "orchestra".
In Ancient Greece, the orchestra was the space between the auditorium and the proscenium (or stage), in which were stationed the chorus and the instrumentalists. The word "orchestra" literally means "a dancing place".
In some theatres, the orchestra is the area of seats directly in front of the stage (called "primafila" or "platea"); the term more properly applies to the place in a theatre, or concert hall reserved for the musicians.
In musical theatre, the accompaniment ensemble for the musical may be called an orchestra (more specifically a pit orchestra), even if it is composed–as been the case since the development of 1960s-era rock musicals–of a small chamber group of eight to twenty or more musicians, including strings, woodwinds, brass, percussion and rock instruments such as electric guitar, electric bass and synthesizer.

</doc>
<doc id="22707" url="https://en.wikipedia.org/wiki?curid=22707" title="Oolong">
Oolong

Oolong RP: /uːlɒŋ/, GA: /ulɑŋ/ () is a traditional Chinese tea ("Camellia sinensis)" produced through a unique process including withering the plant under the strong sun and oxidation before curling and twisting. Most oolong teas, especially those of fine quality, involve unique tea plant cultivars that are exclusively used for particular varieties. The degree of oxidation can range from 8 to 85%, depending on the variety and production style. Oolong is especially popular with tea connoisseurs of south China and Chinese expatriates in Southeast Asia, as is the Fujian preparation process known as the Gongfu tea ceremony.
In Chinese tea culture, semi-oxidised oolong teas are collectively grouped as "qīngchá" (). The taste of oolong varies widely among different subvarieties. It can be sweet and fruity with honey aromas, or woody and thick with roasted aromas, or green and fresh with bouquet aromas, all depending on the horticulture and style of production. Several subvarieties of oolong, including those produced in the Wuyi Mountains of northern Fujian, such as Da Hong Pao, are among the most famous Chinese teas.
Different varieties of oolong are processed differently, but the leaves are formed into one of two distinct styles. Some are rolled into long curly leaves, while others are 'wrap-curled' into small beads, each with a tail. The former style is the more traditional of the two in China.
The name "oolong tea" came into the English language from the Chinese name (), meaning "black dragon tea."
The manufacture of oolong is intricate because some of the basic steps involved in its making are repeated many times before the desired amount of bruising and browning of the leaves is achieved. Withering, roling, shaping, and firing are similar to black tea, but much more attention to timing and temperature is necessary. One last step, baking or roasting, is exclusive to oolong and is referred to as the real art in making this tea
Possible origins.
There are three widely accepted explanations of the origin of the Chinese name. According to the "tribute tea" theory, oolong tea came directly from Dragon-Phoenix Tea Cake tribute tea. The term oolong tea replaced the old term when loose tea came into fashion. Since it was dark, long, and curly, it was called Black Dragon tea.
According to the "Wuyi" theory, oolong tea first existed in the Wuyi Mountains region. This is evidenced by Qing dynasty poems such as Wuyi Tea Song (Wuyi Chage) and Tea Tale (Chashuo). It was said that oolong tea was named after the part of the Wuyi Mountain where it was originally produced.
According to the "Anxi" theory, oolong tea had its origin in the Anxi oolong tea plant, which was discovered by a man named Sulong, Wulong, or Wuliang.
Another tale tells of a man named Wu Liang (later corrupted to Wu Long, or Oolong) who discovered oolong tea by accident when he was distracted by a deer after a hard day's tea-picking, and by the time he remembered to return to the tea it had already started to oxidize.
Varieties.
Fujian, China.
Tea production in Fujian is concentrated in two regions: the Wuyi Mountains and Anxi County. Both are major historical centers of oolong tea production in China.
Wuyi Mountains.
The most famous and expensive oolong teas are made here, and the production is still usually accredited as being organic. Some of the better known cliff teas are:
Guangdong, China.
The name "dan cong" originally meant phoenix teas all picked from one tree. In recent times though it has become a generic term for all Phoenix Mountain oolongs. True dan congs are still being produced, but they are extremely high quality and almost impossible to get in western markets.
Taiwan.
Tea cultivation began in Taiwan in the 18th century. Since then, many of the teas which are grown in Fujian province have also been grown in Taiwan. Since the 1970s, the tea industry in Taiwan has expanded at a rapid rate, in line with the rest of Taiwan's economy. Due to high domestic demand and a strong tea culture, most Taiwanese tea is bought and consumed by the Taiwanese.
As the weather in Taiwan is highly variable, tea quality may differ from season to season. Although the island is not particularly large, it is geographically varied, with high, steep mountains rising abruptly from low-lying coastal plains. The different weather patterns, temperatures, altitudes, and soil ultimately result in differences in appearance, aroma, and flavour of the tea grown in Taiwan. In some mountainous areas, teas have been cultivated at ever higher elevations to produce a unique sweet taste that fetches a premium price.
Steeping.
Generally, 3 grams of tea per 200 ml of water, or about two teaspoons of oolong tea per cup, should be used. Oolong teas should be prepared with 200 to 205 °F (93 to 96 °C) water (not boiling) and steeped 3–10 minutes. High quality oolong can be steeped several times from the same leaves and, unlike other teas, it improves with rebrewing: it is common to steep the same leaves three to five times, the third or fourth steeping usually being considered the best.
A widely used ceremonial method of steeping oolongs in Taiwan and China is called gongfucha. This method uses a small steeping vessel, such as a gaiwan or Yixing clay teapot, with more tea than usual for the amount of water used. Multiple short steeps of 20 seconds to 1 minute are performed; the tea is often served in one- to two-ounce tasting cups.
Caffeine.
Oolong generally contains caffeine, although the caffeine content in tea will vary based on terroir, when the leaf is plucked, and the production processes.

</doc>
<doc id="22709" url="https://en.wikipedia.org/wiki?curid=22709" title="Okapi">
Okapi

The okapi ("Okapia johnstoni"), is a giraffid artiodactyl mammal native to the northeast of the Democratic Republic of the Congo in Central Africa. Although the okapi bears striped markings reminiscent of zebras, it is most closely related to the giraffe. The okapi and the giraffe are the only living members of the family Giraffidae. The okapi stands about tall at the shoulder and has an average body length of about . Its weight ranges from . It has a long neck, and large, flexible ears. Its coat is a chocolate to reddish brown, much in contrast with the white horizontal stripes and rings on the legs and white ankles. Male okapis have short, hair-covered horns called ossicones, less than in length. Females possess hair whorls, and ossicones are absent.
Okapis are primarily diurnal but may be active for a few hours in darkness. They are essentially solitary, coming together only to breed. Okapis are herbivores, feeding on tree leaves and buds, grasses, ferns, fruits, and fungi. Rut in males and estrus in females does not depend on the season. In captivity, estrous cycles recur every 15 days. The gestational period is around 440 to 450 days long, following which usually a single calf is born. The juveniles are kept in hiding, and nursing takes place infrequently. Juveniles start taking solid food from three months, and weaning takes place at six months.
Okapis inhabit canopy forests at altitudes of . They are endemic to the tropical forests of the Democratic Republic of the Congo, where they occur across the central, northern and eastern regions. The International Union for the Conservation of Nature and Natural Resources (IUCN) classifies the okapi as Endangered. Major threats include habitat loss due to logging and human settlement. Extensive hunting for bushmeat and skin and illegal mining have also led to a decline in populations. The Okapi Conservation Project was established in 1987 to protect okapi populations.
Etymology and taxonomy.
The scientific name of the okapi is "Okapia johnstoni". It was first described by British zoologist Ray Lankester in 1901. The generic name "Okapia" derives from the Lese Karo name "o'api", while the specific name ("johnstoni") is in recognition of the British Governor of Uganda, Sir Harry Johnston, who first acquired an okapi specimen for science from the Ituri Forest while repatriating a group of Pygmies to the Belgian Congo. The animal was brought to prominent European attention by speculation on its existence found in press reports covering Henry Morton Stanley's journeys in 1887. Remains of a carcass were later sent to London by the English adventurer and colonial administrator Harry Johnston and became a media event in 1901. 
In 1901, zoologist Philip Sclater presented a painting of the okapi before the Zoological Society of London that depicted its physical features with some clarity. There was much confusion regarding the taxonomical status of this newly discovered animal. Sir Harry Johnston himself called it a "Helladotherium", or a relative of other extinct giraffids. Based on the description of the okapi by Pygmies, who referred to it as a "horse", Sclater named the species "Equus johnstoni". Subsequently, Lankester declared that the okapi represented an unknown genus of Giraffidae, which he placed in its own genus "Okapia", and assigned the name "Okapia johnstoni" to the species.
In 1902, Swiss zoologist Charles Immanuel Forsyth Major suggested the inclusion of "O. johnstoni" in the extinct giraffid subfamily Palaeotraginae. However, the species was placed in its own subfamily Okapiinae, by Swedish palaeontologist Birger Bohlin in 1926, mainly due to the lack of a cingulum, a major feature of the palaeotragids. In 1986, "Okapia" was finally established as a sister genus of "Giraffa" on the basis of cladistic analysis. The two genera together with "Palaeotragus" constitute the tribe Giraffini.
Evolution.
The earliest members of Giraffidae first appeared in the Early Miocene in Africa, having diverged from the superficially deer-like climacoceratids. Giraffids spread into Europe and Asia by the middle Miocene in a first radiation. Another radiation began in the Pliocene but was terminated by a decline in diversity in the Pleistocene. Several important primitive giraffids existed more or less contemporaneously in the Miocene (23-10 million years ago), including "Canthumeryx", "Giraffokeryx", "Palaeotragus" and "Samotherium". According to palaeontologist and author Kathleen Hunt, "Samotherium" split into "Okapia" (18 million years ago) and "Giraffa" (12 million years ago). However, another author J. D. Skinner argued that "Canthumeryx" gave rise to the okapi and giraffe through the latter three genera and that the okapi is the extant form of "Palaeotragus". The okapi is sometimes referred to as an example of a living fossil, as it has existed as a species over a long geological time period, and morphologically resembles more primitive forms (e.g. "Samotherium").
Characteristics.
The okapi is a medium-sized giraffid, standing tall at the shoulder. Its average body length is about and its weight ranges from . It has a long neck, and large and flexible ears. The coat is a chocolate to reddish brown, much in contrast with the white horizontal stripes and rings on the legs and white ankles. The striking stripes make it resemble a zebra. These features serve as an effective camouflage amidst dense vegetation. The face, throat and chest are greyish white. Interdigital glands are present on all four feet, and are slightly larger on the front feet. Male okapis have short, hair-covered horns called ossicones, less than in length. The okapi exhibits sexual dimorphism, with females taller on average, slightly redder and lacking prominent horns, instead possessing hair whorls.
The okapi shows several adaptations to its tropical habitat. The large number of rod cells in the retina facilitate night vision, and there is an efficient olfactory system. The large auditory bullae lead to a strong sense of hearing. The dental formula of the okapi is . Teeth are low-crowned, fine-cusped and efficiently cut tender foliage. The large caecum and colon help in microbial digestion, and a quick rate of food passage allows for lower cell wall digestion than in other ruminants.
The okapi can be easily distinguished from its nearest extant relative, the giraffe. It is much smaller and shares more external similarities with the deer and bovids than with the giraffe. While both sexes possess horns in the giraffe, only males bear horns in the okapi. The okapi has large palatine sinuses, unique among the giraffids. Morphological similarities shared between the giraffe and the okapi include a similar gait - both use a pacing gait, stepping simultaneously with the front and the hind leg on the same side of the body, unlike other ungulates that walk by moving alternate legs on either side of the body - and a long black tongue (longer in the okapi) useful in plucking buds and leaves as well as for grooming.
Ecology and behaviour.
Okapis are primarily diurnal but may be active for a few hours in darkness. They are essentially solitary, coming together only to breed. They have overlapping home ranges and typically occur at densities of about 0.6 animals per square kilometre. Male home ranges average while female home ranges average . Males migrate continuously, while females are sedentary. Males often mark territories and bushes with their urine, while females use common defecation sites. Grooming is a common practice, focused at the earlobes and the neck. Okapis often rub their neck against trees, leaving a brown exudate. 
The male is protective of his territory, but allows females to pass through the domain to forage. Males visit female home ranges at the time of breeding. Although generally tranquil, the okapi can kick and butt with its head to show aggression. As the vocal cords are poorly developed, vocal communication is mainly restricted to three sounds - "chuff" (contact calls used by both sexes), "moan" (by females during courtship) and "bleat" (by infants under stress). Individuals may engage in Flehmen response, a visual expression in which the animals curls back its upper lips, displays the teeth and inhales through the mouth for a few seconds. The leopard is the main predator of the okapi.
Diet.
Okapis are herbivores, feeding on tree leaves and buds, grasses, ferns, fruits, and fungi. They prefer to feed in treefall gaps. The staple food comprises shrubs and lianas. The main constituents of the diet are woody, dicotyledonous species; monocotyledonous plants are not eaten regularly. In the Ituri forest, the okapi feeds mainly upon the plant families Acanthaceae, Ebenaceae, Euphorbiaceae, Flacourtiaceae, Loganiaceae, Rubiaceae and Violaceae.
Reproduction.
Female okapis become sexually mature when about one-and-a-half year old, while males reach maturity after two years. Rut in males and estrus in females does not depend on the season. In captivity, estrus cycles recur every 15 days. The male and the female begin courtship by circling, smelling and licking each other. The male shows his dominance by extending his neck, tossing his head and protruding one leg forward. This is followed by mounting and copulation.
The gestational period is around 440 to 450 days long, following which usually a single calf is born, weighing . The udder of the pregnant female starts swelling two months before parturition, and vulval discharges may occur. Parturition takes 3–4 hours, and the female stands throughout this period, though she may rest during brief intervals. The mother consumes the afterbirth, and extensively grooms the infant. The milk of the female is very rich in proteins and has low fat content. As in other ruminants, the infant can stand within 30 minutes of birth. Although generally similar to adults, newborn calves have false eyelashes, a long dorsal mane and long white hairs in the stripes. These features gradually disappear and give way to the general appearance within a year. The juveniles are kept in hiding, and nursing takes place infrequently. The growth rate of calves is appreciably high in the first few months of birth, after which it gradually declines. Juveniles start taking solid food from three months, and weaning takes place at six months. Horn development in males takes one year after birth. The okapi's average lifespan is 20 to 30 years.
Habitat and distribution.
Okapis inhabit canopy forests at altitudes of . They are endemic to the tropical forests of the Democratic Republic of the Congo. They do not occur in gallery forests, habitats disturbed by human settlement and swamp forests, but may occasionally use seasonally inundated areas. In the wet season, they visit rocky inselbergs that offer forage uncommon elsewhere. A study found that the population density of the okapi averaged 0.53 animals per square kilometre in mixed "Cynometera" forests.
The okapi occurs across central, northern and eastern Democratic Republic of the Congo, and north and east of the Congo river. The species ranges from the Maiko forest northward to the Ituri forest, then through the river basins of the Rubi, Lake Tele and Ebola to the west and the Ubangi river further north. Smaller populations exist west and south of the Congo river. They are also common in the Wamba and Epulu areas. The okapi is extinct in Uganda.
Threats and conservation.
The International Union for the Conservation of Nature and Natural Resources (IUCN) classifies the okapi as Endangered. It is fully protected under Congolese law. The Okapi Wildlife Reserve and Maiko National Park support significant populations of the okapi, though there has been a steady decline in numbers due to several threats. Other areas of occurrence are the Rubi Tele Hunting Reserve and the Abumombanzi Reserve. Major threats include habitat loss due to logging and human settlement. Extensive hunting for bushmeat and skin and illegal mining have also led to population declines. A threat that has emerged quite recently is the presence of illegal armed groups around protected areas, inhibiting conservation and monitoring actions. A small population occurs north of the Virunga National Park, but is bereft of protection due to the presence of armed groups in the vicinity. In June 2012, a gang of poachers attacked the headquarters of the Okapi Wildlife Reserve, killing six guards and other staff as well as 13 of the captive okapi.
The Okapi Conservation Project, established in 1987, works towards the conservation of the okapi as well as the growth of the indigenous Mbuti people. In November 2011, the White Oak Conservation center and Jacksonville Zoo and Gardens hosted an international meeting of the Okapi Species Survival Plan (SSP) and the Okapi European Endangered Species Programme (EEP) at Jacksonville, which was attended by representatives from zoos from the USA, Europe and Japan. The aim was to discuss the management of captive okapis and arrange support for okapi conservation. Many zoos in North America and Europe currently have okapis in captivity.

</doc>
<doc id="22710" url="https://en.wikipedia.org/wiki?curid=22710" title="Ovary">
Ovary

The ovary (From , literally "egg" or "nut") is an ovum-producing reproductive organ, often found in pairs at the lower back of the female as part of the vertebrate female reproductive system. Birds have only one functional ovary (left), while the other remains vestigial. Ovaries in female are analogous to testes in male, in that they are both gonads and endocrine glands. Although ovaries occur in a wide variety of animals, both vertebrate and invertebrate, this article is primarily about human ovaries.
Structure.
In the case of human ovaries, each one is whitish in color and located alongside the lateral wall of the uterus in a region called the ovarian fossa. The fossa usually lies beneath the external iliac artery and in front of the ureter and the internal iliac artery. It is about 4 cm x 3 cm x 2 cm in size.
Usually, ovulation occurs in one of the two ovaries (at random) releasing a fertilizable egg each menstrual cycle; however, if there was a case where one ovary was absent or dysfunctional then the other ovary would continue providing eggs to be released without any changes in cycle length or frequency. 
Ligaments.
In humans the paired ovaries lie within the pelvic cavity, on either side of the uterus, to which they are attached via a fibrous cord called the ovarian ligament. The ovaries are uncovered in the peritoneal cavity but are tethered to the body wall via the suspensory ligament of the ovary. The part of the broad ligament of the uterus that covers the ovary is known as the mesovarium. The ovary is thus considered an intraperitoneal organ.
Extremities.
There are two extremities to the ovary:
Histology.
The ovary also contains blood vessels and lymphatics.
Function.
Gamete production.
The ovaries are the site of production and periodical release of egg cells, the female gametes. In the ovaries, the developing egg cell (or oocyte) grows within the environment provided by follicles. Follicles are composed of different types and number of cells according to the stage of their maturation, and their size is indicative of the stage of oocyte development.
When the oocyte finishes its maturation in the ovary, a surge of luteinizing hormone secreted by the pituitary gland stimulates the release of the oocyte through the rupture of the follicle, a process called ovulation. The follicle remains functional and reorganizes into a corpus luteum, which secretes progesterone in order to prepare the uterus for an eventual implantation of the embryo.
Endocrine function.
Ovaries secrete estrogen, testosterone and progesterone. In women, fifty percent of testosterone is produced by the ovaries and adrenal glands and released directly into the blood stream. Estrogen is responsible for the appearance of secondary sex characteristics for females at puberty and for the maturation and maintenance of the reproductive organs in their mature functional state. Progesterone prepares the uterus for pregnancy, and the mammary glands for lactation. Progesterone functions with estrogen by promoting menstrual cycle changes in the endometrium.
Ovarian aging.
As women age, they experience a decline in reproductive performance leading to menopause. This decline is tied to a decline in the number of ovarian follicles. Although about 1 million oocytes are present at birth in the human ovary, only about 500 (about 0.05%) of these ovulate, and the rest are wasted. The decline in ovarian reserve appears to occur at a constantly increasing rate with age, and leads to nearly complete exhaustion of the reserve by about age 52. As ovarian reserve and fertility decline with age, there is also a parallel increase in pregnancy failure and meiotic errors resulting in chromosomally abnormal conceptions.
Women with an inherited mutation in the DNA repair gene BRCA1 undergo menopause prematurely, suggesting that naturally occurring DNA damages in oocytes are repaired less efficiently in these women, and this inefficiency leads to early reproductive failure. The BRCA1 protein plays a key role in a type of DNA repair termed homologous recombinational repair that is the only known cellular process that can accurately repair DNA double-strand breaks. Titus et al. showed that DNA double-strand breaks accumulate with age in humans and mice in primordial follicles. Primodial follicles contain oocytes that are at an intermediate (prophase I) stage of meiosis. Meiosis is the general process in eukaryotic organisms by which germ cells are formed, and it is likely an adaptation for removing DNA damages, especially double-strand breaks, from germ line DNA. (see Meiosis and Origin and function of meiosis). Homologous recombinational repair is especially promoted during meiosis. Titus et al. also found that expression of 4 key genes necessary for homologous recombinational repair of DNA double-strand breaks (BRCA1, MRE11, RAD51 and ATM) decline with age in the oocytes of humans and mice. They hypothesized that DNA double-strand break repair is vital for the maintenance of oocyte reserve and that a decline in efficiency of repair with age plays a key role in ovarian aging.
Clinical significance.
Ovarian diseases can be classified as endocrine disorders or as a disorders of the reproductive system.
If the egg fails to release from the follicle in the ovary an ovarian cyst may form. Small ovarian cysts are common in healthy women. Some women have more follicles than usual (polycystic ovary syndrome), which inhibits the follicles to grow normally and this will cause cycle irregularities.
Other conditions include:
Society and culture.
Cryopreservation.
Cryopreservation of ovarian tissue, often called "ovarian tissue cryopreservation", is of interest to women who want to preserve their reproductive function beyond the natural limit, or whose reproductive potential is threatened by cancer therapy, for example in hematologic malignancies or breast cancer. The procedure is to take a part of the ovary and carry out slow freezing before storing it in liquid nitrogen whilst therapy is undertaken. Tissue can then be thawed and implanted near the fallopian, either orthotopic (on the natural location) or heterotopic (on the abdominal wall), where it starts to produce new eggs, allowing normal conception to take place. A study of 60 procedures concluded that ovarian tissue harvesting appears to be safe. The ovarian tissue may also be transplanted into mice that are immunocompromised (SCID mice) to avoid graft rejection, and tissue can be harvested later when mature follicles have developed.
Other animals.
Ovaries of some kind are found in the female reproductive system of many animals that employ sexual reproduction, including invertebrates. However, they develop in a very different way in most invertebrates than they do in vertebrates, and are not truly homologous.
Many of the features found in human ovaries are common to all vertebrates, including the presence of follicular cells, tunica albuginea, and so on. However, many species produce a far greater number of eggs during their lifetime than do humans, so that, in fish and amphibians, there may be hundreds, or even millions of fertile eggs present in the ovary at any given time. In these species, fresh eggs may be developing from the germinal epithelium throughout life. Corpora lutea are found only in mammals, and in some elasmobranch fish; in other species, the remnants of the follicle are quickly resorbed by the ovary. In birds, reptiles, and monotremes, the egg is relatively large, filling the follicle, and distorting the shape of the ovary at maturity.
Amphibians and reptiles have no ovarian medulla; the central part of the ovary is a hollow, lymph-filled space.
The ovary of teleosts is also often hollow, but in this case, the eggs are shed into the cavity, which opens into the oviduct. Certain nematodes of the genus "Philometra" are parasitic in the ovary of marine fishes and can be spectacular, with females as long as 40 cm, coiled in the ovary of a fish half this length. These nematodes never parasitize humans.
Although most normal female vertebrates have two ovaries, this is not the case in all species. In most birds and in platypuses, the right ovary never matures, so that only the left is functional. (Exceptions include the Kiwi and some, but not all raptors, in which both ovaries persist.) In some elasmobranchs, only the right ovary develops fully. In the primitive jawless fish, and some teleosts, there is only one ovary, formed by the fusion of the paired organs in the embryo.

</doc>
<doc id="22713" url="https://en.wikipedia.org/wiki?curid=22713" title="Opium">
Opium

Opium (poppy tears, "lachryma papaveris") is the dried latex obtained from the opium poppy ("Papaver somniferum"). Opium latex contains approximately 12% of the analgesic alkaloid morphine, which is processed chemically to produce heroin and other synthetic opioids for medicinal use and for the illegal drug trade. The latex also contains the closely related opiates codeine and thebaine and non-analgesic alkaloids such as papaverine and noscapine. The traditional, labor-intensive method of obtaining the latex is to scratch ("score") the immature seed pods (fruits) by hand; the latex leaks out and dries to a sticky yellowish residue that is later scraped off, and dehydrated. The word "meconium" (derived from the Greek for "opium-like", but now used to refer to infant stools) historically referred to related, weaker preparations made from other parts of the opium poppy or different species of poppies.
The production of opium itself has not changed since ancient times. Through selective breeding of the "Papaver somniferum" plant, the content of the phenanthrene alkaloids morphine, codeine, and to a lesser extent thebaine, has been greatly increased. In modern times, much of the thebaine, which often serves as the raw material for the synthesis for hydrocodone, hydromorphone, and other semisynthetic opiates, originates from extracting "Papaver orientale" or "Papaver bracteatum".
Opium for illegal use is often converted into heroin, which is less bulky, making it easier to smuggle, and which multiplies its potency to approximately twice that of morphine.
History.
Cultivation of opium poppies for food, anaesthetics, and ritual purposes dates back to at least the Neolithic Age (new stone age). The Sumerian, Assyrian, Egyptian, Indian, Minoan, Greek, Roman, Persian and Arab Empires all made widespread use of opium, which was the most potent form of pain relief then available, allowing ancient surgeons to perform prolonged surgical procedures. Opium is mentioned in the most important medical texts of the ancient world, including the Ebers Papyrus and the writings of Dioscorides, Galen, and Avicenna. Widespread medical use of unprocessed opium continued through the American Civil War before giving way to morphine and its successors, which could be injected at a precisely controlled dosage.
In China, recreational use began in the 15th century, but was limited by its rarity and expense. Opium trade became more regular by the 17th century, when it was mixed with tobacco for smoking, and addiction was first recognized. Prior to the arrival of the tobacco pipe, opium was only taken orally; when smoked, the drug has a far more potent effect, and its addictive effect is greatly magnified. Opium prohibition in China began in 1729, yet was followed by nearly two centuries of increasing opium use. China had a positive balance sheet in trading with the British, which led to a decrease of the British silver stocks. Therefore, the British tried to encourage Chinese opium use to enhance their balance, and they delivered it from Indian provinces under British control. In India, its cultivation, as well as the manufacture and traffic to China, were subject to the British East India Company (BEIC), as a strict monopoly of the British government. There was an extensive and complicated system of BEIC agencies involved in the supervision and management of opium production and distribution in India. A massive destruction of opium by an emissary of the Chinese Daoguang Emperor in an attempt to stop opium imports, led to the First Opium War (18391842), in which Britain defeated China. After 1860, opium use continued to increase with widespread domestic production in China. By 1905, an estimated 25% of the male population were regular consumers of the drug. Recreational use of opium elsewhere in the world remained rare into late in the 19th century, as indicated by ambivalent reports of opium usage.
Global regulation of opium began with the stigmatization of Chinese immigrants and opium dens in San Francisco, California, leading rapidly from town ordinances in the 1870s to the formation of the International Opium Commission in 1909. During this period, the portrayal of opium in literature became squalid and violent, British opium trade was largely supplanted by domestic Chinese production, purified morphine and heroin became widely available for injection, and patent medicines containing opiates reached a peak of popularity. Opium was prohibited in many countries during the early 20th century, leading to the modern pattern of opium production as a precursor for illegal recreational drugs or tightly regulated legal prescription drugs. Illicit opium production, now dominated by Afghanistan, was decimated in 2000, when production was banned by the Taliban, but has increased steadily since the fall of the Taliban in 2001 and over the course of the war in Afghanistan. Worldwide production in 2006 was 6610 metric tons—about one-fifth the level of production in 1906.
Ancient use.
Opium has been actively collected since prehistoric times, and may be the soma plant ubiquitously mentioned in the Rig Veda. Though western scholars typically date the text at 1500 BCE, Indian scholars maintain that the verses and the history contained in them have been orally transmitted thousands of years before. "Soma" is Vedic Sanskrit for moon, describing both the shape of the bulb and its nocturnal juice emission, which in ancient times would have been visible by moonlight only. A common name for males in Afghanistan is "Redey", which in Pashto means "poppy". This term may be derived from the Sanskrit words "rddhi" and "hrdya", which mean "magical", "a type of medicinal plant", and "heart-pleasing", respectively. The upper South Asian belt of Afghanistan, Pakistan, northern India, and Burma still account for the world's largest supply of opium.
At least 17 finds of "Papaver somniferum" from Neolithic settlements have been reported throughout Switzerland, Germany, and Spain, including the placement of large numbers of poppy seed capsules at a burial site (the "Cueva de los Murciélagos", or "Bat Cave", in Spain), which have been carbon-14 dated to 4200 BCE. Numerous finds of "P. somniferum" or "P. setigerum" from Bronze Age and Iron Age settlements have also been reported.
The first known cultivation of opium poppies was in Mesopotamia, approximately 3400 BCE, by Sumerians, who called the plant "hul gil", the "joy plant". Tablets found at Nippur, a Sumerian spiritual center south of Baghdad, described the collection of poppy juice in the morning and its use in production of opium. Cultivation continued in the Middle East by the Assyrians, who also collected poppy juice in the morning after scoring the pods with an iron scoop; they called the juice "aratpa-pal", possibly the root of "Papaver". Opium production continued under the Babylonians and Egyptians.
Opium was used with poison hemlock to put people quickly and painlessly to death, but it was also used in medicine. The Ebers Papyrus, "circa" 1500 BCE, describes a way to "stop a crying child" using grains of the poppy plant strained to a pulp. "Spongia somnifera", sponges soaked in opium, were used during surgery. The Egyptians cultivated "opium thebaicum" in famous poppy fields around 1300 BCE. Opium was traded from Egypt by the Phoenicians and Minoans to destinations around the Mediterranean Sea, including Greece, Carthage, and Europe. By 1100 BCE, opium was cultivated on Cyprus, where surgical-quality knives were used to score the poppy pods, and opium was cultivated, traded, and smoked. Opium was also mentioned after the Persian conquest of Assyria and Babylonian lands in the 6th century BCE.
From the earliest finds, opium has appeared to have ritual significance, and anthropologists have speculated ancient priests may have used the drug as a proof of healing power. In Egypt, the use of opium was generally restricted to priests, magicians, and warriors, its invention is credited to Thoth, and it was said to have been given by Isis to Ra as treatment for a headache. A figure of the Minoan "goddess of the narcotics", wearing a crown of three opium poppies, "circa" 1300 BCE, was recovered from the Sanctuary of Gazi, Crete, together with a simple smoking apparatus. The Greek gods Hypnos (Sleep), Nyx (Night), and Thanatos (Death) were depicted wreathed in poppies or holding them. Poppies also frequently adorned statues of Apollo, Asklepios, Pluto, Demeter, Aphrodite, Kybele and Isis, symbolizing nocturnal oblivion.
Islamic societies (500–1500 AD).
As the power of the Roman Empire declined, the lands to the south, and east of the Mediterranean Sea became incorporated into the Islamic Empires. Some Muslims believe "hadiths", such as in "Sahih Bukhari", prohibits every intoxicating substance, though the use of intoxicants in medicine has been widely permitted by scholars. Dioscorides' five-volume "De Materia Medica", the precursor of pharmacopoeias, remained in use (with some improvements in Arabic versions) from the 1st to 16th centuries, and described opium and the wide range of its uses prevalent in the ancient world.
Between 400 and 1200 AD, Arab traders introduced opium to China. The Persian physician Muhammad ibn Zakariya al-Razi ("Rhazes", 845–930 AD) maintained a laboratory and school in Baghdad, and was a student and critic of Galen; he made use of opium in anesthesia and recommended its use for the treatment of melancholy in "Fi ma-la-yahdara al-tabib", "In the Absence of a Physician", a home medical manual directed toward ordinary citizens for self-treatment if a doctor was not available.
The renowned Andalusian ophthalmologic surgeon Abu al-Qasim al-Zahrawi ("Abulcasis", 936–1013 AD) relied on opium and mandrake as surgical anaesthetics and wrote a treatise, "al-Tasrif", that influenced medical thought well into the 16th century.
The Persian physician Abū ‘Alī al-Husayn ibn Sina ("Avicenna") described opium as the most powerful of the stupefacients, in comparison to mandrake and other highly effective herbs, in "The Canon of Medicine". The text lists medicinal effects of opium, such as analgesia, hypnosis, antitussive effects, gastrointestinal effects, cognitive effects, respiratory depression, neuromuscular disturbances, and sexual dysfunction. It also refers to opium's potential as a poison. Avicenna describes several methods of delivery and recommendations for doses of the drug. This classic text was translated into Latin in 1175 and later into many other languages and remained authoritative into the 17th century. Şerafeddin Sabuncuoğlu used opium in the 14th-century Ottoman Empire to treat migraine headaches, sciatica, and other painful ailments.
Reintroduction to Western medicine.
Manuscripts of Pseudo-Apuleius's 5th-century work from the 10th and 11th centuries refer to the use of wild poppy "Papaver agreste" or "Papaver rhoeas" (identified as "P. silvaticum") instead of "P. somniferum" for inducing sleep and relieving pain.
The use of Paracelsus' laudanum was introduced to Western medicine in 1527, when Philippus Aureolus Theophrastus Bombastus von Hohenheim, better known by the name Paracelsus, returned from his wanderings in Arabia with a famous sword, within the pommel of which he kept "Stones of Immortality" compounded from opium thebaicum, citrus juice, and "quintessence of gold." The name "Paracelsus" was a pseudonym signifying him the equal or better of Aulus Cornelius Celsus, whose text, which described the use of opium or a similar preparation, had recently been translated and reintroduced to medieval Europe. "The Canon of Medicine", the standard medical textbook Paracelsus burned in a public bonfire three weeks after being appointed professor at the University of Basel, also described the use of opium, though many Latin translations were of poor quality. "Laudanum" was originally the 16th-century term for a medicine associated with a particular physician that was widely well-regarded, but became standardized as "tincture of opium", a solution of opium in ethanol, which Paracelsus has been credited with developing. During his lifetime, Paracelsus was viewed as an adventurer who challenged the theories and mercenary motives of contemporary medicine with dangerous chemical therapies, but his therapies marked a turning point in Western medicine. In the 17th century, laudanum was recommended for pain, sleeplessness, and diarrhea by Thomas Sydenham, the renowned "father of English medicine" or "English Hippocrates", to whom is attributed the quote, "Among the remedies which it has pleased Almighty God to give to man to relieve his sufferings, none is so universal and so efficacious as opium."
Use of opium as a cure-all was reflected in the formulation of mithridatium described in the 1728 "Chambers Cyclopedia", which included true opium in the mixture. Subsequently, laudanum became the basis of many popular patent medicines of the 19th century.
During the 18th century, opium was found to be a good remedy for nervous disorders. Due to its sedative and tranquilizing properties, it was used to quiet the minds of those with psychosis, help with people who were considered insane, and also to help treat patients with insomnia. However, despite its medicinal values in these cases, it was noted that in cases of psychosis, it could cause anger or depression, and due to the drug's euphoric effects, it could cause depressed patients to become more depressed after the effects wore off because they would get used to being high.
The standard medical use of opium persisted well into the 19th century. US president William Henry Harrison was treated with opium in 1841, and in the American Civil War, the Union Army used 2.8 million ounces of opium tincture and powder and about 500,000 opium pills. During this time of popularity, users called opium "God's Own Medicine."
Recreational use in Europe, the Middle East and the US (15th to 19th centuries).
Opium is said to have been used for recreational purposes from the 14th century onwards in Muslim societies. Testimonies of historians, diplomats, religious scholars, intellectuals and travellers, Ottoman and European, confirm, from the 16th to the 19th centuries, Anatolian opium was eaten in Constantinople as much as it was exported to Europe. In 1573, for instance, a Venetian visitor to the Ottoman Empire observed many of the Turkish natives of Constantinople regularly drank a "certain black water made with opium" that makes them feel good, but to which they become so addicted, if they try to go without, they will "quickly die". From eating it, dervishes were said to draw ecstasy, soldiers courage, and others bliss and voluptuousness. Indeed, Turkey supplied the West with opium long before China. In his "Confessions of an English Opium-Eater" (1821, p. 188), it is Ottoman, not Chinese, addicts about whom Thomas de Quincey writes: "I question whether any Turk, of all that ever entered the paradise of opium-eaters, can have had half the pleasure I had."
Extensive textual and pictorial sources also show that poppy cultivation and opium consumption were widespread in Safavid Iran and Mughal India.
The most important reason for the increase in opiate consumption in the United States during the 19th century was the prescribing and dispensing of legal opiates by physicians and pharmacists to women with "female problems" (mostly to relieve menstrual pain). Between 150,000 and 200,000 opiate addicts lived in the United States in the late 19th century and between two-thirds and three-quarters of these addicts were women.
Recreational use in China.
The earliest clear description of the use of opium as a recreational drug in China came from Xu Boling, who wrote in 1483 that opium was "mainly used to aid masculinity, strengthen sperm and regain vigor", and that it "enhances the art of alchemists, sex and court ladies". He also described an expedition sent by the Ming dynasty Chenghua Emperor in 1483 to procure opium for a price "equal to that of gold" in Hainan, Fujian, Zhejiang, Sichuan and Shaanxi, where it is close to the western lands of Xiyu. A century later, Li Shizhen listed standard medical uses of opium in his renowned "Compendium of Materia Medica" (1578), but also wrote that "lay people use it for the art of sex", in particular the ability to "arrest seminal emission". This association of opium with sex continued in China until the end of the 19th century.
Opium smoking began as a privilege of the elite and remained a great luxury into the early 19th century. However, by 1861, Wang Tao wrote that opium was used even by rich peasants, and even a small village without a rice store would have a shop where opium was sold.
Smoking of opium came on the heels of tobacco smoking and may have been encouraged by a brief ban on the smoking of tobacco by the Ming emperor. The prohibition ended in 1644 with the coming of the Qing dynasty, which encouraged smokers to mix in increasing amounts of opium. In 1705, Wang Shizhen wrote, "nowadays, from nobility and gentlemen down to slaves and women, all are addicted to tobacco." Tobacco in that time was frequently mixed with other herbs (this continues with clove cigarettes to the modern day), and opium was one component in the mixture. Tobacco mixed with opium was called "madak" (or "madat") and became popular throughout China and its seafaring trade partners (such as Taiwan, Java, and the Philippines) in the 17th century. In 1712, Engelbert Kaempfer described addiction to "madak": "No commodity throughout the Indies is retailed with greater profit by the Batavians than opium, which [its] users cannot do without, nor can they come by it except it be brought by the ships of the Batavians from Bengal and Coromandel."
Fueled in part by the 1729 ban on "madak", which at first effectively exempted pure opium as a potentially medicinal product, the smoking of pure opium became more popular in the 18th century. In 1736, the smoking of pure opium was described by Huang Shujing, involving a pipe made from bamboo rimmed with silver, stuffed with palm slices and hair, fed by a clay bowl in which a globule of molten opium was held over the flame of an oil lamp. This elaborate procedure, requiring the maintenance of pots of opium at just the right temperature for a globule to be scooped up with a needle-like skewer for smoking, formed the basis of a craft of "paste-scooping" by which servant girls could become prostitutes as the opportunity arose.
Chinese diaspora.
Beginning in 19th-century China, famine and political upheaval, as well as rumors of wealth to be had in nearby Southeast Asia, led to the Chinese Diaspora. Chinese emigrants to cities such as San Francisco, London, and New York brought with them the Chinese manner of opium smoking and the social traditions of the opium den. The Indian Diaspora distributed opium-eaters in the same way, and both social groups survived as "lascars" (seamen) and "coolies" (manual laborers). French sailors provided another major group of opium smokers, having contracted the habit in French Indochina, where the drug was promoted by the colonial government as a monopoly and source of revenue. Among white Europeans, opium was more frequently consumed as laudanum or in patent medicines. Britain's All-India Opium Act of 1878 formalized social distinctions, limiting recreational opium sales to registered Indian opium-eaters and Chinese opium-smokers and prohibiting its sale to workers from Burma. Likewise, American law sought to contain addiction to immigrants by prohibiting Chinese from smoking opium in the presence of a white man.
Because of the low social status of immigrant workers, contemporary writers and media had little trouble portraying opium dens as seats of vice, white slavery, gambling, knife- and revolver-fights, a source for drugs causing deadly overdoses, with the potential to addict and corrupt the white population. By 1919, anti-Chinese riots attacked Limehouse, the Chinatown of London. Chinese men were deported for playing keno and sentenced to hard labor for opium possession. Both the immigrant population and the social use of opium fell into decline. Yet despite lurid literary accounts to the contrary, 19th-century London was not a hotbed of opium smoking. The total lack of photographic evidence of opium smoking in Britain, as opposed to the relative abundance of historical photos depicting opium smoking in North America and France, indicates the infamous Limehouse opium-smoking scene was little more than fantasy on the part of British writers of the day, who were intent on scandalizing their readers while drumming up the threat of the "yellow peril".
Prohibition and conflict in China.
Opium prohibition began in 1729, when the Qing Yongzheng Emperor disturbed by "madak" smoking at court and carrying out the government's role of upholding Confucian virtues, officially prohibited the sale of opium, except for a small amount for medicinal purposes. The ban punished sellers and opium den keepers, but not users of the drug. Opium was banned completely in 1799, and this prohibition continued until 1860.
During the Qing dynasty, China opened itself to foreign trade under the Canton System through the port of Guangzhou (Canton), with traders from the East India Company visiting the port by the 1690s. Due to the growing British demand for Indian tea and the Chinese Emperor's lack of interest in British commodities other than silver, British traders resorted to trade in opium as a high-value commodity for which China was not self-sufficient. The English traders had been purchasing small amounts of opium from India for trade since Ralph Fitch first visited in the mid-16th century. Trade in opium was standardized, with production of balls of raw opium, 1.1 to 1.6 kilograms, 30% water content, wrapped in poppy leaves and petals, and shipped in chests of 60–65 kilograms (one picul).
Chests of opium were sold in auctions in Calcutta with the understanding that the independent purchasers would then smuggle it into China.
After the 1757 Battle of Plassey and 1764 Battle of Buxar, the British East India Company gained the power to act as "diwan" of Bengal, Bihar, and Odisha "(See company rule in India)". This allowed the company to exercise a monopoly over opium production and export in India, to encourage ryots to cultivate the cash crops of indigo and opium with cash advances, and to prohibit the "hoarding" of rice. This strategy led to the increase of the land tax to 50% of the value of crops and to the doubling of East India Company profits by 1777. It is also claimed to have contributed to the starvation of 10 million people in the Bengal famine of 1770. Beginning in 1773, the British government began enacting oversight of the company's operations, and in response to the Indian Rebellion of 1857, this policy culminated in the establishment of direct rule over the presidencies and provinces of British India. Bengal opium was highly prized, commanding twice the price of the domestic Chinese product, which was regarded as inferior in quality.
Some competition came from the newly independent United States, which began to compete in Guangzhou, selling Turkish opium in the 1820s. Portuguese traders also brought opium from the independent Malwa states of western India, although by 1820, the British were able to restrict this trade by charging "pass duty" on the opium when it was forced to pass through Bombay to reach an "entrepot".
Despite drastic penalties and continued prohibition of opium until 1860, opium importation rose steadily from 200 chests per year under the Yongzheng Emperor to 1,000 under the Qianlong Emperor, 4,000 under the Jiaqing Emperor, and 30,000 under the Daoguang Emperor. The illegal sale of opium became one of the world's most valuable single commodity trades and has been called "the most long continued and systematic international crime of modern times". Opium smuggling provided 15 to 20% of the British Empire's revenue and simultaneously caused scarcity of silver in China.
In response to the ever-growing number of Chinese people becoming addicted to opium, the Qing Daoguang Emperor took strong action to halt the import of opium, including the seizure of cargo. In 1838, the Chinese Commissioner Lin Zexu destroyed 20,000 chests of opium in Guangzhou. Given that a chest of opium was worth nearly $1,000 in 1800, this was a substantial economic loss. The British queen Victoria, not willing to replace the cheap opium with costly silver, began the First Opium War in 1840, the British winning Hong Kong and trade concessions in the first of a series of Unequal Treaties.
The opium trade incurred intense enmity from the later British Prime Minister William Ewart Gladstone. As a member of Parliament, Gladstone called it "most infamous and atrocious" referring to the opium trade between China and British India in particular. Gladstone was fiercely against both of the Opium Wars Britain waged in China in the First Opium War initiated in 1840 and the Second Opium War initiated in 1857, denounced British violence against Chinese, and was ardently opposed to the British trade in opium to China. Gladstone lambasted it as "Palmerston's Opium War" and said that he felt "in dread of the judgments of God upon England for our national iniquity towards China" in May 1840. A famous speech was made by Gladstone in Parliament against the First Opium War. Gladstone criticized it as "a war more unjust in its origin, a war more calculated in its progress to cover this country with permanent disgrace,". His hostility to opium stemmed from the effects of opium brought upon his sister Helen. Due to the First Opium war brought on by Palmerston, there was initial reluctance to join the government of Peel on part of Gladstone before 1841.
Following China's defeat in the Second Opium War in 1858, China was forced to legalize opium and began massive domestic production. Importation of opium peaked in 1879 at 6,700 tons, and by 1906, China was producing 85% of the world's opium, some 35,000 tons, and 27% of its adult male population regularly used opium —13.5 million people consuming 39,000 tons of opium yearly. From 1880 to the beginning of the Communist era, the British attempted to discourage the use of opium in China, but this effectively promoted the use of morphine, heroin, and cocaine, further exacerbating the problem of addiction.
Scientific evidence of the pernicious nature of opium use was largely undocumented in the 1890s, when Protestant missionaries in China decided to strengthen their opposition to the trade by compiling data which would demonstrate the harm the drug did. Faced with the problem that many Chinese associated Christianity with opium, partly due to the arrival of early Protestant missionaries on opium clippers, at the 1890 Shanghai Missionary Conference, they agreed to establish the Permanent Committee for the Promotion of Anti-Opium Societies in an attempt to overcome this problem and to arouse public opinion against the opium trade. The members of the committee were John Glasgow Kerr, MD, American Presbyterian Mission in Canton; B.C. Atterbury, MD, American Presbyterian Mission in Peking; Archdeacon Arthur E. Moule, Church Missionary Society in Shanghai; Henry Whitney, MD, American Board of Commissioners for foreign Missions in Foochow; the Rev. Samuel Clarke, China Inland Mission in Kweiyang; the Rev. Arthur Gostick Shorrock, English Baptist Mission in Taiyuan; and the Rev. Griffith John, London Mission Society in Hankow. These missionaries were generally outraged over the British government's Royal Commission on Opium visiting India but not China. Accordingly, the missionaries first organized the Anti-Opium League in China among their colleagues in every mission station in China. American missionary Hampden Coit DuBose acted as first president. This organization, which had elected national officers and held an annual national meeting, was instrumental in gathering data from every Western-trained medical doctor in China, which was then published as William Hector Park compiled "Opinions of Over 100 Physicians on the Use of Opium in China" (Shanghai: American Presbyterian Mission Press, 1899). The vast majority of these medical doctors were missionaries; the survey also included doctors who were in private practices, particularly in Shanghai and Hong Kong, as well as Chinese who had been trained in medical schools in Western countries. In England, the home director of the China Inland Mission, Benjamin Broomhall, was an active opponent of the opium trade, writing two books to promote the banning of opium smoking: "The Truth about Opium Smoking" and "The Chinese Opium Smoker". In 1888, Broomhall formed and became secretary of the Christian Union for the Severance of the British Empire with the Opium Traffic and editor of its periodical, "National Righteousness". He lobbied the British Parliament to stop the opium trade. He and James Laidlaw Maxwell appealed to the London Missionary Conference of 1888 and the Edinburgh Missionary Conference of 1910 to condemn the continuation of the trade. When Broomhall was dying, his son Marshall read to him from "The Times" the welcome news that an agreement had been signed ensuring the end of the opium trade within two years.
Official Chinese resistance to opium was renewed on September 20, 1906, with an antiopium initiative intended to eliminate the drug problem within 10 years. The program relied on the turning of public sentiment against opium, with mass meetings at which opium paraphernalia were publicly burned, as well as coercive legal action and the granting of police powers to organizations such as the Fujian Anti-Opium Society. Smokers were required to register for licenses for gradually reducing rations of the drug. Action against opium farmers centred upon a highly repressive incarnation of law enforcement in which rural populations had their property destroyed, their land confiscated and/or were publically tortured, humiliated and executed. Addicts sometimes turned to missionaries for treatment for their addiction, though many associated these foreigners with the drug trade. The program was counted as a substantial success, with a cessation of direct British opium exports to China (but not Hong Kong) and most provinces declared free of opium production. Nonetheless, the success of the program was only temporary, with opium use rapidly increasing during the disorder following the death of Yuan Shikai in 1916. Opium farming also increased after the death of Yuan Shikai, peaking in 1930 when the League of Nations singled China out as the primary source of illicit opium in East and Southeast Asia. Many local powerholders facilitated the trade during this period to finance conflicts over territory and political campaigns. In some areas food crops were eradicated to make way for opium, contributing to famines in Kweichow and Shensi Provinces between 1921 and 1923, and food deficits in other provinces .
Beginning in 1915, Chinese nationalist groups came to describe the period of military losses and Unequal Treaties as the "Century of National Humiliation", later defined to end with the conclusion of the Chinese Civil War in 1949.
In the northern provinces of Ningxia and Suiyuan in China, Chinese Muslim General Ma Fuxiang both prohibited and engaged in the opium trade. It was hoped that Ma Fuxiang would have improved the situation, since Chinese Muslims were well known for opposition to smoking opium. Ma Fuxiang officially prohibited opium and made it illegal in Ningxia, but the Guominjun reversed his policy; by 1933, people from every level of society were abusing the drug, and Ningxia was left in destitution. In 1923, an officer of the Bank of China from Baotou found out that Ma Fuxiang was assisting the drug trade in opium which helped finance his military expenses. He earned $2 million from taxing those sales in 1923. General Ma had been using the bank, a branch of the Government of China's exchequer, to arrange for silver currency to be transported to Baotou to use it to sponsor the trade.
The opium trade under the Chinese Communist Party was important to its finances in the 1940s. Peter Vladimirov's diary provided a first hand account. Chen Yung-Fa provided a detailed historical account of how the opium trade was essential to the economy of Yan'an during this period. Mitsubishi and Mitsui were involved in the opium trade during the Japanese occupation of China.
The Mao Zedong government is generally credited with eradicating both consumption and production of opium during the 1950s using unrestrained repression and social reform. Ten million addicts were forced into compulsory treatment, dealers were executed, and opium-producing regions were planted with new crops. Remaining opium production shifted south of the Chinese border into the Golden Triangle region. The remnant opium trade primarily served Southeast Asia, but spread to American soldiers during the Vietnam War, with 20% of soldiers regarding themselves as addicted during the peak of the epidemic in 1971. In 2003, China was estimated to have four million regular drug users and one million registered drug addicts.
Prohibition outside China.
There were no legal restrictions on the importation or use of opium in the United States until the San Francisco Opium Den Ordinance, which banned dens for public smoking of opium in 1875, a measure fueled by anti-Chinese sentiment and the perception that whites were starting to frequent the dens. This was followed by an 1891 California law requiring that narcotics carry warning labels and that their sales be recorded in a registry; amendments to the California Pharmacy and Poison Act in 1907 made it a crime to sell opiates without a prescription, and bans on possession of opium or opium pipes in 1909 were enacted.
At the US federal level, the legal actions taken reflected constitutional restrictions under the enumerated powers doctrine prior to reinterpretation of the commerce clause, which did not allow the federal government to enact arbitrary prohibitions, but did permit arbitrary taxation. Beginning in 1883, opium importation was taxed at $6 to $300 per pound, until the Opium Exclusion Act of 1909 prohibited the importation of opium altogether. In a similar manner, the Harrison Narcotics Tax Act of 1914, passed in fulfillment of the International Opium Convention of 1912, nominally placed a tax on the distribution of opiates, but served as a "de facto" prohibition of the drugs. Today, opium is regulated by the Drug Enforcement Administration under the Controlled Substances Act.
Following passage of a Colonial Australian law in 1895, Queensland's Aboriginals Protection and Restriction of the Sale of Opium Act 1897 addressed opium addiction among Aboriginal people, though it soon became a general vehicle for depriving them of basic rights by administrative regulation. By 1905 all Australian states and territories had passed similar laws making prohibitions to Opium sale. Smoking and possession was prohibited in 1908.
Hardening of Canadian attitudes toward Chinese opium users and fear of a spread of the drug into the white population led to the effective criminalization of opium for nonmedical use in Canada between 1908 and the mid-1920s.
In 1909, the International Opium Commission was founded, and by 1914, 34 nations had agreed that the production and importation of opium should be diminished. In 1924, 62 nations participated in a meeting of the Commission. Subsequently, this role passed to the League of Nations, and all signatory nations agreed to prohibit the import, sale, distribution, export, and use of all narcotic drugs, except for medical and scientific purposes. This role was later taken up by the International Narcotics Control Board of the United Nations under of the Single Convention on Narcotic Drugs, and subsequently under the Convention on Psychotropic Substances. Opium-producing nations are required to designate a government agency to take physical possession of licit opium crops as soon as possible after harvest and conduct all wholesaling and exporting through that agency.
Regulation in Britain and the United States.
Before the 1920s, regulation in Britain was controlled by the pharmacists. Pharmacists that were found to have prescribed opium for illegitimate causes and anyone found to have sold opium without proper qualifications would be prosecuted. Due to the passing of the Rolleston Act in Britain in 1926, doctors could prescribe opiates such as morphine and heroin on their own accord based on if they felt that their patients needed it. This Act came about due to the fact that Britain didn’t see people’s addiction as an indulgence, but rather as a medical problem that needed weaning off the drug rather than cutting the patient off altogether. The passing of this act put the control of opium use in the hands of medical doctors instead of pharmacists. However, as the 20th century continued, the addiction to opiates, especially heroin in young people, continued to rise and so the sale and prescription of opiates was limited to doctors in treatment centers and if these doctors were found to be prescribing opiates without just cause, then they could lose their licence to practise or prescribe drugs.
The abuse of opium in the United States began in the late 19th century and was largely stigmatized with Chinese immigrants. During this time the use of opium had little negative connotation and was used freely until 1882 when a law was passed to confine opium smoking to specific dens. Until the full ban on opium based products came into effect just after the turn of the century, physicians in the US considered opium a miracle drug that could help with many ailments. Therefore, the ban on said products was more a result of negative connotations towards its use and distribution by Chinese immigrants who were heavily persecuted during this particular period in history. As the 19th century progressed however, there was a doctor by the name of Hamilton Wright that worked to decrease the use of opium in the US by submitting the Harrison Act to congress. This act put taxes and restrictions on the sale and prescription of opium, as well as trying to stigmatize the opium poppy and its derivatives as "demon drugs," to try and scare people away from them. This act and the stigma of a demon drug on opium, led to the criminalization of people that used opium-based products.
20th century historical use.
During the Communist era in Eastern Europe, poppy stalks sold in bundles by farmers were processed by users with household chemicals to make "kompot" ("Polish heroin"), and poppy seeds were used to produce "koknar", an opiate.
Obsolescence.
Globally, opium has gradually been superseded by a variety of purified, semi-synthetic, and synthetic opioids with progressively stronger effects, and by other general anesthetics. This process began in 1804, when Friedrich Wilhelm Adam Sertürner first isolated morphine from the opium poppy. The process continued until 1817, when Sertürner published the isolation of pure morphine from opium after at least thirteen years of research and a nearly disastrous trial on himself and three boys. The great advantage of purified morphine was that a patient could be treated with a known dose—whereas with raw plant material, as Gabriel Fallopius once lamented, "if soporifics are weak they do not help; if they are strong they are exceedingly dangerous." Morphine was the first pharmaceutical isolated from a natural product, and this success encouraged the isolation of other alkaloids: by 1820, isolations of noscapine, strychnine, veratrine, colchicine, caffeine, and quinine were reported. Morphine sales began in 1827, by Heinrich Emanuel Merck of Darmstadt, and helped him expand his family pharmacy into the Merck KGaA pharmaceutical company.
Codeine was isolated in 1832 by Pierre Jean Robiquet.
The use of diethyl ether and chloroform for general anesthesia began in 1846–1847, and rapidly displaced the use of opiates and tropane alkaloids from Solanaceae due to their relative safety.
Heroin, the first semi-synthetic opioid, was first synthesized in 1874, but was not pursued until its rediscovery in 1897 by Felix Hoffmann at the Bayer pharmaceutical company in Elberfeld, Germany. From 1898 to 1910 heroin was marketed as a non-addictive morphine substitute and cough medicine for children. By 1902, sales made up 5% of the company's profits, and "heroinism" had attracted media attention. Oxycodone, a thebaine derivative similar to codeine, was introduced by Bayer in 1916 and promoted as a less-addictive analgesic. Preparations of the drug such as oxycodone with paracetamol and extended release oxycodone remain popular to this day.
A range of synthetic opioids such as methadone (1937), pethidine (1939), fentanyl (late 1950s), and derivatives thereof have been introduced, and each is preferred for certain specialized applications. Nonetheless, morphine remains the drug of choice for American combat medics, who carry packs of syrettes containing 16 milligrams each for use on severely wounded soldiers. No drug has been found that can match the painkilling effect of opioids without also duplicating much of their addictive potential.
Modern production and usage.
"Papaver somniferum".
Opium poppies ("Papaver somniferum") are popular and attractive garden plants, whose flowers vary greatly in color, size and form. A modest amount of domestic cultivation in private gardens is not usually subject to legal controls. In part, this tolerance reflects variation in addictive potency. A cultivar for opium production, "Papaver somniferum L. elite", contains 91.2% morphine, codeine, and thebaine in its latex alkaloids, whereas in the latex of the condiment cultivar "Marianne", these three alkaloids total only 14.0 %. The remaining alkaloids in the latter cultivar are primarily narcotoline and noscapine.
Seed capsules can be dried and used for decorations, but they also contain morphine, codeine, and other alkaloids. These pods can be boiled in water to produce a bitter tea that induces a long-lasting intoxication "(See Poppy tea)". If allowed to mature, poppy pods (poppy straw) can be crushed and used to produce lower quantities of morphinans. In poppies subjected to mutagenesis and selection on a mass scale, researchers have been able to use poppy straw to obtain large quantities of oripavine, a precursor to opioids and antagonists such as naltrexone. Although millennia older, the production of poppy head decoctions can be seen as a quick and dirty variant of the Kábáy poppy straw process, which since its publication in 1930 has become the major method of obtaining licit opium alkaloids worldwide, as discussed under the Wikipedia Morphine article.
Poppy seeds are a common and flavorsome topping for breads and cakes. One gram of poppy seeds contains up to 33 micrograms of morphine and 14 micrograms of codeine, and the Substance Abuse and Mental Health Services Administration in the United States formerly mandated that all drug screening laboratories use a standard cutoff of 300 nanograms per milliliter in urine samples. A single poppy seed roll (0.76 grams of seeds) usually did not produce a positive drug test, but a positive result was observed from eating two rolls. A slice of poppy seed cake containing nearly five grams of seeds per slice produced positive results for 24 hours. Such results are viewed as false positive indications of drug use and were the basis of a legal defense. On November 30, 1998, the standard cutoff was increased to 2000 nanograms (two micrograms) per milliliter. Confirmation by gas chromatograpy-mass spectrometry will distinguish amongst opium and variants including poppy seeds, heroin, and morphine and codeine pharmaceuticals by measuring the morphine:codeine ratio and looking for the presence of noscapine and acetylcodeine, the latter of which is only found in illicitly produced heroin, and heroin metabolites such as 6-monoacetylmorphine.
Harvesting and processing.
When grown for opium production, the skin of the ripening pods of these poppies is scored by a sharp blade at a time carefully chosen so that rain, wind, and dew cannot spoil the exudation of white, milky latex, usually in the afternoon. Incisions are made while the pods are still raw, with no more than a slight yellow tint, and must be shallow to avoid penetrating hollow inner chambers or "loculi" while cutting into the lactiferous vessels. In Indian Subcontinent, Afghanistan, Central Asia and Iran, the special tool used to make the incisions is called a "nushtar" or "nishtar" (from Persian, meaning a lancet) and carries three or four blades three millimeters apart, which are scored upward along the pod. Incisions are made three or four times at intervals of two to three days, and each time the "poppy tears," which dry to a sticky brown resin, are collected the following morning. One acre harvested in this way can produce three to five kilograms of raw opium. In the Soviet Union, pods were typically scored horizontally, and opium was collected three times, or else one or two collections were followed by isolation of opiates from the ripe capsules. Oil poppies, an alternative strain of "P. somniferum", were also used for production of opiates from their capsules and stems. A traditional Chinese method of harvesting opium latex involved cutting off the heads and piercing them with a coarse needle then collecting the dried opium 24 to 48 hours later.
Raw opium may be sold to a merchant or broker on the black market, but it usually does not travel far from the field before it is refined into morphine base, because pungent, jelly-like raw opium is bulkier and harder to smuggle. Crude laboratories in the field are capable of refining opium into morphine base by a simple acid-base extraction. A sticky, brown paste, morphine base is pressed into bricks and sun-dried, and can either be smoked, prepared into other forms or processed into heroin.
Other methods of preparation (besides smoking), include processing into regular opium tincture ("tinctura opii"), laudanum, paregoric ("tinctura opii camphorata"), herbal wine (e.g. "vinum opii"), opium powder ("pulvis opii"), opium sirup ("sirupus opii") and opium extract ("extractum opii"). Vinum opii is made by combining sugar, white wine, cinnamon, and cloves. Opium syrup is made by combining 997.5 part sugar syrup with 2.5 parts opium extract. Opium extract ("extractum opii") finally can be made by macerating raw opium with water. To make opium extract, 20 parts water are combined with 1 part raw opium which has been boiled for 5 minutes (the latter to ease mixing).
Heroin is widely preferred because of increased potency. One study in postaddicts found heroin to be approximately 2.2 times more potent than morphine by weight with a similar duration; at these relative quantities, they could distinguish the drugs subjectively but had no preference. Heroin was also found to be twice as potent as morphine in surgical anesthesia. Morphine is converted into heroin by a simple chemical reaction with acetic anhydride, followed by a varying degree of purification. Especially in Mexican production, opium may be converted directly to "black tar heroin" in a simplified procedure. This form predominates in the U.S. west of the Mississippi. Relative to other preparations of heroin, it has been associated with a dramatically decreased rate of HIV transmission among intravenous drug users (4% in Los Angeles vs. 40% in New York) due to technical requirements of injection, although it is also associated with greater risk of venous sclerosis and necrotizing fasciitis.
Illegal production.
Opium production has fallen since 1906, when 41,000 tons were produced, but because 39,000 tons of that year's opium were consumed in China, overall usage in the rest of the world was much lower. These figures from 1906 have been criticized as overestimates. In 1980, 2,000 tons of opium supplied all legal and illegal uses. Recently, opium production has increased considerably, surpassing 5,000 tons in 2002 and reaching 8,600 tons in Afghanistan and 840 tons in the Golden Triangle in 2014. Production is expected to increase in 2015 as new, improved seeds have been brought into Afghanistan. The World Health Organization has estimated that current production of opium would need to increase fivefold to account for total global medical need.
In 2002, the price for one kilogram of opium was $300 for the farmer, $800 for purchasers in Afghanistan, and $16,000 on the streets of Europe before conversion into heroin.
Afghanistan is currently the primary producer of the drug. After regularly producing 70% of the world's opium, Afghanistan decreased production to 74 tons per year under a ban by the Taliban in 2000, a move which cut production by 94 percent. A year later, after American and British troops invaded Afghanistan, removed the Taliban and installed the interim government, the land under cultivation leapt back to , with Afghanistan supplanting Burma to become the world's largest opium producer once more. Opium production in that country has increased rapidly since, reaching an all-time high in 2006. According to DEA statistics, Afghanistan's production of oven-dried opium increased to 1,278 tons in 2002, more than doubled by 2003, and nearly doubled again during 2004. In late 2004, the U.S. government estimated that 206,000 hectares were under poppy cultivation, 4.5% of the country's total cropland, and produced 4,200 metric tons of opium, 76% of the world's supply, yielding 60% of Afghanistan's gross domestic product. In 2006, the UN Office on Drugs and Crime estimated production to have risen 59% to in cultivation, yielding 6,100 tons of opium, 82% of the world's supply. The value of the resulting heroin was estimated at $3.5 billion, of which Afghan farmers were estimated to have received $700 million in revenue. For farmers, the crop can be up to ten times more profitable than wheat. The price of opium is around $138 per kilo. Opium production has led to rising tensions in Afghan villages. Though direct conflict has yet to occur, the opinions of the new class of young, rich men involved in the opium trade are at odds with those of the traditional village leaders.
An increasingly large fraction of opium is processed into morphine base and heroin in drug labs in Afghanistan. Despite an international set of chemical controls designed to restrict availability of acetic anhydride, it enters the country, perhaps through its Central Asian neighbors which do not participate. A counternarcotics law passed in December 2005 requires Afghanistan to develop registries or regulations for tracking, storing, and owning acetic anhydride.
Besides Afghanistan, smaller quantities of opium are produced in Pakistan, the Golden Triangle region of Southeast Asia (particularly Burma), Colombia, Guatemala, and Mexico.
Chinese production mainly trades with and profits from North America. In 2002, they were seeking to expand through eastern United States. In the post 9/11 era, trading between borders became difficult and because new international laws were set into place, the opium trade became more diffused. Power shifted from remote to high-end smugglers and opium traders. Outsourcing became a huge factor for survival for many smugglers and opium farmers.
In South American countries, opium poppies are technically illegal, but nonetheless appear in some nurseries as ornamentals.
Legal production.
Legal opium production is allowed under the United Nations Single Convention on Narcotic Drugs and other international drug treaties, subject to strict supervision by the law enforcement agencies of individual countries. The leading legal production method is the Gregory process, whereby the entire poppy, excluding roots and leaves, is mashed and stewed in dilute acid solutions. The alkaloids are then recovered via acid-base extraction and purified. This process was developed in the UK during World War II, when wartime shortages of many essential drugs encouraged innovation in pharmaceutical processing.
Legal opium production in India is much more traditional. As of 2008, opium was collected by farmers who were licensed to grow of opium poppies, who to maintain their licences needed to sell 56 kilograms of unadulterated raw opium paste. The price of opium paste is fixed by the government according to the quality and quantity tendered. The average is around 1500 rupees ($29 US) per kilogram. Some additional money is made by drying the poppy heads and collecting poppy seeds, and a small fraction of opium beyond the quota may be consumed locally or diverted to the black market. The opium paste is dried and processed into government opium and alkaloid factories before it is packed into cases of 60 kilograms for export. Purification of chemical constituents is done in India for domestic production, but typically done abroad by foreign importers.
Legal opium importation from India and Turkey is conducted by Mallinckrodt, Noramco, Abbott Laboratories, Purdue Pharma, and Cody Laboratories Inc. in the United States, and legal opium production is conducted by GlaxoSmithKline, Johnson and Johnson, Johnson Matthey, and Mayne in Tasmania, Australia; Sanofi Aventis in France; Shionogi Pharmaceutical in Japan; and MacFarlan Smith in the United Kingdom. The UN treaty requires that every country submit annual reports to the International Narcotics Control Board, stating that year's actual consumption of many classes of controlled drugs as well as opioids and projecting required quantities for the next year. This is to allow trends in consumption to be monitored and production quotas allotted.
A recent proposal from the European Senlis Council hopes to solve the problems caused by the large quantity of opium produced illegally in Afghanistan, most of which is converted to heroin and smuggled for sale in Europe and the USA. This proposal is to license Afghan farmers to produce opium for the world pharmaceutical market, and thereby solve another problem, that of chronic underuse of potent analgesics where required within developing nations. Part of the proposal is to overcome the "80–20 rule" that requires the U.S. to purchase 80% of its legal opium from India and Turkey to include Afghanistan, by establishing a second-tier system of supply control that complements the current INCB regulated supply and demand system by providing poppy-based medicines to countries who cannot meet their demand under the current regulations. Senlis arranged a conference in Kabul that brought drug policy experts from around the world to meet with Afghan government officials to discuss internal security, corruption issues, and legal issues within Afghanistan.
In June 2007, the Council launched a "Poppy for Medicines" project that provides a technical blueprint for the implementation of an integrated control system within Afghan village-based poppy for medicine projects: the idea promotes the economic diversification by redirecting proceeds from the legal cultivation of poppy and production of poppy-based medicines (See Senlis Council). There has been criticism of the Senlis report findings by Macfarlan Smith, who argue that though they produce morphine in Europe, they were never asked to contribute to the report.
Cultivation in the UK.
In late 2006, the British government permitted the pharmaceutical company MacFarlan Smith (a Johnson Matthey company) to cultivate opium poppies in England for medicinal reasons, after Macfarlan Smith's primary source, India, decided to increase the price of export opium latex. This move is well received by British farmers, with a major opium poppy field located in Didcot, England. The British government has contradicted the Home Office's suggestion that opium cultivation can be legalized in Afghanistan for exports to the United Kingdom, helping lower poverty and internal fighting whilst helping the NHS to meet the high demand for morphine and heroin. Opium poppy cultivation in the United Kingdom does not need a licence, but a licence is required for those wishing to extract opium for medicinal products.
Consumption.
In the industrialized world, the United States is the world's biggest consumer of prescription opioids, with Italy one of the lowest because of tighter regulations on prescribing narcotics for pain relief. Most opium imported into the United States is broken down into its alkaloid constituents, and whether legal or illegal, most current drug use occurs with processed derivatives such as heroin rather than with unrefined opium.
Intravenous injection of opiates is most used: by comparison with injection, "dragon chasing" (heating of heroin with barbital on a piece of foil), and madak and "ack ack" (smoking of cigarettes containing tobacco mixed with heroin powder) are only 40% and 20% efficient, respectively. One study of British heroin addicts found a 12-fold excess mortality ratio (1.8% of the group dying per year). Most heroin deaths result not from overdose "per se", but combination with other depressant drugs such as alcohol or benzodiazepines.
The smoking of opium does not involve the burning of the material as might be imagined. Rather, the prepared opium is indirectly heated to temperatures at which the active alkaloids, chiefly morphine, are vaporized. In the past, smokers would use a specially designed opium pipe which had a removable knob-like pipe-bowl of fired earthenware attached by a metal fitting to a long, cylindrical stem. A small "pill" of opium about the size of a pea would be placed on the pipe-bowl, which was then heated by holding it over an opium lamp, a special oil lamp with a distinct funnel-like chimney to channel heat into a small area. The smoker would lie on his or her side in order to guide the pipe-bowl and the tiny pill of opium over the stream of heat rising from the chimney of the oil lamp and inhale the vaporized opium fumes as needed. Several pills of opium were smoked at a single session depending on the smoker's tolerance to the drug. The effects could last up to twelve hours.
In Eastern culture, opium is more commonly used in the form of paregoric to treat diarrhea. This is a weaker solution than laudanum, an alcoholic tincture which was prevalently used as a pain medication and sleeping aid. Tincture of opium has been prescribed for, among other things, severe diarrhea. Taken thirty minutes prior to meals, it significantly slows intestinal motility, giving the intestines greater time to absorb fluid in the stool.
Despite the historically negative view of opium as a cause of addiction, the use of morphine and other derivatives isolated from opium in the treatment of chronic pain has been reestablished. If given in controlled doses, modern opiates can be an effective treatment for neuropathic pain and other forms of chronic pain.
Chemical and physiological properties.
Opium contains two main groups of alkaloids. Phenanthrenes such as morphine, codeine, and thebaine are the main psychoactive constituents. Isoquinolines such as papaverine and noscapine have no significant central nervous system effects, and are not regulated under the Controlled Substances Act. Morphine is the most prevalent and important alkaloid in opium, consisting of 10%–16% of the total, and is responsible for most of its harmful effects such as lung edema, respiratory difficulties, coma, or cardiac or respiratory collapse. Morphine binds to and activates mu opioid receptor in the brain, spinal cord, stomach and intestine. Regular use can lead to drug tolerance or physical dependence. Chronic opium addicts in 1906 China or modern-day Iran consume an average of eight grams of opium daily.
Both analgesia and drug addiction are functions of the mu opioid receptor, the class of opioid receptor first identified as responsive to morphine. Tolerance is associated with the superactivation of the receptor, which may be affected by the degree of endocytosis caused by the opioid administered, and leads to a superactivation of cyclic AMP signaling. Long-term use of morphine in palliative care and management of chronic pain cannot be managed without the possible development of drug tolerance or physical dependence. Many techniques of drug treatment exist, including pharmacologically based treatments with naltrexone, methadone, or ibogaine.
Slang terms.
Some slang terms for opium include "O.P.", "hop", "midnight oil", "tar", "dope", and "Big O". "Tar" and "dope" can also refer to heroin. The traditional opium pipe is known as a "dream stick".
Cultural references.
There is a longstanding literary history by and about opium users.
Towards the end of the 19th century, references to opium and opium addiction, in the contexts of crime and the foreign underclass, abound within English literature.
Opium likewise underwent a transformation in Chinese literature, becoming associated with indolence and vice by the early 20th century.
In the 20th century, as the use of opium was eclipsed by morphine and heroin, its role in literature became more limited and often focused on issues related to its prohibition.

</doc>
<doc id="22716" url="https://en.wikipedia.org/wiki?curid=22716" title="Online algorithm">
Online algorithm

In computer science, an online algorithm is one that can process its input piece-by-piece in a serial fashion, i.e., in the order that the input is fed to the algorithm, without having the entire input available from the start.
In contrast, an offline algorithm is given the whole problem data from the beginning and is required to output an answer which solves the problem at hand.
As an example, consider the sorting algorithms selection sort and insertion sort: Selection sort repeatedly selects the minimum element from the unsorted remainder and places it at the front, which requires access to the entire input; it is thus an offline algorithm. On the other hand, insertion sort considers one input element per iteration and produces a partial solution without considering future elements. Thus insertion sort is an online algorithm.
Note that insertion sort produces the optimum result, i.e., a correctly sorted list. For many problems, online algorithms cannot match the performance of offline algorithms. If the ratio between the performance of an online algorithm and an optimal offline algorithm is bounded, the online algorithm is called competitive.
Not every "online algorithm" has an "offline" counterpart.
Definition.
Because it does not know the whole input, an online algorithm is forced to make decisions that may later turn out not to be optimal, and the study of online algorithms has focused on the quality of decision-making that is possible in this setting. Competitive analysis formalizes this idea by comparing the relative performance of an online and offline algorithm for the same problem instance. Specifically, the competitive ratio of an algorithm, is defined as the worst-case ratio of its cost divided by the optimal cost, over all possible inputs. The competitive ratio of an online problem is the best competitive ratio achieved by an online algorithm. Intuitively, the competitive ratio of an algorithm gives a measure on the quality of solutions produced by this algorithm, while the competitive ratio of a problem shows the importance of knowing the future for this problem.
Other interpretations.
For other points of view on "online inputs to algorithms", see 
Examples.
Some "online algorithms":
Online problems.
A problem exemplifying the concepts of online algorithms is the Canadian Traveller Problem. The goal of this problem is to minimize the cost of reaching a target in a weighted graph where some of the edges are unreliable and may have been removed from the graph. However, that an edge has been removed ("failed") is only revealed to "the traveller" when she/he reaches one of the edge's endpoints. The worst case for this problem is simply that all of the unreliable edges fail and the problem reduces to the usual Shortest Path Problem. An alternative analysis of the problem can be made with the help of competitive analysis. For this method of analysis, the offline algorithm knows in advance which edges will fail and the goal is to minimize the ratio between the online and offline algorithms' performance. This problem is PSPACE-complete.
There are many formal problems that offers more than one "online algorithm" as solution:

</doc>
<doc id="22717" url="https://en.wikipedia.org/wiki?curid=22717" title="Origin">
Origin

Origin, origins, or original may refer to:

</doc>
<doc id="22718" url="https://en.wikipedia.org/wiki?curid=22718" title="Ozone">
Ozone

Ozone (systematically named 1λ1,3λ1-trioxidane and catena"-trioxygen), or trioxygen"', is an inorganic molecule with the chemical formula '. It is a pale blue gas with a distinctively pungent smell. It is an allotrope of oxygen that is much less stable than the diatomic allotrope , breaking down in the lower atmosphere to normal dioxygen. Ozone is formed from dioxygen by the action of ultraviolet light and also atmospheric electrical discharges, and is present in low concentrations throughout the Earth's atmosphere (stratosphere). In total, ozone makes up only of the atmosphere.
Ozone's odour is sharp, reminiscent of chlorine, and detectable by many people at concentrations of as little as in air. Ozone's O3 formula was determined in 1865. The molecule was later proven to have a bent structure and to be diamagnetic. In standard conditions, ozone is a pale blue gas that condenses at progressively cryogenic temperatures to a dark blue liquid and finally a violet-black solid. Ozone's instability with regard to more common dioxygen is such that both concentrated gas and liquid ozone may decompose explosively.
It is therefore used commercially only in low concentrations.
Ozone is a powerful oxidant (far more so than dioxygen) and has many industrial and consumer applications related to oxidation. This same high oxidising potential, however, causes ozone to damage mucous and respiratory tissues in animals, and also tissues in plants, above concentrations of about . This makes ozone a potent respiratory hazard and pollutant near ground level. However, the ozone layer (a portion of the stratosphere with a higher concentration of ozone, from two to eight ppm) is beneficial, preventing damaging ultraviolet light from reaching the Earth's surface, to the benefit of both plants and animals.
Nomenclature.
The trivial name "ozone" is the most commonly used and preferred IUPAC name. The systematic names "1λ1,3λ1-trioxidane" and "catena-trioxygen", valid IUPAC names, are constructed according to the substitutive and additive nomenclatures, respectively. The name "ozone" derives from "ozein" (ὄζειν), the Greek word for smell (verb), referring to ozone's distinctive smell.
In appropriate contexts, ozone can be viewed as trioxidane with two hydrogen atoms removed, and as such, "trioxidanylidene" may be used as a context-specific systematic name, according to substitutive nomenclature. By default, these names pay no regard to the radicality of the ozone molecule. In even more specific context, this can also name the non-radical singlet ground state, whereas the diradical state is named "trioxidanediyl".
"Trioxidanediyl" (or "ozonide") is used, non-systematically, to refer to the substituent group (-OOO-). Care should be taken to avoid confusing the name of the group for the context-specific name for ozone given above.
History.
In 1785, Dutch chemist Martinus van Marum was conducting experiments involving electrical sparking above water when he noticed an unusual smell, which he attributed to the electrical reactions, failing to realize he had in fact created ozone. A half century later, Christian Friedrich Schönbein noticed the same pungent odour and recognized it as the smell often following a bolt of lightning. In 1839 he succeeded in isolating the gaseous chemical and named it "ozone", from the Greek word "" () meaning "to smell". For this reason, Schönbein is generally credited with the discovery of ozone. The formula for ozone, O3, was not determined until 1865 by Jacques-Louis Soret and confirmed by Schönbein in 1867.
For much of the second half of the nineteenth century and well into the twentieth, ozone was considered a healthy component of the environment by naturalists and health-seekers. The Beaumont, California, had as its official slogan "Beaumont: Zone of Ozone," as evidenced on postcards and Chamber of Commerce letterhead. Naturalists working outdoors often considered the higher elevations beneficial because of their ozone content. "There is quite a different atmosphere [at higher elevation] with enough ozone to sustain the necessary energy [to work]," wrote naturalist Henry Henshaw, working in Hawaii. Seaside air was considered to be healthy because of its "ozone" content but the smell giving rise to this belief is in fact that of halogenated seaweed metabolites.
Physical properties.
Ozone is colourless or slightly bluish gas (blue when liquefied), slightly soluble in water and much more soluble in inert non-polar solvents such as carbon tetrachloride or fluorocarbons, where it forms a blue solution. At , it condenses to form a dark blue liquid. It is dangerous to allow this liquid to warm to its boiling point, because both concentrated gaseous ozone and liquid ozone can detonate. At temperatures below , it forms a violet-black solid.
Most people can detect about 0.01 μmol/mol of ozone in air where it has a very specific sharp odour somewhat resembling chlorine bleach. Exposure of 0.1 to 1 μmol/mol produces headaches, burning eyes and irritation to the respiratory passages.
Even low concentrations of ozone in air are very destructive to organic materials such as latex, plastics and animal lung tissue.
Ozone is diamagnetic, which means that its electrons are all paired. In contrast, O2 is paramagnetic, containing two unpaired electrons.
Structure.
According to experimental evidence from microwave spectroscopy, ozone is a bent molecule, with C2v symmetry (similar to the water molecule). The O – O distances are . The O – O – O angle is 116.78°. The central atom is "sp"² hybridized with one lone pair. Ozone is a polar molecule with a dipole moment of 0.53 D. The bonding can be expressed as a resonance hybrid with a single bond on one side and double bond on the other producing an overall bond order of 1.5 for each side.
Reactions.
Ozone is a powerful oxidizing agent, far stronger than O2. It is also unstable at high concentrations, decaying to ordinary diatomic oxygen. It has a varying half-life length, depending upon atmospheric conditions (temperature, humidity, and air movement). In a sealed chamber with a fan that moves the gas, ozone has a half-life of approximately a day at room temperature. Some unverified claims imply that ozone can have a half life as short as a half an hour under atmospheric conditions.
This reaction proceeds more rapidly with increasing temperature and increased pressure. Deflagration of ozone can be triggered by a spark, and can occur in ozone concentrations of 10 wt% or higher.
With metals.
Ozone will oxidise most metals (except gold, platinum, and iridium) to oxides of the metals in their highest oxidation state. For example:
With nitrogen and carbon compounds.
Ozone also oxidizes nitric oxide to nitrogen dioxide:
This reaction is accompanied by chemiluminescence. The can be further oxidized:
The formed can react with to form .
Solid nitronium perchlorate can be made from NO2, ClO2, and gases:
Ozone does not react with ammonium salts, but it oxidizes ammonia to ammonium nitrate:
Ozone reacts with carbon to form carbon dioxide, even at room temperature:
With sulfur compounds.
Ozone oxidises sulfides to sulfates. For example, lead(II) sulfide is oxidised to lead(II) sulfate:
Sulfuric acid can be produced from ozone, water and either elemental sulfur or sulfur dioxide:
In the gas phase, ozone reacts with hydrogen sulfide to form sulfur dioxide:
In an aqueous solution, however, two competing simultaneous reactions occur, one to produce elemental sulfur, and one to produce sulfuric acid:
With alkenes and alkynes.
Alkenes can be oxidatively cloven by ozone, in a process called ozonolysis, giving alcohols, aldehydes, ketones, and carboxylic acids, depending on the second step of the workup.
Usually ozonolysis is carried out in a solution of dichloromethane, at a temperature of −78oC. After a sequence of cleavage and rearrangement, an organic ozonide is formed. With reductive workup (e.g. zinc in acetic acid or dimethyl sulfide), ketones and aldehydes will be formed, with oxidative workup (e.g. aqueous or alcoholic hydrogen peroxide), carboxylic acids will be formed.
Other substrates.
All three atoms of ozone may also react, as in the reaction of tin(II) chloride with hydrochloric acid and ozone:
Iodine perchlorate can be made by treating iodine dissolved in cold anhydrous perchloric acid with ozone:
Combustion.
Ozone can be used for combustion reactions and combustible gases; ozone provides higher temperatures than burning in dioxygen (O2). The following is a reaction for the combustion of carbon subnitride which can also cause higher temperatures:
Ozone can react at cryogenic temperatures. At , atomic hydrogen reacts with liquid ozone to form a hydrogen superoxide radical, which dimerizes:
Reduction to ozonides.
Reduction of ozone gives the ozonide anion, O. Derivatives of this anion are explosive and must be stored at cryogenic temperatures. Ozonides for all the alkali metals are known. KO3, RbO3, and CsO3 can be prepared from their respective superoxides:
Although KO3 can be formed as above, it can also be formed from potassium hydroxide and ozone:
NaO3 and LiO3 must be prepared by action of CsO3 in liquid NH3 on an ion exchange resin containing Na+ or Li+ ions:
A solution of calcium in ammonia reacts with ozone to give to ammonium ozonide and not calcium ozonide:
Applications.
Ozone can be used to remove iron and manganese from water, forming a precipitate which can be filtered:
Ozone will also reduce dissolved hydrogen sulfide in water to sulfurous acid:
These three reactions are central in the use of ozone based well water treatment.
Ozone will also detoxify cyanides by converting them to cyanates, which are a thousand times less toxic.
Ozone will also completely decompose urea:
Ozone Spectroscopy.
Ozone is a bent triatomic molecule with three vibrational modes: the symmetric stretch (1103.157 cm-1), bend (701.42 cm-1) and antisymmetric stretch (1042.096 cm-1). The symmetric stretch and bend are weak absorbers, but the antisymmetric stretch is strong and responsible for ozone being an important minor greenhouse gas. This IR band is also used to detect ambient and atmospheric ozone although UV based measurements are more common. 
The electronic spectrum of ozone is quite complex. An overview can be seen at the MPI Mainz UV/VIS Spectral Atlas of Gaseous Molecules of Atmospheric Interest.
All of the bands are dissociative, meaning that the molecule falls apart to O + O2 after absorbing a photon. The most important absorption is the Hartley band, extending from slightly above 300 nm down to slightly above 200 nm. It is this band that is responsible for absorbing UV C in the stratosphere. 
On the high wavelength side the Hartley band transitions to the so called Huggins band which falls off rapidly till disappearing by ~360 nm. Above 400 nm, extending well out into the NIR are the Chappius and Wulf bands. There unstructured absorption bands are useful for detecting high ambient concentrations of ozone but are so weak that they do not have much practical effect.
There are additional absorption bands in the far UV, which increase slowly from 200 nm down to reaching a maximum at ~120 nm. 
Ozone in Earth's atmosphere.
The standard way to express total ozone levels (the amount of ozone in a vertical column) in the atmosphere is by using Dobson units. Point measurements are reported as mole fractions in nmol/mol (parts per billion, ppb) or as concentrations in μg/m3. The study of ozone concentration in the atmosphere started in the 1920s.
Ozone layer.
Location and production.
The highest levels of ozone in the atmosphere are in the stratosphere, in a region also known as the ozone layer between about 10 km and 50 km above the surface (or between about 6 and 31 miles). However, even in this "layer" the ozone concentrations are only two to eight parts per million, so most of the oxygen there remains of the dioxygen type.
Ozone in the stratosphere is mostly produced from short-wave ultraviolet rays between 240 and 160 nm. Oxygen starts to absorb weakly at 240 nm in the Herzberg bands, but most of the oxygen is dissociated by absorption in the strong Schumann–Runge bands between 200 and 160 nm where ozone does not absorb. While shorter wavelength light, extending to even the X-Ray limit is energetic enough to dissociate molecular oxygen, there is relatively little of it, and, the strong solar emission at Lyman-alpha, 121 nm, falls at a point where molecular oxygen absorption is a minimum.
The process of ozone creation and destruction is called the Chapman cycle and starts with the photolysis of molecular ozone
followed by reaction of the oxygen atom with another molecule of oxygen to form ozone.
where "M" denotes the third body that carries off the excess energy of the reaction. The ozone molecule then can absorb a UVC photon and dissociate
 → O + + kinetic energy
The excess kinetic energy heats the stratosphere when the O atoms and the molecular oxygen fly apart and collide with other molecules. This conversion of UV light into kinetic energy warms the stratosphere. The oxygen atoms produced in the photolysis of ozone then react back with other oxygen molecule as in the previous step to form more ozone. In the clear atmosphere, with only nitrogen and oxygen, ozone can react with the atomic oxygen to form two molecules of O2
An estimate of the rate of this termination step to the cycling of atomic oxygen back to ozone can be found simply by taking the ratios of the concentration of O2 to O3. The termination reaction is catalysed by the presence of certain free radicals, of which the most important are hydroxyl (OH), nitric oxide (NO) and atomic chlorine (Cl) and bromine (Br). In recent decades the amount of ozone in the stratosphere has been declining mostly because of emissions of chlorofluorocarbons (CFC) and similar chlorinated and brominated organic molecules, which have increased the concentration of ozone-depleting catalysts above the natural background.
Importance to surface-dwelling life on Earth.
Ozone in the ozone layer filters out sunlight wavelengths from about 200 nm UV rays to 315 nm, with ozone peak absorption at about 250 nm. This ozone UV absorption is important to life, since it extends the absorption of UV by ordinary oxygen and nitrogen in air (which absorb all wavelengths < 200 nm) through the lower UV-C (200–280 nm) and the entire UV-B band (280–315 nm). The small unabsorbed part that remains of UV-B after passage through ozone causes sunburn in humans, and direct DNA damage in living tissues in both plants and animals. Ozone's effect on mid-range UV-B rays is illustrated by its effect on UV-B at 290 nm, which has a radiation intensity 350 million times as powerful at the top of the atmosphere as at the surface. Nevertheless, enough of UV-B radiation at similar frequency reaches the ground to cause some sunburn, and these same wavelengths are also among those responsible for the production of vitamin D in humans.
The ozone layer has little effect on the longer UV wavelengths called UV-A (315–400 nm), but this radiation does not cause sunburn or direct DNA damage, and while it probably does cause long-term skin damage in certain humans, it is not as dangerous to plants and to the health of surface-dwelling organisms on Earth in general (see ultraviolet for more information on near ultraviolet).
Low level ozone.
Low level ozone (or tropospheric ozone) is an atmospheric pollutant. It is not emitted directly by car engines or by industrial operations, but formed by the reaction of sunlight on air containing hydrocarbons and nitrogen oxides that react to form ozone directly at the source of the pollution or many kilometers down wind.
Ozone reacts directly with some hydrocarbons such as aldehydes and thus begins their removal from the air, but the products are themselves key components of smog. Ozone photolysis by UV light leads to production of the hydroxyl radical HO• and this plays a part in the removal of hydrocarbons from the air, but is also the first step in the creation of components of smog such as peroxyacyl nitrates, which can be powerful eye irritants. The atmospheric lifetime of tropospheric ozone is about 22 days; its main removal mechanisms are being deposited to the ground, the above-mentioned reaction giving HO•, and by reactions with OH and the peroxy radical HO2•.
There is evidence of significant reduction in agricultural yields because of increased ground-level ozone and pollution which interferes with photosynthesis and stunts overall growth of some plant species. The United States Environmental Protection Agency is proposing a secondary regulation to reduce crop damage, in addition to the primary regulation designed for the protection of human health.
Certain examples of cities with elevated ozone readings are Houston, Texas, and Mexico City, Mexico. Houston has a reading of around 41 nmol/mol, while Mexico City is far more hazardous, with a reading of about 125 nmol/mol.
Ozone cracking.
Ozone gas attacks any polymer possessing olefinic or double bonds within its chain structure, such as natural rubber, nitrile rubber, and styrene-butadiene rubber. Products made using these polymers are especially susceptible to attack, which causes cracks to grow longer and deeper with time, the rate of crack growth depending on the load carried by the rubber component and the concentration of ozone in the atmosphere. Such materials can be protected by adding antiozonants, such as waxes, which bond to the surface to create a protective film or blend with the material and provide long term protection. Ozone cracking used to be a serious problem in car tires for example, but the problem is now seen only in very old tires. On the other hand, many critical products like gaskets and O-rings may be attacked by ozone produced within compressed air systems. Fuel lines made of reinforced rubber are also susceptible to attack, especially within the engine compartment, where some ozone is produced by electrical components. Storing rubber products in close proximity to a DC electric motor can accelerate ozone cracking. The commutator of the motor generates sparks which in turn produce ozone.
Ozone as a greenhouse gas.
Although ozone was present at ground level before the Industrial Revolution, peak concentrations are now far higher than the pre-industrial levels, and even background concentrations well away from sources of pollution are substantially higher. Ozone acts as a greenhouse gas, absorbing some of the infrared energy emitted by the earth. Quantifying the greenhouse gas potency of ozone is difficult because it is not present in uniform concentrations across the globe. However, the most widely accepted scientific assessments relating to climate change (e.g. the Intergovernmental Panel on Climate Change Third Assessment Report) suggest that the radiative forcing of tropospheric ozone is about 25% that of carbon dioxide.
The annual global warming potential of tropospheric ozone is between 918–1022 tons carbon dioxide equivalent/tons tropospheric ozone. This means on a per-molecule basis, ozone in the troposphere has a radiative forcing effect roughly 1,000 times as strong as carbon dioxide. However, tropospheric ozone is a short-lived greenhouse gas, which decays in the atmosphere much more quickly than carbon dioxide. This means that over a 20-year span, the global warming potential of tropospheric ozone is much less, roughly 62 to 69 tons carbon dioxide equivalent / ton tropospheric ozone.
Because of its short-lived nature, tropospheric ozone does not have strong global effects, but has very strong radiative forcing effects on regional scales. In fact, there are regions of the world where tropospheric ozone has a radiative forcing up to 150% of carbon dioxide.
Health effects.
Ozone air pollution.
Ozone precursors are a group of pollutants, predominantly those emitted during the combustion of fossil fuels. Ground-level ozone pollution (tropospheric ozone) is created near the Earth's surface by the action of daylight UV rays on these precursors. The ozone at ground level is primarily from fossil fuel precursors, but methane is a natural precursor, and the very low natural background level of ozone at ground level is considered safe. This section examines health impacts of fossil fuel burning, which raises ground level ozone far above background levels.
There is a great deal of evidence to show that ground level ozone can harm lung function and irritate the respiratory system. Exposure to ozone and the pollutants that produce it is linked to premature death, asthma, bronchitis, heart attack, and other cardiopulmonary problems.
Long-term exposure to ozone has been shown to increase risk of death from respiratory illness. A study of 450,000 people living in United States cities saw a significant correlation between ozone levels and respiratory illness over the 18-year follow-up period. The study revealed that people living in cities with high ozone levels such as Houston or Los Angeles had an over 30% increased risk of dying from lung disease.
Air quality guidelines such as those from the World Health Organization, the United States Environmental Protection Agency (EPA) and the European Union are based on detailed studies designed to identify the levels that can cause measurable ill health effects.
According to scientists with the US EPA, susceptible people can be adversely affected by ozone levels as low as 40 nmol/mol. In the EU, the current target value for ozone concentrations is 120 µg/m3 which is about 60 nmol/mol. This target applies to all member states in accordance with Directive 2008/50/EC. Ozone concentration is measured as a maximum daily mean of 8 hour averages and the target should not be exceeded on more than 25 calendar days per year, starting from January 2010. Whilst the directive requires in the future a strict compliance with 120 µg/m3 limit (i.e. mean ozone concentration not to be exceeded on any day of the year), there is no date set for this requirement and this is treated as a long-term objective. 
In the USA, the Clean Air Act directs the EPA to set National Ambient Air Quality Standards for several pollutants, including ground-level ozone, and counties out of compliance with these standards are required to take steps to reduce their levels. In May 2008, under a court order, the EPA lowered its ozone standard from 80 nmol/mol to 75 nmol/mol. The move proved controversial, since the Agency's own scientists and advisory board had recommended lowering the standard to 60 nmol/mol. Many public health and environmental groups also supported the 60 nmol/mol standard, and the World Health Organization recommends 51 nmol/mol.
On January 7, 2010, the U.S. Environmental Protection Agency (EPA) announced proposed revisions to the National Ambient Air Quality Standard (NAAQS) for the pollutant ozone, the principal component of smog:
The EPA has developed an Air Quality Index (AQI) to help explain air pollution levels to the general public. Under the current standards, eight-hour average ozone mole fractions of 85 to 104 nmol/mol are described as "unhealthy for sensitive groups," 105 nmol/mol to 124 nmol/mol as "unhealthy," and 125 nmol/mol to 404 nmol/mol as "very unhealthy."
Ozone can also be present in indoor air pollution, partly as a result of electronic equipment such as photocopiers. A connection has also been known to exist between the increased pollen, fungal spores, and ozone caused by thunderstorms and hospital admissions of asthma sufferers.
In the Victorian era, one British folk myth held that the smell of the sea was caused by ozone. In fact, the characteristic "smell of the sea" is caused by dimethyl sulfide a chemical generated by phytoplankton. Victorian British folk considered the resulting smell "bracing".
Heat waves.
Ozone production rises during heat waves, because plants absorb less ozone. It is estimated that curtailed ozone absorption by plants is responsible for the loss of 460 lives in the UK in the hot summer of 2006. A similar investigation to assess the joint effects of ozone and heat during the European heat waves in 2003, concluded that these appear to be additive.
Physiology.
Ozone, along with reactive forms of oxygen such as superoxide, singlet oxygen, hydrogen peroxide, and hypochlorite ions, is naturally produced by white blood cells and other biological systems (such as the roots of marigolds) as a means of destroying foreign bodies. Ozone reacts directly with organic double bonds. Also, when ozone breaks down to dioxygen it gives rise to oxygen free radicals, which are highly reactive and capable of damaging many organic molecules. Moreover, it is believed that the powerful oxidizing properties of ozone may be a contributing factor of inflammation. The cause-and-effect relationship of how the ozone is created in the body and what it does is still under consideration and still subject to various interpretations, since other body chemical processes can trigger some of the same reactions. A team headed by Dr. Paul Wentworth Jr. of the Department of Chemistry at the Scripps Research Institute has shown evidence linking the antibody-catalyzed water-oxidation pathway of the human immune response to the production of ozone. In this system, ozone is produced by antibody-catalyzed production of trioxidane from water and neutrophil-produced singlet oxygen.
When inhaled, ozone reacts with compounds lining the lungs to form specific, cholesterol-derived metabolites that are thought to facilitate the build-up and pathogenesis of atherosclerotic plaques (a form of heart disease). These metabolites have been confirmed as naturally occurring in human atherosclerotic arteries and are categorized into a class of secosterols termed "atheronals", generated by ozonolysis of cholesterol's double bond to form a 5,6 secosterol as well as a secondary condensation product via aldolization.
Ozone has been implicated to have an adverse effect on plant growth: "... ozone reduced total chlorophylls, carotenoid and carbohydrate concentration, and increased 1-aminocyclopropane-1-carboxylic acid (ACC) content and ethylene production. In treated plants, the ascorbate leaf pool was decreased, while lipid peroxidation and solute leakage were significantly higher than in ozone-free controls. The data indicated that ozone triggered protective mechanisms against oxidative stress in citrus."
Safety regulations.
Due to the strongly oxidizing properties of ozone, ozone is a primary irritant, affecting especially the eyes and respiratory systems and can be hazardous at even low concentrations. The Canadian Center for Occupation Safety and Health reports that: "Even very low concentrations of ozone can be harmful to the upper respiratory tract and the lungs. The severity of injury depends on both by the concentration of ozone and the duration of exposure. Severe and permanent lung injury or death could result from even a very short-term exposure to relatively low concentrations." To protect workers potentially exposed to ozone, U.S. Occupational Safety and Health Administration has established a permissible exposure limit (PEL) of 0.1 μmol/mol (29 CFR 1910.1000 table Z-1), calculated as an 8-hour time weighted average. Higher concentrations are especially hazardous and NIOSH has established an Immediately Dangerous to Life and Health Limit (IDLH) of 5 μmol/mol. Work environments where ozone is used or where it is likely to be produced should have adequate ventilation and it is prudent to have a monitor for ozone that will alarm if the concentration exceeds the OSHA PEL. Continuous monitors for ozone are available from several suppliers.
Elevated ozone exposure can occur on passenger aircraft, with levels depending on altitude and atmospheric turbulence. United States Federal Aviation Authority regulations set a limit of 250 nmol/mol with a maximum four-hour average of 100 nmol/mol. Some planes are equipped with ozone converters in the ventilation system to reduce passenger exposure.
Production.
Ozone generators are used to produce ozone for cleaning air or remove smoke odors in unoccupied rooms. These ozone generators can produce over 3 g of ozone per hour. Ozone often forms in nature under conditions where O2 will not react.Ozone used in industry is measured in μmol/mol (ppm, parts per million), nmol/mol (ppb, parts per billion), μg/m3, mg/h (milligrams per hour) or weight percent. The regime of applied concentrations ranges from 1 to 5% in air and from 6 to 14% in oxygen for older generation methods. New electrolytic methods can achieve up 20 to 30% dissolved ozone concentrations in output water.
Temperature and humidity plays a large role in how much ozone is being produced using traditional generation methods such as corona discharge and ultraviolet light. Old generation methods will produce less than 50% its nominal capacity if operated with humid ambient air than when it operates in very dry air. New generators using electrolytic methods can achieve higher purity and dissolution through using water molecules as the source of ozone production.
Corona discharge method.
This is the most common type of ozone generator for most industrial and personal uses. While variations of the "hot spark" coronal discharge method of ozone production exist, including medical grade and industrial grade ozone generators, these units usually work by means of a corona discharge tube. They are typically cost-effective and do not require an oxygen source other than the ambient air to produce ozone concentrations of 3–6%. Fluctuations in ambient air, due to weather or other environmental conditions, cause variability in ozone production. However, they also produce nitrogen oxides as a by-product. Use of an air dryer can reduce or eliminate nitric acid formation by removing water vapor and increase ozone production. Use of an oxygen concentrator can further increase the ozone production and further reduce the risk of nitric acid formation by removing not only the water vapor, but also the bulk of the nitrogen.
Ultraviolet light.
UV ozone generators, or vacuum-ultraviolet (VUV) ozone generators, employ a light source that generates a narrow-band ultraviolet light, a subset of that produced by the Sun. The Sun's UV sustains the ozone layer in the stratosphere of Earth.
While standard UV ozone generators tend to be less expensive, they usually produce ozone with a concentration of about 0.5% or lower. Another disadvantage of this method is that it requires the air (oxygen) to be exposed to the UV source for a longer amount of time, and any gas that is not exposed to the UV source will not be treated. This makes UV generators impractical for use in situations that deal with rapidly moving air or water streams (in-duct air sterilization, for example). Production of ozone is one of the potential dangers of ultraviolet germicidal irradiation. VUV ozone generators are used in swimming pool and spa applications ranging to millions of gallons of water. VUV ozone generators, unlike corona discharge generators, do not produce harmful nitrogen by-products and also unlike corona discharge systems, VUV ozone generators work extremely well in humid air environments. There is also not normally a need for expensive off-gas mechanisms, and no need for air driers or oxygen concentrators which require extra costs and maintenance.
Cold plasma.
In the cold plasma method, pure oxygen gas is exposed to a plasma created by dielectric barrier discharge. The diatomic oxygen is split into single atoms, which then recombine in triplets to form ozone.
Cold plasma machines utilize pure oxygen as the input source and produce a maximum concentration of about 5% ozone. They produce far greater quantities of ozone in a given space of time compared to ultraviolet production. However, because cold plasma ozone generators are very expensive, they are found less frequently than the previous two types.
The discharges manifest as filamentary transfer of electrons (micro discharges) in a gap between two electrodes. In order to evenly distribute the micro discharges, a dielectric insulator must be used to separate the metallic electrodes and to prevent arcing.
Some cold plasma units also have the capability of producing short-lived allotropes of oxygen which include O4, O5, O6, O7, etc. These species are even more reactive than ordinary .
Electrolytic.
Electrolytic ozone generation (EOG) splits water molecules into H2, O2, and O3.
In most EOG methods, the hydrogen gas will be removed to leave oxygen and ozone as the only reaction products. Therefore, EOG can achieve higher dissolution in water without other competing gases found in corona discharge method, such as nitrogen gases present in ambient air.
This method of generation can achieve concentrations of 20–30% and is independent of air quality because water is used as the source material. Production of ozone electrolytically is typically unfavorable because of the high overpotential required to produce ozone as compared to oxygen. This is why ozone is not produced during typical water electrolysis. However, it is possible to increase the overpotential of oxygen by careful catalyst selection such that ozone is preferentially produced under electrolysis. Catalysts typically chosen for this approach are lead dioxide or boron-doped diamond.
Special considerations.
Ozone cannot be stored and transported like other industrial gases (because it quickly decays into diatomic oxygen) and must therefore be produced on site. Available ozone generators vary in the arrangement and design of the high-voltage electrodes. At production capacities higher than 20 kg per hour, a gas/water tube heat-exchanger may be utilized as ground electrode and assembled with tubular high-voltage electrodes on the gas-side. The regime of typical gas pressures is around absolute in oxygen and absolute in air. Several megawatts of electrical power may be installed in large facilities, applied as one phase AC current at 50 to 8000 Hz and peak voltages between 3,000 and 20,000 volts. Applied voltage is usually inversely related to the applied frequency.
The dominating parameter influencing ozone generation efficiency is the gas temperature, which is controlled by cooling water temperature and/or gas velocity. The cooler the water, the better the ozone synthesis. The lower the gas velocity, the higher the concentration (but the lower the net ozone produced). At typical industrial conditions, almost 90% of the effective power is dissipated as heat and needs to be removed by a sufficient cooling water flow.
Because of the high reactivity of ozone, only a few materials may be used like stainless steel (quality 316L), titanium, aluminium (as long as no moisture is present), glass, polytetrafluorethylene, or polyvinylidene fluoride. Viton may be used with the restriction of constant mechanical forces and absence of humidity (humidity limitations apply depending on the formulation). Hypalon may be used with the restriction that no water come in contact with it, except for normal atmospheric levels. Embrittlement or shrinkage is the common mode of failure of elastomers with exposure to ozone. Ozone cracking is the common mode of failure of elastomer seals like O-rings.
Silicone rubbers are usually adequate for use as gaskets in ozone concentrations below 1 wt%, such as in equipment for accelerated aging of rubber samples.
Incidental production.
Ozone may be formed from by electrical discharges and by action of high energy electromagnetic radiation. Unsuppressed arcing breaks down the chemical bonds of the atmospheric oxygen surrounding the contacts [ → 2O]. Free radicals of oxygen in and around the arc recombine to create ozone []. Certain electrical equipment generate significant levels of ozone. This is especially true of devices using high voltages, such as ionic air purifiers, laser printers, photocopiers, tasers and arc welders. Electric motors using brushes can generate ozone from repeated sparking inside the unit. Large motors that use brushes, such as those used by elevators or hydraulic pumps, will generate more ozone than smaller motors.
Ozone is similarly formed in the Catatumbo lightning storms phenomenon on the Catatumbo River in Venezuela, which helps to replenish ozone in the upper troposphere. It is the world's largest single natural generator of ozone, lending calls for it to be designated a UNESCO World Heritage Site.
Laboratory production.
In the laboratory, ozone can be produced by electrolysis using a 9 volt battery, a pencil graphite rod cathode, a platinum wire anode and a 3 molar sulfuric acid electrolyte. The half cell reactions taking place are:
In the net reaction, three equivalents of water are converted into one equivalent of ozone and three equivalents of hydrogen. Oxygen formation is a competing reaction.
It can also be "prepared" by high voltage arc. This can be done with an apparatus consisting of two concentric glass tubes sealed together at the top, with in and out spigots at the top and bottom of the outer tube. The inner core should have a length of metal foil inserted into it connected to one side of the power source. The other side of the power source should be connected to another piece of foil wrapped around the outer tube. Dry should be run through the tube in one spigot. As the is run through one spigot into the apparatus and high voltage is applied to the foil leads, electricity will discharge between the dry dioxygen in the middle and form and out the other spigot. The reaction can be summarized as follows:
Applications.
Industry.
The largest use of ozone is in the preparation of pharmaceuticals, synthetic lubricants, and many other commercially useful organic compounds, where it is used to sever carbon-carbon bonds. It can also be used for bleaching substances and for killing microorganisms in air and water sources. Many municipal drinking water systems kill bacteria with ozone instead of the more common chlorine. Ozone has a very high oxidation potential. Ozone does not form organochlorine compounds, nor does it remain in the water after treatment. Ozone can form the suspected carcinogen bromate in source water with high bromide concentrations. The Safe Drinking Water Act mandates that these systems introduce an amount of chlorine to maintain a minimum of 0.2 μmol/mol residual free chlorine in the pipes, based on results of regular testing. Where electrical power is abundant, ozone is a cost-effective method of treating water, since it is produced on demand and does not require transportation and storage of hazardous chemicals. Once it has decayed, it leaves no taste or odour in drinking water.
Although low levels of ozone have been advertised to be of some disinfectant use in residential homes, the concentration of ozone in dry air required to have a rapid, substantial effect on airborne pathogens exceeds safe levels recommended by the U.S. Occupational Safety and Health Administration and Environmental Protection Agency. Humidity control can vastly improve both the killing power of the ozone and the rate at which it decays back to oxygen (more humidity allows more effectiveness). Spore forms of most pathogens are very tolerant of atmospheric ozone in concentrations where asthma patients start to have issues.
Industrially, ozone is used to:
Ozone is a reagent in many organic reactions in the laboratory and in industry. Ozonolysis is the cleavage of an alkene to carbonyl compounds.
Many hospitals around the world use large ozone generators to decontaminate operating rooms between surgeries. The rooms are cleaned and then sealed airtight before being filled with ozone which effectively kills or neutralizes all remaining bacteria.
Ozone is used as an alternative to chlorine or chlorine dioxide in the bleaching of wood pulp. It is often used in conjunction with oxygen and hydrogen peroxide to eliminate the need for chlorine-containing compounds in the manufacture of high-quality, white paper.
Ozone can be used to detoxify cyanide wastes (for example from gold and silver mining) by oxidising cyanide to cyanate and eventually to carbon dioxide.
Consumers.
Devices generating high levels of ozone, some of which use ionization, are used to sanitize and deodorize uninhabited buildings, rooms, ductwork, woodsheds, and boats and other vehicles.
One company has been successfully selling a CPAP sanitizer for the CPAP gear used by sleep apnea patients. This sanitizer works by pumping high concentration levels of electrically-generated ozone into the unit's humidification water tank (with or without water in it) and out through the hose into the mask, which is enclosed and sealed in an ozone-capturing receptacle (that also contains the ozone generator and pump that pushes it into the water tank), which completes a closed-loop system. This closed-loop system prevents the high levels of ozone from escaping while effectively sanitizing the CPAP equipment, as the CPAP equipment is prone to developing bacterial infestations and harboring viruses and other pathogens because of the constant moisture generated by the CPAP system's humidifier. The sanitizing unit has a two-hour cycle, it pumps the ozone for 6–10 minutes (user-designated) and then resting for two hours while maintaining the sealed closed-circuit loop as the ozone decays back into oxygen and finishes the sanitizing effect.
In the U.S., air purifiers emitting low levels of ozone have been sold. This kind of air purifier is sometimes claimed to imitate nature's way of purifying the air without filters and to sanitize both it and household surfaces. The United States Environmental Protection Agency (EPA) has declared that there is "evidence to show that at concentrations that do not exceed public health standards, ozone is not effective at removing many odor-causing chemicals" or "viruses, bacteria, mold, or other biological pollutants." Furthermore, its report states that "results of some controlled studies show that concentrations of ozone considerably higher than these [human safety] standards are possible even when a user follows the manufacturer’s operating instructions." A couple kept repeating health claims for the generator they sold, without supporting scientific studies. In 1998 a federal jury convicted them, among others things, of illegally distributing an ozone generator and of wire fraud.
Ozonated water is used to launder clothes and to sanitize food, drinking water, and surfaces in the home. According to the U.S. Food and Drug Administration (FDA), it is "amending the food additive regulations to provide for the safe use of ozone in gaseous and aqueous phases as an antimicrobial agent on food, including meat and poultry." Studies at California Polytechnic University demonstrated that 0.3 μmol/mol levels of ozone dissolved in filtered tapwater can produce a reduction of more than 99.99% in such food-borne microorganisms as salmonella, "E. coli" 0157:H7 and "Campylobacter". This quantity is 20,000 times the WHO-recommended limits stated above.
Ozone can be used to remove pesticide residues from fruits and vegetables.
Ozone is used in homes and hot tubs to kill bacteria in the water and to reduce the amount of chlorine or bromine required by reactivating them to their free state. Since ozone does not remain in the water long enough, ozone by itself is ineffective at preventing cross-contamination among bathers and must be used in conjunction with halogens. Gaseous ozone created by ultraviolet light or by corona discharge is injected into the water.
Ozone is also widely used in treatment of water in aquariums and fish ponds. Its use can minimize bacterial growth, control parasites, eliminate transmission of some diseases, and reduce or eliminate "yellowing" of the water. Ozone must not come in contact with fish's gill structures. Natural salt water (with life forms) provides enough "instantaneous demand" that controlled amounts of ozone activate bromide ion to hypobromous acid, and the ozone entirely decays in a few seconds to minutes. If oxygen fed ozone is used, the water will be higher in dissolved oxygen, fish's gill structures will atrophy and they will become dependent on higher dissolved oxygen levels.
Aquaculture.
Ozonation - a process of infusing water with ozone - can be used in aquaculture to facilitate organic breakdown. Ozone is also added to recirculating systems to reduce nitrite levels through conversion into nitrate. If nitrite levels in the water are high, nitrites will also accumulate in the blood and tissues of fish, where it interferes with oxygen transport (it causes oxidation of the heme-group of haemoglobin from ferrous () to ferric (), making haemoglobin unable to bind ). Despite these apparent positive effects, ozone use in recirculation systems has been linked to reducing the level of bioavailable iodine in salt water systems, resulting in iodine deficiency symptoms such as goitre and decreased growth in Senegalese sole (Solea senegalensis) larvae.
Ozonate seawater is used for surface disinfection of haddock and Atlantic halibut eggs against nodavirus. Nodavirus is a lethal and vertically transmitted virus which causes severe mortality in fish. Haddock eggs should not be treated with high ozone level as eggs so treated did not hatch and died after 3–4 days.
Agriculture.
Ozone application on freshly cut pineapple and banana shows increase in flavonoids and total phenol contents when exposure is up to 20 minutes. Decrease in ascorbic acid (one form of vitamin C) content is observed but the positive effect on total phenol content and flavonoids can overcome the negative effect. Tomatoes upon treatment with ozone shows an increase in β-carotene, lutein and lycopene. However, ozone application on strawberries in pre-harvest period shows decrease in ascorbic acid content.
Ozone facilitates the extraction of some heavy metals from soil using EDTA. EDTA forms strong, water-soluble coordination compounds with some heavy metals (Pb, Zn) thereby making it possible to dissolve them out from contaminated soil. If contaminated soil is pre-treated with ozone, the extraction efficacy of Pb, Am and Pu increases by 11.0–28.9%, 43.5% and 50.7% respectively.

</doc>
<doc id="22719" url="https://en.wikipedia.org/wiki?curid=22719" title="Orchidaceae">
Orchidaceae

Orchidaceae is a diverse and widespread family of flowering plants, with blooms that are often colourful and often fragrant, commonly known as the orchid family. Along with the Asteraceae, they are one of the two largest families of flowering plants. Orchidaceae has about 27,800 currently accepted species, distributed in about 880 genera. The determination of which family is larger is still under debate, because verified data on the members of such enormous families are continually in flux. Regardless, the number of orchid species nearly equals the number of bony fishes and is more than twice the number of bird species, and about four times the number of mammal species. The family also encompasses about 6–11% of all seed plants. The largest genera are "Bulbophyllum" (2,000 species), "Epidendrum" (1,500 species), "Dendrobium" (1,400 species) and "Pleurothallis" (1,000 species).
The family also includes "Vanilla" (the genus of the vanilla plant), "Orchis" (type genus), and many commonly cultivated plants such as "Phalaenopsis" and "Cattleya". Moreover, since the introduction of tropical species into cultivation in the 19th century, horticulturists have produced more than 100,000 hybrids and cultivars.
Description.
Orchids are easily distinguished from other plants, as they share some very evident shared derived characteristics, or "apomorphies". Among these are: bilateral symmetry of the flower (zygomorphism), many resupinate flowers, a nearly always highly modified petal ("labellum"), fused stamens and carpels, and extremely small seeds.
Stem and roots.
All orchids are perennial herbs that lack any permanent woody structure. They can grow according to two patterns:
Terrestrial orchids may be rhizomatous or form corms or tubers. The root caps of terrestrial orchids are smooth and white.
Some sympodial terrestrial orchids, such as "Orchis" and "Ophrys", have two subterranean tuberous roots. One is used as a food reserve for wintry periods, and provides for the development of the other one, from which visible growth develops.
In warm and constantly humid climates, many terrestrial orchids do not need pseudobulbs.
Epiphytic orchids, those that grow upon a support, have modified aerial roots that can sometimes be a few meters long. In the older parts of the roots, a modified spongy epidermis, called velamen, has the function to absorb humidity. It is made of dead cells and can have a silvery-grey, white or brown appearance. In some orchids, the velamen includes spongy and fibrous bodies near the passage cells, called tilosomes.
The cells of the root epidermis grow at a right angle to the axis of the root to allow them to get a firm grasp on their support. Nutrients mainly come from animal droppings and other organic detritus collecting among on their supporting surfaces.
The base of the stem of sympodial epiphytes, or in some species essentially the entire stem, may be thickened to form a pseudobulb that contains nutrients and water for drier periods.
The pseudobulb has a smooth surface with lengthwise grooves, and can have different shapes, often conical or oblong. Its size is very variable; in some small species of "Bulbophyllum", it is no longer than two millimeters, while in the largest orchid in the world, "Grammatophyllum speciosum" (giant orchid), it can reach three meters. Some "Dendrobium" species have long, canelike pseudobulbs with short, rounded leaves over the whole length; some other orchids have hidden or extremely small pseudobulbs, completely included inside the leaves.
With ageing, the pseudobulb sheds its leaves and becomes dormant. At this stage it is often called a backbulb. Backbulbs still hold nutrition for the plant, but then a pseudobulb usually takes over, exploiting the last reserves accumulated in the backbulb, which eventually dies off, too. A pseudobulb typically lives for about five years. Orchids without noticeable pseudobulbs are also said to have growths, an individual component of a sympodial plant.
Leaves.
Like most monocots, orchids generally have simple leaves with parallel veins, although some Vanilloideae have a reticulate venation. Leaves may be ovate, lanceolate, or orbiculate, and very variable in size on the individual plant. Their characteristics are often diagnostic. They are normally alternate on the stem, often folded lengthwise along the centre ("plicate"), and have no stipules. Orchid leaves often have siliceous bodies called stegmata in the vascular bundle sheaths (not present in the Orchidoideae) and are fibrous.
The structure of the leaves corresponds to the specific habitat of the plant. Species that typically bask in sunlight, or grow on sites which can be occasionally very dry, have thick, leathery leaves and the laminae are covered by a waxy cuticle to retain their necessary water supply. Shade-loving species, on the other hand, have long, thin leaves.
The leaves of most orchids are perennial, that is, they live for several years, while others, especially those with plicate leaves as in "Catasetum", shed them annually and develop new leaves together with new pseudobulbs.
The leaves of some orchids are considered ornamental. The leaves of the "Macodes sanderiana", a semiterrestrial or rock-hugging ("lithophyte") orchid, show a sparkling silver and gold veining on a light green background. The cordate leaves of "Psychopsis limminghei" are light brownish-green with maroon-puce markings, created by flower pigments. The attractive mottle of the leaves of lady's slippers from tropical and subtropical Asia ("Paphiopedilum"), is caused by uneven distribution of chlorophyll. Also, "Phalaenopsis schilleriana" is a pastel pink orchid with leaves spotted dark green and light green. The jewel orchid ("Ludisia discolor") is grown more for its colorful leaves than its white flowers.
Some orchids, as "Dendrophylax lindenii" (ghost orchid), "Aphyllorchis" and "Taeniophyllum" depend on their green roots for photosynthesis and lack normally developed leaves, as do all of the heterotrophic species.
Orchids of the genus "Corallorhiza" (coralroot orchids) lack leaves altogether and instead wrap their roots around the roots of mature trees and use specialized fungi to harvest sugars.
Flowers.
Orchidaceae are well known for the many structural variations in their flowers.
Some orchids have single flowers, but most have a racemose inflorescence, sometimes with a large number of flowers. The flowering stem can be basal, that is, produced from the base of the tuber, like in "Cymbidium", apical, meaning it grows from the apex of the main stem, like in "Cattleya", or axillary, from the leaf axil, as in "Vanda".
As an apomorphy of the clade, orchid flowers are primitively zygomorphic (bilaterally symmetrical), although in some genera like "Mormodes", "Ludisia" and "Macodes", this kind of symmetry may be difficult to notice.
The orchid flower, like most flowers of monocots, has two whorls of sterile elements. The outer whorl has three sepals and the inner whorl has three petals. The sepals are usually very similar to the petals (and thus called "tepals", 1), but may be completely distinct.
The medial petal, called the "labellum" or lip (6), which is always modified and enlarged, is actually the "upper" medial petal; however, as the flower develops, the inferior ovary (7) or the pedicel usually rotates 180 degrees, so that the labellum arrives at the lower part of the flower, thus becoming suitable to form a platform for pollinators. This characteristic, called resupination, occurs primitively in the family and is considered apomorphic, a derived characteristic all Orchidaceae share. The torsion of the ovary is very evident from the longitudinal section shown ("below right"). Some orchids have secondarily lost this resupination, e.g. "Zygopetalum" and "Epidendrum secundum".
The normal form of the sepals can be found in "Cattleya", where they form a triangle. In "Paphiopedilum" (Venus slippers), the lower two sepals are fused into a synsepal, while the lip has taken the form of a slipper. In "Masdevallia", all the sepals are fused.
Orchid flowers with abnormal numbers of petals or lips are called peloric. Peloria is a genetic trait, but its expression is environmentally influenced and may appear random.
Orchid flowers primitively had three stamens, but this situation is now limited to the genus "Neuwiedia". "Apostasia" and the Cypripedioideae have two stamens, the central one being sterile and reduced to a staminode. All of the other orchids, the clade called "Monandria", retain only the central stamen, the others being reduced to staminodes (4). The filaments of the stamens are always adnate (fused) to the style to form cylindrical structure called the gynostemium or column (2). In the primitive Apostasioideae, this fusion is only partial; in the Vanilloideae, it is more deep; in Orchidoideae and Epidendroideae, it is total. The stigma (9) is very asymmetrical, as all of its lobes are bent towards the centre of the flower and lie on the bottom of the column.
Pollen is released as single grains, like in most other plants, in the Apostasioideae, Cypripedioideae and Vanilloideae. In the other subfamilies, that comprise the great majority of orchids, the anther (3), carries and two pollinia.
A pollinium is a waxy mass of pollen grains held together by the glue-like alkaloid viscin, containing both cellulosic strands and mucopolysaccharides. Each pollinium is connected to a filament which can take the form of a caudicle, as in "Dactylorhiza" or "Habenaria", or a "stipe", as in "Vanda". Caudicles or stipes hold the pollinia to the viscidium, a sticky pad which sticks the pollinia to the body of pollinators.
At the upper edge of the stigma of single-anthered orchids, in front of the anther cap, there is the rostellum (5), a slender extension involved in the complex pollination mechanism.
As mentioned, the ovary is always inferior (located behind the flower). It is three-carpelate and one or, more rarely, three-partitioned, with parietal placentation (axile in the Apostasioideae).
In 2011, a member of the genus "Bulbophyllum", "Bulbophyllum nocturnum", was discovered to flower nocturnally.
Fruits and seeds.
The ovary typically develops into a capsule that is dehiscent by three or six longitudinal slits, while remaining closed at both ends.
The seeds are generally almost microscopic and very numerous, in some species over a million per capsule. After ripening, they blow off like dust particles or spores. They lack endosperm and must enter symbiotic relationships with various mycorrhizal basidiomyceteous fungi that provide them the necessary nutrients to germinate, so that all orchid species are mycoheterotrophic during germination and reliant upon fungi to complete their lifecycles.
As the chance for a seed to meet a suitable fungus is very small, only a minute fraction of all the seeds released grow into adult plants. In cultivation, germination typically takes weeks.
Horticultural techniques have been devised for germinating orchid seeds on an artificial nutrient medium, eliminating the requirement of the fungus for germination and greatly aiding the propagation of ornamental orchids. The usual medium for the sowing of orchids in artificial conditions is agar agar gel combined with a carbohydrate energy source. The carbohydrate source can be combinations of discrete sugars or can be derived from other sources such as banana, pineapple, peach or even tomato puree or coconut water. After the preparation of the agar agar medium it is poured into test tubes or jars which are then autoclaved (or cooked in a pressure cooker) to sterilize the medium. After cooking, the medium begins to gel as it cools.
Pollination.
The complex mechanisms which orchids have evolved to achieve cross-pollination were investigated by Charles Darwin and described in "Fertilisation of Orchids" (1862). Orchids have developed highly specialized pollination systems, thus the chances of being pollinated are often scarce, so orchid flowers usually remain receptive for very long periods, rendering unpollinated flowers long-lasting in cultivation. Most orchids deliver pollen in a single mass. Each time pollination succeeds, thousands of ovules can be fertilized.
Pollinators are often visually attracted by the shape and colours of the labellum. However, some "Bulbophyllum" species attract male fruit flies ("Bactrocera" spp.) solely via a floral chemical which simultaneously acts as a floral reward (e.g. methyl eugenol, raspberry ketone or zingerone) to perform pollination. The flowers may produce attractive odours. Although absent in most species, nectar may be produced in a spur of the labellum (8 in the illustration above), or on the point of the sepals, or in the septa of the ovary, the most typical position amongst the Asparagales.
In orchids that produce pollinia, pollination happens as some variant of the following sequence: when the pollinator enters into the flower, it touches a viscidium, which promptly sticks to its body, generally on the head or abdomen. While leaving the flower, it pulls the pollinium out of the anther, as it is connected to the viscidium by the caudicle or stipe. The caudicle then bends and the pollinium is moved forwards and downwards. When the pollinator enters another flower of the same species, the pollinium has taken such position that it will stick to the stigma of the second flower, just below the rostellum, pollinating it. The possessors of orchids may be able to reproduce the process with a pencil, small paintbrush, or other similar device.
Some orchids mainly or totally rely on self-pollination, especially in colder regions where pollinators are particularly rare. The caudicles may dry up if the flower has not been visited by any pollinator, and the pollinia then fall directly on the stigma. Otherwise, the anther may rotate and then enter the stigma cavity of the flower (as in "Holcoglossum amesianum").
The slipper orchid "Paphiopedilum parishii" reproduces by self-fertilization. This occurs when the anther changes from a solid to a liquid state and directly contacts the stigma surface without the aid of any pollinating agent or floral assembly.
The labellum of the Cypripedioideae is poke-bonnet-shaped, and has the function of trapping visiting insects. The only exit leads to the anthers that deposit pollen on the visitor.
In some extremely specialized orchids, such as the Eurasian genus "Ophrys", the labellum is adapted to have a colour, shape and odour which attracts male insects via mimicry of a receptive female. Pollination happens as the insect attempts to mate with flowers.
Many neotropical orchids are pollinated by male orchid bees, which visit the flowers to gather volatile chemicals they require to synthesize pheromonal attractants. Males of such species as "Euglossa imperialis" or "Eulaema meriana" have been observed to leave their territories periodically to forage for aromatic compounds, such as cineole, to synthesize pheromone for attracting and mating with females. Each type of orchid places the pollinia on a different body part of a different species of bee, so as to enforce proper cross-pollination. 
A rare achlorophyllous saprophytic orchid growing entirely underground in Australia, "Rhizanthella slateri", is never exposed to light, and depends on ants and other terrestrial insects to pollinate it.
"Catasetum", a genus discussed briefly by Darwin, actually launches its viscid pollinia with explosive force when an insect touches a seta, knocking the pollinator off the flower.
After pollination, the sepals and petals fade and wilt, but they usually remain attached to the ovary.
Asexual reproduction.
Some species, such as "Phalaenopsis", "Dendrobium" and "Vanda", produce offshoots or plantlets formed from one of the nodes along the stem, through the accumulation of growth hormones at that point. These shoots are known as "keiki".
Taxonomy.
The taxonomy of this family is in constant flux, as new studies continue to clarify the relationships between species and groups of species, allowing more taxa at several ranks to be recognized. The Orchidaceae is currently placed in the order Asparagales by the APG III system of 2009.
Five subfamilies are recognised. The cladogram below was made according to the APG system of 1998. It represents the view that most botanists had held up to that time. It was supported by morphological studies, but never received strong support in molecular phylogenetic studies.
In 2015, a phylogenetic study showed strong statistical support for the following topology of the orchid tree, using 9 kb of plastid and nuclear DNA from 7 genes, a topology that was confirmed by a phylogenomic study in the same year.
Evolution.
A study in the scientific journal "Nature" has hypothesised that the origin of orchids goes back much longer than originally expected. An extinct species of stingless bee, "Proplebeia dominicana", was found trapped in Miocene amber from about 15-20 million years ago. The bee was carrying pollen of a previously unknown orchid taxon, "Meliorchis caribea", on its wings. This find is the first evidence of fossilised orchids to date and shows insects were active pollinators of orchids then. This extinct orchid, "M. caribea", has been placed within the extant tribe Cranichideae, subtribe Goodyerinae (subfamily Orchidoideae).
Genetic sequencing indicates orchids may have arisen earlier, 76 to 84 million years ago during the Late Cretaceous. According to Mark W. Chase "et al." (2001), the overall biogeography and phylogenetic patterns of Orchidaceae show they are even older and may go back roughly 100 million years.
Using the molecular clock method, it was possible to determine the age of the major branches of the orchid family. This also confirmed that the subfamily Vanilloideae is a branch at the basal dichotomy of the monandrous orchids, and must have evolved very early in the evolution of the family. Since this subfamily occurs worldwide in tropical and subtropical regions, from tropical America to tropical Asia, New Guinea and West Africa, and the continents began to split about 100 million years ago, significant biotic exchange must have occurred after this split (since the age of "Vanilla" is estimated at 60 to 70 million years).
Genera.
The following are amongst the most notable genera of the orchid family:
Etymology.
The type genus (i.e. the genus after which the family is named) is "Orchis". The genus name comes from the Ancient Greek (""), literally meaning "testicle", because of the shape of the twin tubers in some species of "Orchis". The term "orchid" was introduced in 1845 by John Lindley in "School Botany", as a shortened form of "Orchidaceae".
Distribution.
Orchidaceae are cosmopolitan, occurring in almost every habitat apart from glaciers. The world's richest diversity of orchid genera and species is found in the tropics, but they are also found above the Arctic Circle, in southern Patagonia, and two species of "Nematoceras" on Macquarie Island at 54° south.
The following list gives a rough overview of their distribution:
Ecology.
A majority of orchids are perennial epiphytes, which grow anchored to trees or shrubs in the tropics and subtropics. Species such as "Angraecum sororium" are lithophytes, growing on rocks or very rocky soil. Other orchids (including the majority of temperate Orchidaceae) are terrestrial and can be found in habitat areas such as grasslands or forest.
Some orchids, such as "Neottia" and "Corallorhiza", lack chlorophyll, so are unable to photosynthesise. Instead, these species obtain energy and nutrients by parasitising soil fungi through the formation of orchid mycorrhizas. The fungi involved include those that form ectomycorrhizas with trees and other woody plants, parasites such as "Armillaria", and saprotrophs. These orchids are known as myco-heterotrophs, but were formerly (incorrectly) described as saprophytes as it was believed they gained their nutrition by breaking down organic matter. While only a few species are achlorophyllous holoparasites, all orchids are myco-heterotrophic during germination and seedling growth, and even photosynthetic adult plants may continue to obtain carbon from their mycorrhizal fungi.
Uses.
Perfumery.
The scent of orchids is frequently analysed by perfumers (using headspace technology and gas-liquid chromatography) to identify potential fragrance chemicals.
Horticulture.
The other important use of orchids is their cultivation for the enjoyment of the flowers. Most cultivated orchids are tropical or subtropical, but quite a few which grow in colder climates can be found on the market. Temperate species available at nurseries include "Ophrys apifera" (bee orchid), "Gymnadenia conopsea" (fragrant orchid), "Anacamptis pyramidalis" (pyramidal orchid) and "Dactylorhiza fuchsii" (common spotted orchid).
Orchids of all types have also often been sought by collectors of both species and hybrids. Many hundreds of societies and clubs worldwide have been established. These can be small, local clubs such as the Sutherland Shire Orchid Society, or larger, national organisations such as the American Orchid Society. Both serve to encourage cultivation and collection of orchids, but some go further by concentrating on conservation or research.
The term "botanical orchid" loosely denotes those small-flowered, tropical orchids belonging to several genera that do not fit into the "florist" orchid category. A few of these genera contain enormous numbers of species. Some, such as "Pleurothallis" and "Bulbophyllum", contain approximately 1700 and 2000 species, respectively, and are often extremely vegetatively diverse. The primary use of the term is among orchid hobbyists wishing to describe unusual species they grow, though it is also used to distinguish naturally occurring orchid species from horticulturally created hybrids.
Use as food.
The dried seed pods of one orchid genus, "Vanilla" (especially "Vanilla planifolia"), are commercially important as a flavouring in baking, for perfume manufacture and aromatherapy.
The underground tubers of terrestrial orchids [mainly "Orchis mascula" (early purple orchid)] are ground to a powder and used for cooking, such as in the hot beverage "salep" or in the Turkish frozen treat "dondurma". The name "salep" has been claimed to come from the Arabic expression "ḥasyu al-tha`lab", "fox testicles", but it appears more likely the name comes directly from the Arabic name "saḥlab". The similarity in appearance to testes naturally accounts for "salep" being considered an aphrodisiac.
The dried leaves of "Jumellea fragrans" are used to flavour rum on Reunion Island.
Some saprophytic orchid species of the group "Gastrodia" produce potato-like tubers and were consumed as food by native peoples in Australia and can be successfully cultivated, notably "Gastrodia sesamoides". Wild stands of these plants can still be found in the same areas as early aboriginal settlements, such as Ku-ring-gai Chase National Park in Australia. Aboriginal peoples located the plants in habitat by observing where bandicoots had scratched in search of the tubers after detecting the plants underground by scent.
Traditional medicinal uses.
Orchids have been used in traditional medicine in an effort to treat many diseases and ailments. They have been used as a source of herbal remedies in China since 2800 BC. "Gastrodia elata" is one of the three orchids listed in the earliest known Chinese Materia Medica ("Shennon bencaojing") (c. 100 AD). Theophrastus mentions orchids in his "Enquiry into Plants" (372–286 BC).
Cultural symbolism.
Orchids have many associations with symbolic values. For example, the orchid is the City Flower of Shaoxing, China. "Cattleya mossiae" is the national Venezuelan flower, while "Cattleya trianae" is the national flower of Colombia. "Vanda" 'Miss Joaquim' is the national flower of Singapore. "Guarianthe skinneri" is the national flower of Costa Rica. Orchids native to the Mediterranean are depicted on the "Ara Pacis" in Rome, until now the only known instance of orchids in ancient art, and the earliest in European art.

</doc>
<doc id="22721" url="https://en.wikipedia.org/wiki?curid=22721" title="Obsidian">
Obsidian

Obsidian is a naturally occurring volcanic glass formed as an extrusive igneous rock.
It is produced when felsic lava extruded from a volcano cools rapidly with minimum crystal growth. Obsidian is commonly found within the margins of rhyolitic lava flows known as obsidian flows, where the chemical composition (high silica content) induces a high viscosity and polymerization degree of the lava. The inhibition of atomic diffusion through this highly viscous and polymerized lava explains the lack of crystal growth. Obsidian is hard and brittle; it therefore fractures with very sharp edges, which were used in the past in cutting and piercing tools, and it has been used experimentally as surgical scalpel blades.
Origin and properties.
The translation into English of "Natural History" written by the elder Pliny of Rome shows a few sentences on the subject of a volcanic glass called Obsian, so named from its resemblance to a stone ("obsiānus lapis") found in Ethiopia by Obsius, a Roman explorer.
Obsidian is the rock formed as a result of quickly cooled lava, which is the parent material. Tektites were once thought by many to be obsidian produced by lunar volcanic eruptions, though few scientists now adhere to this hypothesis.
Obsidian is mineral-like, but not a true mineral because as a glass it is not crystalline; in addition, its composition is too complex to comprise a single mineral. It is sometimes classified as a mineraloid. Though obsidian is usually dark in color similar to mafic rocks such as basalt, obsidian's composition is extremely felsic. Obsidian consists mainly of SiO2 (silicon dioxide), usually 70% or more. Crystalline rocks with obsidian's composition include granite and rhyolite. Because obsidian is metastable at the Earth's surface (over time the glass becomes fine-grained mineral crystals), no obsidian has been found that is older than Cretaceous age. This breakdown of obsidian is accelerated by the presence of water. Having a low water content when newly formed, typically less than 1% water by weight, obsidian becomes progressively hydrated when exposed to groundwater, forming perlite.
Pure obsidian is usually dark in appearance, though the color varies depending on the presence of impurities. Iron and magnesium typically give the obsidian a dark brown to black color. Very few samples are nearly colorless. In some stones, the inclusion of small, white, radially clustered crystals of cristobalite in the black glass produce a blotchy or snowflake pattern ("snowflake obsidian"). Obsidian may contain patterns of gas bubbles remaining from the lava flow, aligned along layers created as the molten rock was flowing before being cooled. These bubbles can produce interesting effects such as a golden sheen ("sheen obsidian"). An iridescent, rainbow-like sheen ("rainbow obsidian") is caused by inclusions of magnetite nanoparticles.
Occurrence.
Obsidian can be found in locations which have experienced rhyolitic eruptions. It can be found in Argentina, Armenia, Azerbaijan, Australia, Canada, Chile, Georgia, Greece, El Salvador, Guatemala, Iceland, Italy, Japan, Kenya, Mexico, New Zealand, Papua New Guinea, Peru, Scotland, Turkey and the United States. Obsidian flows which may be hiked on are found within the calderas of Newberry Volcano and Medicine Lake Volcano in the Cascade Range of western North America, and at Inyo Craters east of the Sierra Nevada in California. Yellowstone National Park has a mountainside containing obsidian located between Mammoth Hot Springs and the Norris Geyser Basin, and deposits can be found in many other western U.S. states including Arizona, Colorado, New Mexico, Texas, Utah, Washington, Oregon and Idaho. Obsidian can also be found in the eastern U.S. states of Virginia, as well as Pennsylvania and North Carolina.
There are only four major deposit areas in the central Mediterranean: Lipari, Pantelleria, Palmarola and Monte Arci.
Ancient sources in the Aegean were Melos and Giali.
Acigöl town and the Göllü Dağ volcano were the most important sources in central Anatolia, one of the more important source areas in the prehistoric Near East.
Historical use.
The first archaeological evidence known of usage were made from within Kariandusi and other sites of the Acheulian age (beginning 1.5 million years previously) dated 700,000 BC, although the number of objects found at these sites were very low relative to the Neolithic. Use of obsidian in pottery of the Neolithic in the area around Lipari was found to be significantly less at a distance representing two weeks journeying. Anatolian sources of obsidian are known to have been the material used in the Levant and modern-day Iraqi Kurdistan from a time beginning sometime about 12,500 BC. The first attested civilized use is from excavations at Tell Brak dated the late fifth millennia. Obsidian was valued in Stone Age cultures because, like flint, it could be fractured to produce sharp blades or arrowheads. Like all glass and some other types of naturally occurring rocks, obsidian breaks with a characteristic conchoidal fracture. It was also polished to create early mirrors. Modern archaeologists have developed a relative dating system, obsidian hydration dating, to calculate the age of obsidian artifacts.
Middle East.
In the Ubaid in the 5th millennium BC, blades were manufactured from obsidian extracted from outcrops located in modern-day Turkey. Ancient Egyptians used obsidian imported from the eastern Mediterranean and southern Red Sea regions. Obsidian was also used in ritual circumcisions because of its deftness and sharpness. In the eastern Mediterranean area the material was used to make tools, mirrors and decorative objects.
Obsidian has also been found in Gilat, a site in the western Negev in Israel. Eight obsidian artifacts dating to the Chalcolithic Age found at this site were traced to obsidian sources in Anatolia. Neutron activation analysis (NAA) on the obsidian found at this site helped to reveal trade routes and exchange networks previously unknown.
Americas.
Lithic analysis can be instrumental in understanding prehispanic groups in Mesoamerica. A careful analysis of obsidian in a culture or place can be of considerable use to reconstruct commerce, production, distribution and thereby understand economic, social and political aspects of a civilization. This is the case in Yaxchilán, a Maya city where even warfare implications have been studied linked with obsidian use and its debris. Another example is the archeological recovery at coastal Chumash sites in California indicating considerable trade with the distant site of Casa Diablo, California in the Sierra Nevada Mountains.
Pre-Columbian Mesoamericans' use of obsidian was extensive and sophisticated; including carved and worked obsidian for tools and decorative objects. Mesoamericans also made a type of sword with obsidian blades mounted in a wooden body. Called a "macuahuitl", the weapon was capable of inflicting terrible injuries, combining the sharp cutting edge of an obsidian blade with the ragged cut of a serrated weapon.
Native American people traded obsidian throughout the Americas. Each volcano and in some cases each volcanic eruption produces a distinguishable type of obsidian, making it possible for archaeologists to trace the origins of a particular artifact. Similar tracing techniques have allowed obsidian to be identified in Greece also as coming from Melos, Nisyros or Yiali, islands in the Aegean Sea. Obsidian cores and blades were traded great distances inland from the coast.
In Chile obsidian tools from Chaitén Volcano have been found as far away as in Chan-Chan 400 km north of the volcano and also in sites 400 km south of it.
Easter Island.
Obsidian was also used on Rapa Nui (Easter Island) for edged tools such as "Mataia" and the pupils of the eyes of their Moai (statues).
Current use.
Though not approved by the US Food and Drug Administration (FDA) for use on humans, obsidian is used by some surgeons for scalpel blades, as well-crafted obsidian blades have a cutting edge many times sharper than high-quality steel surgical scalpels, the cutting edge of the blade being only about 3 nanometers thick. Even the sharpest metal knife has a jagged, irregular blade when viewed under a strong enough microscope; when examined even under an electron microscope an obsidian blade is still smooth and even. One study found that obsidian incisions produced fewer inflammatory cells and less granulation tissue at seven days, in a group of rats, although no differences were found after 21 days. Don Crabtree produced obsidian blades for surgery and other purposes, and has written articles on the subject. Obsidian scalpels may currently be purchased for surgical use on research animals.
Obsidian is also used for ornamental purposes and as a gemstone. It presents a different appearance depending on how it is cut: in one direction it is jet black, while in another it is glistening gray. "Apache tears" are small rounded obsidian nuggets often embedded within a grayish-white perlite matrix.
Plinths for audio turntables have been made of obsidian since the 1970s; e.g. the grayish-black SH-10B3 plinth by Technics.

</doc>
<doc id="22722" url="https://en.wikipedia.org/wiki?curid=22722" title="Otaku">
Otaku

 is a Japanese term for people with obsessive interests, commonly the anime and manga fandom. Its contemporary usage originated with Akio Nakamori's 1983 essay in "Manga Burikko". "Otaku" may be used as a pejorative; its negativity stems from the stereotypical view of otaku and the media's reporting on Tsutomu Miyazaki, "The Otaku Murderer", in 1989. According to studies published in 2013, the term has become less negative, and an increasing number of people now self-identify as otaku.
Otaku subculture is a central theme of various anime and manga works, documentaries and academic research. The subculture began in the 1980s as changing social mentalities and the nurturing of otaku traits by Japanese schools combined with the resignation of such individuals to become social outcasts. The subculture's birth coincided with the anime boom, after the release of works like Mobile Suit Gundam before branched into Comic Market. The definition of otaku subsequently became more complex, and numerous classifications of otaku emerged. In 2005, the Nomura Research Institute divided otaku into twelve groups and estimated the size and market impact of each of these groups. Other institutions have split it further or focus on a single otaku interest. These publications classify distinct groups including anime, manga, camera, automobile, idol and electronics otaku. The economic impact of otaku has been estimated to be as high as ¥2 trillion ($18 billion).
Etymology.
"Otaku" is derived from a Japanese term for another person's house or family ( "otaku"). This word is often used metaphorically, as an honorific second-person pronoun. In this usage, its literal translation is "you". For example, in the anime Macross, first aired in 1982, Lynn Minmay uses the term this way. The modern slang form, which is distinguished from the older usage by being written only in hiragana (おたく), katakana (オタク or, less frequently, ヲタク) or rarely in rōmaji, first appeared in public discourse in the 1980s, through the work of humorist and essayist Akio Nakamori. His 1983 series , printed in the lolicon magazine "Manga Burikko", applied the term to unpleasant fans in caricature. Animators Haruhiko Mikimoto and Shōji Kawamori had used the term among themselves as an honorific second-person pronoun since the late 1970s. Supposedly, some fans used it past the point in their relationships where others would have moved on to a less formal style. Because this misuse indicated social awkwardness, Nakamori chose the word itself to label the fans. Morikawa Kaichirō who is an author, and lecturer at Meiji University identified this as the origin of its contemporary usage.
Another claim for the origin of the term comes from the works of science fiction author Motoko Arai, who used the word in her novels as a second-person pronoun and the readers adopted the term for themselves. However, a different claim points to a 1981 "Variety" magazine essay.
In 1989, the case of Tsutomu Miyazaki, "The Otaku Murderer", brought the fandom, very negatively, to national attention. Miyazaki, who randomly chose and murdered four girls, had a collection of 5,763 videotapes, some containing anime and slasher films that were found interspersed with videos and pictures of his victims. Later that year, the contemporary knowledge magazine Bessatsu Takarajima dedicated its 104th issue to the topic of otaku. It was called and delved into the subculture of otaku with 19 articles by otaku insiders, among them Akio Nakamori. This publication has been claimed by scholar Rudyard Pesimo to have popularized the term.
Usage.
In modern Japanese slang, the term "otaku" is mostly equivalent to "geek" or "nerd", but in a more derogatory manner than used in the West. However, it can relate to any fan of any particular theme, topic, hobby or form of entertainment. "When these people are referred to as otaku, they are judged for their behaviors - and people suddenly see an “otaku” as a person unable to relate to reality". The word entered English as a loanword from the Japanese language. It is typically used to refer to a fan of anime/manga but can also refer to Japanese video games or Japanese culture in general. The American magazine "Otaku USA" popularizes and covers these aspects. The usage of the word is a source of contention among some fans, owing to its negative connotations and stereotyping of the fandom. Widespread English exposure to the term came in 1988 with the release of Gunbuster, which referred to anime fans as otaku. Gunbuster was released officially in English in March 1990. The term's usage spread throughout rec.arts.anime with discussions about Otaku no Video's portrayal of otaku before its 1994 English release. Positive and negative aspects, including the pejorative usage, were intermixed. The term was also popularized by William Gibson's 1996 novel "Idoru", which references otaku.
Subculture.
Morikawa Kaichirō identifies the subculture as distinctly Japanese, a product of the school system and society. Japanese schools have a class structure which functions as a caste system, but clubs are an exception to the social hierarchy. In these clubs, a student's interests will be recognized and nurtured, catering to the interests of otaku. Secondly, the vertical structure of Japanese society identifies the value of individuals by their success. Until the late 1980s, unathletic and unattractive males focused on academics, hoping to secure a good job and marry to raise their social standing. Those unable to succeed socially focused instead on their interests, often into adulthood, with their lifestyle centering on those interests, furthering the creation of the otaku subculture.
Even prior to the coinage of the term, the stereotypical traits of the subculture were identified in a 1981 issue of "Fan Rōdo" (Fan road) about "culture clubs". These individuals were drawn to anime, a counter-culture, with the release of hard science fiction works like Mobile Suit Gundam. These works allowed a congregation and development of obsessive interests that turned anime into a medium for unpopular students, catering to obsessed fans. After these fans discovered Comic Market, the term was used as a self-confirming and self-mocking collective identity.
The 1989 "Otaku Murderer" case gave a negative connotation to the fandom from which it has not fully recovered. The usage of "(interest) otaku", however, is used for teasing or self-deprecation, but the unqualified term remains negative. The identification of otaku turned negative in late 2004 when Kaoru Kobayashi kidnapped, sexually assaulted, and murdered a seven-year-old first-grade student. Japanese journalist Akihiro Ōtani suspected that Kobayashi's crime was committed by a member of the figure moe zoku even before his arrest. Although Kobayashi was not an otaku, the degree of social hostility against otaku increased. Otaku were seen by law enforcement as possible suspects for sex crimes, and local governments called for stricter laws controlling the depiction of eroticism in otaku materials.
Not all attention has been negative. In his book, "Otaku", Hiroki Azuma observed: "Between 2001 and 2007, the otaku forms and markets quite rapidly won social recognition in Japan", citing the fact that "[i]n 2003, Miyazaki Hayao won the Academy Award for his "Spirited Away"; around the same time Murakami Takashi achieved recognition for otaku-like designs; in 2004, the Japanese pavilion in the 2004 International Architecture exhibition of the Venice Biennale (Biennale Architecture) featured “otaku”. In 2005, the word "moe" - one of the keywords of the present volume - was chosen as one of the top ten “buzzwords of the year." The former Prime Minister of Japan Taro Aso has also claimed to be an otaku, using this subculture to promote Japan in foreign affairs. In 2013, a Japanese study of 137,734 people found that 42.2% self-identify as a type of otaku. This study suggests that the stigma of the word has vanished, and the term has been embraced by many.
Places.
The district of Akihabara in Tokyo, where there are maid cafes featuring waitresses who dress up and act like maids or anime characters, is a notable attraction center for otaku. Akihabara also has dozens of stores specializing in anime, manga, retro video games, figurines, card games and other collectibles. Another popular location is Otome Road in Ikebukuro, Tokyo. In Nagoya, students from Nagoya City University started a project on ways to help promote hidden tourist attractions related to the otaku culture to attract more otaku to the city.
Subtypes.
There are specific terms for different types of otaku, including , a self-mockingly pejorative Japanese term for female fans of yaoi, which focuses on homosexual male relationships. "Reki-jo" are female otaku who are interested in Japanese history. Some terms refer to a location, like "Akiba-kei", a slang term meaning "Akihabara-style" which applies to those familiar with Akihabara's culture. Another is , a type of cheering that is part of Akiba-kei. Other terms, such as , literally "painful car", describe vehicles who are decorated with fictional characters, especially bishōjo game or eroge characters.
Media.
Otaku often participate in self-mocking through the production or interest in humor directed at their subculture. Anime and manga otaku are the subject of numerous self-critical works, like Otaku no Video, which contains a live-interview mockumentary that pokes fun at the otaku subculture and includes Gainax's own staff as the interviewees. Other works depict otaku subculture less critically, like Genshiken and Comic Party. A well-known novel-cum-manga-cum-anime is Welcome to the N.H.K., which focuses on the popular subcultures popular with otaku and highlights other social outcasts like the hikikomori and NEETs. Works that focus on an otaku character include "WataMote - No Matter How I Look at It, It’s You Guys' Fault I’m Not Popular!", the story of an unattractive and unsociable otome game otaku who exhibits delusions about her social status. Watamote is a self-mocking insight that follows the heroine's delusion and attempts to reform herself only by facing reality with comedic results on the path to popularity. An American documentary, "Otaku Unite!", focuses on the American side of the otaku culture.
Types and classification of Japanese otaku.
The Nomura Research Institute (NRI) has made two major studies into otaku, the first in 2004 and a revised study with a more specific definition in 2005. The 2005 study defines twelve major fields of otaku interests. Of these groups, manga (Japanese comics) was the largest, with 350,000 individuals and ¥83 billion market scale. Idol otaku were the next largest group, with 280,000 individuals and ¥61 billion. Travel otaku with 250,000 individuals and ¥81 billion. PC otaku with 190,000 individuals and ¥36 billion. Video game otaku with 160,000 individuals and ¥21 billion. Automobile otaku with 140,000 individuals and ¥54 billion. Animation (anime) otaku with 110,000 individuals and ¥20 billion. The remaining five categories include Mobile IT equipment otaku, with 70,000 individuals and ¥8 billion; Audio-visual equipment otaku, with 60,000 individuals and ¥12 billion; camera otaku, with 50,000 individuals and ¥18 billion; fashion otaku, with 40,000 individuals and ¥13 billion; and railway otaku, with 20,000 individuals and ¥4 billion. These values were partially released with a much higher estimation in 2004, but this definition focused on the consumerism and not the "unique psychological characteristics" of otaku used in the 2005 study.
NRI's 2005 study also put forth five archetypes of otaku. The first is the family-oriented otaku, who has broad interests and is more mature than other otaku; their object of interest is secretive and they are "closet otaku". The second is the serious "leaving my own mark on the world" otaku, with interests in mechanical or business personality fields. The third type is the "media-sensitive multiple interest" otaku, whose diverse interests are shared with others. The fourth type is the "outgoing and assertive otaku", who gain recognition by promoting their hobby. The last is the "fan magazine-obsessed otaku", which is predominately female with the a small group of males being the "moe type"; the secret hobby is focused on the production or interest in fan works. The Hamagin Research Institute found that moe-related content was worth ¥88.8 billion ($807 million) in 2005, and one analyst estimated the market could be as much as ¥2 trillion ($18 billion). Japan based "Tokyo Otaku Mode" a place for news relating to Otaku has been liked on Facebook almost 10 million times.
Other classifications of otaku interests include vocaloid, cosplay, figures and professional wrestling as categorized by the Yano Research Institute. Yano Research reports and the tracks market growth and trends in sectors heavily influenced by otaku consumerism. In 2012, it noted around 30% growth in dating sim and online gaming otaku, while vocaloid, cosplay, idols and maid services grew by 10%, confirming its 2011 predictions.

</doc>
<doc id="22723" url="https://en.wikipedia.org/wiki?curid=22723" title="Object modeling language">
Object modeling language

An Object Modeling Language is a standardized set of symbols used to model a software system using an object-oriented framework. The symbols can be either informal or formal ranging from predefined graphical templates to formal object models defined by grammars and specifications.
A modeling language is usually associated with a methodology for object-oriented development. The modeling language defines the elements of the model. E.g., that a model has classes, methods, object properties, etc. The methodology defines the steps developers and users need to take to develop and maintain a software system. Steps such as "Define requirements", "Develop code", and "Test system". 
It is common to equate the modeling language and the modeling methodology. For example the Booch method may refer to Grady Booch's standard for diagramming, his methodology, or both. Or the Rumbaugh Object Modeling Technique is both a set of diagrams and a process model for developing object-oriented systems.
In the early years of the object-oriented community there were several competing modeling and methodology standards. Booch and Rumbaugh were two of the most popular. Ivar Jacobson's Objectory, Shlaer-Mellor,and Yourdon-Coad were also popular.
However, the object-oriented community values re-use and standardization. As shown in the graphic there were efforts starting in the mid '90's to reconcile the leading models and focus on one unified specification. The graphic shows the evolution of one of the most important object modeling language standards: the Unified Modeling Language (UML).
The UML began as an attempt by some of the major thought leaders in the community to define a standard language at the OOPSLA '95 Conference. Originally, Grady Booch and James Rumbaugh merged their models into a unified model. This was followed by Booch's company Rational Software purchasing Ivar Jacobson's Objectory company and merging their model into the UML. At the time Rational and Objectory were two of the dominant players in the small world of independent vendors of Object-Oriented tools and methods.
The Object Management Group then picked up and took over ownership of the UML. The OMG is one of the most influential standards organizations in the object-oriented world. The UML is both a formal metamodel and a collection of graphical templates. The meta-model defines the elements in an object-oriented model such as classes and properties. It is essentially the same thing as the meta-model in object-oriented languages such as Smalltalk or CLOS. However, in those cases the meta-model is meant primarily to be used by developers at run time to dynamically inspect and modify an application object model. The UML meta-model provides a mathematical formal foundation for the various graphic views used by the modeling language to describe an emerging system.
The following diagram illustrates the class hierarchy of the various graphic templates defined by the UML. "Structure diagrams" define the static structure of an object: its place in the class hierarchy, its relation to other objects, etc. "Behavior diagrams" specify the dynamic aspects of the model, business process logic, coordination and timing of distributed objects, etc. 

</doc>
<doc id="22725" url="https://en.wikipedia.org/wiki?curid=22725" title="On Fairy-Stories">
On Fairy-Stories

"On Fairy-Stories" is an essay by J. R. R. Tolkien which discusses the fairy-story as a literary form. It was initially written (and entitled simply "Fairy Stories") for presentation by Tolkien as the Andrew Lang lecture at the University of St Andrews, Scotland, in 1939. It first appeared in print, with some enhancement, in 1947, in a festschrift volume, "Essays Presented to Charles Williams", compiled by C. S. Lewis. Charles Williams, a friend of Lewis's, had been relocated with the Oxford University Press staff from London to Oxford during the London blitz in World War II. This allowed him to participate in gatherings of the Inklings with Lewis and Tolkien. The volume of essays was intended to be presented to Williams upon the return of the OUP staff to London with the ending of the war. However, Williams died suddenly on 15 May 1945, and the book was published as a memorial volume.
"On Fairy-Stories" was subsequently published with "Leaf by Niggle" in "Tree and Leaf", as well as in "The Tolkien Reader", published in 1966. The length of the essay, as it appears in "Tree and Leaf", is 60 pages, including about ten pages of notes.
The essay is significant because it contains Tolkien's explanation of his philosophy on fantasy and thoughts on mythopoiesis. Moreover, the essay is an early analysis of speculative fiction by one of the most important authors in the genre.
Literary context.
Tolkien was among the pioneers of the genre that we would now call fantasy writing. In particular, his stories – together with those of C. S. Lewis — were among the first to establish the convention of an alternative world or universe as the setting for speculative fiction. Most earlier works with styles similar to Tolkien's, such as the science fiction of H.G. Wells or the Gothic romances of Mary Shelley, were set in a world that is recognisably that of the author and introduced only a single fantastic element—or at most a fantastic milieu within the author's world, as with Lovecraft or Howard. Tolkien departed from this; his work was nominally part of the history of our own world, but did not have the close linkage to history or contemporary times that his precursors had.
The essay "On Fairy-Stories" is an attempt to explain and defend the genre of fairy tales or "Märchen". It distinguishes "Märchen" from "traveller's tales" (such as "Gulliver's Travels"), science fiction (such as H.G. Wells's "The Time Machine"), beast tales (such as Aesop's Fables and "Peter Rabbit"), and dream stories (such as "Alice in Wonderland"). One touchstone of the authentic fairy tale is that it is presented as wholly credible. "It is at any rate essential to a genuine fairy-story, as distinct from the employment of this form for lesser or debased purposes, that it should be presented as 'true.' ...But since the fairy-story deals with 'marvels,' it cannot tolerate any frame or machinery suggesting that the whole framework in which they occur is a figment or illusion."
Tolkien emphasises that through the use of fantasy, which he equates with fancy and imagination, the author can bring the reader to experience a world which is consistent and rational, under rules other than those of the normal world. He calls this "a rare achievement of Art," and notes that it was important to him as a reader: "It was in fairy-stories that I first divined the potency of the words, and the wonder of things, such as stone, and wood, and iron; tree and grass; house and fire; bread and wine."
Tolkien suggests that fairy stories allow the reader to review his own world from the "perspective" of a different world. This concept, which shares much in common with phenomenology, Tolkien calls "recovery," in the sense that one's unquestioned assumptions might be recovered and changed by an outside perspective. Second, he defends fairy stories as offering escapist pleasure to the reader, justifying this analogy: a prisoner is not obliged to think of nothing but cells and wardens. And third, Tolkien suggests that fairy stories can provide moral or emotional consolation, through their happy ending, which he terms a "eucatastrophe".
In conclusion and as expanded upon in an epilogue, Tolkien asserts that a truly good and representative fairy story is marked by joy: "Far more powerful and poignant is the effect [of joy] in a serious tale of Faerie. In such stories, when the sudden turn comes, we get a piercing glimpse of joy, and heart's desire, that for a moment passes outside the frame, rends indeed the very web of story, and lets a gleam come through." Tolkien sees Christianity as partaking in and fulfilling the overarching mythological nature of the cosmos: "I would venture to say that approaching the Christian story from this perspective, it has long been my feeling (a joyous feeling) that God redeemed the corrupt making-creatures, men, in a way fitting to this aspect, as to others, of their strange nature. The Gospels contain a fairy-story, or a story of a larger kind which embraces all the essence of fairy-stories. ...and among its marvels is the greatest and most complete conceivable eucatastrophe. The Birth of Christ is the eucatastrophe of Man's history. The Resurrection is the eucatastrophe of the story of the Incarnation."

</doc>
<doc id="22727" url="https://en.wikipedia.org/wiki?curid=22727" title="Otaku no Video">
Otaku no Video

 is a 1991 comedy anime spoofing the life and culture of otaku, individuals with obsessive interests in media, particularly anime and manga, as well as the history of Gainax, its creators. It is noted for its mix of conventional documentary film styles (with actual film, no less), with a more traditional anime storytelling fashion. It is licensed in the United States by AnimEigo. The "DAICON III and IV Opening Animations" from the early eighties are also featured in this OVA.
Plot summary.
The story begins in "Otaku No Video 1982", where the main character is a normal Japanese male, Ken Kubo, living quite happily in Japan during the year 1982 with his girlfriend Yoshiko and as a member of his college's tennis team, until he meets one of his former friends from high school, Tanaka. After Tanaka brings him into his circle of friends (all of them being otaku, too: a female illustrator, an information geek, a martial artist, and a weapons collector), Kubo soon makes the wish to become the "Otaking", the King of all the otaku.
Kubo's quest continues in "More Otaku No Video 1985", set 3 years later. He manages to create his own model kits, open shops, and even build a factory in China. Later, he loses it all when one of his rivals (who's also married to Yoshiko, who never forgave Kubo for abandoning her) takes control of his enterprise with Tanaka's unwitting aid. But after Kubo and Tanaka make peace, teaming up with hard-working artist Misuzu, Kubo and friends successfully take over the anime industry with a magical girl show, "Misty May", during the nineties. Once they have reached the peak of their ambitions, Ken and Tanaka create Otakuland in 1999, the equivalent of Disneyland for otaku (the story suggests Otakuland to be located in the same city of Urayasu, Chiba Prefecture, as the original Tokyo Disneyland.)
Many years later, Ken and Tanaka return to Otakuland in a post-apocalyptic submerged Japan and find its central structure, a giant robot, converted into a functional spaceship piloted by their old otaku friends. Miraculously rejuvenated, they fly off into space in search of "The Planet of Otaku".
"A Portrait of an Otaku".
A controversial and humorous part of "Otaku no Video" was the inclusion of live-action documentary excerpts, titled "A Portrait of an Otaku". In these segments, the documentary crew would interview an anonymous otaku, typically ashamed at being a fan and whose face are censored with a mosaic and have their voices digitally masked. The mock documentary segments serve as a counterpoint to the anime: while the anime emphasizes the camaradrie, creativity, and dreams of mainstream acceptance of otaku, the mock interviews exaggerate its negative qualities. The subjects run the gamut of the otaku subculture: the interviews cover a cosplayer who now works as a computer programmer and outright denies his cosplay days, even when presented with photographic evidence, but keeps his Char Aznable helmet in his desk drawer, an airsoft otaku, a garage kit otaku, and a shut-in who videorecords television programs for trade, but has not actually watched anything he's recorded. The interviews also contain fans who engage in a range of illicit or unsavory activities, such as cel thieves, a pornography fan attempting to manufacture glasses to defeat the mosaic censorship common in Japanese porno videos and who is shown masturbating during the interview, and a computer gamer -famous Gainax member Hideaki Anno- obsessed with a character in a hentai computer game (Noriko from "Gunbuster" -one of Anno's works- who makes a cameo in Gainax's own hentai game: "Cybernetic High School").
It is believed that all the subjects in the Portrait of an Otaku segments were Gainax employees or connected to Gainax at the time of filming. The first otaku interviewed bore a remarkable resemblance to Toshio Okada, a principal founder in Gainax, in both background and physical appearance. The gaijin otaku, Shon Hernandez, has been confirmed to have been Craig York, who with Shon Howell and Lea Hernandez, whose names were borrowed for the character", were the main staff of General Products USA, an early western branch of Gainax's merchandising in the early 1990s. The interview with "Shon Hernandez" has been a point of contention with Lea Hernandez, who, in an interview with "PULP magazine", noted that the interview was unscripted and that Craig York had been fairly sincere in his thoughts and had felt that Gainax insulted their American members. In the interview, the words spoken by Shon Hernandez in the background are noticeably different from what is shown on screen via subtitle (which is based on the Japanese voiceover "translation").
At FanimeCon 2003, Hiroshi Sato, an animator and another Gainax member, mentioned that he had been in one of the interviews in "Otaku no Video". In "Otaku no Video", the garage kit otaku was given the pseudonym "Sato Hiroshi" for the interview.
Production and release.
Since "Otaku no Video" was partially based in the personal life of the original creators of Gainax, who started their careers as otaku during the late seventies and the beginning of the eighties, many anime titles from that period are shown as footage or referenced in the OVA (in costumes, cosplay or other related material). Among them are "Gatchaman", "Uchuu Senkan Yamato", "Urusei Yatsura", "Captain Harlock", "Mobile Suit Gundam", "Space Adventure Cobra", "Phoenix 2772", "Magical Princess Minky Momo", "The Super Dimension Fortress Macross", "", "The Wings of Honneamise", "Top wo Nerae!" and the "Daicon III and IV Opening Animations".
"Otaku no Video" was released with subtitles in North America by AnimEigo on March 17, 1993.

</doc>
<doc id="22735" url="https://en.wikipedia.org/wiki?curid=22735" title="Original sin">
Original sin

Original sin, also called ancestral sin, is the Christian doctrine of humanity's state of sin resulting from the fall of man, namely the sin of consuming from the tree of knowledge of good and evil, stemming from Adam's rebellion in Eden. This condition has been characterized in many ways, ranging from something as insignificant as a slight deficiency, or a tendency toward sin yet without collective guilt, referred to as a "sin nature", to something as drastic as total depravity or automatic guilt of all humans through collective guilt.
The concept of original sin was first alluded to in the 2nd century by Irenaeus, Bishop of Lyons in his controversy with certain dualist Gnostics. Other church fathers such as Augustine also developed the doctrine, seeing it as based on the New Testament teaching of Paul the Apostle ( and ) and the Old Testament verse of . Tertullian, Cyprian, Ambrose and Ambrosiaster considered that humanity shares in Adam's sin, transmitted by human generation. Augustine's formulation of original sin was popular among Protestant reformers, such as Martin Luther and John Calvin, who equated original sin with concupiscence, affirming that it persisted even after baptism and completely destroyed freedom. The Jansenist movement, which the Catholic Church declared to be heretical, also maintained that original sin destroyed freedom of will.
In Judaism.
Jewish theologians are divided in regard to the cause of what is called "original sin". Some teach that it was due to Adam's yielding to temptation in eating of the forbidden fruit and has been inherited by his descendants; the majority of chazalic opinions, however, do not hold Adam responsible for the sins of humanity, teaching that, in Genesis 8:21 and 6:5-8, God recognized that Adam did not willfully sin. However, Adam is recognized by some as having brought death into the world by his disobedience. Because of his sin, his descendants will live a mortal life, which will end in death of their bodies. The doctrine of "inherited sin" is not found in most of mainstream Judaism. Although some in Orthodox Judaism place blame on Adam for overall corruption of the world, and though there were some Jewish teachers in Talmudic times who believed that death was a punishment brought upon humanity on account of Adam's sin, that is not the dominant view in most of Judaism today. Modern Judaism generally teaches that humans are born sin-free and untainted, and choose to sin later and bring suffering to themselves. The concept of inherited sin is also not found in any real form in Islam. Some interpretations of original sin are rejected by other Christian theologies.
History of the doctrine.
The formalized doctrine of original sin was first developed in the 2nd-century by Irenaeus, the Bishop of Lyons, in his struggle against Gnosticism. Irenaeus contrasted their doctrine with the view that the Fall was a step in the wrong direction by Adam, with whom, Irenaeus believed, his descendants had some solidarity or identity. Irenaeus believed that Adam's sin had grave consequences for humanity, that it is the source of human sinfulness, mortality and enslavement to sin, and that all human beings participate in his sin and share his guilt.
The Greek Fathers emphasized the cosmic dimension of the Fall, namely that since Adam human beings are born into a fallen world, but held fast to belief that man, though fallen, is free. They thus did not teach that human beings are deprived of free will and involved in total depravity, which is one understanding of original sin. During this period the doctrines of human depravity and the inherently sinful nature of human flesh were taught by Gnostics, and orthodox Christian writers took great pains to counter them. Christian Apologists insisted that God's future judgment of humanity implied humanity must have the ability to live righteously.
Augustine.
Augustine of Hippo (354–430) taught that Adam's sin is transmitted by concupiscence, or "hurtful desire", resulting in humanity becoming a "massa damnata" (mass of perdition, condemned crowd), with much enfeebled, though not destroyed, freedom of will. When Adam sinned, human nature was thenceforth transformed. Adam and Eve, via sexual reproduction, recreated human nature. Their descendants now live in sin, in the form of concupiscence, a term Augustine used in a metaphysical, not a psychological sense. Augustine insisted that concupiscence was not "a being" but a "bad quality", the privation of good or a wound. He admitted that sexual concupiscence ("libido") might have been present in the perfect human nature in paradise, and that only later it became disobedient to human will as a result of the first couple's disobedience to God's will in the original sin. In Augustine's view (termed "Realism"), all of humanity was really present in Adam when he sinned, and therefore all have sinned. Original sin, according to Augustine, consists of the guilt of Adam which all humans inherit. As sinners, humans are utterly depraved in nature, lack the freedom to do good, and cannot respond to the will of God without divine grace. Justo Gonzalez interprets Augustine's teaching that grace is irresistible, results in conversion, and leads to perseverance.
Augustine articulated his explanation in reaction to Pelagianism, which insisted that humans have of themselves, without the necessary help of God's grace, the ability to lead a morally good life, and thus denied both the importance of baptism and the teaching that God is the giver of all that is good. Pelagius claimed that the influence of Adam on other humans was merely that of bad example. Augustine held that the effects of Adam's sin are transmitted to his descendants not by example but by the very fact of generation from that ancestor. A wounded nature comes to the soul and body of the new person from his/her parents, who experience "libido" (or "concupiscence"). Augustine's view was that human procreation was the way the transmission was being effected. He did not blame, however, the sexual passion itself, but the spiritual "concupiscence" present in human nature, soul and body, even after baptismal regeneration. Christian parents transmit their wounded nature to children, because they give them birth, not the "re-birth". Augustine used Ciceronian Stoic concept of passions, to interpret St. Paul's doctrine of universal sin and redemption. In that view, also sexual desire itself as well as other bodily passions were consequence of the original sin, in which pure affections were wounded by vice and became disobedient to human reason and will. As long as they carry a threat to the dominion of reason over the soul they constitute moral evil, but since they do not presuppose consent, one cannot call them sins. Humanity will be liberated from passions, and pure affections will be restored only when all sin has been washed away and ended, that is in the resurrection of the dead.
Augustine believed that the only definitive destinations of souls are heaven and hell. He concluded that unbaptized infants go to hell as a consequence of original sin. The Latin Church Fathers who followed Augustine adopted his position, which became a point of reference for Latin theologians in the Middle Ages. In the later medieval period, some theologians continued to hold Augustine's view, others held that unbaptized infants suffered no pain at all: unaware of being deprived of the beatific vision, they enjoyed a state of natural, not supernatural happiness. Starting around 1300, unbaptized infants were often said to inhabit the "limbo of infants". The "Catechism of the Catholic Church", 1261 declares: "As regards children who have died without Baptism, the Church can only entrust them to the mercy of God, as she does in her funeral rites for them. Indeed, the great mercy of God who desires that all men should be saved, and Jesus' tenderness toward children which caused him to say: 'Let the children come to me, do not hinder them,' allow us to hope that there is a way of salvation for children who have died without Baptism. All the more urgent is the Church's call not to prevent little children coming to Christ through the gift of holy Baptism." But the theory of Limbo, while it "never entered into the dogmatic definitions of the Magisterium ... remains ... a possible theological hypothesis".
Cassian.
In the works of John Cassian (c. 360 – 435), "Conference" XIII recounts how the wise monk Chaeremon, of whom he is writing, responded to puzzlement caused by his own statement that "man even though he strive with all his might for a good result, yet cannot become master of what is good unless he has acquired it simply by the gift of Divine bounty and not by the efforts of his own toil" (chapter 1). In chapter 11, Cassian presents Chaeremon as speaking of the cases of Paul the persecutor and Matthew the publican as difficulties for those who say "the beginning of free will is in our own power", and the cases of Zaccheus and the good thief on the cross as difficulties for those who say "the beginning of our free will is always due to the inspiration of the grace of God", and as concluding: "These two then; viz., the grace of God and free will seem opposed to each other, but really are in harmony, and we gather from the system of goodness that we ought to have both alike, lest if we withdraw one of them from man, we may seem to have broken the rule of the Church's faith: for when God sees us inclined to will what is good, He meets, guides, and strengthens us: for 'At the voice of thy cry, as soon as He shall hear, He will answer thee'; and: 'Call upon Me', He says, 'in the day of tribulation and I will deliver thee, and thou shalt glorify Me'. And again, if He finds that we are unwilling or have grown cold, He stirs our hearts with salutary exhortations, by which a good will is either renewed or formed in us."
Cassian did not accept the idea of total depravity, on which Martin Luther was to insist. He taught that human nature is fallen or depraved, but not totally. Augustine Casiday states that, at the same time, Cassian "baldly asserts that God's grace, not human free will, is responsible for 'everything which pertains to salvation' – even faith." Cassian pointed out that people still have moral freedom and one has the option to choose to follow God. Colm Luibhéid says that, according to Cassian, there are cases where the soul makes the first little turn, but in Cassian's view, according to Casiday, any sparks of goodwill that may exist, not "directly" caused by God, are totally inadequate and only "direct" divine intervention ensures spiritual progress; and Lauren Pristas says that "for Cassian, salvation is, from beginning to end, the effect of God's grace."
Church reaction.
Opposition to Augustine's ideas about original sin, which he had developed in reaction to Pelagianism, arose rapidly. After a long and bitter struggle the general principles of Augustine's teaching were confirmed within Western Christianity by many councils, especially the Second Council of Orange in 529. However, while the Church condemned Pelagius, it did not endorse Augustine entirely and, while Augustine's authority was accepted, he was interpreted in the light of writers such as Cassian. Some of the followers of Augustine identified original sin with concupiscence in the psychological sense, but this identification was challenged by the 11th-century Saint Anselm of Canterbury, who defined original sin as "privation of the righteousness that every man ought to possess", thus separating it from concupiscence. In the 12th century the identification of original sin with concupiscence was supported by Peter Lombard and others, but was rejected by the leading theologians in the next century, chief of whom was Thomas Aquinas. He distinguished the supernatural gifts of Adam before the Fall from what was merely natural, and said that it was the former that were lost, privileges that enabled man to keep his inferior powers in submission to reason and directed to his supernatural end. Even after the fall, man thus kept his natural abilities of reason, will and passions. Rigorous Augustine-inspired views persisted among the Franciscans, though the most prominent Franciscan theologians, such as Duns Scotus and William of Ockham, eliminated the element of concupiscence.
Protestant reformation.
Martin Luther (1483–1546) asserted that humans inherit Adamic guilt and are in a state of sin from the moment of conception. The second article in Lutheranism's Augsburg Confession presents its doctrine of original sin in summary form:
Luther, however, also agreed with the Roman Catholic doctrine of the Immaculate Conception (that Mary was conceived free from original sin) by saying:
Protestant Reformer John Calvin (1509–1564) developed a systematic theology of Augustinian Protestantism by interpretation of Augustine of Hippo's notion of original sin. Calvin believed that humans inherit Adamic guilt and are in a state of sin from the moment of conception. This inherently sinful nature (the basis for the Calvinistic doctrine of "total depravity") results in a complete alienation from God and the total inability of humans to achieve reconciliation with God based on their own abilities. Not only do individuals inherit a sinful nature due to Adam's fall, but since he was the federal head and representative of the human race, all whom he represented inherit the guilt of his sin by imputation. Redemption by Jesus Christ is the only remedy.
John Calvin defined original sin in his "Institutes of the Christian Religion" as follows: 
Council of Trent.
The Council of Trent (1545–1563), while not pronouncing on points disputed among Catholic theologians, condemned the teaching that in baptism the whole of what belongs to the essence of sin is not taken away, but is only cancelled or not imputed, and declared the concupiscence that remains after baptism not truly and properly "sin" in the baptized, but only to be called sin in the sense that it is of sin and inclines to sin.
In 1567, soon after the close of the Council of Trent, Pope Pius V went beyond Trent by sanctioning Aquinas's distinction between nature and supernature in Adam's state before the Fall, condemned the identification of original sin with concupiscence, and approved the view that the unbaptized could have right use of will.
Denominational views.
Roman Catholicism.
The "Catechism of the Catholic Church" says:
By his sin Adam, as the first man, lost the original holiness and justice he had received from God, not only for himself but for all humans.
Adam and Eve transmitted to their descendants human nature wounded by their own first sin and hence deprived of original holiness and justice; this deprivation is called "original sin".
As a result of original sin, human nature is weakened in its powers, subject to ignorance, suffering and the domination of death, and inclined to sin (this inclination is called "concupiscence").
The Catholic Church teaches that every human person born on this earth is made in the image of God. Within man "is both the powerful surge toward the good because we are made in the image of God, and the darker impulses toward evil because of the effects of Original Sin." Furthermore, it explicitly denies that we inherit "guilt" from anyone, maintaining that instead we inherit our fallen nature. In this it differs from the Calvinism/Protestant position that each person actually inherits Adam's guilt, and teaches instead that "original sin does not have the character of a personal fault in any of Adam's descendants ... but the consequences for nature, weakened and inclined to evil, persist in man". "In other words, human beings do not bear any 'original guilt' from Adam and Eve's particular sin."
The Church has always held baptism to be "for the remission of sins", and, as mentioned in "Catechism of the Catholic Church", 403, infants too have traditionally been baptized, though not guilty of any actual personal sin. The sin that through baptism was remitted for them could only be original sin, with which they were connected by the very fact of being a human. The first comprehensive theological explanation of this practice of baptizing infants, guilty of no actual personal sin, was given by Saint Augustine of Hippo, not all of whose ideas on original sin have been adopted by the Catholic Church. Indeed, the Church has condemned the interpretation of some of his ideas by certain leaders of the Protestant Reformation.
The "Catechism of the Catholic Church" explains that in "yielding to the tempter, Adam and Eve committed a "personal sin", but this sin affected "the human nature" that they would then transmit in a "fallen state" ... original sin is called "sin" only in an analogical sense: it is a sin "contracted" and not "committed"—a state and not an act" ("Catechism of the Catholic Church", 404). This "state of deprivation of the original holiness and justice ... transmitted to the descendants of Adam along with human nature" ("Compendium of the Catechism of the Catholic Church", 76) involves no personal responsibility or personal guilt on their part (cf. "Catechism of the Catholic Church", 405). Personal responsibility and guilt were Adam's, who because of his sin, was unable to pass on to his descendants a human nature with the holiness with which it would otherwise have been endowed, in this way implicating them in his sin. The doctrine of original sin thus does not impute the sin of the father to his children, but merely states that they inherit from him a "human nature deprived of original holiness and justice", which is "transmitted by propagation to all mankind".
In the theology of the Catholic Church, original sin is regarded as the general condition of sinfulness, that is (the absence of holiness and perfect charity) into which humans are born, distinct from the actual sins that a person commits. This teaching explicitly states that "original sin does not have the character of a personal fault in any of Adam's descendants". In other words, human beings do not bear any "original guilt" from Adam's particular sin, which is his alone. The prevailing view, also held in Eastern Orthodoxy, is that human beings bear no guilt for the sin of Adam. The Catholic Church teaches: "By our first parents' sin, the devil has acquired a certain domination over man, even though "man remains free"."
The Catholic doctrine of the Immaculate Conception of Mary is that Mary was conceived free from original sin: "the most Blessed Virgin Mary was, from the first moment of her conception, by a singular grace and privilege of almighty God and by virtue of the merits of Jesus Christ, Savior of the human race, preserved immune from all stain of original sin." The doctrine sees her as an exception to the general rule that human beings are not immune from the reality of original sin.
Eastern Orthodoxy.
The Eastern Orthodox's version of "original sin" is the view that sin originates with the Devil, "for the devil sinneth from the beginning. (1 John iii. 8)". They acknowledge that the introduction of ancestral sin into the human race affected the subsequent environment for humanity (see also traducianism). However, they never accepted Augustine of Hippo's notions of original sin and hereditary guilt.
Orthodox Churches accept the teachings of John Cassian, as do Catholic Churches eastern and western, in rejecting the doctrine of Total Depravity, by teaching that human nature is "fallen", that is, depraved, but not totally. Augustine Casiday states that Cassian "baldly asserts that God's grace, not human free will, is responsible for 'everything which pertains to salvation' – even faith." Cassian points out that people still have moral freedom and one has the option to choose to follow God. Colm Luibhéid says that, according to Cassian, there are cases where the soul makes the first little turn, while Augustine Casiday says that, in Cassian's view, any sparks of goodwill that may exist, not "directly" caused by God, are totally inadequate and only "direct" divine intervention ensures spiritual progress. and Lauren Pristas says that "for Cassian, salvation is, from beginning to end, the effect of God's grace."
Eastern Orthodoxy accepts the doctrine of ancestral sin: "Original sin is hereditary. It did not remain only Adam and Eve's. As life passes from them to all of their descendants, so does original sin." "As from an infected source there naturally flows an infected stream, so from a father infected with sin, and consequently mortal, there naturally proceeds a posterity infected like him with sin, and like him mortal."
The Orthodox Church in America makes clear the distinction between "fallen nature" and "fallen man" and this is affirmed in the early teaching of the Church whose role it is to act as the catalyst that leads to true or inner redemption. Every human person born on this earth bears the image of God undistorted within themselves. In the Orthodox Christian understanding, they explicitly deny that humanity inherited "guilt" from anyone. Rather, they maintain that we inherit our fallen nature. While humanity does bear the consequences of the original, or first, sin, humanity does not bear the personal guilt associated with this sin. Adam and Eve are guilty of their willful action; we bear the consequences, chief of which is death."
On whether Mary actually ever sinned, or was stained by original sin, the view of the Eastern Orthodox Church varies, though there is general agreement that she was cleansed from sin at the Annunciation.
Classical Anglicanism.
The original formularies of the Church of England also continue in the Reformation understanding of Original Sin. In the Thirty-Nine Articles, Article IX "Of Original or Birth-sin" states:
However, more recent doctrinal statements (e.g. the 1938 report "Doctrine in the Church of England") permit a greater variety of understandings of this doctrine. The 1938 report summarizes:
Methodism.
The Methodist Church upholds Article VII in the Articles of Religion in the "Book of Discipline of the United Methodist Church": 
Seventh-day Adventism.
Seventh-day Adventists believe that humans are inherently sinful due to the fall of Adam, but they do not totally accept the Augustinian/Calvinistic understanding of original sin, taught in terms of original guilt, but hold more to what could be termed the "total depravity" tradition. Seventh-day Adventists have historically preached a doctrine of inherited weakness, but not a doctrine of inherited guilt. According to Augustine and Calvin, humanity inherits not only Adam's depraved nature but also the actual guilt of his transgression, and Adventists look more toward the Wesleyan model.
In part, the Adventist position on original sin reads:
Early Adventists Pioneers (such as George Storrs and Uriah Smith) tended to de-emphasise the morally corrupt nature inherited from Adam, while stressing the importance of actual, personal sins committed by the individual. They thought of the "sinful nature" in terms of physical mortality rather than moral depravity. Traditionally, Adventists look at sin in terms of willful transgressions, and that Christ triumphed over sin. Adventism believes that Christ is both our Substitute and our Example. They base their belief on texts such as "Whosoever committeth sin transgresseth also the law: for sin is the transgression of the law." (1 John 3:4)
Though believing in the concept of inherited sin from Adam, there is no dogmatic Adventist position on original sin. Related articles dealing with the subject are publicly available on the General Conference of the Seventh-day Adventist Church’s official website on theological doctrine, the Biblical Research Institute.
Jehovah's Witnesses.
According to Jehovah's Witnesses, all humans are born sinners and inherit sin, corruption, and death from Adam. They believe Adam was originally created perfect and sinless, but with free will; the Devil, who was originally a perfect angel, but later developed feelings of pride and self-importance, seduced Eve, and then through her, persuaded Adam to disobey God, and to obey the Devil instead, rebelling against God's sovereignty, making themselves sinners and transmitting a sinful nature to their offspring. Instead of destroying the Devil right away, as well as destroying the disobedient couple, God decided to test the loyalty of the rest of humankind, and to prove to that man cannot be independent of God successfully, that man is lost without God's laws and standards, and can never bring peace to the earth, and that Satan was a deceiver, murderer, and liar.
Witnesses believe that all men possess "inherited sin" from the "one man" Adam, and that man is born corrupt, and dies because of inherited sin and imperfection, that inherited sin is the reason and cause for sickness and suffering, made worse by the Devil's wicked influence. They believe Jesus is the "second Adam", being the sinless Son of God and the Messiah, and that he came to undo Adamic sin; and that salvation and everlasting life can only be obtained through faith and obedience to the second Adam. They believe that "sin" is "missing the mark" of God's standard of perfection, and that everyone is born a sinner, due to being the offspring of sinner Adam.
Mormonism.
The Book of Mormon, a text sacred to Mormonism, contains an original sin doctrine in which humanity inherited a fallen and depraved nature from Adam. Young children, however, are thought to be held innocent until an age of accountability. As Mormon doctrines developed, founder Joseph Smith ultimately taught that humans had an essentially godlike nature, and were not only holy in a premortal state, but could progress eternally to become like God. He wrote as an Article of Faith, "We believe that men will be punished for their own sins, and not for Adam’s transgression." Later Mormons took this creed as a rejection of the doctrine of original sin and any notion of inherited sinfulness. Thus, while modern Mormons will agree that the fall of Adam brought consequences to the world, including the possibility of sin, they generally reject the idea that any culpability is automatically transmitted to Adam and Eve's offspring.
Swedenborgianism.
In Swedenborgianism, exegesis of the first 11 chapters of Genesis from "The First Church", has a view that Adam is not an individual person. Rather, he is a symbolic representation of the "Most Ancient Church", having a more direct contact with heaven than all other successive churches. Swedenborg's view of original sin is referred to as "hereditary evil", which passes from generation to generation. It cannot be completely abolished by an individual man, but can be tempered when someone reforms their own life, and are thus held accountable only for their own sins.
Islam.
The concept of original sin is not recognized in Islam. Muslims believe that Adam and Eve were forgiven by God, and use the following Koranic "suras" to support this belief:
"O Adam, dwell with your wife in the Garden and enjoy as you wish but approach not this tree or you run into harm and transgression. Then Satan whispered to them in order to reveal to them their shame that was hidden from them and he said: 'Your Lord only forbade you this tree lest you become angels or such beings as live forever.' And he swore to them both that he was their sincere adviser. So by deceit he brought them to their fall: when they tasted the tree their shame became manifest to them and they began to sew together the leaves of the Garden over their bodies. And their Lord called unto them: 'Did I not forbid you that tree and tell you that Satan was your avowed enemy?" Sūrat al-Aʻrāf:19–22.
"They said: 
'Our Lord, we have wronged ourselves souls. If You forgive us not and bestow not upon us Your mercy, we shall certainly be of the losers' " Surat al-Aʻrāf:23
".. Thus did Adam disobey his Lord, so he went astray. Then his Lord chose him, and turned to him with forgiveness, and gave him guidance." Surat Ṭā Hāʼ:121–122
"(ِGod) said: 
'Get down (from the Garden), one of you an enemy to the other [i.e. Adam, Eve, and Satan]. On earth will be a dwelling-place for you and an enjoyment – for a short time'. He (God) said: 'Therein you shall live, and therein you shall die, and from it you shall be brought out [i.e. resurrected]." Surat al-Aʻrāf:24–25.
"That no burdened person (with sins) shall bear the burden (sins) of another. And that man can have nothing but what he does (of good and bad). And that his deeds will be seen, Then he will be recompensed with a full and the best [fair] recompense." Surat an-Najm:38–41
Criticism.
Historian Robin Lane Fox argues that the foundation of the doctrine of "original sin", that was accepted by the Church, was based on a "mis-translation" of Paul the Apostle's Epistle to the Romans () by Augustine, in his "On the Grace of Christ, and on Original Sin".
In an 8-page contribution, I.J.J. Spangenberg has stated:
That what Spangenberg calls "traditional theology" is not the only accepted contemporary theology is evident from the writings of Reinhold Niebuhr and others reviewed in Jerry D. Korsmeyer's "Evolution and Eden" and Tatha Wiley's "Original Sin: Origins, Developments, Contemporary Meanings", and from the fact that, with regard to official Catholic Church doctrine on original sin, the authoritative "Catechism of the Catholic Church" "explicitly acknowledges that the account of the fall in Genesis 2 and 3 uses figurative language". Difficulty for what Spangenberg calls the dialogue between religion and science arises, in the view of Korsmeyer, from a confrontation between a few popularizers of scientific knowledge and "religious fundamentalists who consider that their religious knowledge includes scientific conclusions drawn from the Bible".

</doc>
<doc id="22738" url="https://en.wikipedia.org/wiki?curid=22738" title="Operation Enduring Freedom">
Operation Enduring Freedom

Operation Enduring Freedom (OEF) is the official name used by the government of the United States of America to describe the Global War on Terrorism.
The Operation comprises several subordinate operations:
Etymology.
The U.S. government used the term "Operation Enduring Freedom - Afghanistan" to officially describe the War in Afghanistan, from the period between October 2001 and December 2014. Continued operations in Afghanistan by the United States' military forces, both non-combat and combat, now occur under the name Operation Freedom's Sentinel.
The operation was originally called "Operation Infinite Justice", but as similar phrases have been used by adherents of several religions as an exclusive description of God, it is believed to have been changed to avoid offense to Muslims, who are the majority religion in Afghanistan. In September 2001, U.S. President George W. Bush's remark that "this crusade, this war on terrorism, is going to take a while", which prompted widespread criticism from the Islamic world, may also have contributed to the renaming of the operation.
The term "OEF-A" typically refers to the phase of the War in Afghanistan from 2001 to 2014. Other operations, such as the Georgia Train and Equip Program, are only loosely or nominally connected, such as through government funding vehicles. All the operations, however, have a focus on counterterrorism activities.
Operation Enduring Freedom – Afghanistan, which was a joint U.S., U.K., and Afghan operation, was separate from the International Security Assistance Force (ISAF), which was an operation of North Atlantic Treaty Organization nations including the U.S. and the U.K. The two operations ran in parallel, and although it had been suggested that they merge.
Overview.
In response to the attacks of 11 September, the early combat operations that took place on 7 October 2001 to include a mix of strikes from land-based B-1 Lancer, B-2 Spirit and B-52 Stratofortress bombers, carrier-based F-14 Tomcat and F/A-18 Hornet fighters, and Tomahawk cruise missiles launched from both U.S. and British ships and submarines signaled the start of Operation Enduring Freedom – Afghanistan (OEF-A).
The initial military objectives of OEF-A, as articulated by President George W. Bush in his 20 September Address to a Joint Session of Congress and his 7 October address to the country, included the destruction of terrorist training camps and infrastructure within Afghanistan, the capture of al-Qaeda leaders, and the cessation of terrorist activities in Afghanistan."
In January 2002, over 1,200 soldiers from the United States Special Operations Command Pacific (SOCPAC) deployed to the Philippines to support the Armed Forces of the Philippines (AFP) in their push to uproot terrorist forces on the island of Basilan. Of those groups included are Abu Sayyaf Group (ASG), al-Qaeda and Jemaah Islamiyah. The operation consisted of training the AFP in counter-terrorist operations as well as supporting the local people with humanitarian aid in Operation Smiles.
In October 2002, the Combined Task Force 150 and United States military Special Forces established themselves in Djibouti at Camp Lemonnier. The stated goals of the operation were to provide humanitarian aid and patrol the Horn of Africa to reduce the abilities of terrorist organizations in the region. Similar to OEF-P, the goal of humanitarian aid was emphasised, ostensibly to prevent militant organizations from being able to take hold amongst the population as well as reemerge after being removed.
The military aspect involves coalition forces searching and boarding ships entering the region for illegal cargo as well as providing training and equipment to the armed forces in the region. The humanitarian aspect involves building schools, clinics and water wells to enforce the confidence of the local people.
Since 2001, the cumulative expenditure by the U.S. government on Operation Enduring Freedom has exceeded $150 billion.
The operation continues, with military direction mostly coming from United States Central Command.
Operation Enduring Freedom – Afghanistan (OEF-A).
The Taliban.
Seizing upon a power vacuum after the Soviets withdrew from Afghanistan after their invasion, the Taliban assumed the role of government from 1996–2001. Their extreme interpretation of Islamic law prompted them to ban music, television, sports, and dancing, and enforce harsh judicial penalties (See Human rights in Afghanistan). Amputation was an accepted form of punishment for stealing, and public executions could often be seen at the Kabul football stadium. Women's rights groups around the world were frequently critical as the Taliban banned women from appearing in public or holding many jobs outside the home. They drew further criticism when they destroyed the Buddhas of Bamyan, historical statues nearly 1500 years old, because the Buddhas were considered idols.
In 1996, Saudi dissident Osama bin Laden moved to Afghanistan upon the invitation of the Northern Alliance leader Abdur Rabb ur Rasool Sayyaf. When the Taliban came to power, bin Laden was able to forge an alliance between the Taliban and his al-Qaeda organization. It is understood that al-Qaeda-trained fighters known as the 055 Brigade were integrated with the Taliban army between 1997 and 2001. It has been suggested that the Taliban and bin Laden had very close connections.
US-led coalition action.
On 20 September 2001, the U.S. stated that Osama bin Laden was behind the 11 September attacks in 2001. The US made a five-point ultimatum to the Taliban:
On 21 September 2001, the Taliban rejected this ultimatum, stating there was no evidence in their possession linking bin Laden to the 11 September attacks.
On 22 September 2001 the United Arab Emirates and later Saudi Arabia withdrew their recognition of the Taliban as the legal government of Afghanistan, leaving neighboring Pakistan as the only remaining country with diplomatic ties.
On 4 October 2001, it is believed that the Taliban covertly offered to turn bin Laden over to Pakistan for trial in an international tribunal that operated according to Islamic shar'ia law.
On 7 October 2001, the Taliban proposed to try bin Laden in Afghanistan in an Islamic court. This proposition was immediately rejected by the US. Later on the same day, United States and British forces initiated military action against the Taliban, bombing Taliban forces and al-Qaeda terrorist training camps.
On 14 October 2001, the Taliban proposed to hand bin Laden over to a third country for trial, but only if they were given evidence of bin Laden's involvement in the events of 11 September 2001. The US rejected this proposal and military operations ensued.
The UN Security Council, on 16 January 2002, unanimously established an arms embargo and the freezing of identifiable assets belonging to bin Laden, al-Qaeda, and the remaining Taliban.
Combat operations start.
On Sunday 7 October 2001, American and British forces began an aerial bombing campaign targeting Taliban forces and al-Qaeda.
The Northern Alliance, aided by Joint Special Operations teams consisting of Green Berets from the 5th Special Forces Group, aircrew members from the 160th Special Operations Aviation Regiment (SOAR), and Air Force Combat Controllers, fought against the Taliban. Aided by U.S. bombing and massive defections, they captured Mazari Sharif on 9 November. They then rapidly gained control of most of northern Afghanistan, and took control of Kabul on 13 November after the Taliban unexpectedly fled the city. The Taliban were restricted to a smaller and smaller region, with Kunduz, the last Taliban-held city in the north, captured on 26 November. Most of the Taliban fled to Pakistan.
The war continued in the south of the country, where the Taliban retreated to Kandahar. After Kandahar fell in December, remnants of the Taliban and al-Qaeda continued to mount resistance. Meanwhile, in November 2001 the U.S. military and its allied forces established their first ground base in Afghanistan to the south west of Kandahar, known as FOB Rhino.
The Battle of Tora Bora, involving U.S., British and Northern Alliance forces took place in December 2001 to further destroy the Taliban and suspected al-Qaeda in Afghanistan. In early March 2002 the United States military, along with allied Afghan military forces, conducted a large operation to destroy al-Qaeda in an operation code-named Operation Anaconda.
The operation was carried out by elements of the United States 10th Mountain Division, 101st Airborne Division, the U.S. special forces groups TF 11, TF Bowie, TF Dagger, TF K-Bar, British Royal Marines, the Norwegian "Forsvarets Spesialkommando" (FSK), "Hærens Jegerkommando" and "Marinejegerkommandoen", Canada's 3rd Battalion Princess Patricia's Canadian Light Infantry, Canada's Joint Task Force 2, the German KSK, and elements of the Australian Special Air Service Regiment and of the New Zealand Special Air Service and the Afghan National Army.
After managing to evade U.S. forces throughout the summer of 2002, the remnants of the Taliban gradually began to regain their confidence. A U.S. and Canadian led operation (supported by British and Dutch forces), Operation Mountain Thrust was launched in May 2006 to counter renewed Taliban insurgency.
Since January 2006, the NATO International Security Assistance Force undertook combat duties from Operation Enduring Freedom in southern Afghanistan, the NATO force chiefly made up of British, Canadian and Dutch forces (and some smaller contributions from Denmark, Romania and Estonia and air support from Norway as well as air and artillery support from the U.S.) ("see the article Coalition combat operations in Afghanistan in 2006"). The United States military also conducts military operations separate from NATO as part of Operation Enduring Freedom in other parts of Afghanistan, in areas such as Kandahar, Bagram, and Kabul (including Camp Eggers and Camp Phoenix.)
International support.
The United States was supported by during Operation Enduring Freedom (OEF) in Afghanistan in 2001–2003 and in subsequent coalition operations directly or indirectly in support of OEF. See the article Afghanistan War order of battle for the current disposition of coalition forces in Afghanistan.
Result.
The U.S.-led coalition initially removed the Taliban from power and seriously crippled al-Qaeda and associated militants in Afghanistan. However, success in quelling the Taliban insurgency since the 2001 invasion has been mixed. Many believe the Taliban cannot be defeated as long as it has sanctuary in neighboring Pakistan and that Operation Enduring Freedom has transformed into a continuing full-fledged war with no end in sight.
On 9 October 2004, Afghanistan elected Hamid Karzai president in its first direct elections. The following year, Afghans conducted the Afghan parliamentary election, 2005 on 18 September. Since the invasion, hundreds of schools and mosques have been constructed, millions of dollars in aid have been distributed, and the occurrence of violence has been reduced.
While military forces interdict insurgents and assure security, Provincial reconstruction teams are tasked with infrastructure building, such as constructing roads and bridges, assisting during floods, and providing food and water to refugees. Many warlords have participated in an allegiance program, recognizing the legitimacy of the government of Afghanistan, and surrendering their soldiers and weapons; however, subsequent actions have led to questions about their true loyalties.
The Afghan National Army, Afghan National Police, and Afghan Border Police are being trained to assume the task of securing their nation.
On 31 December 2014, Operation Enduring Freedom - Afghanistan concluded, and was succeeded by Operation Freedom's Sentinel on 1 January 2015.
Criticism.
AFP, reporting on a news story in the Sunday, 3 April 2004, issue of "The New Yorker", wrote that retired Army Colonel Hy Rothstein, "who served in the Army Special Forces for more than 20 years, ...commissioned by The Pentagon to examine the war in Afghanistan concluded the conflict created conditions that have given 'warlordism, banditry and opium production a new lease on life'..."
The conduct of U.S. forces was criticised in a report entitled Enduring Freedom – Abuses by U.S. Forces in Afghanistan by U.S.-based human rights group Human Rights Watch in 2004. Some Pakistani scholars, such as Masood Ashraf Raja, editor of , have also provided a more specific form of criticism that relates to the consequences of the Global War on Terrorism on the region.
Operation Enduring Freedom – Philippines (OEF-P).
Abu Sayyaf Group.
The Abu Sayyaf Group (ASG) Al Harakat Al Islamiyya, is deemed a "foreign terrorist organization" by the United States government. Specifically, it is an Islamist separatist group based in and around the southern islands of the Republic of the Philippines, primarily Jolo, Basilan, and Mindanao.
Since inception in the early 1990s, the group has carried out bombings, assassinations, kidnappings, and extortion in their fight for an independent Islamic state in western Mindanao and the Sulu Archipelago. Its claimed overarching goal is to create a Pan-Islamic superstate across the "Malay" portions of Southeast Asia, spanning, from east to west, the large island of Mindanao, the Sulu Archipelago (Basilan and Jolo islands), the large island of Borneo (Malaysia and Indonesia), the South China Sea, and the Malay Peninsula (Peninsular Malaysia, Thailand and Myanmar).
Jemaah Islamiyah.
Jemaah Islamiyah is a militant Islamic terrorist organization dedicated to the establishment of a fundamentalist Islamic theocracy in Southeast Asia, in particular Indonesia, Singapore, Brunei, Malaysia, the south of Thailand and the Philippines.
Financial links between Jemaah Islamiyah and other terrorist groups, such as Abu Sayyaf and al-Qaeda, have been found to exist. Jemaah Islamiyah means "Islamic Group" or "Islamic Community" and is often abbreviated JI.
Jemaah Islamiyah is thought to have killed hundreds of civilians. Also, it is suspected of carrying out the Bali car bombing on 12 October 2002, in which suicide bombers attacked a nightclub killing 202 people and wounding many more. Most of the casualties were Australian tourists. After this attack, the U.S. State Department designated Jemaah Islamiyah as a Foreign Terrorist Organization. Jemaah Islamiyah is also suspected of carrying out the Zamboanga bombings, the Metro Manila bombings, the 2004 Australian embassy bombing and the 2005 Bali terrorist bombing.
U.S. actions.
In January 2002, 1,200 members of United States Special Operations Command, Pacific (SOCPAC) were deployed to the Philippines to assist the Armed Forces of the Philippines (AFP) in uprooting al-Qaeda, Jemaah Islamiyah and Abu Sayyaf. The members of SOCPAC were assigned to assist in military operations against the terrorist forces as well as humanitarian operations for the island of Basilan, where most of the conflict was expected to take place.
The United States Special Forces (SF) unit trained and equipped special forces and scout rangers of the AFP, creating the Light Reaction Company (LRC). The LRC and elements of SOCPAC deployed to Basilan on completion of their training. The stated goals of the deployment were denying the ASG sanctuary, surveiling, controlling, and denying ASG routes, surveiling supporting villages and key personnel, conducting local training to overcome AFP weaknesses and sustain AFP strengths, supporting operations by the AFP "strike force" (LRC) in the area of responsibility (AOR), conducting and supporting civil affairs operations in the AOR.
Result.
The desired result was for the AFP to gain sufficient capability to locate and destroy the ASG, to recover hostages and to enhance the legitimacy of the Philippine government. Much of the operation was a success: the ASG was driven from Basilan and one U.S. hostage was recovered. The Abu Sayyaf Group's ranks, which once counted more than 800 members, was reduced to less than 100. The humanitarian portion of the operation, Operation Smiles, created 14 schools, 7 clinics, 3 hospitals and provided medical care to over 18,000 residents of Basilan. Humanitarian groups were able to continue their work without fear of further kidnappings and terrorists attacks by the Abu Sayyaf Group.
Operation Enduring Freedom – Horn of Africa (OEF-HOA).
Unlike other operations contained in Operation Enduring Freedom, OEF-HOA does not have a specific terrorist organization as a target. OEF-HOA instead focuses its efforts to disrupt and detect terrorist activities in the region and to work with host nations to deny the reemergence of terrorist cells and activities. Operations began in mid-2002 at Camp Lemonier by a Combined Joint Special Operations Task Force (CJSOTF) augmented by support forces from Fort Stewart, Fort Hood, and Fort Story. In October 2002, the Combined Joint Task Force, Horn of Africa (CJTF-HOA) was established at Djibouti at Camp Lemonier, taking over responsibilities from the CJSOTF. CJTF-HOA comprised approximately 2,000 personnel including U.S. military and Special Operations Forces (SOF), and coalition force members, Combined Task Force 150 (CTF-150). The coalition force consists of ships from Australia, Canada, France, Germany, Netherlands, Italy, Pakistan, New Zealand, Spain, Turkey and the United Kingdom. The primary goal of the coalition forces is to monitor, inspect, board and stop suspected shipments from entering the Horn of Africa region.
CJTF-HOA has devoted the majority of its efforts to train selected armed forces units of the countries of Djibouti, Kenya and Ethiopia in counterterrorism and counterinsurgency tactics. Humanitarian efforts conducted by CJTF-HOA include the rebuilding of schools and medical clinics, as well as providing medical services to those countries whose forces are being trained. The program expands as part of the Trans-Saharan Counter Terrorism Initiative as CJTF personnel also assist in training the forces of Chad, Niger, Mauritania and Mali.
US action.
Anti-piracy operations were undertaken by the coalition throughout 2006 with a battle fought in March when US vessels were attacked by pirates. In January 2007, during the war in Somalia, an AC-130 airstrike was conducted against al-Qaeda members embedded with forces of the Islamic Courts Union (ICU) operating in southern Somalia near Ras Kamboni. US naval forces, including the aircraft carrier USS "Dwight D. Eisenhower", were positioned off the coast of Somalia to provide support and to prevent any al-Qaeda forces escaping by sea. Actions against pirates also occurred in June and October 2007 with varying amounts of success.
Military decorations.
Since 2002, the United States military has created military awards and decorations related to Operation Enduring Freedom
NATO also created a military decoration related to Operation Enduring Freedom:
References.
http://www.politifact.com/truth-o-meter/promises/obameter/promise/1096/end-war-afghanistan-2014/

</doc>
<doc id="22739" url="https://en.wikipedia.org/wiki?curid=22739" title="Obfuscation (software)">
Obfuscation (software)

In software development, obfuscation is the deliberate act of creating obfuscated code, i.e. source or machine code that is difficult for humans to understand. Like obfuscation in natural language, it may use needlessly roundabout expressions to compose statements.
Programmers may deliberately obfuscate code to conceal its purpose (security through obscurity) or its logic, in order to prevent tampering, deter reverse engineering, or as a puzzle or recreational challenge for someone reading the source code.
Programs known as "obfuscators" transform readable code into obfuscated code using various techniques.
Overview.
The architecture and characteristics of some languages may make them easier to obfuscate than others. C, C++, and the Perl programming language are some examples of languages easy to obfuscate.
Recreational obfuscation.
Writing and reading obfuscated source code can be a brain teaser for programmers. A number of programming contests reward the most creatively obfuscated code: the International Obfuscated C Code Contest, Obfuscated Perl Contest, and International Obfuscated Ruby Code Contest.
Types of obfuscations include simple keyword substitution, use or non-use of whitespace to create artistic effects, and self-generating or heavily compressed programs.
Short obfuscated Perl programs may be used in signatures of Perl programmers. These are JAPHs ("Just another Perl hacker").
Examples.
This is a winning entry from the International Obfuscated C Code Contest written by Ian Phillipps in 1988 and subsequently reverse engineered by Thomas Ball.
It is a C program that when compiled and run will generate the 12 verses of "The 12 Days of Christmas". It contains all the strings required for the poem in an encoded form within the code.
A non-winning entry from the same year, this next example illustrates creative use of whitespace; it generates mazes of arbitrary length:
Modern C compilers don't allow constant strings to be overwritten, which can be avoided by changing "*M" to "M[3]" and omitting "M=".
The following example by Óscar Toledo Gutiérrez, Best of Show entry in the 19th IOCCC, implements a 8080 emulator complete with terminal and disk controller, capable of booting CP/M-80 and running CP/M applications,
An example of a JAPH:
This slowly displays the text "Just another Perl / Unix hacker", multiple characters at a time, with delays. An explanation can be found here.
Some Python examples can be found in the official Python programming FAQ.
Disadvantages of obfuscation.
Obfuscation can make reading, writing and reverse-engineering a program difficult and time-consuming, but not necessarily impossible. Some anti-virus software, such as AVG, will also alert their users when they land on a site with code obfuscated, as one of the purposes of obfuscation can be to hide malicious code. However, some developers may employ code obfuscation for the purpose of reducing file size or increasing security. The average user may not expect their antivirus software to provide alerts about an otherwise harmless piece of code, especially from trusted corporations, so such a feature may actually serve as a deterrent.
Obfuscating software.
A variety of tools exist to perform or assist with code obfuscation.
These include experimental research tools created by academics, hobbyist tools,
commercial products written by professionals, and open-source software.
There also exist deobfuscation tools that attempt to perform the reverse
transformation.
Although the majority of commercial obfuscation solutions work by transforming
either program source
code, or platform-independent bytecode as used by
Java and
.NET, there are also some that work with C and
C++ - languages that are typically compiled to native code, or work directly on compiled binaries.
Obfuscation and copyleft licenses.
There has been debate on whether it is illegal to skirt copyleft software licenses by releasing source code in obfuscated form, such as in cases in which the author is less willing to make the source code available. The issue is addressed in the GNU General Public License by defining source code as the "preferred" version of the source code be made available. The GNU website states "Obfuscated 'source code' is not real source code and does not count as source code." 

</doc>
<doc id="22742" url="https://en.wikipedia.org/wiki?curid=22742" title="Ötzi">
Ötzi

Ötzi (; also called Ötzi the Iceman, the Similaun Man, the Man from Hauslabjoch, the Tyrolean Iceman, Homo tyrolensis, and the Hauslabjoch mummy) is a well-preserved natural mummy of a man who lived around 3,300 BCE, more precisely between 3359 and 3105 BCE, with a 66% chance that he died between 3239 and 3105 BCE. The mummy was found in September 1991 in the Ötztal Alps, hence the nickname "Ötzi", near the Similaun mountain and Hauslabjoch on the border between Austria and Italy. He is Europe's oldest known natural human mummy, and has offered an unprecedented view of Chalcolithic Europeans. His body and belongings are displayed in the South Tyrol Museum of Archaeology in Bolzano, South Tyrol, Italy.
Discovery.
Ötzi was found on 19 September 1991 by two German tourists, at an elevation of on the east ridge of the Fineilspitze in the Ötztal Alps on the Austrian–Italian border. The tourists, Helmut and Erika Simon, were walking off the path between the mountain passes Hauslabjoch and Tisenjoch. They believed that the body was of a recently deceased mountaineer. The next day, a mountain gendarme and the keeper of the nearby Similaunhütte first attempted to remove the body, which was frozen in ice below the torso, using a pneumatic drill and ice-axes, but had to give up due to bad weather. The next day, eight groups visited the site, amongst whom happened to be the famous mountaineers Hans Kammerlander and Reinhold Messner. The body was semi-officially extracted on 22 September and officially salvaged the following day. It was transported to the office of the medical examiner in Innsbruck, together with other objects found. On 24 September the find was examined there by archaeologist Konrad Spindler of the University of Innsbruck. He dated the find to be "about four thousand years old", based on the typology of an axe among the retrieved objects.
At the Treaty of Saint-Germain-en-Laye (1919), the border between North and South Tyrol was defined as the watershed of the rivers Inn and Etsch. However, near Tisenjoch the (now withdrawn) glacier complicated establishing the watershed at the time and the border was established too far north. Therefore, although Ötzi's find site drains to the Austrian side, surveys in October 1991 showed that the body had been located inside Italian territory as delineated in 1919. The province of South Tyrol therefore claimed property rights, but agreed to let Innsbruck University finish its scientific examinations. Since 1998, it has been on display at the South Tyrol Museum of Archaeology in Bolzano, the capital of South Tyrol.
Scientific analyses.
The corpse has been extensively examined, measured, X-rayed, and dated. Tissues and intestinal contents have been examined microscopically, as have the items found with the body. In August 2004, frozen bodies of three Austro-Hungarian soldiers killed during the Battle of San Matteo (1918) were found on the mountain Punta San Matteo in Trentino. One body was sent to a museum in the hope that research on how the environment affected its preservation would help unravel Ötzi's past.
Body.
By current estimates, at the time of his death Ötzi was approximately tall, weighed about and was about 45 years of age. When his body was found, it weighed . Because the body was covered in ice shortly after his death, it had only partially deteriorated. Analysis of pollen, dust grains and the isotopic composition of his tooth enamel indicates that he spent his childhood near the present village of Feldthurns, north of Bolzano, but later went to live in valleys about 50 kilometres farther north. Analysis by Franco Rollo's group at the University of Camerino has shown that Ötzi's mitochondrial DNA belongs to the K1 subcluster of the mitochondrial haplogroup K, but that it cannot be categorized into any of the three modern branches of that subcluster. Rollo's group published Ötzi's complete mtDNA sequence in 2008.
Analysis of Ötzi's intestinal contents showed two meals (the last one consumed about eight hours before his death), one of chamois meat, the other of red deer and herb bread. Both were eaten with grain as well as roots and fruits. The grain from both meals was a highly processed einkorn wheat bran, quite possibly eaten in the form of bread. In the proximity of the body, and thus possibly originating from the Iceman's provisions, chaff and grains of einkorn and barley, and seeds of flax and poppy were discovered, as well as kernels of sloes (small plumlike fruits of the blackthorn tree) and various seeds of berries growing in the wild. Hair analysis was used to examine his diet from several months before.
Pollen in the first meal showed that it had been consumed in a mid-altitude conifer forest, and other pollens indicated the presence of wheat and legumes, which may have been domesticated crops. Pollen grains of hop-hornbeam were also discovered. The pollen was very well preserved, with the cells inside remaining intact, indicating that it had been fresh (a few hours old) at the time of Ötzi's death, which places the event in the spring. Einkorn wheat is harvested in the late summer, and sloes in the autumn; these must have been stored from the previous year.
In 2009, a CAT scan revealed that the stomach had shifted upward to where his lower lung area would normally be. Analysis of the contents revealed the partly digested remains of ibex meat, confirmed by DNA analysis, suggesting he had a meal less than two hours before his death. Wheat grains were also found.
High levels of both copper particles and arsenic were found in Ötzi's hair. This, along with Ötzi's copper axe blade, which is 99.7% pure copper, has led scientists to speculate that Ötzi was involved in copper smelting.
By examining the proportions of Ötzi's tibia, femur and pelvis, Christopher Ruff has determined that Ötzi's lifestyle included long walks over hilly terrain. This degree of mobility is not characteristic of other Copper Age Europeans. Ruff proposes that this may indicate that Ötzi was a high-altitude shepherd.
Using modern 3-D technology, a facial reconstruction has been created for the South Tyrol Museum of Archaeology in Bolzano, Italy. It shows Ötzi looking old for his 45 years, with deep-set brown eyes, a beard, a furrowed face, and sunken cheeks. He is depicted looking tired and ungroomed.
Health.
Ötzi apparently had whipworm ("Trichuris trichiura"), an intestinal parasite. During CT scans, it was observed that three or four of his right ribs had been cracked when he had been lying face down after death, or where the ice had crushed his body. One of his fingernails (of the two found) shows three Beau's lines indicating he was sick three times in the six months before he died. The last incident, two months before he died, lasted about two weeks. Also, it was found that his epidermis, the outer skin layer, was missing, a natural process from his mummification in ice. Ötzi's teeth showed considerable internal deterioration from cavities. These oral pathologies may have been brought about by his grain-heavy, high carbohydrate diet. DNA analysis in February 2012 revealed that Ötzi was lactose intolerant, supporting the theory that lactose intolerance was still common at that time, despite the increasing spread of agriculture and dairying.
Skeletal details and tattooing.
Ötzi had a total of 61 tattoos, consisting of 19 groups of black lines ranging from 1 to 3 mm in thickness and 7 to 40 mm long. These include groups of parallel lines running along the longitudinal axis of his body and to both sides of the lumbar spine, as well as a cruciform mark behind the right knee and on the right ankle, and parallel lines around the left wrist. The greatest concentration of markings is found on his legs, which together exhibit 12 groups of lines. A microscopic examination of samples collected from these tattoos revealed that they were created from pigment manufactured out of fireplace ash or soot 
Radiological examination of Ötzi's bones showed "age-conditioned or strain-induced degeneration" corresponding to many tattooed areas, including osteochondrosis and slight spondylosis in the lumbar spine and wear-and-tear degeneration in the knee and especially in the ankle joints. It has been speculated that these tattoos may have been related to pain relief treatments similar to acupressure or acupuncture. If so, this is at least 2000 years before their previously known earliest use in China (c. 1000 BCE). Recent research into archaeological evidence for ancient tattooing has confirmed that Ötzi is the oldest tattooed human mummy yet discovered.
Clothes and shoes.
Ötzi's clothes were sophisticated. He wore a cloak made of woven grass and a coat, a belt, a pair of leggings, a loincloth and shoes, all made of leather of different skins. He also wore a bearskin cap with a leather chin strap. The shoes were waterproof and wide, seemingly designed for walking across the snow; they were constructed using bearskin for the soles, deer hide for the top panels, and a netting made of tree bark. Soft grass went around the foot and in the shoe and functioned like modern socks. The coat, belt, leggings and loincloth were constructed of vertical strips of leather sewn together with sinew. His belt had a pouch sewn to it that contained a cache of useful items: a scraper, drill, flint flake, bone awl and a dried fungus.
The shoes have since been reproduced by a Czech academic, who said that "because the shoes are actually quite complex, I'm convinced that even 5,300 years ago, people had the equivalent of a cobbler who made shoes for other people". The reproductions were found to constitute such excellent footwear that it was reported that a Czech company offered to purchase the rights to sell them. However, a more recent hypothesis by British archaeologist Jacqui Wood says that Ötzi's "shoes" were actually the upper part of snowshoes. According to this theory, the item currently interpreted as part of a "backpack" is actually the wood frame and netting of one snowshoe and animal hide to cover the face.
Tools and equipment.
Other items found with the Iceman were a copper axe with a yew handle, a flint-bladed knife with an ash handle and a quiver of 14 arrows with viburnum and dogwood shafts. Two of the arrows, which were broken, were tipped with flint and had fletching (stabilizing fins), while the other 12 were unfinished and untipped. The arrows were found in a quiver with what is presumed to be a bow string, an unidentified tool, and an antler tool which might have been used for sharpening arrow points. There was also an unfinished yew longbow that was long.
In addition, among Ötzi's possessions were berries, two birch bark baskets, and two species of polypore mushrooms with leather strings through them. One of these, the birch fungus, is known to have antibacterial properties, and was probably used for medicinal purposes. The other was a type of tinder fungus, included with part of what appeared to be a complex firelighting kit. The kit featured pieces of over a dozen different plants, in addition to flint and pyrite for creating sparks.
Ötzi's copper axe was of particular interest. The axe's haft is long and made from carefully worked yew with a right-angled crook at the shoulder, leading to the blade. The long axe head is made of almost pure copper, produced by a combination of casting, cold forging, polishing, and sharpening. It was let into the forked end of the crook and fixed there using birch-tar and tight leather lashing. The blade part of the head extends out of the lashing and shows clear signs of having been used to chop and cut. At the time, such an axe would have been a valuable possession, important both as a tool and as a status symbol for the bearer.
Genetic analysis.
A group of scientists have sequenced Ötzi's full genome and the report was published on 28 February 2012. The Y-DNA of Ötzi belongs to a subclade of G defined by the SNPs M201, P287, P15, L223 and L91 (G-L91, ISOGG G2a2b, former "G2a4"). He was not typed for any of the subclades downstreaming from G-L91. G-L91 is now mostly found in South Corsica.
Analysis of his mitochondrial DNA has shown that Ötzi belongs to the K1 subclade, but cannot be categorized into any of the three modern branches of that subclade (K1a, K1b or K1c). The new subclade has provisionally been named "K1ö" for "Ötzi". Multiplex assay study was able to confirm that the Iceman's mtDNA belongs to a previously unknown European mtDNA clade with a very limited distribution amongst modern data sets.
By autosomal DNA he is most closely related to southern Europeans, especially to the geographically isolated populations of the two Mediterranean islands of Sardinia and Corsica.
DNA analysis also showed him at high risk of atherosclerosis, lactose intolerance, and the presence of the DNA sequence of "Borrelia burgdorferi", possibly making him the earliest known human with Lyme disease. A later analysis suggested the sequence may have been a different "Borrelia" species.
A 2012 paper by paleoanthropologist John Hawks suggests that Ötzi had a higher degree of Neanderthal ancestry than modern Europeans.
In October 2013, it was reported that 19 modern Tyrolean men were related to Ötzi. Scientists from the Institute of Legal Medicine at Innsbruck Medical University had analysed the DNA of over 3,700 Tyrolean male blood donors and found 19 who shared a particular genetic mutation with the 5,300-year-old man, which led them to identify the link.
Blood.
In May 2012, scientists announced the discovery that Ötzi still had intact blood cells. These are the oldest complete human blood cells ever identified. In most bodies this old, the blood cells are either shrunken or mere remnants, but Ötzi's have the same dimensions as living red blood cells and resembled a modern-day sample.
Cause of death.
Initial speculation.
It was initially believed that Ötzi died from exposure during a winter storm. Later it was speculated that Ötzi may have been a victim of a ritual sacrifice, perhaps for being a chieftain. This explanation was inspired by theories previously advanced for the first millennium BCE bodies recovered from peat bogs such as the Tollund Man and the Lindow Man.
Theories involving struggle followed by cold death.
Initial data.
In 2001 X-rays and a CT scan revealed that Ötzi had an arrowhead lodged in his left shoulder when he died, and a matching small tear on his coat. The discovery of the arrowhead prompted researchers to theorize Ötzi died of blood loss from the wound, which would probably have been fatal even if modern medical techniques had been available. Further research found that the arrow's shaft had been removed before death, and close examination of the body found bruises and cuts to the hands, wrists and chest and cerebral trauma indicative of a blow to the head. One of the cuts was to the base of his thumb that reached down to the bone but had no time to heal before his death. Currently, it is believed that the cause of death was a blow to the head, however researchers are unsure of what inflicted the fatal injury.
Battle theory.
Unpublished and thus unconfirmed DNA analyses claim they revealed traces of blood from four other people on his gear: one from his knife, two from the same arrowhead, and a fourth from his coat. Interpretations of these findings were that Ötzi killed two people with the same arrow, and was able to retrieve it on both occasions, and the blood on his coat was from a wounded comrade he may have carried over his back. Ötzi's posture in death (frozen body, face down, left arm bent across the chest) could support a theory that before death occurred and rigor mortis set in, the Iceman was turned on to his stomach in the effort to remove the arrow shaft.
Burial theory.
In 2010, it was proposed that Ötzi died at a much lower altitude and was buried higher in the mountains, as posited by archaeologist Alessandro Vanzetti of the Sapienza University of Rome and his colleagues. According to their study of the items found near Ötzi and their locations, it is possible that the iceman may have been placed above what has been interpreted as a stone burial mound but was subsequently moved with each thaw cycle that created a flowing watery mix driven by gravity before being re-frozen.
While archaeobotanist Klaus Oeggl of the University of Innsbruck agrees that the natural process described probably caused the body to move from the ridge that includes the stone formation, he pointed out that the paper provided no compelling evidence to demonstrate that the scattered stones constituted a burial platform. Moreover, biological anthropologist Albert Zink argues that the iceman's bones display no dislocations that would have resulted from a downhill slide and that the intact blood clots in his arrow wound would show damage were the body carted up the mountain.
In either case, the burial theory does not contradict the possibility of a violent cause of death as stated in the preceding theories.
Legal dispute.
Italian law entitled the Simons to a finders' fee from the South Tyrolean provincial government of 25% of the value of Ötzi. In 1994 the authorities offered a "symbolic" reward of 10 million lire (€5,200), which the Simons turned down. In 2003, the Simons filed a lawsuit which asked a court in Bolzano to recognize their role in Ötzi's discovery and declare them his "official discoverers". The court decided in the Simons' favor in November 2003, and at the end of December that year the Simons announced that they were seeking US$300,000 as their fee. The provincial government decided to appeal.
In addition, two people came forward to claim that they were part of the same mountaineering party that came across Ötzi and discovered the body first:
According to The Telegraph report in 2005 the rival claims were heard by a Bolzano court. The legal case angered Mrs. Simon, who alleged that neither woman was present on the mountain that day. In 2005, Mrs. Simon's lawyer said: "Mrs. Simon is very upset by all this and by the fact that these two new claimants have decided to appear 14 years after Ötzi was found." In 2008, however, Jarc stated for a Slovene newspaper that she wrote two times to the Bolzano court in regard to her claim but received no reply whatsoever.
In 2004, Helmut Simon died. Two years later, in June 2006, an appeals court affirmed that the Simons had indeed discovered the Iceman and were therefore entitled to a finder's fee. It also ruled that the provincial government had to pay the Simons' legal costs. After this ruling, Mrs. Erika Simon reduced her claim to €150,000. The provincial government's response was that the expenses it had incurred to establish a museum and the costs of preserving the Iceman should be considered in determining the finder's fee. It insisted it would pay no more than €50,000. In September 2006, the authorities appealed the case to Italy's highest court, the Court of Cassation.
On 29 September 2008 it was announced that the provincial government and Mrs. Simon had reached a settlement of the dispute, under which she would receive €150,000 in recognition of Ötzi's discovery by her and her late husband and the tourist income that it attracts.
"Ötzi's curse".
Influenced by the "Curse of the pharaohs" and the media theme of cursed mummies, claims have been made that Ötzi is cursed. The allegation revolves around the deaths of several people connected to the discovery, recovery and subsequent examination of Ötzi. It is alleged that they have died under mysterious circumstances. These persons include co-discoverer Helmut Simon, and Konrad Spindler, the first examiner of the mummy in Austria in 1991. To date, the deaths of seven people, of which four were the result of some violence in the form of accidents, have been attributed to the alleged curse. In reality hundreds of people were involved in the recovery of Ötzi and are still involved in studying the body and the artifacts found with it. The fact that a small percentage of them have died over the years has not been shown to be statistically significant.

</doc>
<doc id="22743" url="https://en.wikipedia.org/wiki?curid=22743" title="Operation Deadlight">
Operation Deadlight

Operation "Deadlight" was the code name for the Royal Navy operation to scuttle German U-boats surrendered to the Allies after the defeat of Germany near the end of World War II.
Of the 156 U-boats that surrendered to the allies at the end of the war, 116 were scuttled as part of Operation "Deadlight". The operation was carried out by the Royal Navy and it was planned to tow the submarines to three areas about 100 miles north-west of Ireland and sink them. The areas were codenamed XX, YY and ZZ. The intention was to use XX as the main area for scuttling while 36 boats would be towed to ZZ for use as targets for aerial attack. YY was to be a reserve position where, if the weather was good enough, submarines could be diverted from XX to be sunk by naval forces. In the case of those submarines not being used as targets, the plan was to sink them via explosive charges, with naval gunfire as a fall-back option if that failed.
When Operation "Deadlight" was activated, it was found that many of the U-boats were in an extremely poor condition as a result of being moored in exposed harbours while awaiting disposal. Combined with poor weather, this meant that 56 of the boats sank before reaching the designated scuttling areas, and those which did, were generally sunk by gunfire rather than explosive charges. The first sinking took place on 17 November 1945 and the last on 11 February 1946.
U-boats excluded from Operation "Deadlight".
Several U-boats escaped Operation "Deadlight". Some were claimed as prizes by Britain, France, Norway and the Soviet Union. Four were in East Asia when Germany surrendered and were commandeered by Japan ( was renamed "I-501", - "I-506", - "I-505", - "I-502", and a fifth boat, , had been sold to Japan in 1943 and renamed "RO-500"). Two U-boats that survived Operation "Deadlight" are today museum ships. was earmarked for scuttling, but Rear Admiral Daniel V. Gallery argued successfully that she did not fall under Operation "Deadlight". United States Navy Task Group 22.3, under then-Captain Gallery, had captured "U-505" in battle on 4 June 1944. Having been captured, not surrendered at the end of the war, she survived to become a war memorial at the Museum of Science and Industry in Chicago. was transferred to Norway by Britain in October 1948 and became the Norwegian "Kaura". She was returned to Germany in 1965, to become a museum ship in 1971.
"Deadlight" U-boats discovery.
Between 2001 and 2003, nautical archaeologist Innes McCartney discovered and surveyed fourteen of the U-boat wrecks; including the rare Type XXI U-boat "U-2506", once under the command of Horst von Schroeter; and the successful Type IXC U-boat, commanded by Adolf Piening.
In the late 1990s, an approach was made to the British Ministry of Defence for salvage rights to the Operation "Deadlight" U-boats, by a firm which planned to raise up to a hundred of them. Because the U-boats were constructed in the pre-atomic age, the wrecks contain metals which are not radioactively tainted and which are therefore valuable for certain research purposes. No salvage award was made, due to objections from Russia and the USA, and it is now probable that the U-boats will remain under the sea.

</doc>
<doc id="22746" url="https://en.wikipedia.org/wiki?curid=22746" title="Order of the Eastern Star">
Order of the Eastern Star

The Order of the Eastern Star is a Freemasonic appendant body open to both men and women. It was established in 1850 by lawyer and educator Rob Morris, a noted Freemason. The order is based on teachings from the Bible, but is open to people of all religious beliefs. It has approximately 10,000 chapters in twenty countries and approximately 500,000 members under its General Grand Chapter.
Members of the Order are aged 18 and older; men must be Master Masons and women must have specific relationships with Masons. Originally, a woman would have to be the daughter, widow, wife, sister, or mother of a master Mason, but the Order now allows other relatives as well as allowing Job's Daughters, Rainbow Girls, Members of the Organization of Triangle (NY only) and members of the Constellation of Junior Stars (NY only) to become members when of age.
History.
The Order was created by Rob Morris in 1850 when he was teaching at the Eureka Masonic College in Richland, Mississippi. While confined by illness, he set down the principles of the order in his "Rosary of the Eastern Star". By 1855, he had organized a "Supreme Constellation" in New York, which chartered chapters throughout the United States.
In 1866, Dr. Morris started working with Robert Macoy, and handed the Order over to him while Morris was traveling in the Holy Land. Macoy organized the current system of Chapters, and modified Dr. Morris' "Rosary" into a "Ritual".
On December 1, 1874, Queen Esther Chapter No. 1 became the first Prince Hall Affiliate chapter of the Order of the Eastern Star when it was established in Washington, D.C. by Thornton Andrew Jackson.
The "General Grand Chapter" was formed in Indianapolis, Indiana on November 6, 1876. Committees formed at that time created the "Ritual of the Order of the Eastern Star" in more or less its current form.
Emblem and heroines.
The emblem of the Order is a five-pointed star with the white ray of the star pointing downwards towards the manger. In the Chapter room, the downward-pointing white ray points to the West. The character-building lessons taught in the Order are stories inspired by Biblical figures:
Officers.
There are 18 main officers in a full chapter:
Traditionally, a woman who is elected Associate Conductress will be elected to Conductress the following year, then the next year Associate Matron, and then next year as Worthy Matron. A man elected Associate Patron will usually be elected Worthy Patron the following year. Usually the woman who is elected to become Associate Matron will let it be known who she wishes to be her Associate Patron, so the next year they will both go to the East together as Worthy Matron and Worthy Patron. There is no male counterpart to the Conductress and Associate Conductress. Only women are allowed to be Matrons, Conductresses, and the Star Points (Adah, Ruth, etc.) and only men can be Patrons.
Headquarters.
The General Grand Chapter headquarters, the International Temple, is located in the Dupont Circle neighborhood of Washington, D.C., in the former Perry Belmont Mansion. The mansion was built in 1909 for the purpose of entertaining the guests of Perry Belmont. This included Britain's Prince of Wales in 1919. General Grand Chapter purchased the building in 1935. The secretary of General Grand Chapter lives there while serving his or her term of office. The mansion features works of art from around the world, most of which were given as gifts from various international Eastern Star chapters.
Charities.
The Order has a charitable foundation and from 1986-2001 contributed $513,147 to Alzheimer's disease research, juvenile diabetes research, and juvenile asthma research. It also provides bursaries to students of theology and religious music, as well as other scholarships that differ by jurisdiction. In 2000 over $83,000 was donated. Many jurisdictions support a Masonic and/or Eastern Star retirement center or nursing home for older members; some homes are also open to the public. The Elizabeth Bentley OES Scholarship Fund was started in 1947.

</doc>
<doc id="22747" url="https://en.wikipedia.org/wiki?curid=22747" title="OSI model">
OSI model

The Open Systems Interconnection model (OSI model) is a conceptual model that characterizes and standardizes the communication functions of a telecommunication or computing system without regard to their underlying internal structure and technology. Its goal is the interoperability of diverse communication systems with standard protocols. The model partitions a communication system into abstraction layers. The original version of the model defined seven layers.
A layer serves the layer above it and is served by the layer below it. For example, a layer that provides error-free communications across a network provides the path needed by applications above it, while it calls the next lower layer to send and receive packets that comprise the contents of that path. Two instances at the same layer are visualized as connected by a "horizontal" connection in that layer.
The model is a product of the Open Systems Interconnection project at the International Organization for Standardization (ISO), maintained by the identification ISO/IEC 7498-1.
History.
In the late 1970s, two projects began independently, with the same goal: to define a unifying standard for the architecture of networking systems. One was administered by the International Organization for Standardization (ISO), while the other was undertaken by the International Telegraph and Telephone Consultative Committee, or CCITT (the abbreviation is from the French version of the name). These two international standards bodies each developed a document that defined similar networking models.
In 1983, these two documents were merged to form a standard called The Basic Reference Model for Open Systems Interconnection. The standard is usually referred to as the Open Systems Interconnection Reference Model, the OSI Reference Model, or simply the OSI model. It was published in 1984 by both the ISO, as standard ISO 7498, and the renamed CCITT (now called the Telecommunications Standardization Sector of the International Telecommunication Union or ITU-T) as standard X.200.
OSI had two major components, an "abstract model" of networking, called the Basic Reference Model or seven-layer model, and a set of specific protocols.
The concept of a seven-layer model was provided by the work of Charles Bachman at Honeywell Information Services. Various aspects of OSI design evolved from experiences with the ARPANET, NPLNET, EIN, CYCLADES network and the work in IFIP WG6.1. The new design was documented in ISO 7498 and its various addenda. In this model, a networking system was divided into layers. Within each layer, one or more entities implement its functionality. Each entity interacted directly only with the layer immediately beneath it, and provided facilities for use by the layer above it.
Protocols enable an entity in one host to interact with a corresponding entity at the same layer in another host. Service definitions abstractly described the functionality provided to an (N)-layer by an (N-1) layer, where N was one of the seven layers of protocols operating in the local host.
The OSI standards documents are available from the ITU-T as the X.200-series of recommendations. Some of the protocol specifications were also available as part of the ITU-T X series. The equivalent ISO and ISO/IEC standards for the OSI model were available from ISO, but only some of them without fees.
Description of OSI layers.
The recommendation X.200 describes seven layers, labeled 1 to 7. Layer 1 is the lowest layer in this model.
At each level "N", two entities at the communicating devices (layer N "peers") exchange protocol data units (PDUs) by means of a layer N "protocol". Each PDU contains a payload, called the service data unit (SDU), along with protocol-related headers and/or footers.
Data processing by two communicating OSI-compatible devices is done as such:
Some orthogonal aspects, such as management and security, involve all of the layers (See ITU-T X.800 Recommendation). These services are aimed at improving the CIA triad - confidentiality, integrity, and availability - of the transmitted data. In practice, the availability of a communication service is determined by the interaction between network design and network management protocols. Appropriate choices for both of these are needed to protect against denial of service.
Layer 1: Physical Layer.
The physical layer has the following major functions:
The physical layer of Parallel SCSI operates in this layer, as do the physical layers of Ethernet and other local-area networks, such as Token Ring, FDDI, ITU-T G.hn, and IEEE 802.11 (Wi-Fi), as well as personal area networks such as Bluetooth and IEEE 802.15.4.
Layer 2: Data Link Layer.
The data link layer provides node-to-node data transfer -- a link between two directly connected nodes. It detects and possibly corrects errors that may occur in the physical layer.
It, among other things, defines the protocol to establish and terminate a connection between two physically connected devices. It also defines the protocol for flow control between them.
IEEE 802 divides the data link layer into two sublayers:
The MAC and LLC layers of IEEE 802 networks such as 802.3 Ethernet, 802.11 Wi-Fi, and 802.15.4 ZigBee, operate at the data link layer.
The Point-to-Point Protocol (PPP) is a data link layer that can operate over several different physical layers, such as synchronous and asynchronous serial lines.
The ITU-T G.hn standard, which provides high-speed local area networking over existing wires (power lines, phone lines and coaxial cables), includes a complete data link layer that provides both error correction and flow control by means of a selective-repeat sliding-window protocol.
Layer 3: Network Layer.
The network layer provides the functional and procedural means of transferring variable length data sequences (called datagrams) from one node to another connected to the same "network." It translates logical network address into physical machine address. A network is a medium to which many nodes can be connected, on which every node has an "address" and which permits nodes connected to it to transfer messages to other nodes connected to it by merely providing the content of a message and the address of the destination node and letting the network find the way to deliver ("route") the message to the destination node. In addition to message routing, the network may implement message delivery by splitting the message into several fragments, delivering each fragment by a separate route and reassembling the fragments, report delivery errors, etc.
Datagram delivery at the network layer is "not" guaranteed to be "reliable".
A number of layer-management protocols, a function defined in the "management annex", ISO 7498/4, belong to the network layer. These include routing protocols, multicast group management, network-layer information and error, and network-layer address assignment. It is the function of the payload that makes these belong to the network layer, not the protocol that carries them.
Layer 4: Transport Layer.
The transport layer provides the functional and procedural means of transferring variable-length data sequences from a source to a destination host via one or more networks, while maintaining the quality of service functions.
An example of a transport-layer protocol in the standard Internet stack is Transmission Control Protocol (TCP), usually built on top of the Internet Protocol (IP).
The transport layer controls the reliability of a given link through flow control, segmentation/desegmentation, and error control. Some protocols are state- and connection-oriented. This means that the transport layer can keep track of the segments and retransmit those that fail. The transport layer also provides the acknowledgement of the successful data transmission and sends the next data if no errors occurred. The transport layer creates packets out of the message received from the application layer. Packetizing is a process of dividing the long message into smaller messages.
OSI defines five classes of connection-mode transport protocols ranging from class 0 (which is also known as TP0 and provides the fewest features) to class 4 (TP4, designed for less reliable networks, similar to the Internet). Class 0 contains no error recovery, and was designed for use on network layers that provide error-free connections. Class 4 is closest to TCP, although TCP contains functions, such as the graceful close, which OSI assigns to the session layer. Also, all OSI TP connection-mode protocol classes provide expedited data and preservation of record boundaries. Detailed characteristics of TP0-4 classes are shown in the following table:
An easy way to visualize the transport layer is to compare it with a post office, which deals with the dispatch and classification of mail and parcels sent. Do remember, however, that a post office manages the outer envelope of mail. Higher layers may have the equivalent of double envelopes, such as cryptographic presentation services that can be read by the addressee only. Roughly speaking, tunneling protocols operate at the transport layer, such as carrying non-IP protocols such as IBM's SNA or Novell's IPX over an IP network, or end-to-end encryption with IPsec. While Generic Routing Encapsulation (GRE) might seem to be a network-layer protocol, if the encapsulation of the payload takes place only at endpoint, GRE becomes closer to a transport protocol that uses IP headers but contains complete frames or packets to deliver to an endpoint. L2TP carries PPP frames inside transport packet.
Although not developed under the OSI Reference Model and not strictly conforming to the OSI definition of the transport layer, the Transmission Control Protocol (TCP) and the User Datagram Protocol (UDP) of the Internet Protocol Suite are commonly categorized as layer-4 protocols within OSI.
Layer 5: Session Layer.
The session layer controls the dialogues (connections) between computers. It establishes, manages and terminates the connections between the local and remote application. It provides for full-duplex, half-duplex, or simplex operation, and establishes checkpointing, adjournment, termination, and restart procedures. The OSI model made this layer responsible for graceful close of sessions, which is a property of the Transmission Control Protocol, and also for session checkpointing and recovery, which is not usually used in the Internet Protocol Suite. The session layer is commonly implemented explicitly in application environments that use remote procedure calls.
Layer 6: Presentation Layer.
The presentation layer establishes context between application-layer entities, in which the application-layer entities may use different syntax and semantics if the presentation service provides a big mapping between them. If a mapping is available, presentation service data units are encapsulated into session protocol data units, and passed down the protocol stack.
This layer provides independence from data representation (e.g., encryption) by translating between application and network formats. The presentation layer transforms data into the form that the application accepts. This layer formats and encrypts data to be sent across a network. It is sometimes called the syntax layer.
The original presentation structure used the Basic Encoding Rules of Abstract Syntax Notation One (ASN.1), with capabilities such as converting an EBCDIC-coded text file to an ASCII-coded file, or serialization of objects and other data structures from and to XML.
Layer 7: Application Layer.
The application layer is the OSI layer closest to the end user, which means both the OSI application layer and the user interact directly with the software application. This layer interacts with software applications that implement a communicating component. Such application programs fall outside the scope of the OSI model. Application-layer functions typically include identifying communication partners, determining resource availability, and synchronizing communication. When identifying communication partners, the application layer determines the identity and availability of communication partners for an application with data to transmit. When determining resource availability, the application layer must decide whether sufficient network or the requested communication exists. In synchronizing communication, all communication between applications requires cooperation that is managed by the application layer. This layer supports application and end-user processes. Communication partners are identified, quality of service is identified, user authentication and privacy are considered, and any constraints on data syntax are identified. Everything at this layer is application-specific.
Cross-layer functions.
There are some functions or services that are not tied to a given layer, but they can affect more than one layer. Examples include the following:
Interfaces.
Neither the OSI Reference Model nor OSI protocols specify any programming interfaces, other than deliberately abstract service specifications. Protocol specifications precisely define the interfaces between different computers, but the software interfaces inside computers, known as network sockets are implementation-specific.
For example, Microsoft Windows' Winsock, and Unix's Berkeley sockets and System V Transport Layer Interface, are interfaces between applications (layer 5 and above) and the transport (layer 4). NDIS and ODI are interfaces between the media (layer 2) and the network protocol (layer 3).
Interface standards, except for the physical layer to media, are approximate implementations of OSI service specifications.
Comparison with TCP/IP model.
The design of protocols in the TCP/IP model of the Internet does not concern itself with strict hierarchical encapsulation and layering. RFC 3439 contains a section entitled "Layering considered harmful". TCP/IP does recognize four broad layers of functionality which are derived from the operating scope of their contained protocols: the scope of the software application; the end-to-end transport connection; the internetworking range; and the scope of the direct links to other nodes on the local network.
Despite using a different concept for layering than the OSI model, these layers are nevertheless often compared with the OSI layering scheme in the following way:
These comparisons are based on the original seven-layer protocol model as defined in ISO 7498, rather than refinements in such things as the internal organization of the network layer document.
The presumably strict layering of the OSI model as it is usually described does not present contradictions in TCP/IP, as it is permissible that protocol usage does not follow the hierarchy implied in a layered model. Such examples exist in some routing protocols (e.g., OSPF), or in the description of tunneling protocols, which provide a link layer for an application, although the tunnel host protocol might well be a transport or even an application-layer protocol in its own right.

</doc>
<doc id="22751" url="https://en.wikipedia.org/wiki?curid=22751" title="Original Sin (2001 film)">
Original Sin (2001 film)

Original Sin is a 2001 erotic thriller film starring Antonio Banderas and Angelina Jolie. It is based on the novel "Waltz into Darkness" by Cornell Woolrich, and is a remake of the 1969 François Truffaut film "Mississippi Mermaid".
Plot.
"Original Sin" is set in the late 19th century Cuba during the Spanish rule, and flashes back and forth from the scene of a woman awaiting her execution by garrote while telling her story to a priest, to the actual events of that story. 
Luis Vargas (Antonio Banderas), a wealthy Cuban businessman, sends for American Julia Russell (Angelina Jolie) to sail to his country to be his bride. Julia departs from the ship, looking nothing like the photos she's sent prior to her voyage. Julia explains she wants more than a man who is interested in a pretty face, and that's why she's been deceptive - substituting a plain-looking woman in place of her own picture. Luis also admits to deception; he's been misleading her into believing he's a poor working man, instead of the rich owner of a coffee company.
Luis and Julia wed within hours of her setting foot in Cuba. Luis falls passionately in love with his new wife.
Meanwhile, Julia's sister Emily has been trying to contact her, worried about her after such a long trip to a strange land. Luis forces Julia to write back, fearing that if Julia continues to ignore Emily's letters, Emily will assume something terrible has befallen her sister and might send the authorities to check on her welfare. Holding off as long as possible, Julia finally pens a letter to her sister.
In order to assure that his wife has everything she wants, Luis adds Julia to his business and personal bank accounts, giving her free rein to spend as she pleases. Luis discovers Julia has run off with nearly all of his fortune, and then teams up with a detective, Walter Downs (Thomas Jane), hired by Emily to find her real sister Julia. Walter reveals to Luis he believes Julia to be an impostor and the intended wife to be dead by her hand, and that she may be working with someone. The two set out together looking for her.
Luis finds Julia and discovers she is actually working with Walter and that he & Luis are staying at the same hotel. Luis believes she loves him and lies to Walter, but, when confronted, a fight breaks out and Luis shoots Walter. Julia coldly tells Luis to go and buy them tickets home, but the minute he leaves, Walter gets to his feet; he had loaded the gun with blanks. Julia appears to love Luis, but, Walter has too much control over her, so, she continues to work for him as she and Luis run off to live in secret with the supposedly dead Walter in pursuit. 
Luis throws away his promising future and opens himself to living a lie with Julia. One night, Luis follows Julia and discovers Walter is alive and that the two are still working together; she is apparently going to poison her husband that very night. He returns home and waits for her, and when she arrives, reveals he knows of the plan, confesses his love for her once more and swallows the poisoned drink. Julia flees with the dying Luis, with Walter close behind. They run into him at a train station; Walter is furious that Julia has betrayed him. As Walter holds a knife to her throat, Luis shoots and wounds him, with Julia finishing him off.
Back in the "mise en scene", Julia finishes her story and asks the priest to pray with her. The next morning the guards come to her cell to take her to her execution, only to find the priest in her clothing.
In Morocco, Julia is watching a card game. She walks around the table occupied by gamblers — including Luis — and thanks them for allowing her to watch. As Julia signals Luis about the other players' cards, he begins telling them the story of how they got there.
Reception.
"Original Sin" was poorly received by critics. It currently holds a 12% rating on Rotten Tomatoes based on 91 reviews with the consensus stating: "Laughably melodramatic, "Original Sin" features bad acting, poor dialogue and even worse plotting."
Angelina Jolie was nominated for a Golden Raspberry Award for Worst Actress for her work in both this film and "", but lost the trophy to Mariah Carey for "Glitter".

</doc>
<doc id="22753" url="https://en.wikipedia.org/wiki?curid=22753" title="Oscar Hammerstein II">
Oscar Hammerstein II

Oscar Greeley Clendenning Hammerstein II (; July 12, 1895 – August 23, 1960) was an American librettist, theatrical producer, and (usually uncredited) theatre director of musicals for almost forty years. Hammerstein won eight Tony Awards and two Academy Awards for Best Original Song. Many of his songs are standard repertoire for singers and jazz musicians. He co-wrote 850 songs. Hammerstein was the lyricist and playwright in his partnerships; his collaborators wrote the music. Hammerstein collaborated with composers Jerome Kern, Vincent Youmans, Rudolf Friml, Richard A. Whiting and Sigmund Romberg; but his most famous collaborations, by far, were with Richard Rodgers, and included "The Sound of Music".
Early life.
Oscar Greeley Clendenning Hammerstein II was born in New York City, the son of Alice Hammerstein (née Nimmo) and theatrical manager William Hammerstein. His grandfather was Polish-born German theatre impresario Oscar Hammerstein I. His father was from a Jewish family, and his mother was the daughter of Scottish and English parents. He was raised Episcopalian.
Although Hammerstein's father managed the Victoria Theatre for his father and was a producer of vaudeville shows, he was opposed to his son's desire to participate in the arts. Hammerstein attended Columbia University (1912–1916) and studied at Columbia Law School until 1917. As a student, he maintained high grades and engaged in numerous extracurricular activities. These included playing first base on the baseball team and becoming an active member of Pi Lambda Phi, a mostly Jewish fraternity.
When he was 19, and still a student at Columbia, his father died of Bright's disease, June 10, 1914, symptoms of which doctors originally attributed to scarlet fever. On the train trip to the funeral with his brother, he read the headlines in the "New York Herald": "Hammerstein's Death a Shock to the Theater Circle." The "New York Times" wrote, "Hammerstein, the Barnum of Vaudeville, Dead at Forty." When he and his brother arrived home, they attended their father's funeral with their grandfather, and more than a thousand others, at Temple Israel in Harlem, and took part in the ceremonies held in the Jewish tradition. Two hours later, "taps was sounded over Broadway," writes biographer Hugh Fordin.
After his father's death, he participated in his first play with the Varsity Show, entitled "On Your Way". Throughout the rest of his college career, Hammerstein wrote and performed in several Varsity Shows.
Early career.
After quitting law school to pursue theatre, Hammerstein began his first professional collaboration, with Herbert Stothart, Otto Harbach and Frank Mandel. He began as an apprentice and went on to form a 20-year collaboration with Harbach. Out of this collaboration came his first musical, "Always You", for which he wrote the book and lyrics. It opened on Broadway in 1920.
Throughout the next forty years, Hammerstein teamed with many other composers, including Jerome Kern, with whom Hammerstein enjoyed a highly successful collaboration. In 1927, Kern and Hammerstein had their biggest hit, "Show Boat", which is often revived and is still considered one of the masterpieces of the American musical theatre. "Here we come to a completely new genre — the musical play as distinguished from musical comedy. Now ... the play was the thing, and everything else was subservient to that play. Now ... came complete integration of song, humor and production numbers into a single and inextricable artistic entity." Many years later, Hammerstein's wife Dorothy bristled when she heard a remark that Jerome Kern had written "Ol' Man River." "Indeed not," she retorted. "Jerome Kern wrote "dum, dum, dum-dum. My husband wrote 'Ol' Man River'."
Other Kern-Hammerstein musicals include "Sweet Adeline", "Music in the Air", "Three Sisters", and "Very Warm for May". Hammerstein also collaborated with Vincent Youmans ("Wildflower"), Rudolf Friml ("Rose-Marie"), and Sigmund Romberg ("The Desert Song" and "The New Moon").
Rodgers and Hammerstein.
Hammerstein's most successful and sustained collaboration began when he teamed up with Richard Rodgers to write a musical adaptation of the play "Green Grow the Lilacs". Rodgers' first partner, Lorenz Hart, originally planned to collaborate with Rodgers on this piece, but his alcoholism had become out of control, and he was unable to write. Hart was also not certain that the idea had much merit, and the two therefore separated. The adaptation became the first Rodgers and Hammerstein collaboration, entitled "Oklahoma!", which opened on Broadway in 1943. It furthered the revolution begun by "Show Boat", by thoroughly integrating all the aspects of musical theatre, with the songs and dances arising out of and further developing the plot and characters. William A. Everett and Paul R. Laird wrote that this was a "show, that, like 'Show Boat', became a milestone, so that later historians writing about important moments in twentieth-century theatre would begin to identify eras according to their relationship to 'Oklahoma.'" After "Oklahoma!", Rodgers and Hammerstein were the most important contributors to the musical-play form – with such masterworks as "Carousel", "The King and I" and "South Pacific". The examples they set in creating vital plays, often rich with social thought, provided the necessary encouragement for other gifted writers to create musical plays of their own".
The partnership went on to produce these and other Broadway musicals such as "Allegro", "Me and Juliet", "Pipe Dream", "Flower Drum Song", and "The Sound of Music", as well as the musical film "State Fair" (and its stage adaptation of the same name), and the television musical "Cinderella", all featured in the revue "A Grand Night for Singing". Hammerstein also wrote the book and lyrics for "Carmen Jones", an adaptation of Georges Bizet's opera "Carmen" with an all-black cast that became a 1943 Broadway musical and a 1954 film.
Death.
Hammerstein died of stomach cancer on August 23, 1960, at his home Highland Farm in Doylestown, Pennsylvania, at 65, shortly after the opening of "The Sound of Music" on Broadway. The final song he wrote was "Edelweiss", which was added near the end of the second act during rehearsal. This was not an Austrian folk song, but had been written specifically for the musical. After his death, "The Sound of Music" was made into the hit 1965 film adaptation, which won the Academy Award for Best Picture.
The lights of Times Square were turned off for one minute, and London's West End lights were dimmed in recognition of his contribution to the musical. He was cremated, and his ashes were buried at the Ferncliff Cemetery in Hartsdale, New York. A memorial plaque was unveiled at Southwark Cathedral, England, on May 24, 1961. He was survived by his second wife, Dorothy, his three children and two stepchildren.
Personal life.
Hammerstein married his second wife, the Australian-born Dorothy (Blanchard) Jacobson (1899-1987), on May 13, 1929. He had three children: William Hammerstein (1918–2001) and Alice Hammerstein Mathias by his first wife, Myra Finn, and James Hammerstein by Blanchard. By Dorothy he also had a stepdaughter, Susan Blanchard (whose four husbands included Henry Fonda and Richard Widmark), and a stepson, Henry Jacobson.
Reputation.
Hammerstein was one of the most important "book writers" in Broadway history – he made the story, not the songs or the stars, central to the musical and brought musical theater to full maturity as an art form. According to Stephen Sondheim, "What few people understand is that Oscar's big contribution to the theater was as a theoretician, as a Peter Brook, as an innovator. People don't understand how experimental "Show Boat" and "Oklahoma!" felt at the time they were done. Oscar is not about the 'lark that is learning to pray' – that's easy to make fun of. He's about "Allegro"."
His reputation for being sentimental is based largely on the movie versions of the musicals, especially "The Sound of Music", in which a song sung by those in favor of reaching an accommodation with the Nazis, "No Way to Stop It", was cut. As recent revivals of "Show Boat", "Oklahoma!", "Carousel", and "The King and I" in London and New York show, Hammerstein was one of the more tough-minded and socially conscious American musical theater artists. According to Richard Kislan, "The shows of Rodgers and Hammerstein were the product of sincerity. In the light of criticism directed against them and their universe of sweetness and light, it is important to understand that they believed sincerely in what they wrote." According to Marc Bauch, "The Rodgers and Hammerstein musicals are romantic musical plays. Love is important."
According to "The Rodgers and Hammerstein Story" by Stanley Green, "For three minutes, on the night of September first, the entire Times Square area in New York City was blacked out in honor of the man who had done so much to light up that particular part of the world. From 8:57 to 9:00 p.m., every neon sign and every light bulb was turned off and all traffic was halted between 42nd Street and 53rd Street, and between 8th Ave and the Avenue of the Americas. A crowd of 5,000 people, many with heads bowed, assembled at the base of the statue of Father Duffy on Times Square where two trumpeters blew taps. It was the most complete blackout on Broadway since World War II, and the greatest tribute of its kind ever paid to one man."
Songs.
Hammerstein contributed the lyrics to 850 songs, according to "The Complete Lyrics of Oscar Hammerstein II", edited by Amy Asch. Some well-known songs are "Ol' Man River", "Can't Help Lovin' That Man" and "Make Believe" from "Show Boat"; "Indian Love Call" from "Rose-Marie"; "People Will Say We're in Love" and "Oklahoma" (which has been the official state song of Oklahoma since 1953) from "Oklahoma!"; "Some Enchanted Evening", from "South Pacific"; "Getting to Know You" and "Shall We Dance" from "The King and I"; and the title song as well as "Climb Ev'ry Mountain" from "The Sound of Music".
Several albums of Hammerstein's musicals were named to the "Songs of the Century" list as compiled by the Recording Industry Association of America (RIAA), the National Endowment for the Arts, and Scholastic Corporation:
Awards and legacy.
Hammerstein won two Oscars for best original song—in 1941 for "The Last Time I Saw Paris" in the film "Lady Be Good", and in 1945 for "It Might as Well Be Spring" in "State Fair." In 1950, the team of Rodgers and Hammerstein received The Hundred Year Association of New York's Gold Medal Award "in recognition of outstanding contributions to the City of New York."
Hammerstein won eight Tony Awards, six for lyrics or book, and two as producer of the Best Musical ("South Pacific" and "The Sound of Music"). Rodgers and Hammerstein began writing together before the era of the Tonys: "Oklahoma!" opened in 1943 and "Carousel" in 1945, and the Tony Awards were not awarded until 1947. They won a special Pulitzer Prize in 1944 for "Oklahoma!" and, with Joshua Logan, the annual Pulitzer Prize for Drama in 1950 for "South Pacific". The Oscar Hammerstein II Center for Theater Studies at Columbia University was established in 1981 with a $1-million gift from his family.
His advice and work influenced Stephen Sondheim, a friend of the Hammerstein family from childhood. Sondheim has attributed his success in theater, and especially as a lyricist, directly to Hammerstein's influence and guidance.
The Oscar Hammerstein Award for Lifetime Achievement in Musical Theatre is presented annually. The York Theatre Company in New York City is the Administrator of the award. The 2009 winners were Jerry Bock and Sheldon Harnick. Past awardees are composers such as Stephen Sondheim and performers such as Carol Channing. The 2010 award went to Thomas Meehan.
Oscar Hammerstein was a member of the American Theater Hall of Fame.

</doc>
<doc id="22756" url="https://en.wikipedia.org/wiki?curid=22756" title="Otto Jespersen">
Otto Jespersen

Jens Otto Harry Jespersen or Otto Jespersen (; 16 July 1860 – 30 April 1943) was a Danish linguist who specialized in the grammar of the English language.
Early life.
Otto Jespersen was born in Randers in Jutland. He was inspired by the work of Danish philologist Rasmus Rask as a boy, and with the help of Rask's grammars taught himself some Icelandic, Italian, and Spanish. He entered the University of Copenhagen in 1877 when he was 17, initially studying law but not forgetting his language studies. In 1881 he shifted his focus completely to languages, and in 1887 earned his master's degree in French, with English and Latin as his secondary languages. He supported himself during his studies through part-time work as a schoolteacher and as a shorthand reporter in the Danish parliament. In 1887–1888, he traveled to England, Germany and France, meeting linguists like Henry Sweet and Paul Passy and attending lectures at institutions like Oxford University. Following the advice of his mentor Vilhelm Thomsen, he returned to Copenhagen in August 1888 and began work on his doctoral dissertation on the English case system. He successfully defended his dissertation in 1891.
Academic life and work.
Jespersen was a professor of English at the University of Copenhagen from 1893 to 1925, and served as Rector of the university in 1920–21. His early work focused primarily on language teaching reform and on phonetics, but he is best known for his later work on syntax and on language development.
He advanced the theories of "Rank" and "Nexus" in Danish in two papers: "Sprogets logik" (1913) and "De to hovedarter af grammatiske forbindelser" (1921). Jespersen in this theory of ranks removes the parts of speech from the syntax, and differentiates between primaries, secondaries, and tertiaries; e.g. in ""well honed phrase"," "phrase" is a primary, this being defined by a secondary, "honed", which again is defined by a tertiary "well". The term "Nexus" is applied to sentences, structures similar to sentences and sentences in formation, in which two concepts are expressed in one unit; e.g., "it rained, he ran indoors". This term is qualified by a further concept called a "junction" which represents one idea, expressed by means of two or more elements, whereas a nexus combines two ideas. Junction and nexus proved valuable in bringing the concept of context to the forefront of the attention of the world of linguistics.
He was most widely recognized for some of his books. "Language: Its Nature, Development and Origin" (1922) is considered by many to be his masterpiece. "Modern English Grammar on Historical Principles" (1909–1949), concentrated on morphology and syntax, and "Growth and Structure of the English Language" (1905) is a comprehensive view of English by someone with another native language, and still in print, over 70 years after his death and more than 100 years after publication. Late in his life he published "Analytic Syntax" (1937), in which he presents his views on syntactic structure using an idiosyncratic shorthand notation. In "The Philosophy of Grammar" (1924) he challenged the accepted views of common concepts in Grammar and proposed corrections to the basic definitions of grammatical case, pronoun, object, voice etc., and developed further his notions of "Rank" and "Nexus". In the 21st century this book is still used as one of the basic texts in modern Structural linguistics. "Mankind, Nation and Individual: from a linguistic point of view" (1925) is one of the pioneering works on Sociolinguistics.
Jespersen visited the United States twice: he lectured at the Congress of Arts and Sciences in St. Louis in 1904, and in 1909–1910 he visited both the University of California and Columbia University. While in the U.S., he took occasion to study the country's educational system. His autobiography (see below) was published in English translation as recently as 1995.
Jespersen was a proponent of phonosemanticism and wrote: “Is there really much more logic in the opposite extreme which denies any kind of sound symbolism (apart from the small class of evident echoisms and ‘onomatopoeia’) and sees in our words only a collection of accidental and irrational associations of sound and meaning? ...There is no denying that there are words which we feel instinctively to be adequate to express the ideas they stand for.”
After his retirement in 1925, Jespersen remained active in the international linguistic community. In addition to continuing to write, he convened and chaired the first International Meeting on Linguistic Research in Geneva in 1930, and acted as president of the Fourth International Congress of Linguists in Copenhagen in 1936.
Jespersen was an important figure in the international language movement. He was an early supporter of the Esperanto offshoot Ido and in 1927 published his own project Novial. He also worked with the International Auxiliary Language Association.
Jespersen received honorary degrees from Columbia University in New York (1910), St. Andrews University in Scotland (1925), and the Sorbonne in Paris (1927). He was one of the first six international scholars to be elected as honorary members of the Linguistic Society of America.
Trivia.
He appears as a character in Joseph Skibell's 2010 novel "A Curable Romantic".
In C. S. Lewis' science fiction novel "Out of the Silent Planet", he is said to be comparable in philology to Einstein and Schroedinger in physics.

</doc>
<doc id="22758" url="https://en.wikipedia.org/wiki?curid=22758" title="List of object-oriented programming languages">
List of object-oriented programming languages

This is a list of notable object-oriented programming languages, which are also listed in .

</doc>
<doc id="22759" url="https://en.wikipedia.org/wiki?curid=22759" title="OOP">
OOP

OOP, Oop, or oop may refer to:

</doc>
<doc id="22760" url="https://en.wikipedia.org/wiki?curid=22760" title="Occidental">
Occidental

"Occidental" is derived from a Latin word for the direction west, "occidens", and is a term sometimes used to refer to the European continent. The corresponding antonym Oriental ("of the Orient") is of similar derivation: it is taken from the Latin for east, "oriens".
Other Usages.
It may also refer to:

</doc>
<doc id="22761" url="https://en.wikipedia.org/wiki?curid=22761" title="Occidental language">
Occidental language

The language Occidental, later Interlingue, is a planned international auxiliary language created by the Balto-German naval officer and teacher Edgar de Wahl, and published in 1922. The vocabulary is based on already existing international words. The language is thereby naturalistic, at the same time as it is constructed to be regular. Occidental was quite popular in the years before the Second World War, but declined in the years thereafter.
Occidental is devised so that many of its derived word forms reflect the similar forms common to a number of Western European languages, primarily those in the Romance family. This was done through application of de Wahl's rule which is a set of rules for converting verb infinitives into derived nouns and adjectives. The result is a language easy to understand at first sight for individuals acquainted with several Western European languages. Coupled with a simplified grammar, this made Occidental exceptionally popular in Europe during the 15 years before World War II.
In "The Esperanto Book", Don Harlow says that Occidental had an intentional emphasis on European forms, and that some of its leading followers espoused a Eurocentric philosophy, which may have hindered its spread. Still, Occidental gained adherents in many nations including Asian nations. According to the Occidental magazine "Cosmoglotta" in 1928, a majority of Ido adherents took up Occidental in place of Ido.
Occidental survived World War II, undergoing a name change to "Interlingue", but faded into insignificance following the appearance in the early 1950s of a competing naturalistic project, Interlingua, which attracted among others the notable Occidentalist Ric Berger.
Alphabet and pronunciation.
Occidental is written with 26 Latin letters: a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z. The letters of the alphabet are pronounced as "a, be, ce, de, e, ef, ge, ha, i, jot, ka, el, em, en, o, pe, qu, er, es, te, u, ve, duplic ve, ix, ypsilon", and "zet".
Pronunciation.
The vowels "a, e, i, o", and "u" have a continental pronunciation and are all sounded. The "y" (initial and medial) are pronounced as in "yes", "ey" (final) as in "they", and "eu" as éh-oo.
The consonants are pronounced as in English, with the following exceptions:
Grammar.
Like English, Interlingue has a definite article and an indefinite article. The definite article (the) is "li", and the indefinite (a, an) is "un". Plural of a noun is made by adding "-s" after a vowel, or "-es" after a consonant.
Personal pronouns.
Interlingue has two forms for the personal pronouns: one for the subject form (nominative), and one for the object form (accusative or dative). In short, the personal pronouns in the subject form are:
The variants "illa" and "ella" both exist for third person singular feminine. The pronoun expressing politeness is "vu", which behaves like second person plural. The indefinite personal pronoun "one" is "on" in Occidental. If necessary, one can specify the gender of third person plural by using "illos" (masculine) or "illas" (feminine).
In the object form the pronouns are: "me, te, le, la, it, nos, vos", and "les" (with "los" and "las" as specific masculine and feminine forms, respectively). The possessive pronouns are "mi, tui, su" (his/her/its), "nor, vor" and "lor".
Example texts.
Translation: "Material civilization, science, and even art unify themselves more and more. The educated European feels himself almost at home in all lands that have European civilization, that is, more and more, in the entire world. Today almost all states war with the same armaments. Without pause the modes of intercommunication improve, and in consequence from that the world seems to decrease. A Parisian is now closer to an Englishman or a German than he was a hundred years before to a French peasant."

</doc>
<doc id="22763" url="https://en.wikipedia.org/wiki?curid=22763" title="Osiris">
Osiris

Osiris (, alternatively Ausir, Asiri or Ausar, among other spellings), was an Egyptian god, usually identified as the god of the afterlife, the underworld, and the dead, but more appropriately as the god of transition, resurrection, and regeneration. He was classically depicted as a green-skinned man with a pharaoh's beard, partially mummy-wrapped at the legs, wearing a distinctive crown with two large ostrich feathers at either side, and holding a symbolic crook and flail.
Osiris was at times considered the oldest son of the earth god Geb, though other sources state his father is the sun-god Ra and the sky goddess Nut, as well as being brother and husband of Isis, with Horus being considered his posthumously begotten son. He was also associated with the epithet Khenti-Amentiu, meaning "Foremost of the Westerners", a reference to his kingship in the land of the dead. As ruler of the dead, Osiris was also sometimes called "king of the living": ancient Egyptians considered the blessed dead "the living ones".
Osiris was considered the brother of Isis, Set, Nephthys, and Horus the Elder, and father of Horus the younger.
Osiris is first attested in the middle of the Fifth dynasty of Egypt, although it is likely that he was worshipped much earlier; the Khenti-Amentiu epithet dates to at least the first dynasty, also as a pharaonic title. Most information available on the myths of Osiris is derived from allusions contained in the Pyramid Texts at the end of the Fifth Dynasty, later New Kingdom source documents such as the Shabaka Stone and the "Contending of Horus and Seth", and much later, in narrative style from the writings of Greek authors including Plutarch and Diodorus Siculus.
Osiris was considered not only a merciful judge of the dead in the afterlife, but also the underworld agency that granted all life, including sprouting vegetation and the fertile flooding of the Nile River. He was described as the "Lord of love", "He Who is Permanently Benign and Youthful" and the "Lord of Silence". The Kings of Egypt were associated with Osiris in death — as Osiris rose from the dead they would, in union with him, inherit eternal life through a process of imitative magic. By the New Kingdom all people, not just pharaohs, were believed to be associated with Osiris at death, if they incurred the costs of the assimilation rituals.
Through the hope of new life after death, Osiris began to be associated with the cycles observed in nature, in particular vegetation and the annual flooding of the Nile, through his links with the heliacal rising of Orion and Sirius at the start of the new year. Osiris was widely worshipped as Lord of the Dead until the suppression of the Egyptian religion during the rise of Christianity in the Roman Empire.
Etymology of the name.
"Osiris" is a Latin transliteration of the Ancient Greek , which in turn is the Greek adaptation of the original theonym in the Egyptian language. In Egyptian hieroglyphs the name is written "Wsjr", as the hieroglyphic writing does not restitute all the vowels, and Egyptologists transliterate the name variously as Asar, Yasar, Aser, Asaru, Ausar, Ausir, Wesir, Usir, Usire or Ausare.
Several proposals have been made for the etymology and meaning of the original name "Wsjr". John Gwyn Griffiths (1980) proposed a derivation from "wser" signifying "the powerful". Moreover, one of the oldest attestations of the god Osiris appears in the mastaba of the deceased Netjer-wser (God Almighty).
David Lorton (1985) proposed that "Wsjr" is composed by the morphemes "set-jret" signifying "ritual activity", Osiris being the one who receives it. Wolfhart Westendorf (1987) proposed an etymology from "Waset-jret" "she who bears the eye".
Appearance.
Osiris is represented in his most developed form of iconography wearing the "Atef" crown, which is similar to the White crown of Upper Egypt, but with the addition of two curling ostrich feathers at each side (see also Atef crown (hieroglyph)). He also carries the crook and flail. The crook is thought to represent Osiris as a shepherd god. The symbolism of the flail is more uncertain with shepherds whip, fly-whisk, or association with the god Andjety of the ninth nome of Lower Egypt proposed.
He was commonly depicted as a pharaoh with a complexion of either green (the color of rebirth) or black (alluding to the fertility of the Nile floodplain) in mummiform (wearing the trappings of mummification from chest downward).
More rarely, he was depicted as a lunar god with a crown encompassing the moon.
Early mythology.
The Pyramid Texts describe early conceptions of an afterlife in terms of eternal travelling with the sun god amongst the stars. Amongst these mortuary texts, at the beginning of the 4th dynasty, is found: "An offering the king gives and Anubis". By the end of the 5th dynasty, the formula in all tombs becomes "An offering the king gives and Osiris".
Father of Horus.
Osiris is the mythological father of the god Horus, whose conception is described in the Osiris myth, a central myth in ancient Egyptian belief. The myth described Osiris as having been killed by his brother Set, who wanted Osiris' throne. Isis joined the fragmented pieces of Osiris, but the only body part missing was the phallus. Isis fashioned a golden phallus, and briefly brought Osiris back to life by use of a spell that she learned from her father. This spell gave her time to become pregnant by Osiris before he again died. Isis later gave birth to Horus. As such, since Horus was born after Osiris' resurrection, Horus became thought of as a representation of new beginnings and the vanquisher of the evil Set.
"Ptah-Seker" (who resulted from the identification of Creator god Ptah with Seker), god of reincarnation, thus gradually became identified with Osiris, the two becoming Ptah-Seker-Osiris. As the sun was thought to spend the night in the underworld, and was subsequently "reincarnated" every morning, Ptah-Seker-Osiris was identified as both Creator god, king of the underworld, god of the afterlife, reincarnation, life, death, and resurrection.
Ram god.
Osiris' soul, or rather his "Ba", was occasionally worshipped in its own right, almost as if it were a distinct god, especially in the Delta city of Mendes. This aspect of Osiris was referred to as "Banebdjedet", which is grammatically feminine (also spelt ""Banebded" or "Banebdjed""), literally "the "ba" of the lord of the "djed", which roughly means "The soul of the lord of the pillar of continuity". The "djed", a type of pillar, was usually understood as the backbone of Osiris, and, at the same time, as the Nile, the backbone of Egypt.
The Nile, supplying water, and Osiris (strongly connected to the vegetable regeneration) who died only to be resurrected, represented continuity and stability. As "Banebdjed", Osiris was given epithets such as "Lord of the Sky" and "Life of the (sun god) Ra", since Ra, when he had become identified with Atum, was considered Osiris' ancestor, from whom his regal authority is inherited. "Ba" does not mean "soul" in the western sense, and has to do with power, reputation, force of character, especially in the case of a god.
Since the "ba" was associated with power, and also happened to be a word for ram in Egyptian, Banebdjed was depicted as a ram, or as Ram-headed. A living, sacred ram was kept at Mendes and worshipped as the incarnation of the god, and upon death, the rams were mummified and buried in a ram-specific necropolis. Banebdjed was consequently said to be Horus' father, as Banebdjed was an aspect of Osiris.
Regarding the association of Osiris with the ram, the god's traditional crook and flail are the instruments of the shepherd, which has suggested to some scholars also an origin for Osiris in herding tribes of the upper Nile. The crook and flail were originally symbols of the minor agricultural deity Andjety, and passed to Osiris later. From Osiris, they eventually passed to Egyptian kings in general as symbols of divine authority.
Mythology.
The cult of Osiris (who was a god chiefly of regeneration and rebirth) had a particularly strong interest in the concept of immortality. Plutarch recounts one version of the myth in which Set (Osiris' brother), along with the Queen of Ethiopia, conspired with 72 accomplices to plot the assassination of Osiris.
Set fooled Osiris into getting into a box, which Set then shut, sealed with lead, and threw into the Nile. Osiris' wife, Isis, searched for his remains until she finally found him embedded in a tamarind tree trunk, which was holding up the roof of a palace in Byblos on the Phoenician coast. She managed to remove the coffin and open it, but Osiris was already dead.
In one version of the myth, she used a spell learned from her father and brought him back to life so he could impregnate her. Afterwards he died again and she hid his body in the desert. Months later, she gave birth to Horus. While she raised Horus, Set was hunting one night and came across the body of Osiris.
Enraged, he tore the body into fourteen pieces and scattered them throughout the land. Isis gathered up all the parts of the body, except the penis (which had been eaten by a fish, the "medjed") and bandaged them together for a proper burial. The gods were impressed by the devotion of Isis and resurrected Osiris as the god of the underworld. Because of his death and resurrection, Osiris was associated with the flooding and retreating of the Nile and thus with the crops along the Nile valley.
Diodorus Siculus gives another version of the myth in which Osiris was described as an ancient king who taught the Egyptians the arts of civilization, including agriculture, then travelled the world with his sister Isis, the satyrs, and the nine muses, before finally returning to Egypt. Osiris was then murdered by his evil brother Typhon, who was identified with Set. Typhon divided the body into twenty-six pieces, which he distributed amongst his fellow conspirators in order to implicate them in the murder. Isis and Hercules (Horus) avenged the death of Osiris and slew Typhon. Isis recovered all the parts of Osiris' body, except the phallus, and secretly buried them. She made replicas of them and distributed them to several locations, which then became centres of Osiris worship.
Death or transition and institution as god of the afterlife.
Ancient Egyptians believed that death was in fact transition. They believed that the ka, or life-force, left the body at the point of death and even their practices of preserving the body further indicated their understanding of the continuance of life. Hence Osiris is known as the God of Transition and commonly also well known as the God of Resurrection and Regeneration.
Plutarch and others have noted that the sacrifices to Osiris were "gloomy, solemn, and mournful..." (Isis and Osiris, 69) and that the great mystery festival, celebrated in two phases, began at Abydos commemorating the death of the god, on the same day that grain was planted in the ground (Isis and Osiris, 13). "The death of the grain and the death of the god were one and the same: the cereal was identified with the god who came from heaven; he was the bread by which man lives. The resurrection of the god symbolized the rebirth of the grain." (Larson 17) The annual festival involved the construction of "Osiris Beds" formed in shape of Osiris, filled with soil and sown with seed.
The germinating seed symbolized Osiris rising from the dead. An almost pristine example was found in the tomb of Tutankhamun by Howard Carter.
The first phase of the festival was a public drama depicting the murder and dismemberment of Osiris, the search of his body by Isis, his triumphal return as the resurrected god, and the battle in which Horus defeated Set. This was all presented by skilled actors as a literary history, and was the main method of recruiting cult membership.
According to Julius Firmicus Maternus of the fourth century, this play was re-enacted each year by worshippers who "beat their breasts and gashed their shoulders... When they pretend that the mutilated remains of the god have been found and rejoined...they turn from mourning to rejoicing." ("De Errore Profanorum").
The passion of Osiris was reflected in his name 'Wenennefer" ("the one who continues to be perfect"), which also alludes to his post mortem power.
Ikhernofret Stela.
Much of the extant information about the Passion of Osiris can be found on the Ikhernofret Stela at Abydos erected in the 12th Dynasty by Ikhernofret (also I-Kher-Nefert), possibly a priest of Osiris or other official (the titles of Ikhernofret are described in his stela from Abydos) during the reign of Senwosret III (Pharaoh Sesostris, about 1875 BC). The Passion Plays were held in the last month of the inundation (the annual Nile flood), coinciding with Spring, and held at Abydos/Abedjou which was the traditional place where the body of Osiris/Wesir drifted ashore after having been drowned in the Nile.
The part of the myth recounting the chopping up of the body into 14 pieces by Set is not recounted in this particular stela. Although it is attested to be a part of the rituals by a version of the Papyrus Jumilhac, in which it took Isis 12 days to reassemble the pieces, coinciding with the festival of ploughing. Some elements of the ceremony were held in the temple, while others involved public participation in a form of theatre. The Stela of I-Kher-Nefert recounts the programme of events of the public elements over the five days of the Festival:
Wheat and clay rituals.
Contrasting with the public "theatrical" ceremonies sourced from the I-Kher-Nefert stele (from the Middle Kingdom), more esoteric ceremonies were performed inside the temples by priests witnessed only by chosen initiates. Plutarch mentions that (for much later period) two days after the beginning of the festival "the priests bring forth a sacred chest containing a small golden coffer, into which they pour some potable water...and a great shout arises from the company for joy that Osiris is found (or resurrected). Then they knead some fertile soil with the water...and fashion therefrom a crescent-shaped figure, which they cloth and adorn, this indicating that they regard these gods as the substance of Earth and Water." ("Isis and Osiris," 39). Yet his accounts were still obscure, for he also wrote, "I pass over the cutting of the wood" - opting not to describe it, since he considered it as a most sacred ritual ("Ibid." 21).
In the Osirian temple at Denderah, an inscription (translated by Budge, Chapter XV, Osiris and the Egyptian Resurrection) describes in detail the making of wheat paste models of each dismembered piece of Osiris to be sent out to the town where each piece is discovered by Isis. At the temple of Mendes, figures of Osiris were made from wheat and paste placed in a trough on the day of the murder, then water was added for several days, until finally the mixture was kneaded into a mold of Osiris and taken to the temple to be buried (the sacred grain for these cakes were grown only in the temple fields). Molds were made from the wood of a red tree in the forms of the sixteen dismembered parts of Osiris, the cakes of 'divine' bread were made from each mold, placed in a silver chest and set near the head of the god with "the inward parts of Osiris" as described in the Book of the Dead (XVII).
On the first day of the Festival of Ploughing, where the goddess Isis appeared in her shrine where she was stripped naked, paste made from the grain were placed in her bed and moistened with water, representing the fecund earth. All of these sacred rituals were "climaxed by the eating of sacramental god, the eucharist by which the celebrants were transformed, in their persuasion, into replicas of their god-man" (Larson 20).
Judgment.
The idea of divine justice being exercised after death for wrongdoing during life is first encountered during the Old Kingdom, in a 6th dynasty tomb containing fragments of what would be described later as the Negative Confessions.
With the rise of the cult of Osiris during the Middle Kingdom the “"democratization of religion"” offered to even his humblest followers the prospect of eternal life, with moral fitness becoming the dominant factor in determining a person's suitability.
At death a person faced judgment by a tribunal of forty-two divine judges. If they led a life in conformance with the precepts of the goddess Ma'at, who represented truth and right living, the person was welcomed into the kingdom of Osiris. If found guilty, the person was thrown to a ""devourer" and didn't share in eternal life.
The person who is taken by the devourer is subject first to terrifying punishment and then annihilated. These depictions of punishment may have influenced medieval perceptions of the inferno in hell via early Christian and Coptic texts.
Purification for those who are considered justified may be found in the descriptions of ""Flame Island", where they experience the triumph over evil and rebirth. For the damned, complete destruction into a state of non-being awaits, but there is no suggestion of eternal torture.
Divine pardon at judgement was always a central concern for the Ancient Egyptians.
During the reign of Seti I, Osiris was also invoked in royal decrees to pursue the living when wrongdoing was observed, but kept secret and not reported.
Greco-Roman era.
Hellenization.
Eventually, in Egypt, the Hellenic pharaohs decided to produce a deity that would be acceptable to both the local Egyptian population, and the influx of Hellenic visitors, to bring the two groups together, rather than allow a source of rebellion to grow. Thus Osiris was identified explicitly with Apis, while really an aspect of Ptah, who had already been identified as Osiris by this point, and a syncretism of the two was created, known as Serapis, and depicted as a standard Greek god.
Destruction of cult.
The cult of Osiris continued until the 6th century AD on the island of Philae in Upper Nile. The Theodosian decrees of the 390s, to destroy all pagan temples, were not enforced there. The worship of Isis and Osiris was allowed to continue at Philae until the time of Justinian I, by treaty between the Blemmyes-Nobadae and Diocletian. Every year they visited Elephantine, and at certain intervals took the image of Isis up river to the land of the Blemmyes for oracular purposes. The practices ended when Justinian sent Narses to destroy sanctuaries, arrest priests, and seize divine images, which were taken to Constantinople.

</doc>
<doc id="22764" url="https://en.wikipedia.org/wiki?curid=22764" title="Orthodox Bahá'í Faith">
Orthodox Bahá'í Faith

The Orthodox Bahá'í Faith is a small Bahá'í sect that formed in 1960 by Mason Remey, and subsequently was the name used by Joel Marangella after he claimed to be Remey's successor. The basis of the dispute is over the identity of the Bahá'í "Guardian", a term referring to the appointed head of the religion, an executive hereditary office held by Shoghi Effendi from 1921 to 1957.
Other than on the matter of leadership and organization, there are few differences between the orthodox and mainstream Bahá'ís in matters of doctrine. As a group who believe that Mason Remey was the second Guardian of the Bahá'í Faith, they are considered heretical Covenant-breakers by the majority of Bahá'ís who follow the leadership of the Universal House of Justice. 
Membership data of the Orthodox Bahá'ís is scarce. One source estimated them at no more than 100 members as of 1988. Memorandums from an Illinois court case in 2007 state their membership in the United States at 40. Websites claiming to represent the Orthodox community indicate followers in the United States and India. Joel Marangella died in San Diego, California on Sept 1, 2013.
Background.
Following the unexpected death of the Bahá'í Faith's first Guardian Shoghi Effendi in 1957, the 27 living Hands of the Cause, having the responsibility to acknowledge any appointment of a successor, gathered and decided that he had died "without having appointed his successor," and that the Universal House of Justice would decide on the situation after its first election. Charles Mason Remey, one of the Hands, declared himself the successor to Shoghi Effendi in 1960. His claim was rejected by the 26 remaining Hands, on the basis that he was not a descendant of Bahá'u'lláh, nor was he appointed to the position by Shoghi Effendi. Remey based his claim on his being the president of the International Bahá'í Council appointed by Shoghi Effendi in 1951. The result was that Remey was unanimously expelled from the Bahá'í community by the Hands of the Cause.
In 1962 Remey asked his supporters in the United States to organize themselves and elect a "National Spiritual Assembly Under the Hereditary Guardianship" (NSAUHG), first elected in 1963. The Assembly of 9 members was incorporated in New Mexico in 1964.
In 1964 the NSAUHG filed a lawsuit against the National Spiritual Assembly (NSA) of the Bahá'ís of the United States to receive the legal title to the Bahá'í House of Worship in Illinois, and all other property owned by the NSA. The NSA counter-sued, and in August 1966 Remey instructed the NSAUHG to withdraw from any action in the matter "regardless of the consequences." Later that year, Remey asked the NSAUHG to dissolve, as well as the International Bahá'í Council that he had appointed with Joel Marangella as president, residing in France. Marangella previously served on the National Spiritual Assembly of France in 1961, and was declared a Covenant-breaker when he accepted Mason Remey as the next Guardian.
Over the years following 1966 the followers of Mason Remey were not organized; with some of his followers concluding that Remey was suffering from dementia, until several of the individuals involved began forming their own groups based on different understandings of succession.
In 1962 Remey gave Marangella a sealed envelope, with instructions to open it when the time was right. In 1965 Mason Remey called for the International Bahá'í Council, of which Marangella was president, to become active. Marangella then opened the sealed letter, which was a hand-written note by Remey appointing Marangella as his successor. Marangella looks upon that time as the time of his official appointment. Remey then changed his mind, deactivated the International Bahá'í Council in 1966, and in 1969 Marangella announced that he was the third Guardian. All of the members of the 1966 NSAUHG accepted Marangella's claim. 
In 1970 Marangella appointed members to a "National Bureau of the Orthodox Bahá'ís in New York", which two years later was moved to New Mexico, and subsequently changed its name to "Mother Bahá'í Council of the United States" (1978) and "Provisional National Bahá'í Council" (2000), with all members appointed by Joel Marangella.. Marangella died in San Diego, CA on Sept 1, 2013.
The third Guardian of the Baha'i Faith Joel Bray Marangella in his Proclamation of 22 September 2006 appointed a Persian Nosrat'u'llah Bahremand the eldest son of Hassan Bahremand, a prominent member of the Orthodox Baha'i Faith as the Fourth Guardian of Orthodox Baha'i Faith. 

</doc>
<doc id="22770" url="https://en.wikipedia.org/wiki?curid=22770" title="1 (number)">
1 (number)

1 (one; or , also called unit, unity, and (multiplicative) identity), is a number, a numeral, and the name of the glyph representing that number. It represents a single entity, the unit of counting or measurement. For example, a line segment of "unit length" is a line segment of length 1.
As a number.
One, sometimes referred to as unity, is the integer before two and after zero. One is the first non-zero number in the natural numbers as well as the first odd number in the natural numbers.
Any number multiplied by one is that number, as one is the identity for multiplication. As a result, one is its own factorial, its own square, its own cube, and so on. One is also the result of the empty product, as any number multiplied by one is itself. It is also the only natural number that is neither composite nor prime with respect to division, but instead considered a unit.
As a digit.
The glyph used today in the Western world to represent the number 1, a vertical line, often with a serif at the top and sometimes a short horizontal line at the bottom, traces its roots back to the Indians, who wrote 1 as a horizontal line, much like the Chinese character 一. The Gupta wrote it as a curved line, and the Nagari sometimes added a small circle on the left (rotated a quarter turn to the right, this 9-look-alike became the present day numeral 1 in the Gujarati and Punjabi scripts). The Nepali also rotated it to the right but kept the circle small. This eventually became the top serif in the modern numeral, but the occasional short horizontal line at the bottom probably originates from similarity with the Roman numeral formula_1. In some countries, the little serif at the top is sometimes extended into a long upstroke, sometimes as long as the vertical line, which can lead to confusion with the glyph for seven in other countries. Where the 1 is written with a long upstroke, the number 7 has a horizontal stroke through the vertical line.
While the shape of the 1 character has an ascender in most modern typefaces, in typefaces with text figures, the character usually is of x-height, as, for example, in .
Many older typewriters do not have a separate symbol for "1" and use the lowercase "l" instead. It is possible to find cases when the uppercase "J" is used, while it may be for decorative purposes.
Mathematics.
Mathematically, 1 is:
One cannot be used as the base of a positional numeral system. (Sometimes tallying is referred to as "base 1", since only one mark — the tally itself — is needed, but this is not a positional notation.)
Since the base 1 exponential function (1"x") always equals 1, its inverse does not exist (which would be called the logarithm base 1 if it did exist).
There are two ways to write the real number 1 as a recurring decimal: as 1.000..., and as 0.999... ("q.v."). There is only one way to represent the real number 1 as a Dedekind cut: formula_2.
Formalizations of the natural numbers have their own representations of 1:
In a multiplicative group or monoid, the identity element is sometimes denoted "1", especially in abelian groups, but "e" (from the German "Einheit", "unity") is more traditional. However, "1" is especially common for the multiplicative identity of a ring, i.e., when an addition and "0" are also present. When such a ring has characteristic "n" not equal to 0, the element called 1 has the property that "n"1 = 1"n" = 0 (where this 0 is the additive identity of the ring). Important examples are general fields.
One is the first figurate number of every kind, such as triangular number, pentagonal number and centered hexagonal number, to name just a few.
In many mathematical and engineering equations, numeric values are typically "normalized" to fall within the unit interval from 0 to 1, where 1 usually represents the maximum possible value in the range of parameters.
Because of the multiplicative identity, if "f"("x") is a multiplicative function, then "f"(1) must equal 1.
It is also the first and second number in the Fibonacci sequence (0 is the zeroth) and is the first number in many other mathematical sequences. As a matter of convention, Sloane's early "Handbook of Integer Sequences" added an initial 1 to any sequence that did not already have it and considered these initial 1's in its lexicographic ordering. Sloane's later "Encyclopedia of Integer Sequences" and its Web counterpart, the "On-Line Encyclopedia of Integer Sequences", ignore initial ones in their lexicographic ordering of sequences, because such initial ones often correspond to trivial cases.
One is neither a prime number nor a composite number, but a unit, like −1 and, in the Gaussian integers, "i" and −"i". The fundamental theorem of arithmetic guarantees unique factorization over the integers only up to units. (For example, 4 = 22, but if units are included, is also equal to, say, (−1)6×123×22, among infinitely many similar "factorizations".)
The definition of a field requires that 1 must not be equal to 0. Thus, there are no fields of characteristic 1. Nevertheless, abstract algebra can consider the field with one element, which is not a singleton and is not a set at all.
One is the only positive integer divisible by exactly one positive integer (whereas prime numbers are divisible by exactly two positive integers, composite numbers are divisible by more than two positive integers, and zero is divisible by all positive integers). One was formerly considered prime by some mathematicians, using the definition that a prime is divisible only by one and itself. However, this complicates the fundamental theorem of arithmetic, so modern definitions exclude units.
One is one of three possible values of the Möbius function: it takes the value one for square-free integers with an even number of distinct prime factors.
One is the only odd number in the range of Euler's totient function φ("x"), in the cases "x" = 1 and "x" = 2.
One is the only 1-perfect number (see multiply perfect number).
By definition, 1 is the magnitude, absolute value, or norm of a unit complex number, unit vector, and a unit matrix (more usually called an identity matrix). Note that the term "unit matrix" is sometimes used to mean something quite different.
By definition, 1 is the probability of an event that is almost certain to occur.
One is the most common leading digit in many sets of data, a consequence of Benford's law.
The ancient Egyptians represented all fractions (with the exception of 2/3) in terms of sums of fractions with numerator 1 and distinct denominators. For example, formula_3. Such representations are popularly known as Egyptian Fractions or Unit Fractions. 
The Generating Function that has all coefficients 1 is given by
formula_4.
This power series converges and has finite value if and only if, formula_5. 
In philosophy.
In the philosophy of Plotinus and a number of other neoplatonists, The One is the ultimate reality and source of all existence.
Philo of Alexandria (20 BC – AD 50) regarded the number one as God's number, and the basis for all numbers ("De Allegoriis Legum," ii.12 [i.66]).
Etymology.
The word one can be used as a noun, an adjective and a pronoun.
It comes from the Old English word an, which comes from the Proto-Germanic root *ainaz. The Proto-Germanic root *ainaz comes from the Proto-Indo-European root *oi-no-.
Compare the Proto-Germanic root *ainaz to Old Frisian an, Gothic ains, Danish een, Dutch een, German eins and Old Norse einn.
Compare the Proto-Indo-European root *oi-no- (which means one, single) to Greek oinos (which means "ace" on dice), Latin unus (one), Old Persian aivam, Old Church Slavonic -inu and ino-, Lithuanian vienas, Old Irish oin and Breton un (one).

</doc>
<doc id="22773" url="https://en.wikipedia.org/wiki?curid=22773" title="Oxidative phosphorylation">
Oxidative phosphorylation

Oxidative phosphorylation (or OXPHOS in short) is the metabolic pathway in which the mitochondria in cells use their structure, enzymes, and energy released by the oxidation of nutrients to reform ATP. Although the many forms of life on earth use a range of different nutrients, ATP is the molecule that supplies energy to metabolism. Almost all aerobic organisms carry out oxidative phosphorylation. This pathway is probably so pervasive because it is a highly efficient way of releasing energy, compared to alternative fermentation processes such as anaerobic glycolysis.
During oxidative phosphorylation, electrons are transferred from electron donors to electron acceptors such as oxygen, in redox reactions. These redox reactions release energy, which is used to form ATP. In eukaryotes, these redox reactions are carried out by a series of protein complexes within the inner membrane of the cell's mitochondria, whereas, in prokaryotes, these proteins are located in the cells' intermembrane space. These linked sets of proteins are called electron transport chains. In eukaryotes, five main protein complexes are involved, whereas in prokaryotes many different enzymes are present, using a variety of electron donors and acceptors.
The energy released by electrons flowing through this electron transport chain is used to transport protons across the inner mitochondrial membrane, in a process called "electron transport". This generates potential energy in the form of a pH gradient and an electrical potential across this membrane. This store of energy is tapped by allowing protons to flow back across the membrane and down this gradient, through a large enzyme called ATP synthase; this process is known as chemiosmosis. This enzyme uses this energy to generate ATP from adenosine diphosphate (ADP), in a phosphorylation reaction. This reaction is driven by the proton flow, which forces the rotation of a part of the enzyme; the ATP synthase is a rotary mechanical motor.
Although oxidative phosphorylation is a vital part of metabolism, it produces reactive oxygen species such as superoxide and hydrogen peroxide, which lead to propagation of free radicals, damaging cells and contributing to disease and, possibly, aging (senescence). The enzymes carrying out this metabolic pathway are also the target of many drugs and poisons that inhibit their activities.
Overview of energy transfer by chemiosmosis.
Oxidative phosphorylation works by using energy-releasing chemical reactions to drive energy-requiring reactions: The two sets of reactions are said to be "coupled". This means one cannot occur without the other. The flow of electrons through the electron transport chain, from electron donors such as NADH to electron acceptors such as oxygen, is an exergonic process – it releases energy, whereas the synthesis of ATP is an endergonic process, which requires an input of energy. Both the electron transport chain and the ATP synthase are embedded in a membrane, and energy is transferred from electron transport chain to the ATP synthase by movements of protons across this membrane, in a process called "chemiosmosis". In practice, this is like a simple electric circuit, with a current of protons being driven from the negative N-side of the membrane to the positive P-side by the proton-pumping enzymes of the electron transport chain. These enzymes are like a battery, as they perform work to drive current through the circuit. The movement of protons creates an electrochemical gradient across the membrane, which is often called the "proton-motive force". It has two components: a difference in proton concentration (a H+ gradient, ΔpH) and a difference in electric potential, with the N-side having a negative charge.
ATP synthase releases this stored energy by completing the circuit and allowing protons to flow down the electrochemical gradient, back to the N-side of the membrane. This kinetic energy drives the rotation of part of the enzymes structure and couples this motion to the synthesis of ATP.
The two components of the proton-motive force are thermodynamically equivalent: In mitochondria, the largest part of energy is provided by the potential; in alkaliphile bacteria the electrical energy even has to compensate for a counteracting inverse pH difference. Inversely, chloroplasts operate mainly on ΔpH. However, they also require a small membrane potential for the kinetics of ATP synthesis. At least in the case of the fusobacterium "P. modestum" it drives the counter-rotation of subunits a and c of the FO motor of ATP synthase.
The amount of energy released by oxidative phosphorylation is high, compared with the amount produced by anaerobic fermentation. Glycolysis produces only 2 ATP molecules, but somewhere between 30 and 36 ATPs are produced by the oxidative phosphorylation of the 10 NADH and 2 succinate molecules made by converting one molecule of glucose to carbon dioxide and water, while each cycle of beta oxidation of a fatty acid yields about 14 ATPs. These ATP yields are theoretical maximum values; in practice, some protons leak across the membrane, lowering the yield of ATP.
Electron and proton transfer molecules.
The electron transport chain carries both protons and electrons, passing electrons from donors to acceptors, and transporting protons across a membrane. These processes use both soluble and protein-bound transfer molecules. In mitochondria, electrons are transferred within the intermembrane space by the water-soluble electron transfer protein cytochrome c. This carries only electrons, and these are transferred by the reduction and oxidation of an iron atom that the protein holds within a heme group in its structure. Cytochrome c is also found in some bacteria, where it is located within the periplasmic space.
Within the inner mitochondrial membrane, the lipid-soluble electron carrier coenzyme Q10 (Q) carries both electrons and protons by a redox cycle. This small benzoquinone molecule is very hydrophobic, so it diffuses freely within the membrane. When Q accepts two electrons and two protons, it becomes reduced to the "ubiquinol" form (QH2); when QH2 releases two electrons and two protons, it becomes oxidized back to the "ubiquinone" (Q) form. As a result, if two enzymes are arranged so that Q is reduced on one side of the membrane and QH2 oxidized on the other, ubiquinone will couple these reactions and shuttle protons across the membrane. Some bacterial electron transport chains use different quinones, such as menaquinone, in addition to ubiquinone.
Within proteins, electrons are transferred between flavin cofactors, iron–sulfur clusters, and cytochromes. There are several types of iron–sulfur cluster. The simplest kind found in the electron transfer chain consists of two iron atoms joined by two atoms of inorganic sulfur; these are called [2Fe–2S] clusters. The second kind, called [4Fe–4S], contains a cube of four iron atoms and four sulfur atoms. Each iron atom in these clusters is coordinated by an additional amino acid, usually by the sulfur atom of cysteine. Metal ion cofactors undergo redox reactions without binding or releasing protons, so in the electron transport chain they serve solely to transport electrons through proteins. Electrons move quite long distances through proteins by hopping along chains of these cofactors. This occurs by quantum tunnelling, which is rapid over distances of less than 1.4 m.
Eukaryotic electron transport chains.
Many catabolic biochemical processes, such as glycolysis, the citric acid cycle, and beta oxidation, produce the reduced coenzyme NADH. This coenzyme contains electrons that have a high transfer potential; in other words, they will release a large amount of energy upon oxidation. However, the cell does not release this energy all at once, as this would be an uncontrollable reaction. Instead, the electrons are removed from NADH and passed to oxygen through a series of enzymes that each release a small amount of the energy. This set of enzymes, consisting of complexes I through IV, is called the electron transport chain and is found in the inner membrane of the mitochondrion. Succinate is also oxidized by the electron transport chain, but feeds into the pathway at a different point.
In eukaryotes, the enzymes in this electron transport system use the energy released from the oxidation of NADH to pump protons across the inner membrane of the mitochondrion. This causes protons to build up in the intermembrane space, and generates an electrochemical gradient across the membrane. The energy stored in this potential is then used by ATP synthase to produce ATP. Oxidative phosphorylation in the eukaryotic mitochondrion is the best-understood example of this process. The mitochondrion is present in almost all eukaryotes, with the exception of anaerobic protozoa such as "Trichomonas vaginalis" that instead reduce protons to hydrogen in a remnant mitochondrion called a hydrogenosome.
NADH-coenzyme Q oxidoreductase (complex I).
NADH-coenzyme Q oxidoreductase, also known as "NADH dehydrogenase" or "complex I", is the first protein in the electron transport chain. Complex I is a giant enzyme with the mammalian complex I having 46 subunits and a molecular mass of about 1,000 kilodaltons (kDa). The structure is known in detail only from a bacterium; in most organisms the complex resembles a boot with a large "ball" poking out from the membrane into the mitochondrion. The genes that encode the individual proteins are contained in both the cell nucleus and the mitochondrial genome, as is the case for many enzymes present in the mitochondrion.
The reaction that is catalyzed by this enzyme is the two electron oxidation of NADH by coenzyme Q10 or "ubiquinone" (represented as Q in the equation below), a lipid-soluble quinone that is found in the mitochondrion membrane:
formula_1
The start of the reaction, and indeed of the entire electron chain, is the binding of a NADH molecule to complex I and the donation of two electrons. The electrons enter complex I via a prosthetic group attached to the complex, flavin mononucleotide (FMN). The addition of electrons to FMN converts it to its reduced form, FMNH2. The electrons are then transferred through a series of iron–sulfur clusters: the second kind of prosthetic group present in the complex. There are both [2Fe–2S] and [4Fe–4S] iron–sulfur clusters in complex I.
As the electrons pass through this complex, four protons are pumped from the matrix into the intermembrane space. Exactly how this occurs is unclear, but it seems to involve conformational changes in complex I that cause the protein to bind protons on the N-side of the membrane and release them on the P-side of the membrane. Finally, the electrons are transferred from the chain of iron–sulfur clusters to a ubiquinone molecule in the membrane. Reduction of ubiquinone also contributes to the generation of a proton gradient, as two protons are taken up from the matrix as it is reduced to ubiquinol (QH2).
Succinate-Q oxidoreductase (complex II).
Succinate-Q oxidoreductase, also known as "complex II" or "succinate dehydrogenase", is a second entry point to the electron transport chain. It is unusual because it is the only enzyme that is part of both the citric acid cycle and the electron transport chain. Complex II consists of four protein subunits and contains a bound flavin adenine dinucleotide (FAD) cofactor, iron–sulfur clusters, and a heme group that does not participate in electron transfer to coenzyme Q, but is believed to be important in decreasing production of reactive oxygen species. It oxidizes succinate to fumarate and reduces ubiquinone. As this reaction releases less energy than the oxidation of NADH, complex II does not transport protons across the membrane and does not contribute to the proton gradient.
In some eukaryotes, such as the parasitic worm "Ascaris suum", an enzyme similar to complex II, fumarate reductase (menaquinol:fumarate
oxidoreductase, or QFR), operates in reverse to oxidize ubiquinol and reduce fumarate. This allows the worm to survive in the anaerobic environment of the large intestine, carrying out anaerobic oxidative phosphorylation with fumarate as the electron acceptor. Another unconventional function of complex II is seen in the malaria parasite "Plasmodium falciparum". Here, the reversed action of complex II as an oxidase is important in regenerating ubiquinol, which the parasite uses in an unusual form of pyrimidine biosynthesis.
Electron transfer flavoprotein-Q oxidoreductase.
Electron transfer flavoprotein-ubiquinone oxidoreductase (ETF-Q oxidoreductase), also known as "electron transferring-flavoprotein dehydrogenase", is a third entry point to the electron transport chain. It is an enzyme that accepts electrons from electron-transferring flavoprotein in the mitochondrial matrix, and uses these electrons to reduce ubiquinone. This enzyme contains a flavin and a [4Fe–4S] cluster, but, unlike the other respiratory complexes, it attaches to the surface of the membrane and does not cross the lipid bilayer.
In mammals, this metabolic pathway is important in beta oxidation of fatty acids and catabolism of amino acids and choline, as it accepts electrons from multiple acetyl-CoA dehydrogenases. In plants, ETF-Q oxidoreductase is also important in the metabolic responses that allow survival in extended periods of darkness.
Q-cytochrome c oxidoreductase (complex III).
Q-cytochrome c oxidoreductase is also known as "cytochrome c reductase", "cytochrome bc1 complex", or simply "complex III". In mammals, this enzyme is a dimer, with each subunit complex containing 11 protein subunits, an [2Fe-2S] iron–sulfur cluster and three cytochromes: one cytochrome c1 and two b cytochromes. A cytochrome is a kind of electron-transferring protein that contains at least one heme group. The iron atoms inside complex III’s heme groups alternate between a reduced ferrous (+2) and oxidized ferric (+3) state as the electrons are transferred through the protein.
The reaction catalyzed by complex III is the oxidation of one molecule of ubiquinol and the reduction of two molecules of cytochrome c, a heme protein loosely associated with the mitochondrion. Unlike coenzyme Q, which carries two electrons, cytochrome c carries only one electron.
As only one of the electrons can be transferred from the QH2 donor to a cytochrome c acceptor at a time, the reaction mechanism of complex III is more elaborate than those of the other respiratory complexes, and occurs in two steps called the Q cycle. In the first step, the enzyme binds three substrates, first, QH2, which is then oxidized, with one electron being passed to the second substrate, cytochrome c. The two protons released from QH2 pass into the intermembrane space. The third substrate is Q, which accepts the second electron from the QH2 and is reduced to Q.−, which is the ubisemiquinone free radical. The first two substrates are released, but this ubisemiquinone intermediate remains bound. In the second step, a second molecule of QH2 is bound and again passes its first electron to a cytochrome c acceptor. The second electron is passed to the bound ubisemiquinone, reducing it to QH2 as it gains two protons from the mitochondrial matrix. This QH2 is then released from the enzyme.
As coenzyme Q is reduced to ubiquinol on the inner side of the membrane and oxidized to ubiquinone on the other, a net transfer of protons across the membrane occurs, adding to the proton gradient. The rather complex two-step mechanism by which this occurs is important, as it increases the efficiency of proton transfer. If, instead of the Q cycle, one molecule of QH2 were used to directly reduce two molecules of cytochrome c, the efficiency would be halved, with only one proton transferred per cytochrome c reduced.
Cytochrome c oxidase (complex IV).
Cytochrome c oxidase, also known as "complex IV", is the final protein complex in the electron transport chain. The mammalian enzyme has an extremely complicated structure and contains 13 subunits, two heme groups, as well as multiple metal ion cofactors – in all, three atoms of copper, one of magnesium and one of zinc.
This enzyme mediates the final reaction in the electron transport chain and transfers electrons to oxygen, while pumping protons across the membrane. The final electron acceptor oxygen, which is also called the "terminal electron acceptor", is reduced to water in this step. Both the direct pumping of protons and the consumption of matrix protons in the reduction of oxygen contribute to the proton gradient. The reaction catalyzed is the oxidation of cytochrome c and the reduction of oxygen:
formula_5
Alternative reductases and oxidases.
Many eukaryotic organisms have electron transport chains that differ from the much-studied mammalian enzymes described above. For example, plants have alternative NADH oxidases, which oxidize NADH in the cytosol rather than in the mitochondrial matrix, and pass these electrons to the ubiquinone pool. These enzymes do not transport protons, and, therefore, reduce ubiquinone without altering the electrochemical gradient across the inner membrane.
Another example of a divergent electron transport chain is the "alternative oxidase", which is found in plants, as well as some fungi, protists, and possibly some animals. This enzyme transfers electrons directly from ubiquinol to oxygen.
The electron transport pathways produced by these alternative NADH and ubiquinone oxidases have lower ATP yields than the full pathway. The advantages produced by a shortened pathway are not entirely clear. However, the alternative oxidase is produced in response to stresses such as cold, reactive oxygen species, and infection by pathogens, as well as other factors that inhibit the full electron transport chain. Alternative pathways might, therefore, enhance an organisms' resistance to injury, by reducing oxidative stress.
Organization of complexes.
The original model for how the respiratory chain complexes are organized was that they diffuse freely and independently in the mitochondrial membrane. However, recent data suggest that the complexes might form higher-order structures called supercomplexes or "respirasomes." In this model, the various complexes exist as organized sets of interacting enzymes. These associations might allow channeling of substrates between the various enzyme complexes, increasing the rate and efficiency of electron transfer. Within such mammalian supercomplexes, some components would be present in higher amounts than others, with some data suggesting a ratio between complexes I/II/III/IV and the ATP synthase of approximately 1:1:3:7:4. However, the debate over this supercomplex hypothesis is not completely resolved, as some data do not appear to fit with this model.
Prokaryotic electron transport chains.
In contrast to the general similarity in structure and function of the electron transport chains in eukaryotes, bacteria and archaea possess a large variety of electron-transfer enzymes. These use an equally wide set of chemicals as substrates. In common with eukaryotes, prokaryotic electron transport uses the energy released from the oxidation of a substrate to pump ions across a membrane and generate an electrochemical gradient. In the bacteria, oxidative phosphorylation in "Escherichia coli" is understood in most detail, while archaeal systems are at present poorly understood.
The main difference between eukaryotic and prokaryotic oxidative phosphorylation is that bacteria and archaea use many different substances to donate or accept electrons. This allows prokaryotes to grow under a wide variety of environmental conditions. In "E. coli", for example, oxidative phosphorylation can be driven by a large number of pairs of reducing agents and oxidizing agents, which are listed below. The midpoint potential of a chemical measures how much energy is released when it is oxidized or reduced, with reducing agents having negative potentials and oxidizing agents positive potentials.
As shown above, "E. coli" can grow with reducing agents such as formate, hydrogen, or lactate as electron donors, and nitrate, DMSO, or oxygen as acceptors. The larger the difference in midpoint potential between an oxidizing and reducing agent, the more energy is released when they react. Out of these compounds, the succinate/fumarate pair is unusual, as its midpoint potential is close to zero. Succinate can therefore be oxidized to fumarate if a strong oxidizing agent such as oxygen is available, or fumarate can be reduced to succinate using a strong reducing agent such as formate. These alternative reactions are catalyzed by succinate dehydrogenase and fumarate reductase, respectively.
Some prokaryotes use redox pairs that have only a small difference in midpoint potential. For example, nitrifying bacteria such as "Nitrobacter" oxidize nitrite to nitrate, donating the electrons to oxygen. The small amount of energy released in this reaction is enough to pump protons and generate ATP, but not enough to produce NADH or NADPH directly for use in anabolism. This problem is solved by using a nitrite oxidoreductase to produce enough proton-motive force to run part of the electron transport chain in reverse, causing complex I to generate NADH.
Prokaryotes control their use of these electron donors and acceptors by varying which enzymes are produced, in response to environmental conditions. This flexibility is possible because different oxidases and reductases use the same ubiquinone pool. This allows many combinations of enzymes to function together, linked by the common ubiquinol intermediate. These respiratory chains therefore have a modular design, with easily interchangeable sets of enzyme systems.
In addition to this metabolic diversity, prokaryotes also possess a range of isozymes – different enzymes that catalyze the same reaction. For example, in "E. coli", there are two different types of ubiquinol oxidase using oxygen as an electron acceptor. Under highly aerobic conditions, the cell uses an oxidase with a low affinity for oxygen that can transport two protons per electron. However, if levels of oxygen fall, they switch to an oxidase that transfers only one proton per electron, but has a high affinity for oxygen.
ATP synthase (complex V).
ATP synthase, also called "complex V", is the final enzyme in the oxidative phosphorylation pathway. This enzyme is found in all forms of life and functions in the same way in both prokaryotes and eukaryotes. The enzyme uses the energy stored in a proton gradient across a membrane to drive the synthesis of ATP from ADP and phosphate (Pi). Estimates of the number of protons required to synthesize one ATP have ranged from three to four, with some suggesting cells can vary this ratio, to suit different conditions.
This phosphorylation reaction is an equilibrium, which can be shifted by altering the proton-motive force. In the absence of a proton-motive force, the ATP synthase reaction will run from right to left, hydrolyzing ATP and pumping protons out of the matrix across the membrane. However, when the proton-motive force is high, the reaction is forced to run in the opposite direction; it proceeds from left to right, allowing protons to flow down their concentration gradient and turning ADP into ATP. Indeed, in the closely related vacuolar type H+-ATPases, the hydrolysis reaction is used to acidify cellular compartments, by pumping protons and hydrolysing ATP.
ATP synthase is a massive protein complex with a mushroom-like shape. The mammalian enzyme complex contains 16 subunits and has a mass of approximately 600 kilodaltons. The portion embedded within the membrane is called FO and contains a ring of c subunits and the proton channel. The stalk and the ball-shaped headpiece is called F1 and is the site of ATP synthesis. The ball-shaped complex at the end of the F1 portion contains six proteins of two different kinds (three α subunits and three β subunits), whereas the "stalk" consists of one protein: the γ subunit, with the tip of the stalk extending into the ball of α and β subunits. Both the α and β subunits bind nucleotides, but only the β subunits catalyze the ATP synthesis reaction. Reaching along the side of the F1 portion and back into the membrane is a long rod-like subunit that anchors the α and β subunits into the base of the enzyme.
As protons cross the membrane through the channel in the base of ATP synthase, the FO proton-driven motor rotates. Rotation might be caused by changes in the ionization of amino acids in the ring of c subunits causing electrostatic interactions that propel the ring of c subunits past the proton channel. This rotating ring in turn drives the rotation of the central axle (the γ subunit stalk) within the α and β subunits. The α and β subunits are prevented from rotating themselves by the side-arm, which acts as a stator. This movement of the tip of the γ subunit within the ball of α and β subunits provides the energy for the active sites in the β subunits to undergo a cycle of movements that produces and then releases ATP.
This ATP synthesis reaction is called the "binding change mechanism" and involves the active site of a β subunit cycling between three states. In the "open" state, ADP and phosphate enter the active site (shown in brown in the diagram). The protein then closes up around the molecules and binds them loosely – the "loose" state (shown in red). The enzyme then changes shape again and forces these molecules together, with the active site in the resulting "tight" state (shown in pink) binding the newly produced ATP molecule with very high affinity. Finally, the active site cycles back to the open state, releasing ATP and binding more ADP and phosphate, ready for the next cycle.
In some bacteria and archaea, ATP synthesis is driven by the movement of sodium ions through the cell membrane, rather than the movement of protons. Archaea such as "Methanococcus" also contain the A1Ao synthase, a form of the enzyme that contains additional proteins with little similarity in sequence to other bacterial and eukaryotic ATP synthase subunits. It is possible that, in some species, the A1Ao form of the enzyme is a specialized sodium-driven ATP synthase, but this might not be true in all cases.
Reactive oxygen species.
Molecular oxygen is an ideal terminal electron acceptor because it is a strong oxidizing agent. The reduction of oxygen does involve potentially harmful intermediates. Although the transfer of four electrons and four protons reduces oxygen to water, which is harmless, transfer of one or two electrons produces superoxide or peroxide anions, which are dangerously reactive.
These reactive oxygen species and their reaction products, such as the hydroxyl radical, are very harmful to cells, as they oxidize proteins and cause mutations in DNA. This cellular damage might contribute to disease and is proposed as one cause of aging.
The cytochrome c oxidase complex is highly efficient at reducing oxygen to water, and it releases very few partly reduced intermediates; however small amounts of superoxide anion and peroxide are produced by the electron transport chain. Particularly important is the reduction of coenzyme Q in complex III, as a highly reactive ubisemiquinone free radical is formed as an intermediate in the Q cycle. This unstable species can lead to electron "leakage" when electrons transfer directly to oxygen, forming superoxide. As the production of reactive oxygen species by these proton-pumping complexes is greatest at high membrane potentials, it has been proposed that mitochondria regulate their activity to maintain the membrane potential within a narrow range that balances ATP production against oxidant generation. For instance, oxidants can activate uncoupling proteins that reduce membrane potential.
To counteract these reactive oxygen species, cells contain numerous antioxidant systems, including antioxidant vitamins such as vitamin C and vitamin E, and antioxidant enzymes such as superoxide dismutase, catalase, and peroxidases, which detoxify the reactive species, limiting damage to the cell.
Inhibitors.
There are several well-known drugs and toxins that inhibit oxidative phosphorylation. Although any one of these toxins inhibits only one enzyme in the electron transport chain, inhibition of any step in this process will halt the rest of the process. For example, if oligomycin inhibits ATP synthase, protons cannot pass back into the mitochondrion. As a result, the proton pumps are unable to operate, as the gradient becomes too strong for them to overcome. NADH is then no longer oxidized and the citric acid cycle ceases to operate because the concentration of NAD+ falls below the concentration that these enzymes can use.
Not all inhibitors of oxidative phosphorylation are toxins. In brown adipose tissue, regulated proton channels called uncoupling proteins can uncouple respiration from ATP synthesis. This rapid respiration produces heat, and is particularly important as a way of maintaining body temperature for hibernating animals, although these proteins may also have a more general function in cells' responses to stress.
History.
The field of oxidative phosphorylation began with the report in 1906 by Arthur Harden of a vital role for phosphate in cellular fermentation, but initially only sugar phosphates were known to be involved. However, in the early 1940s, the link between the oxidation of sugars and the generation of ATP was firmly established by Herman Kalckar, confirming the central role of ATP in energy transfer that had been proposed by Fritz Albert Lipmann in 1941. Later, in 1949, Morris Friedkin and Albert L. Lehninger proved that the coenzyme NADH linked metabolic pathways such as the citric acid cycle and the synthesis of ATP. The term "oxidative phosphorylation" was coined by in 1939.
For another twenty years, the mechanism by which ATP is generated remained mysterious, with scientists searching for an elusive "high-energy intermediate" that would link oxidation and phosphorylation reactions. This puzzle was solved by Peter D. Mitchell with the publication of the chemiosmotic theory in 1961. At first, this proposal was highly controversial, but it was slowly accepted and Mitchell was awarded a Nobel prize in 1978. Subsequent research concentrated on purifying and characterizing the enzymes involved, with major contributions being made by David E. Green on the complexes of the electron-transport chain, as well as Efraim Racker on the ATP synthase. A critical step towards solving the mechanism of the ATP synthase was provided by Paul D. Boyer, by his development in 1973 of the "binding change" mechanism, followed by his radical proposal of rotational catalysis in 1982. More recent work has included structural studies on the enzymes involved in oxidative phosphorylation by John E. Walker, with Walker and Boyer being awarded a Nobel Prize in 1997.

</doc>
<doc id="22775" url="https://en.wikipedia.org/wiki?curid=22775" title="Old Fashioned">
Old Fashioned

The Old Fashioned is a cocktail made by muddling sugar with bitters, then adding alcohol, such as whiskey or brandy, and a twist of citrus rind. It is traditionally served in a short, round, tumbler-like glass, which is called an "Old Fashioned glass", named after the drink.
The Old Fashioned, developed during the 19th century and given its name in the 1880s, is an IBA Official Cocktail. It is also one of six basic drinks listed in David A. Embury's "The Fine Art of Mixing Drinks".
History.
The first documented definition of the word "cocktail" was in response to a reader's letter asking to define the word in the May 6, 1806, issue of "The Balance and Columbian Repository" in Hudson, New York. In the May 13, 1806, issue, the paper's editor wrote that it was a potent concoction of spirits, bitters, water, and sugar; it was also referred to at the time as a bittered sling.
J.E. Alexander describes the cocktail similarly in 1833, as he encountered it in New York City, as being rum, gin, or brandy, significant water, bitters, and sugar, though he includes a nutmeg garnish as well.
By the 1860s, it was common for orange curaçao, absinthe, and other liqueurs to be added to the cocktail. The original concoction, albeit in different proportions, came back into vogue, and was referred to as "old-fashioned". The most popular of the in-vogue "old-fashioned" cocktails were made with whiskey, according to a Chicago barman, quoted in The Chicago Daily Tribune in 1882, with rye being more popular than Bourbon. The recipe he describes is a similar combination of spirits, bitters, water and sugar of seventy-six years earlier.
Traditionally, the first use of the name "Old Fashioned" for a Bourbon whiskey cocktail was said to have been, anachronistically, at the Pendennis Club, a gentlemen's club founded in 1881 in Louisville, Kentucky. The recipe was said to have been invented by a bartender at that club in honor of Colonel James E. Pepper, a prominent bourbon distiller, who brought it to the Waldorf-Astoria Hotel bar in New York City.
Recipe.
George Kappeler provides some of the earliest published recipes for Old Fashioned cocktails in his 1895 book. Recipes are given for Whiskey, Brandy, Holland gin, and Old Tom gin. The Whiskey Old Fashioned recipe specifies the following (with a jigger being ):
By the 1860s, as illustrated by Jerry Thomas' 1862 book, basic cocktail recipes included Curaçao, or other liqueurs, not mentioned in the early 19th century descriptions, nor the Chicago Daily Tribune descriptions of the "Old Fashioned" cocktails of the early 1880s; it is absent from Kappeler's Old Fashioned recipes as well. The differences of the Old Fashioned cocktail recipes from the cocktail recipes of the late 19th Century are mainly preparation method, the use of sugar and water in lieu of simple or gomme syrup, and the absence of additional liqueurs. These Old Fashioned cocktail recipes are literally for cocktails done the old-fashioned way.
A book by David Embury published in 1948 provides a slight variation, specifying 12 parts American whiskey, 1 part simple syrup, 1-3 dashes Angostura bitters, a twist of lemon peel over the top, and serve garnished with the lemon peel.
Two additional recipes from the 1900s vary in the precise ingredients, but omit the cherry which was introduced after 1930 as well as the soda water which the occasional recipe calls for. Orange bitters were a popular ingredient in the late 19th century,
Modifications.
The original Old Fashioned recipe would have showcased the whiskey available in America in the 19th century, either Irish, Bourbon or rye whiskey. But in some regions, especially Wisconsin, brandy is substituted for whiskey (sometimes called a Brandy Old Fashioned). Eventually the use of other spirits became common, such as a gin recipe becoming popularized in the late 1940s. Another common modification is to add soda water.
Common garnishes for an Old Fashioned include an orange slice or a maraschino cherry, although these modifications came around 1930, some time after the original recipe was invented. While some recipes began making sparse use of the orange zest for flavor, the practice of muddling orange and other fruit gained prevalence as late as the 1990s.
In popular culture.
In John Updike's novel "Rabbit, Run", the title character resents the job he works at to "earn a living to buy sugar for [his wife Janice] to put into her rotten old Old-Fashioneds".
The drunkard played by Jim Backus in Stanley Kramer's film "It's a Mad, Mad, Mad, Mad World" steps away from the controls of the airplane he is flying to mix himself an Old Fashioned.
The Old Fashioned is the cocktail of choice of Don Draper, the lead character on the "Mad Men" television series, set in the 1960s. The use of the drink in the series coincides with a renewed interest in this and other classic cocktails in the 2000s.
In the film "Crazy, Stupid, Love", Jacob Palmer portrayed by Ryan Gosling enjoys this drink as his beverage of choice.

</doc>
<doc id="22776" url="https://en.wikipedia.org/wiki?curid=22776" title="Omnipotence">
Omnipotence

Omnipotence is the quality of having unlimited power. Monotheistic religions generally attribute omnipotence to only the deity of their faith. In the monotheistic philosophies of Abrahamic religions, omnipotence is often listed as one of a deity's characteristics among many, including omniscience, omnipresence, and omnibenevolence. The presence of all these properties in a single entity has given rise to considerable theological debate, prominently including the problem of theodicy, the question of why such a deity would permit the manifestation of evil.
Meanings.
The term omnipotent has been used to connote a number of different positions. These positions include, but are not limited to, the following:
Under many philosophical definitions of the term "deity", senses 2, 3 and 4 can be shown to be equivalent. However, on all understandings of omnipotence, it is generally held that a deity is able to intervene in the world by superseding the laws of physics, since they are not part of its nature, but the principles on which it has created the physical world. However many modern scholars (such as John Polkinghorne) hold that it is part of a deity's nature to be consistent and that it would be inconsistent for a deity to go against its own laws unless there were an overwhelming reason to do so.
The word "Omnipotence" derives from the Latin term "Omni Potens", meaning "All-Powerful" instead of "Infinite Power" implied by its English counterpart. The term could be applied to both deities and Roman Emperors. Being the one with "All the power", it was not uncommon for nobles to attempt to prove their Emperor's "Omni Potens" to the people, by demonstrating his effectiveness at leading the Empire.
Scholastic definition.
St. Thomas Aquinas, OP acknowledged difficulty in comprehending the Deity's power: "All confess that God is omnipotent; but it seems difficult to explain in what His omnipotence precisely consists: for there may be doubt as to the precise meaning of the word 'all' when we say that God can do all things. If, however, we consider the matter aright, since power is said in reference to possible things, this phrase, 'God can do all things,' is rightly understood to mean that God can do all things that are possible; and for this reason He is said to be omnipotent." In the scholastic understanding, omnipotence is generally understood to be compatible with certain limitations or restrictions. A proposition that is necessarily true is one whose negation is self-contradictory.
St. Thomas explains that:
Omnipotence is all-sufficient power. The adaptation of means to ends in the universe does not argue, as J. S. Mill would have it, that the power of the designer is limited, but only that God has willed to manifest His glory by a world so constituted rather than by another. Indeed the production of secondary causes, capable of accomplishing certain effects, requires greater power than the direct accomplishment of these same effects. On the other hand even though no creature existed, God's power would not be barren, for "creatures are not an end to God." Regarding the Deity's power, medieval theologians contended that there are certain things that even an omnipotent deity cannot do. The statement "a deity can do anything" is only sensible with an assumed suppressed clause, "that implies the perfection of true power". This standard scholastic answer allows that acts of creatures such as walking can be performed by humans but not by a deity. Rather than an advantage in power, human acts such as walking, sitting, or giving birth were possible only because of a "defect" in human power. The capacity to sin, for example, is not a power but a defect or infirmity. In response to questions of a deity performing impossibilities, e.g. making square circles, St. Thomas says that "everything that does not imply a contradiction in terms, is numbered amongst those possible things, in respect of which God is called omnipotent: whereas whatever implies contradiction does not come within the scope of divine omnipotence, because it cannot have the aspect of possibility. Hence it is better to say that such things cannot be done, than that God cannot do them. Nor is this contrary to the word of the angel, saying: 'No word shall be impossible with God.' For whatever implies a contradiction cannot be a word, because no intellect can possibly conceive such a thing."
In recent times, C. S. Lewis has adopted a scholastic position in the course of his work The Problem of Pain. Lewis follows Aquinas' view on contradiction:
In psychology.
Early Freudianism saw a feeling of omnipotence as intrinsic to early childhood. 'As Freud and Ferenczi have shown, the child lives in a sort of megalomania for a long period...the "fiction of omnipotence"'. At birth. 'the baby "is" everything "as far as he knows" - "all powerful"...every step he takes towards establishing his own limits and boundaries will be painful because he'll have to lose this original God-like feeling of omnipotence'.
Freud considered that in a neurotic 'the "omnipotence" which he ascribed to his thoughts and feelings...is a frank acknowledgement of a relic of the old megalomania of infancy'. In some narcissists, the 'period of primary narcissism which subjectively did not need any objects and was entirely independent...may be retained or regressively regained..."omnipotent" behavior'.
D. W. Winnicott took a more positive view of a belief in early omnipotence, seeing it as essential to the child's well-being; and "good-enough" mothering as essential to enable the child to 'cope with the immense shock of loss of omnipotence' - as opposed to whatever 'prematurely forces it out of its narcissistic universe'.
Rejection or limitation.
Some monotheists reject the view that a deity is or could be omnipotent, or take the view that, by choosing to create creatures with freewill, a deity has chosen to limit divine omnipotence. In Conservative and Reform Judaism, and some movements within Protestant Christianity, including open theism, deities are said to act in the world through persuasion, and not by coercion (this is a matter of choice—a deity could act miraculously, and perhaps on occasion does so—while for process theism it is a matter of necessity—creatures have inherent powers that a deity cannot, even in principle, override). Deities are manifested in the world through inspiration and the creation of possibility, not necessarily by miracles or violations of the laws of nature.
The rejection of omnipotence often follows from either philosophical or scriptural considerations, discussed below.
Philosophical grounds.
Process theology rejects unlimited omnipotence on a philosophical basis, arguing that omnipotence as classically understood would be less than perfect, and is therefore incompatible with the idea of a perfect deity. The idea is grounded in Plato's oft-overlooked statement that "being is power."
From this premise, Charles Hartshorne argues further that:
The argument can be stated as follows:
For example, though someone might control a lump of jelly-pudding almost completely, the inability of that pudding to stage any resistance renders that person's power rather unimpressive. Power can only be said to be great if it is over something that has defenses and its own agenda. If a deity's power is to be great, it must therefore be over beings that have at least some of their own defenses and agenda. Thus, if a deity does not have absolute power, it must therefore embody some of the characteristics of power, and some of the characteristics of persuasion. This view is known as dipolar theism.
The most popular works espousing this point are from Harold Kushner (in Judaism). The need for a modified view of omnipotence was also articulated by Alfred North Whitehead in the early 20th century and expanded upon by the aforementioned philosopher Charles Hartshorne. Hartshorne proceeded within the context of the theological system known as process theology.
Scriptural grounds.
In the Authorized King James Version of the Bible, as well as several other versions, in Revelation 19:6 it is stated "...the Lord God omnipotent reigneth" (the original Greek word is παντοκράτωρ, "all-mighty"). Although much of the narrative of the Old Testament describes the Judeo-Christian God as interacting with creation primarily through persuasion, and only occasionally through force. However, it could further be argued that the ability to conflict with truth is not an appropriate representation of accepted definitions of power, which negates the assertion that a deity does not have infinite powers.
Many other verses in the Christian Bible do assert omnipotence of its deity without actually using the word itself. There are several mentions of the Christian deity being referred to as simply "Almighty", showing that the Christian Bible supports the belief of an omnipotent deity. Some such verses are listed below:
Psalms 33:8-9: Let all the earth fear the LORD: let all the inhabitants of the world stand in awe of him. For he spoke, and it was done; he commanded, and it stood fast.
Genesis 17:1: And when Abram was ninety years old and nine, the LORD appeared to Abram, and said unto him, I am the Almighty God; walk before me, and be thou perfect. (The Hebrew word used here is "shadday")
Jeremiah 32:27: Behold, I am the LORD, the God of all flesh: is there any thing too hard for me?
At his command a storm arose and covered the sea. (Psalm 107:25)
Several parts of the New Testament claim Jesus to be one with the Father, who is omnipotent, and others show Jesus to have some separation from the Father and even self-imposed limitations on his power. (Gospel of John)
Paradoxes.
A classical example goes as follows:
Augustine, in his City of God, argued, instead, that God could not do anything that would make God non-omnipotent:
For He is called omnipotent on account of His doing what He wills, not on account of His suffering what He wills not; for if that should befall Him, He would by no means be omnipotent. Wherefore, He cannot do some things for the very reason that He is omnipotent.
Uncertainty and other views.
All the above stated claims of power are each based on scriptual grounds and upon empirical human perception. This perception is limited to our senses. The power of a deity is related to its existence.There are however other ways of perception like: reason, intuition, revelation, divine inspiration, religious experience, mystical states, and historical testimony.
According to the Hindu philosophy the essence of God or Brahman can never be understood or known since Brahman is beyond both existence and non-existence, transcending and including time, causation and space, and thus can never be known in the same material sense as one traditionally 'understands' a given concept or object.
So presuming there is a god-like entity consciently taking actions, we cannot comprehend the limits of a deity's powers.
Since the current laws of physics are only known to be valid in this universe, it is possible that the laws of physics are different in parallel universes, giving a God-like entity more power. If the number of universes is unlimited, then the power of a certain God-like entity is also unlimited, since the laws of physics may be different in other universes, and accordingly making this entity omnipotent. Unfortunately concerning a multiverse there is a lack of empirical correlation. To the extreme there are theories about realms beyond this multiverse (Nirvana, Chaos, Nothingness).
Also trying to develop a theory to explain, assign or reject omnipotence on grounds of logic has little merit, since being omnipotent, in a Cartesian sense, would mean the omnipotent being is above logic. A view supported by René Descartes He issues this idea in his Meditations on First Philosophy. This view is called universal possibilism.
Allowing assumption that a deity exists, further debate may be provoked that said deity is consciously taking actions. It could be concluded from an emanationism point of view, that all actions and creations by a deity are simply flows of divine energy (the flowing Tao in conjunction with qi is often seen as a river; Dharma (Buddhism) the law of nature discovered by Buddha has no beginning or end.)
Pantheism and pandeism see the universe/multiverse itself as God (or, at least, the current state of God), while panentheism sees the universe/multiverse as 'the body of God', making 'God' everybody and everything. So if one does something, actually 'God' is doing it. We are 'God's' means according to this view.
In the Taoist religious or philosophical tradition, the Tao is in some ways equivalent to a deity or the logos. The Tao is understood to have inexhaustible power, yet that power is simply another aspect of its weakness.

</doc>
<doc id="22780" url="https://en.wikipedia.org/wiki?curid=22780" title="Octopus">
Octopus

An octopus ( or ; plural: octopuses, octopi, or octopodes; see below) is a cephalopod mollusc of the order Octopoda. It has two eyes and four pairs of arms and, like other cephalopods, it is bilaterally symmetric. An octopus has a beak, with its mouth at the center point of the arms. An octopus has no internal or external skeleton (although some species have a vestigial remnant of a shell inside their mantles) allowing it to squeeze through tight places. Octopuses are among the most intelligent and behaviorally diverse of all invertebrates.
Octopuses inhabit diverse regions of the ocean, including coral reefs, pelagic waters, and the ocean floor. They have numerous strategies for defending themselves against predators, including the expulsion of ink, the use of camouflage and deimatic displays, their ability to jet quickly through the water, and their ability to hide. An octopus trails its eight arms behind it as it swims. All octopuses are venomous, but only one group, the blue-ringed octopus, is known to be deadly to humans.
Around 300 species are recognized, which is over one-third of the total number of known cephalopod species. The term 'octopus' may also be used to refer specifically to the genus "Octopus".
Etymology and pluralization.
The scientific Latin term "octopus" was derived from Ancient Greek "ὀκτώπους" (oktōpous), which literally translates to "eight-foot" ("ὀκτώ" "eight" + "πούς" "foot"). Related to the word "octopus" are the term "Octopoda" (the taxonomic order of cephalopod molluscs that comprises the octopuses) and the adjective "octopoid".
The standard pluralized form of "octopus" in the English language is "octopuses" , although the Ancient Greek plural "octopodes" , has also been used historically. The alternative plural "octopi" — which misguidedly assumes it is a Latin "-us"-word — is considered grammatically incorrect. It is nevertheless used enough to make it notable, and was formally acknowledged by the descriptivist "Merriam-Webster 11th Collegiate Dictionary" and "Webster's New World College Dictionary". The "Oxford English Dictionary" (2008 Draft Revision) lists "octopuses", "octopi", and "octopodes", in that order, labelling "octopodes" as rare and noting that "octopi" derives from the misapprehension that "octōpus" comes from Latin. In contrast, "New Oxford American Dictionary" (3rd Edition 2010) lists "octopuses" as the only acceptable pluralization, with a usage note indicating "octopodes" as being still occasionally used but "octopi" as being incorrect.
Biology.
Octopuses are characterized by their eight arms, usually bearing suction cups. The arms of octopuses are often distinguished from the pair of feeding tentacles found in squid and cuttlefish. Both types of limb are muscular hydrostats. Unlike most other cephalopods, the majority of octopuses – those in the suborder most commonly known, Incirrina – have almost entirely soft bodies with no internal skeleton. They have neither a protective outer shell like the nautilus, nor any vestige of an internal shell or bones, like cuttlefish or squid. The beak, similar in shape to a parrot's beak, and made of chitin, is the only hard part of their bodies. This enables them to squeeze through very narrow slits between underwater rocks, which is very helpful when they are fleeing from moray eels or other predatory fish. The octopuses in the less-familiar Cirrina suborder have two fins and an internal shell, generally reducing their ability to squeeze into small spaces. These cirrate species are often free-swimming and live in deep-water habitats, while incirrate octopus species are found in reefs and other shallower seafloor habitats.
Octopuses have a relatively short life expectancy, with some species living for as little as six months. Larger species, such as the giant pacific octopus, may live for up to five years under suitable circumstances. However, reproduction is a cause of death: males can live for only a few months after mating, and females die shortly after their eggs hatch. They neglect to eat during the (roughly) one-month period spent taking care of their unhatched eggs, eventually dying of starvation. In a scientific experiment, the removal of both optic glands after spawning was found to result in the cessation of broodiness, the resumption of feeding, increased growth, and greatly extended lifespans.
Octopuses have three hearts. Two branchial hearts pump blood through each of the two gills, while the third is a systemic heart that pumps blood through the body. Octopus blood contains the copper-rich protein hemocyanin for transporting oxygen. Although less efficient under normal conditions than the iron-rich hemoglobin of vertebrates, in cold conditions with low oxygen pressure, hemocyanin oxygen transportation is more efficient than hemoglobin oxygen transportation. The hemocyanin is dissolved in the plasma instead of being carried within red blood cells, and gives the blood a bluish color. The octopus draws water into its mantle cavity, where it passes through its gills. As molluscs, their gills are finely divided and vascularized outgrowths of either the outer or the inner body surface.
Intelligence.
Octopuses are highly intelligent, possibly more so than any other order of invertebrates. The exact extent of their intelligence and learning capability is much debated among biologists, but maze and problem-solving experiments have shown evidence of a memory system that can store both short- and long-term memory. It is not known precisely what contribution learning makes to adult octopus behavior. Young octopuses learn almost no behaviors from their parents, with whom they have very little contact.
An octopus has a highly complex nervous system, only part of which is localized in its brain. Two-thirds of an octopus's neurons are found in the nerve cords of its arms, which have limited functional autonomy. Octopus arms show a variety of complex reflex actions that persist even when they have no input from the brain. Unlike vertebrates, the complex motor skills of octopuses are not organized in their brain using an internal somatotopic map of its body, instead using a nonsomatotopic system unique to large-brained invertebrates. Despite this delegation of control, octopus arms do not become tangled or stuck to each other because the suction cups have chemical sensors that recognize octopus skin and prevent self-attachment. Some octopuses, such as the mimic octopus, will move their arms in ways that emulate the shape and movements of other sea creatures.
In laboratory experiments, octopuses can be readily trained to distinguish between different shapes and patterns. They have been reported to practice observational learning, although the validity of these findings is widely contested on a number of grounds. Octopuses have also been observed in what some have described as play: repeatedly releasing bottles or toys into a circular current in their aquariums and then catching them. Octopuses often break out of their aquariums and sometimes into others in search of food. They have even boarded fishing boats and opened holds to eat crabs.
Tool use.
The octopus has been shown to use tools. At least four specimens of the veined octopus ("Amphioctopus marginatus") have been witnessed retrieving discarded coconut shells, manipulating them, and then reassembling them to use as shelter.
Protective legislation.
Due to their intelligence, octopuses in some countries are on the list of experimental animals on which surgery may not be performed without anesthesia, a protection usually extended only to vertebrates. In the UK from 1993 to 2012, the common octopus ("Octopus vulgaris") was the only invertebrate protected under the Animals (Scientific Procedures) Act 1986. In 2012, this legislation was extended to include all cephalopods in accordance with a general EU directive.
Defense.
An octopus's primary defense is to hide or to disguise itself through camouflage and mimicry. Octopuses have several secondary defenses (defenses they use once they have been seen by a predator). The most common secondary defense is fast escape. Other defenses include distraction with the use of ink sacs and autotomising limbs.
Most octopuses can eject a thick, blackish ink in a large cloud to aid in escaping from predators. The main coloring agent of the ink is melanin, which is the same chemical that gives humans their hair and skin color. This ink cloud is thought to reduce the efficiency of olfactory organs, which would aid an octopus's evasion from predators that employ smell for hunting, such as sharks. Ink clouds of some species might serve as pseudomorphs, or decoys that the predator attacks instead.
An octopus's camouflage is aided by certain specialized skin cells which can change the apparent color, opacity, and reflectivity of the epidermis. Chromatophores contain yellow, orange, red, brown, or black pigments; most species have three of these colors, while some have two or four. Other color-changing cells are reflective iridophores, and leucophores (white). This color-changing ability can also be used to communicate with or warn other octopuses. The highly venomous blue-ringed octopus becomes bright yellow with blue rings when it is provoked. Octopuses can use muscles in the skin to change the texture of their mantle to achieve a greater camouflage. In some species, the mantle can take on the spiky appearance of seaweed, or the scraggly, bumpy texture of a rock, among other disguises. However, in some species, skin anatomy is limited to relatively patternless shades of one color, and limited skin texture. It is thought that octopuses that are day-active and/or live in complex habitats such as coral reefs have evolved more complex skin than their nocturnal and/or sand-dwelling relatives.
When under attack, some octopuses can perform arm autotomy, in a manner similar to the way skinks and other lizards detach their tails. The crawling arm serves as a distraction to would-be predators. Such severed arms remain sensitive to stimuli and move away from unpleasant sensations.
A few species, such as the mimic octopus, have a fourth defense mechanism. They can combine their highly flexible bodies with their color-changing ability to accurately mimic other, more dangerous animals, such as lionfish, sea snakes, and eels.
Reproduction.
When octopuses reproduce, the male uses a specialized arm called a hectocotylus to transfer spermatophores (packets of sperm) from the terminal organ of the reproductive tract (the cephalopod "penis") into the female's mantle cavity. The hectocotylus in benthic octopuses is usually the third right arm. Males die within a few months of mating. In some species, the female octopus can keep the sperm alive inside her for weeks until her eggs are mature. After they have been fertilized, the female lays about 200,000 eggs (this figure dramatically varies between families, genera, species and also individuals).
Senses.
Octopuses have keen eyesight. Like other cephalopods, they can distinguish the polarization of light. Color vision appears to vary from species to species, being present in "O. aegina" but absent in "O. vulgaris". Attached to the brain are two special organs, called statocysts, that allow the octopus to sense the orientation of its body relative to horizontal. An autonomic response keeps the octopus's eyes oriented so the pupil slit is always horizontal.
Octopuses also have an excellent sense of touch. An octopus's suction cups are equipped with chemoreceptors so the octopus can taste what it is touching. The arms contain tension sensors so the octopus knows whether its arms are stretched out. However, it has a very poor proprioceptive sense. The tension receptors are not sufficient for the brain to determine the position of the octopus's body or arms. (It is not clear whether the octopus brain would be capable of processing the large amount of information that this would require; the flexibility of an octopus's arms is much greater than that of the limbs of vertebrates, which devote large areas of cerebral cortex to the processing of proprioceptive inputs.) As a result, the octopus does not possess stereognosis; that is, it does not form a mental image of the overall shape of the object it is handling. It can detect local texture variations, but cannot integrate the information into a larger picture.
The neurological autonomy of the arms means the octopus has great difficulty learning about the detailed effects of its motions. The brain may issue a high-level command to the arms, but the nerve cords in the arms execute the details. There is no neurological path for the brain to receive proprioceptive feedback about just how its command was executed by the arms; the only way it knows just what motions were made is by observing the arms visually, i.e. exteroception.
Octopuses might use the statocyst (a sac-like structure containing a mineralised mass and sensitive hairs) to register sound. The common octopus can hear sounds between 400 Hz and 1000 Hz, and hears best at a frequency of 600 Hz.
Locomotion.
Octopuses move about by crawling or swimming. Their main means of slow travel is crawling, with some swimming. Jet propulsion is their fastest means of locomotion, followed by swimming and walking.
They crawl by walking on their arms, usually on many at once, on both solid and soft surfaces, while supported in water. In 2005, some octopuses ("Adopus aculeatus" and "Amphioctopus marginatus" under current taxonomy) were found to walk on two arms, while at the same time resembling plant matter. This form of locomotion allows these octopuses to move quickly away from a potential predator while possibly not triggering that predator's search image for octopus (food). A study of this behavior conducted by the Weymouth Sea Life Centre led to the suggestion that the two rearmost appendages may be more accurately termed 'legs' rather than 'arms'. Some species of octopus can crawl out of the water for a short period, which they may do between tide pools while hunting crustaceans or gastropods or to escape predators.
Octopuses swim by expelling a jet of water from a contractile mantle, and aiming it via a muscular siphon.
Diet.
Bottom-dwelling octopuses eat mainly crabs, polychaete worms, and other molluscs such as whelks and clams. Open-ocean octopuses eat mainly prawns, fish and other cephalopods. They usually inject their prey with a paralysing saliva before dismembering it into small pieces with their beaks. Octopuses feed on shelled molluscs either by using force, or by drilling a hole in the shell, injecting a secretion into the hole, and then extracting the soft body of the mollusc.
Large octopuses have also been known to catch and kill some species of sharks. Seabirds have also been documented as prey.
Size.
The giant Pacific octopus, "Enteroctopus dofleini", is often cited as the largest known octopus species. Adults usually weigh around 15 kg (33 lb), with an arm span of up to 4.3 m (14 ft). The largest specimen of this species to be scientifically documented was an animal with a live mass of 71 kg (156.5 lb). The alternative contender is the seven-arm octopus, "Haliphron atlanticus", based on a 61 kg (134 lb) carcass estimated to have a live mass of 75 kg (165 lb). However, a number of questionable size records would suggest "E. dofleini" is the largest of all known octopus species by a considerable margin; one such record is of a specimen weighing 272 kg (600 lb) and having an arm span of 9 m (30 ft).
Relationship to humans.
Ancient peoples of the Mediterranean were aware of the octopus, as evidenced by certain artworks and designs of prehistory. For example, a stone carving found in the archaeological recovery from Bronze Age Minoan Crete at Knossos (1900 – 1100 BC) has a depiction of a fisherman carrying an octopus.
In classical Greece, Aristotle (384 BC – 322 BC) commented on the colour-changing abilities of the octopus, both for camouflage and for signalling, in his "Historia animalium":
Octopuses were often depicted in the art of the Moche people of ancient Peru, who worshipped the sea and its animals.
In mythology.
The Gorgon of Greek mythology has been thought to have been inspired by the octopus or squid, the octopus itself representing the severed head of Medusa, the beak as the protruding tongue and fangs, and its tentacles as the snakes.
The Kraken are legendary sea monsters of giant proportions said to dwell off the coasts of Norway and Greenland, usually portrayed in art as a giant octopus attacking ships.
The Hawaiian creation myth relates that the present cosmos is only the last of a series, having arisen in stages from the wreck of the previous universe. In this account, the octopus is the lone survivor of the previous, alien universe.
Akkorokamui is a gigantic octopus-like monster from Ainu folklore, which supposedly lurks in Funka Bay in Hokkaidō and has been sighted in several locations including Taiwan and Korea since the 19th century.
In Japanese mythology and folklore there is a yokai called the tako no nana ashi, that is an octopus with seven tentacles.
In literature.
The octopus has a significant role in Victor Hugo's book "Travailleurs de la mer" ("Toilers of the Sea").
Ian Fleming's 1966 short story collection "Octopussy and The Living Daylights", and the 1983 "James Bond" film partly inspired by Hugo's book.
In John Steinbeck's novella "Sweet Thursday", the marine biologist "Doc" is studying what the denizens of Cannery Row call "devilfish". Doc's study of octopuses to ascertain whether their behavior displays emotional responses similar to humans, such as apoplexy, is a major plot device in the novella.
Ed Ricketts, the marine biologist who was Steinbeck's friend and inspiration for the character Doc, had an octopus as a trademark for products sold by his Pacific Biological Laboratories.
Ringo Starr wrote a 2014 children's book based on his 1969 song "Octopus's Garden". The book is illustrated by Ben Court.
As a metaphor.
Due to having numerous arms that emanate from a common center, the octopus is often used as a metaphor for a group or organization that is perceived as being powerful, manipulative or bent on domination. Use of this terminology is invariably negative and employed by the opponents of the groups or institutions so described.
As food.
Octopus is eaten in many cultures. They are a common food in Mediterranean and Asian sea areas. The arms and sometimes other body parts are prepared in various ways, often varying by species or geography.
As pets.
Though octopuses can be difficult to keep in captivity, some people keep them as pets. They often escape even from supposedly secure tanks, due to their problem-solving skills, mobility and lack of rigid structure.
The variation in size and lifespan among octopus species makes it difficult to know how long a new specimen can naturally be expected to live. That is, a small octopus may be just born or may be an adult, depending on its species. By selecting a well-known species, such as the California two-spot octopus, one can choose a small octopus (around the size of a tennis ball) and be confident it is young with a full life ahead of it.

</doc>
<doc id="22781" url="https://en.wikipedia.org/wiki?curid=22781" title="Omniscience">
Omniscience

Omniscience , mainly in religion, is the capacity to know everything that there is to know. In particular, Hinduism and the Abrahamic religions (Judaism, Christianity, and Islam) believe that there is a divine being who is omniscient. An omniscient point-of-view, in writing, is to know everything that can be known about a character, including past history, thoughts, feelings, etc. In Latin, "omnis" means "all" and "sciens" means "knowing".
Definitions.
There is a distinction between:
Some modern Christian theologians argue that God's omniscience is inherent rather than total, and that God chooses to limit his omniscience in order to preserve the freewill and dignity of his creatures. John Calvin, among other theologians of the 16th century, comfortable with the definition of God as being omniscient in the total sense, in order for worthy beings' abilities to choose freely, embraced the doctrine of predestination.
Jain view.
In Jainism, omniscience is considered the highest type of perception. In the words of a Jain scholar, Jainism view infinite knowledge as an inherent capability of every soul. "Arihanta" is the word used by Jains to refer to those human beings who have conquered all inner passions (like attachment, greed, pride, anger) and possess Kevala Jnana (infinite knowledge). They are said to be of two kinds-
Controversies.
Omnipotence (unlimited power) is sometimes understood to also imply the capacity to know everything that will be.
Nontheism often claims that the very concept of omniscience is inherently contradictory.
Whether omniscience, particularly regarding the choices that a human will make, is compatible with free will has been debated by theists and philosophers. The argument that divine foreknowledge is not compatible with free will is known as theological fatalism. Generally, if humans are truly free to choose between different alternatives, it is very difficult to understand how God could know what this choice will be.
God created knowledge.
Some theists argue that God created all knowledge and has ready access thereto. This statement invokes a circular time contradiction: presupposing the existence of God, before knowledge existed, there was no knowledge at all, which means that God was unable to possess knowledge prior to its creation. Alternately if knowledge was not a "creation" but merely existed in God's mind for all time there would be no contradiction. In Thomistic thought, which holds God to exist outside of time due to his ability to perceive everything at once, everything which God knows in his mind already exists. Hence, God would know of nothing that "was not" in existence (or else it would exist), and God would also know everything that "was" in existence (or else it would not exist), and God would possess this knowledge of what did exist and what did not exist at any point in the history of time.
The circular time contradiction can suppose anything concerning God, such as the creation of life, meaning before God created life, he wasn't alive. Moreover to assume any more attributes, to then say God is merciful, but before the creation of mercy, he wouldn't have been merciful, and before the creation of the concept of negation (meaning to assume something as not), no one would have any concept of what is not. These apparent contradictions, however, presuppose that such attributes are separately defined and detached from God, which is not necessarily so. It is not a given that attributes which can be assigned to or used to describe mankind, can be equally (or even similarly) ascribed to God. Take good and evil for example: goodness is biblically defined as that which is of God; it is intrinsic to his being and is revealed most prominently through his provision of Old Testament Law, the keeping of which is the very definition of goodness and the neglecting of which (on even the slightest of grounds), is the epitome of evil. A similar argument could be laid down concerning God's omniscience (i.e. knowledge). It even eludes the idea a lot more even to assume the concept of "nothing" or negation was created, therefore it is seemingly impossible to conceive such a notion where it draws down to a paradox. Assuming that the creator and creation is separate, and not the same one thing, or process. That it is a "this or that" notion, instead of a "this and that" idea.
To assume that knowledge in Plato's sense as described to be a belief that's true, it then means that before everything came into being, it was all to be conceived as total imagination by God until the set of truth.
One verse "God created man in his own Image" states that God imagined the form of humans, taking image as a root word for imagine, mistakenly understood as man to look like God. [this verse from Genesis 1 is in the Hebrew Scriptures. The word 'Image' is translated from two Hebrew words 'demuth' - likeness or similitude and 'tselem'- an obscure word which translates as image or idol. It is difficult, therefore to make a case for the author's reading of this verse to mean 'God imagined the form of humans'.
The above definitions of omniscience cover what is called "propositional knowledge" ("knowing that"), as opposed to "experiential knowledge" ("knowing how").
That some entity is omniscient in the sense of possessing all possible propositional knowledge does not imply that it also possesses all possible experiential knowledge.
Opinions differ as to whether the propositionally omniscient God of the theists is able to possess all experiential knowledge as well. But it seems at least obvious that a divine infinite being conceived of as necessary infinitely knowledgeable would also know "how", for example, a finite person (man) dying feels as He (God) would have access to all knowledge including the obvious experiences of the dying human. There is a third type of knowledge: "practical" or "procedural knowledge" ("knowing how to do"). If omniscience is taken to be "all" knowledge then all knowledge of all types would be fully known and comprehended.
Omniscience vs free will.
A question arises : an omniscient entity knows everything even about his/her/its own decisions in the future, does it therefore forbid any free will to that entity? William Lane Craig states that the question subdivides into two: (1) If God foreknows the occurrence of some event E, does E happen necessarily?, and (2) If some event E is contingent, how can God foreknow E’s occurrence?
"See : Determinism, Freewill and argument from free will"
Non-theological uses.
The field of literary analysis and criticism can discuss omniscience in the point of view of a narrator. An omniscient narrator, almost always a third-person narrator, can reveal insights into characters and settings that would not be otherwise apparent from the events of the story and which no single character could be aware of.
A collection of surveillance techniques which together contribute to much disparate knowledge about the movements, actions, conversation, appearance, etc. of an individual (or organisation) is sometimes called omniscient technology.
The word "omniscient" characterizes a fictional character in the Devin Townsend album "Ziltoid the Omniscient".
Omniscience in Buddhist India.
The topic of omniscience has been much debated in various Indian traditions, but no more so than by the Buddhists. After Dharmakirti's excursions into the subject of what constitutes a valid cognition, Śāntarakṣita and his student Kamalaśīla thoroughly investigated the subject in the Tattvasamgraha and its commentary the Panjika. The arguments in the text can be broadly grouped into four sections:

</doc>
<doc id="22784" url="https://en.wikipedia.org/wiki?curid=22784" title="Original Chip Set">
Original Chip Set

The Original Chip Set (OCS) was a chipset used in the earliest Commodore Amiga computers and defined the Amiga's graphics and sound capabilities. It was succeeded by the slightly improved Enhanced Chip Set (ECS) and greatly improved Advanced Graphics Architecture (AGA).
The original chipset appeared in Amiga models built between 1985 and 1990: the Amiga 1000, Amiga 2000, Amiga CDTV, and Amiga 500.
Overview of chips.
The chipset which gave the Amiga its unique graphics features consists of three main "custom" chips; "Agnus", "Denise", and "Paula". Both the original chipset and the enhanced chipset were manufactured using NMOS logic technology by Commodore's chip manufacturing subsidiary, MOS Technology. According to Jay Miner, the OCS chipset was fabricated in 5 µm manufacturing process while AGA Lisa was implemented in 1.5 µm process. All three custom chips were originally packaged in 48-pin DIPs; later versions of Agnus, known as Fat Agnus, were packaged in an 84-pin PLCC.
Agnus is the central chip in the design. It controls all access to chip RAM from both the central 68000 processor and the other custom chips, using a complicated priority system. Agnus includes sub-components known as the "blitter" (fast transfer of data in memory without the intervention of the processor) and the "copper" (video-synchronized co-processor). The original Agnus can address of chip RAM. Later revisions, dubbed 'Fat Agnus', added pseudo-fast RAM, which for ECS was changed to 1 MB (sometimes called 'Fatter Agnus') and subsequently to 2 MB chip RAM.
Denise is the main video processor. Without using overscan, the Amiga's graphics display is 320 or 640 pixels wide by 200 (NTSC) or 256 (PAL) pixels tall. Denise also supports interlacing, which doubles the vertical resolution, at the cost of pretty bad flickering on most monitors produced during the same timeframe as the Amiga computers. Planar bitmap graphics are used, which splits the individual bits per pixel into separate areas of memory, called bitplanes. In normal operation, Denise allows between 1 and 5 bitplanes, giving 2 to 32 unique colours. These colours are selected from a palette of 4096 colours (4 bits per RGB component). A 6th bitplane is available for two special video modes: Halfbrite mode and Hold And Modify mode. Denise also supports eight sprites, single pixel scrolling, and a "dual playfield" mode. Denise also handles mouse and digital joystick input.
Paula is primarily the audio chip, with 4 independent hardware-mixed 8-bit PCM sound channels, each of which supports 65 volume levels (no sound to maximum volume) and waveform output rates from roughly 20 samples per second to almost 29,000 samples per second. Paula also handles interrupts and various I/O functions including the floppy disk drive, the serial port, and analog joysticks.
There are many similarities - both in overall functionality and in the division of functionality into the three component chips - between the OCS chipset and the much earlier and simpler chipset of the Atari 8-bit family of home computers, consisting of the ANTIC, GTIA and POKEY chips; both chipsets were conceptually designed by Jay Miner, which explains the similarity.
Agnus.
The Agnus chip is in overall control of the entire chipset's operation. All operations are synchronised to the position of the video beam. This includes access to the built-in RAM, known as chip RAM because the chipset has access to it. Both the central 68000 processor and other members of the chipset have to arbitrate for access to chip RAM via "Agnus". In computing architecture terms, this is Direct Memory Access (DMA), where Agnus is the DMA Controller (DMAC).
Agnus has a complex and priority-based memory access policy that attempts to best coordinate requests for memory access among competing resources. For example, bitplane data fetches are prioritized over blitter transfers as the immediate display of frame buffer data is considered more important than the processing of memory by the blitter. Agnus also attempts to order accesses in such a way so as to overlap CPU bus cycles with DMA cycles. As the original 68000 processor in Amigas tended only to access memory on every second available memory cycle, Agnus operates a system where "odd" memory access cycles are allocated first and as needed to time-critical custom chip DMA while any remaining cycles are available to the CPU, thus the CPU does not generally get locked out of memory access and does not appear to slow down. However, non-time-critical custom chip access, such as "blitter" transfers, can use up any spare odd or even cycles and, if the "BLITHOG" (blitter hog) flag is set, Agnus can lock out the even cycles from the CPU in deference to the "blitter".
Agnus's timings are measured in "colour clocks" of 280 ns. This is equivalent to two low resolution (140 ns) pixels or four high resolution (70 ns) pixels. Like Denise, these timings were designed for display on household TVs, and can be synchronised to an external clock source.
Blitter.
The "blitter" is a sub-component of Agnus. "Blit" is shorthand for "block image transfer" or bit blit. The blitter is a highly parallel memory transfer and logic operation unit. It has three modes of operation: copying blocks of memory, filling blocks (e.g. polygon filling) and line drawing.
The blitter allows the rapid copying of video memory, meaning that the CPU can be freed for other tasks. The blitter was primarily used for drawing and redrawing graphics images on the screen, called "bobs", short for "blitter objects".
The blitter's block copying mode takes zero to three data sources in memory, called A, B and C, performs a programmable boolean function on the data sources and writes the result to a destination area, D. Any of these four areas can overlap. The blitter runs either from the start of the block to the end, known as "ascending" mode, or in reverse, "descending" mode.
Blocks are "rectangular"; they have a "width" in multiples of 16 bits, a height measured in "lines", and a "stride" distance to move from the end of one line to the next. This allows the blitter to operate on any conceivable video resolution. The copy automatically performs a per-pixel logical operation. These operations are described generically using minterms. This is most commonly used to do direct copies (D = A), or apply a pixel mask around blitted objects (D = (C AND B) OR A). The copy can also barrel shift each line by 0 to 15 pixels. This allows the blitter to draw at pixel offsets that are not exactly multiples of 16.
These functions allow the Amiga to move GUI windows around the screen rapidly as each is represented in graphical memory space as a rectangular block of memory which may be shifted to any required screen memory location at will.
The blitter's line mode draws single-pixel thick lines using the Bresenham's line algorithm. It can also apply a 16-bit repeating pattern to the line. The line mode can also be used to draw rotated bobs: each line of bob data is used as line pattern while the line mode draws the tilted bob line by line.
The blitter's filling mode is used to fill per-line horizontal spans. On each span, it reads each pixel in turn from right to left. Whenever it reads a set pixel, it toggles filling mode on or off. When filling mode is on, it sets every pixel until filling mode is turned off or the line ends. Together, these modes allow the blitter to draw individual flat-shaded polygons. Later Amigas tended to use a combination of a faster CPU and blitter for many operations.
Copper.
The "copper" is another sub-component of Agnus; The name is short for "co-processor". The copper is a programmable finite state machine that executes a programmed instruction stream, synchronized with the video hardware.
When it is turned on, the copper has three states; either reading an instruction, executing it, or waiting for a specific video beam position. The copper runs a program called the "copper list" in parallel with the main CPU. The copper runs in sync with the video beam, and it can be used to perform various operations which require video synchronization. Most commonly it is used to control video output, but it can write to most of the chipset registers and thus can be used to initiate blits, set audio registers, or interrupt the CPU.
The copper list has three kinds of instructions, each one being a pair of two bytes, four bytes in total:
The length of the copper list program is limited by execution time. The copper restarts executing the copper list at the start of each new video frame. There is no explicit "end" instruction; instead, the WAIT instruction is used to wait for a location which is never reached.
External video timing.
Under normal circumstances, the Amiga generates its own video timings, but Agnus also supports synchronising the system to an external signal so as to achieve genlocking with external video hardware. There is also an 1 bit output on this connector that indicates whether the Amiga is outputting background colour or not, permitting easy overlaying of Amiga video onto external video. This made the Amiga particularly attractive as a character generator for titling videos and broadcast work, as it avoided the use and expense of AB roll and chromakey units that would be required without the genlock support. The support of overscan, interlacing and genlocking capabilities, and the fact that the display timing was very close to broadcast standards (NTSC or PAL), made the Amiga the first ideal computer for video purposes, and indeed, it was used in many studios for digitizing video data (sometimes called frame-grabbing), subtitling and interactive video news.
Denise.
Denise is programmed to fetch planar video data from 1 to 5 bitplanes and translate that into a colour lookup. The number of bitplanes is arbitrary, thus if 32 colours are not needed, 2, 4, 8 or 16 can be used instead. The number of bitplanes (and resolution) can be changed on the fly, usually by the copper. This allows for very economical use of RAM. There can also be a sixth bitplane, which can be used in three special graphics modes:
In Extra-HalfBrite (EHB), if a pixel is set on the sixth bitplane, the brightness of the regular 32 colour pixel is halved. Early versions of the Amiga 1000 sold in the United States did not have the Extra-HalfBrite mode.
In Hold-and-Modify mode (HAM), each 6-bit pixel is interpreted as 2 control bits and 4 data bits. The 4 possible permutations of control bits are "set", "modify red", "modify green" and "modify blue". With "set", the 4 data bits act like a regular 16-colour display look up. With one of the "modify"s, the red, green or blue component of the previous pixel is modified to the data value, and the other two components are held from the previous pixel. This allows all 4096 colours on screen at once and is an example of lossy image compression in hardware.
In Dual Playfield mode, instead of acting as a single screen, two "playfields" of 8 colours each (3 bitplanes each) are drawn on top of each other. They are independently scrollable and the background colour of the top playfield "shines through" to the underlying playfield.
There are two horizontal graphics resolutions, "lowres" with 140 ns pixels and "hires" with 70 ns pixels. This makes the display 320 or 640 pixels wide without overscan. Denise supports very wide overscan; there is no need for a border around the graphics as other computers suffered from. Vertical resolution, without overscan, is 200 pixels for an 60 Hz NTSC Amiga or 256 for a 50 Hz PAL Amiga. This can be doubled using an interlaced display.
Denise can also lay up to eight 16 pixel wide sprites per scan line (in automatic mode) on top, underneath, or between playfields, and detect collisions between sprites and the playfields or between sprites. These sprites have 3 visible colours and one transparent colour. Optionally, adjacent pairs of sprites can be "attached" to make a single 15 colour sprite. Using Copper or CPU register manipulations, each sprite 'channel' can be reused multiple times in a single frame to increase the total sprites per frame. Sprite position registers may also be changed during a scanline, increasing the total sprites on a single scanline.
Finally, Denise is responsible for handling mouse/joystick x/y inputs.
Paula.
The Paula chip includes logic for audio playback, floppy disk drive control, serial port input/output and mouse/joystick buttons 2 and 3 signals. The logic remained functionally identical across all Amiga models from Commodore.
Audio.
Paula has four DMA-driven 8-bit PCM sample sound channels. Two sound channels are mixed into the left audio output, and the other two are mixed into the right output, producing stereo audio output. The only supported hardware sample format is signed linear 8-bit two's complement. Each sound channel has an independent frequency and a 6-bit volume control (64 levels). Internally, the audio hardware is implemented by four state machines, each having eight different states.
Additionally the hardware allows one channel in a channel pair to modulate the other channel's period or amplitude. It is rarely used on the Amiga due to both frequency and volume being controllable in better ways, but could be used to achieve different kinds of tremolo and vibrato, and even rudimentary FM synthesis effects.
Audio may be output using two methods. Most often, DMA-driven audio is used. As explained in the discussion of Agnus, memory access is prioritized and one DMA slot per scan line is available for each of the four sound channels. On a regular NTSC or PAL display, DMA audio playback is limited to a maximum output rate of 28867 values per channel (PAL: 28837) per second totaling 57674 (PAL: 57734) values per second on each stereo output. This rate can be increased with the ECS and AGA chipsets by using a video mode with higher horizontal scan rate. 
Alternately, Paula may signal the CPU to load a new sample into any of the four audio output buffers by generating an interrupt when a new sample is needed. This allows for output rates that exceed 57 kHz per channel and increases the number of possible voices (simultaneous sounds) through software mixing. 
The Amiga contains an analog low-pass filter (reconstruction filter) which is external to Paula. The filter is a 12 dB/oct Butterworth low-pass filter at approximately 3.3 kHz. The filter can only be applied globally to all four channels. In models after the Amiga 1000 (excluding the very first revision of the Amiga 500), the brightness of the power LED is used to indicate the status of the filter. The filter is active when the LED is at normal brightness, and deactivated when dimmed (on early Amiga 500 models the LED went completely off). Models released before Amiga 1200 also have a static "tone knob" type low-pass filter that is enabled regardless of the optional "LED filter". This filter is a 6 dB/oct low-pass filter with cutoff frequency at 4.5 or 5 kHz.
A software technique was later developed which can play back 14-bit audio by combining two channels set at different volumes. This results in two 14-bit channels instead of four 8-bit channels. This is achieved by playing the high byte of a 16-bit sample at maximum volume, and the low byte at minimum volume (both ranges overlap, so the low byte needs to be shifted right two bits). The bit shift operation requires a small amount of CPU or blitter overhead, whereas conventional 8-bit playback is almost entirely DMA driven. This technique was incorporated into the retargetable audio subsystem AHI, allowing compatible applications to use this mode transparently.
Floppy disk controller.
The floppy controller is unusually flexible. It can read and write raw bit sequences directly from and to the disk via DMA or programmed I/O at 500 (double density) or 250 kbit/s (single density or GCR). MFM or GCR were the two most commonly used formats though in theory any run-length limited code could be used. It also provides a number of convenient features, such as sync-on-word (in MFM coding, $4489 is usually used as the sync word). MFM encoding/decoding is usually done with the blitter — one pass for decode, three passes for encode. Normally the entire track is read or written in one shot, rather than sector-by-sector; this made it possible to get rid of most of the inter-sector gaps that most floppy disk formats need to safely prevent the "bleeding" of a written sector into the previously-existing header of the next sector due to speed variations of the drive. If all sectors and their headers are always written in one go, such bleeding is only an issue at the end of the track (which still must not bleed back into its beginning), so that only one gap per track is needed. This way, for the native Amiga disk format, the raw storage capacity of 3.5 inch DD disks was increased from the typical 720 KB to 880 KB, although the less-than-ideal file system of the earlier Amiga models reduced this again to ca. 830 KB of actual payload data.
In addition to the native 880 KB 3.5-inch disk format, the controller can handle many foreign formats, such as:
The Amiga 3000 introduced a special, dual-speed floppy drive that also allowed to use high density disks with double capacity without any change to Paula's floppy controller.
Serial port.
The serial port is rudimentary, using programmed input/output only and lacking a FIFO buffer. However, virtually any bit rate can be selected, including all standard rates, MIDI rate, as well as extremely high custom rates.

</doc>
<doc id="22786" url="https://en.wikipedia.org/wiki?curid=22786" title="Optic neuritis">
Optic neuritis

Optic neuritis is inflammation of the optic nerve. It is also called papillitis (when the head of the optic nerve is involved) and retrobulbar neuritis (when the posterior of the nerve is involved). It is caused by many different conditions, and it may lead to complete or partial loss of vision. The most common cause is multiple sclerosis.
Signs and symptoms.
Major symptoms are sudden loss of vision (partial or complete), sudden blurred or "foggy" vision, and pain on movement of the affected eye. The vision might also be described as "disturbed/blackened" rather than blurry, as when feeling dizzy. Many patients with optic neuritis may lose some of their color vision in the affected eye (especially red), with colors appearing subtly washed out compared to the other eye. Patients may also experience difficulties judging movement in depth which can be particular troublesome during driving or sport (Pulfrich effect). Likewise transient worsening of vision with increase of body temperature (Uhthoff's phenomenon) and glare disability are a frequent complaint. A study found that 92.2% of patients experienced pain, which actually preceded the visual loss in 39.5% of cases. However, several case studies in children have demonstrated the absence of pain in more than half of cases (approximately 60%) in their pediatric study population, with the most common symptom reported simply as "blurriness." Other remarkable differences between the presentation of adult optic neuritis as compared to pediatric cases include more often unilateral optic neuritis in adults, while children much predominantly present with bilateral involvement. Symptoms peak several days to weeks after onset, while symptoms failing to improve after 8 weeks should suggest a diagnosis other than optic neuritis.
On medical examination the head of the optic nerve can easily be visualised by a slit lamp with high plus or by using direct ophthalmoscopy; however, frequently there is no abnormal appearance of the nerve head in optic neuritis (in cases of retrobulbar optic neuritis), though it may be swollen in some patients (anterior papillitis or more extensive optic neuritis). In many cases, only one eye is affected and patients may not be aware of the loss of color vision until they are asked to close or cover the healthy eye.
Causes.
The optic nerve comprises axons that emerge from the retina of the eye and carry visual information to the primary visual nuclei, most of which is relayed to the occipital cortex of the brain to be processed into vision. Inflammation of the optic nerve causes loss of vision, usually because of the swelling and destruction of the myelin sheath covering the optic nerve.
The most common etiology is multiple sclerosis. Up to 50% of patients with MS will develop an episode of optic neuritis, and 20-30% of the time optic neuritis is the presenting sign of MS. The presence of demyelinating white matter lesions on brain MRI at the time of presentation of optic neuritis is the strongest predictor for developing clinically definite MS. Almost half of the patients with optic neuritis have white matter lesions consistent with multiple sclerosis.
At five years follow-up, the overall risk of developing MS is 30%, with or without MRI lesions. Patients with a normal MRI still develop MS (16%), but at a lower rate compared to those patients with three or more MRI lesions (51%). From the other perspective, however, almost half (44%) of patients with any demyelinating lesions on MRI at presentation will not have developed MS ten years later.
Some other causes of optic neuritis include infection (e.g. syphilis, Lyme disease, herpes zoster), autoimmune disorders (e.g. lupus, neurosarcoidosis, neuromyelitis optica), inflammatory bowel disease, drug induced (e.g. chloramphenicol, ethambutol, Isoniazid, streptomycin, quinine, penicillamine, Aminosalicylic acid, phenothiazine, phenylbutazone), vasculitis, B12 deficiency and diabetes.
Demyelinating recurrent optic neuritis and non-demyelinating (CRION).
The repetition of an idiopatic optic neuritis is considered a distinct clinical condition, and when it shows demyelination, it has been found to be associated to anti-MOG and AQP4-negative neuromyelitis optica
When an inflammatory recurrent optic neuritis is not demyelinating, it is called "Chronic relapsing inflammatory optic neuropathy" (CRION)
When it is anti-MOG related, it is demyelinating and it is considered inside the anti-MOG associated inflammatory demyelinating diseases.
Treatment and prognosis.
In the vast majority of MS associated optic neuritis, visual function spontaneously improves over the first 2–3 months, and there is evidence that corticosteroid treatment does not affect the long term outcome. However, for optic neuritis that is not MS associated (or atypical optic neuritis) the evidence is less clear and therefore the threshold for treatment with intravenous corticosteroids is lower. Intravenous corticosteroids have also been found to reduce the risk of developing MS in the following two years in those patients who have MRI lesions; but this effect disappears by the third year of follow up.
Paradoxically it has been demonstrated that oral administration of corticosteroids in this situation may lead to more recurrent attacks than in non-treated patients (though oral steroids are generally prescribed after the intravenous course, to wean the patient off the medication). This effect of corticosteroids seems to be limited to optic neuritis and has not been observed in other diseases treated with corticosteroids.
A Cochrane Systematic Review studied the effect of corticosteroids for treating participants suffering from optic neuritis. Treatments reviewed included intravenous methylprednisone, oral methylprednisone, and oral prednisone. All treatments reviewed did not show any benefit in terms of recovery to visual acuity, contrast sensitivity, or visual field.
In the longer term, there is evidence that patients with MS who first present with optic neuritis have a relatively more benign MS course.
Epidemiology.
Optic neuritis typically affects young adults ranging from 18–45 years of age, with a mean age of 30–35 years. There is a strong female predominance. The annual incidence is approximately 5/100,000, with a prevalence estimated to be 115/100,000.
Society and culture.
In the season five episode of Dr. Quinn, Medicine Woman, "Season of Miracles", Reverend Timothy Johnson is struck blind by Optic neuritis on Christmas Day, 1872. He remains blind for the duration of the series.
In Charles Dickens "Bleak House" the main character, Esther Summerville suffers from a transient episode of visual loss with symptoms also observed during the course of optic neuritis. Sir William Searle Holdsworth suggested "Bleak House" to have taken place in 1827.

</doc>
<doc id="22787" url="https://en.wikipedia.org/wiki?curid=22787" title="List of organizations with .int domain names">
List of organizations with .int domain names

This is a list of organizations with INT domain names, in alphabetical order of the second-level domain name. The list is not comprehensive. As of June 2012, the INT domain consists of 166 subdomain delegations.
These organizations are generally international organizations established by treaty. Some however (such as YMCA) do not meet current restrictions and were grandfathered in from prior acceptance.

</doc>
<doc id="22788" url="https://en.wikipedia.org/wiki?curid=22788" title="Organization of American States">
Organization of American States

The Organization of American States (, , ), or the OAS or OEA, is an inter-continental organization founded on 30 April 1948, for the purposes of regional solidarity and cooperation among its member states. Headquartered in Washington, D.C., United States, the OAS's members are the 35 independent states of the Americas.
As of 26 May 2015, the Secretary General of OAS is Luis Almagro.
History.
The notion of an international union in the New World was first put forward by Simón Bolívar who, at the 1826 Congress of Panama (still being part of Colombia), proposed creating a league of American republics, with a common military, a mutual defense pact, and a supranational parliamentary assembly. This meeting was attended by representatives of Gran Colombia (comprising the modern-day countries of Colombia, Ecuador, Panama and Venezuela), Peru, Bolivia, The United Provinces of Central America, and Mexico but the grandly titled "Treaty of Union, League, and Perpetual Confederation" was ultimately ratified only by Gran Colombia. Bolívar's dream soon floundered with civil war in Gran Colombia, the disintegration of Central America, and the emergence of national rather than New World outlooks in the newly independent American republics. Bolívar's dream of American unity was meant to unify Hispanic American nations against external powers.
The pursuit of regional solidarity and cooperation again came to the forefront in 1889–1890, at the First International Conference of American States. Gathered together in Washington, D.C., 18 nations resolved to found the International Union of American Republics, served by a permanent secretariat called the Commercial Bureau of the American Republics (renamed the International Commercial Bureau at the Second International Conference in 1901–1902). These two bodies, in existence as of 14 April 1890, represent the point of inception to which the OAS and its General Secretariat trace their origins.
At the Fourth International Conference of American States (Buenos Aires, 1910), the name of the organization was changed to the Union of American Republics and the Bureau became the Pan American Union. The Pan American Union Building was constructed in 1910, on Constitution Avenue, Northwest, Washington, D.C.
In the mid-1930s, U.S. President Franklin Delano Roosevelt organized an inter-American conference in Buenos Aires. One of the items at the conference was a "League of Nations of the Americas", an idea proposed by Colombia, Guatemala, and the Dominican Republic. At the subsequent Inter-American Conference for the Maintenance of Peace, 21 nations pledged to remain neutral in the event of a conflict between any two members. The experience of World War II convinced hemispheric governments that unilateral action could not ensure the territorial integrity of the American nations in the event of external aggression. To meet the challenges of global conflict in the postwar world and to contain conflicts within the hemisphere, they adopted a system of collective security, the Inter-American Treaty of Reciprocal Assistance (Rio Treaty) signed in 1947 in Rio de Janeiro.
The Ninth International Conference of American States was held in Bogotá between March and May 1948 and led by United States Secretary of State George Marshall, a meeting which led to a pledge by members to fight communism in the western hemisphere. This was the event that saw the birth of the OAS as it stands today, with the signature by 21 American countries of the Charter of the Organization of American States on 30 April 1948 (in effect since December 1951). The meeting also adopted the American Declaration of the Rights and Duties of Man, the world's first general human rights instrument, Bogotá considered the first defensive state in the event of war, of the Organization of American States.
The transition from the Pan American Union to OAS would have been smooth if it had not been for the assassination of Colombian leader Jorge Eliécer Gaitán and all the commotion that follows. The Director General of the former, Alberto Lleras Camargo, became the Organization's first Secretary General. The current Secretary General is former Uruguayan minister of foreign affairs Luis Almagro.
Significant milestones in the history of the OAS since the signing of the Charter have included the following:
Goals and purpose.
In the words of Article 1 of the Charter, the goal of the member nations in creating the OAS was "to achieve an order of peace and justice, to promote their solidarity, to strengthen their collaboration, and to defend their sovereignty, their territorial integrity, and their independence". Article 2 then defines eight essential purposes:
Over the course of the 1990s, with the end of the Cold War, the return to democracy in Latin America, and the thrust toward globalization, the OAS made major efforts to reinvent itself to fit the new context. Its stated priorities now include the following:
Organizational structure.
The Organization of American States is composed of an Organization of American States General Secretariat, the Permanent Council, the Inter-American Council for Integral Development, and a number of committees.
The General Secretariat of the Organization of American States consists of six secretariats.
The various committees of the Organization of American States include:
General Assembly.
The General Assembly is the supreme decision-making body of OAS. It convenes once every year in a regular session. In special circumstances, and with the approval of two-thirds of the member states, the Permanent Council can convene special sessions.
The Organization's member states take turns hosting the General Assembly on a rotating basis. The states are represented at its sessions by their chosen delegates: generally, their ministers of foreign affairs, or their appointed deputies. Each state has one vote, and most matters—except for those for which the Charter or the General Assembly's own rules of procedure specifically require a two-thirds majority—are settled by a simple majority vote.
The General Assembly's powers include setting the OAS's general course and policies by means of resolutions and declarations; approving its budget and determining the contributions payable by the member states; approving the reports and previous year's actions of the OAS's specialized agencies; and electing members to serve on those agencies.
Membership and adhesions.
All 35 independent nations of the Americas are members of the OAS. Upon foundation on 5 May 1948, there were 21 members:
The later expansion of the OAS included Canada and the newly independent nations of the Caribbean. Members with later admission dates (sorted chronologically):
Canada and the OAS.
Although Canada obtained independence in its foreign policy from the United Kingdom in 1931, it chose not to join the OAS when it was first formed, despite its close relations with the United States. Canada became a Permanent Observer in the OAS on 2 February 1972. Canada signed the Charter of the Organization of American States on 13 November 1989 and this decision was ratified on 8 January 1990.
In 2004–2005, Canada was the second largest contributor to the OAS, with an annual assessed contribution representing 12.36 percent of the OAS Regular Budget (US$9.2 million) and an additional C$9 million in voluntary contributions to specific projects. Shortly after joining as a full member, Canada was instrumental in the creation of the Unit for the Promotion of Democracy, which provides support for the strengthening and consolidation of democratic processes and institutions in OAS member states.
Status of Cuba.
The current government of Cuba was excluded from participation in the Organization under a decision adopted by the Eighth Meeting of Consultation in Punta del Este, Uruguay, on 31 January 1962. The vote was passed by 14 in favor, with one against (Cuba) and six abstentions (Argentina, Bolivia, Brazil, Chile, Ecuador, and Mexico). The operative part of the resolution reads as follows:
This meant that the Cuban nation was still technically a member state, but that the current government was denied the right of representation and attendance at meetings and of participation in activities. The OAS's position was that although Cuba's participation was suspended, its obligations under the Charter, the American Declaration of the Rights and Duties of Man, etc. still hold: for instance, the Inter-American Commission on Human Rights continued to publish reports on Cuba's human rights situation and to hear individual cases involving Cuban nationals. However, this stance was occasionally questioned by other individual member states.
Cuba's position was stated in an official note sent to the Organization "merely as a courtesy" by Minister of Foreign Affairs Dr. Raúl Roa on 4 November 1964: "Cuba was arbitrarily excluded... The Organization of American States has no juridical, factual, or moral jurisdiction, nor competence, over a state which it has illegally deprived of its rights."
The reincorporation of Cuba as an active member regularly arose as a topic within the inter-American system for instance, it was intimated by the outgoing ambassador of Mexico in 1998but most observers did not see it as a serious possibility while the present government remained in power. Since 1960, the Cuban administration had repeatedly characterized the OAS as the "Ministry of Colonies" of the United States of America. On 6 May 2005, President Fidel Castro reiterated that the island nation would not "be part of a disgraceful institution that has only humiliated the honor of Latin American nations". After Fidel Castro's recent retirement and the ascent of his brother Raúl to power, this official position was reasserted. Venezuelan President Hugo Chávez promised to veto any final declaration of the 2009 Summit of the Americas due to Cuba's exclusion.
On 17 April 2009, after a "trading of warm words" between the administrations of U.S. President Barack Obama and Cuban leader Raúl Castro, OAS Secretary General José Miguel Insulza said he would ask the 2009 General Assembly to annul the 1962 resolution excluding Cuba.
On 3 June 2009, foreign ministers assembled in San Pedro Sula, Honduras, for the OAS's 39th General Assembly, passed a vote to lift Cuba's suspension from the OAS. The United States had been pressuring the OAS for weeks to condition Cuba's readmission to the group on democratic principles and commitment to human rights. Ecuador's Foreign Minister Fander Falconí said there will be no such conditions. "This is a new proposal, it has no conditions—of any kind," Falconí said. "That suspension was made in the Cold War, in the language of the Cold War. What we have done here is fix a historic error." The suspension was lifted at the end of the General Assembly, but, to be readmitted to the Organization, Cuba will need to comply with all the treaties signed by the Member States, including the Inter-American Democratic Charter of 2001. A Declaration by Cuba's Revolutionary Government dated 8 June 2009 stated that while Cuba welcomed the Assembly's gesture, in light of the Organization's historical record "Cuba will not return to the OAS".
Suspension of Honduras.
Following the expulsion of its President Manuel Zelaya, Honduras' membership of the Organization was suspended unanimously at midnight on 5 July 2009. The "de facto" government had already announced it was leaving the OAS hours earlier; this was not, however, taken into account by the OAS, which does not recognize that government as legitimate. An extraordinary meeting had been conducted by the OAS in Washington, D.C., with Zelaya in attendance. The suspension of Honduras was approved unanimously with 33 votes (Honduras did not vote). This was the first suspension carried out by the OAS since that of Cuba in 1962.
After Zelaya's return to Honduras in 2011, the country was re-admitted to the Organization on 1 June 2011 with 32 votes in favor and 1 (Ecuador) against. Venezuela expressed some reservations.
Permanent Observers.
As of 31 January 2014, there are 69 permanent observer countries, as well as the European Union.
Official languages.
The Organization's official languages are Spanish, English, Portuguese, and French, the national languages of the majority of its member nations. The Charter, the basic instrument governing OAS, makes no reference to the use of official languages. These references are to be found in the Rules of Procedure governing the various OAS bodies. Article 51 of the Rules of Procedure of the General Assembly, the supreme body of the OAS, which meets once a year, states that English, French, Portuguese and Spanish are the four official languages. Article 28 stipulates that a Style Committee shall be set up with representatives of the four official languages to review the General Assembly resolutions and declarations. Article 53 states that proposals shall be presented in the four official languages. The Rules of Procedure and Statutes of other bodies, such as the Inter-American Council for Integral Development (CIDI), the Permanent Executive Committee of the Inter-American Council for Integral Development (CEPCIDI), the Inter-American Commission of Women (CIM), the Inter-American Drug Abuse Control Commission (CICAD), the Inter-American Commission on Human Rights (IACHR) and the Inter-American Juridical Committee (CJI), technical bodies of the OAS, also mention the four official languages in which their meetings are to be conducted. Policy is therefore dictated through these instruments that require use of the four official languages at meetings.
Although a number of other languages have official status in one or more member states of OAS (Dutch in Suriname; Haitian Creole alongside French in Haiti; Quechua and Aymara in Peru, Ecuador and Bolivia; Guaraní in Paraguay), they are not official languages of the Organization.

</doc>
<doc id="22789" url="https://en.wikipedia.org/wiki?curid=22789" title="World Organisation for Animal Health">
World Organisation for Animal Health

The World Organisation for Animal Health (OIE) is an intergovernmental organization coordinating, supporting and promoting animal disease control.
Mission and status.
The main objective of the OIE is to control epizootic diseases and thus to prevent their spread. It is recognized as a reference organisation by the World Trade Organization (WTO) and in 2014 had a total of 180 member states. The OIE maintains permanent relations with 45 other international and regional organisations and has Regional and sub-regional Offices on every continent. The OIE does not depend on the UN system; its autonomy is both institutional and financial and its activities are governed by its own constitutional texts. Since its first General Session, held in Paris, The Office carries on its work under the authority of a Committee consisting of delegates of the contracting Governments.
History.
The need to fight animal diseases at global level led to the creation of the Office International des Epizooties through the international Agreement signed on January 25, 1924. In May 2003 the Office became the World Organisation for Animal Health but kept its historical acronym OIE.
World Animal Health Information Database (WAHID) Interface.
Timely dissemination of information is crucial to containing outbreaks. The WAHID Interface provides access to all data held within OIE's new World Animal Health Information System (WAHIS). It replaces and significantly extends the former web interface named Handistatus II System.
A comprehensive range of information is available from:

</doc>
<doc id="22790" url="https://en.wikipedia.org/wiki?curid=22790" title="Ozzie Smith">
Ozzie Smith

Osborne Earl "Ozzie" Smith (born December 26, 1954) is a retired American baseball shortstop who played in Major League Baseball (MLB) for the San Diego Padres and St. Louis Cardinals from 1978 to 1996. Nicknamed "The Wizard" for his defensive brilliance, Smith set major league records for career assists (8,375) and double plays (1,590) by a shortstop (the latter since broken by Omar Vizquel), as well as the National League (NL) record with 2,511 career games at the position; Smith won the NL Gold Glove Award for play at shortstop for 13 consecutive seasons (1980–92). A 15-time All-Star, he accumulated 2,460 hits and 580 stolen bases during his career, and won the NL Silver Slugger Award as the best-hitting shortstop in 1987. He was elected to the Baseball Hall of Fame in his first year of eligibility in 2002. He was also elected to the St. Louis Cardinals Hall of Fame in the inaugural class of 2014.
Smith was born in Mobile, Alabama, but his family moved to Watts, Los Angeles, when he was six years old. While participating in childhood athletic activities, Smith developed quick reflexes; he went on to play baseball in high school and college, at Los Angeles' Locke High School and Cal Poly-San Luis Obispo respectively. Drafted as an amateur player by the Padres, Smith made his major league debut in 1978. He quickly established himself as an outstanding fielder, and later became known for performing backflips on special occasions while taking his position at the beginning of a game. Smith won his first Gold Glove Award in 1980, and made his first All-Star Game appearance in 1981. When conflict with Padres' ownership developed, he was traded to the Cardinals for shortstop Garry Templeton in 1982.
Upon joining the Cardinals, Smith helped the team win the 1982 World Series. Three years later, his game-winning home run during Game 5 of the 1985 National League Championship Series prompted broadcaster Jack Buck's "Go crazy, folks!" play-by-play call. Despite a rotator cuff injury during the 1985 season, Smith posted career highs in multiple offensive categories in 1987. Smith continued to earn Gold Gloves and All-Star appearances on an annual basis until 1993. During 1995 season, Smith had shoulder surgery and was out nearly three months. After tension with his new manager Tony La Russa developed in 1996, Smith retired at season's end, and his uniform number (No. 1) was subsequently retired by the Cardinals. Smith also served as host of the television show "This Week in Baseball" from 1997 to 1998.
Early life.
Smith was born in Mobile, Alabama, the second of Clovi and Marvella Smith's six children (five boys and one girl). While the family lived in Mobile, his father worked as a sandblaster at Brookley Air Force Base. When Smith was six his family moved to the Watts section of Los Angeles, California. His father became a delivery truck driver for Safeway stores, while his mother became an aide at a nursing home. His mother was an influential part of his life who stressed the importance of education and encouraged him to pursue his dreams.
Smith played a variety of sports in his youth, but considered baseball to be his favorite. He developed quick reflexes through various athletic and leisure activity, such as bouncing a ball off the concrete steps in front of his house, moving in closer to reduce reaction time with each throw. When not at the local YMCA or playing sports, Smith sometimes went with friends to the neighborhood lumberyard, springboarding off inner tubes and doing flips into sawdust piles (a precursor to his famous backflips). In 1965, at age ten, he endured the Watts Riots with his family, recalling that, "We had to sleep on the floor because of all the sniping and looting going on."
While Smith was attending junior high school, his parents divorced. Continuing to pursue his interest in baseball, he would ride the bus for nearly an hour to reach Dodger Stadium, cheering for the Los Angeles Dodgers at about 25 games a year. Upon becoming a student at Locke High School, Smith played on the basketball and baseball teams. Smith was a teammate of future National Basketball Association player Marques Johnson on the basketball team, and a teammate of future fellow Hall-of-Fame player Eddie Murray on the baseball side. After high school Smith attended Cal Poly San Luis Obispo in 1974 on a partial academic scholarship, and managed to walk-on to the baseball team. In addition to his academic education, he learned to switch-hit from Cal Poly coach Berdy Harr. When Cal Poly's starting shortstop broke his leg midway through the 1974 season, Smith subsequently took over the starting role. Later named an All-American athlete, he established school records in career at bats (754) and career stolen bases (110) before graduating in 1977.
Professional baseball career.
San Diego Padres.
Smith was playing semi-professional baseball in Clarinda, Iowa, in June 1976 when he was selected in the seventh round of the amateur entry draft by the Detroit Tigers. The parties could not agree on a contract; Smith wanted a $10,000 ($ today) signing bonus, while the Tigers offered $8,500 ($ today). Smith returned to Cal Poly for his senior year, then in the 1977 draft was selected in the fourth round by the San Diego Padres, ultimately agreeing to a contract that included a $5,000 signing bonus ($ today). Smith spent his first year of professional baseball, 1977, with the Class A Walla Walla Padres of the Northwest League.
Smith began 1978 as a non-roster invitee to the San Diego Padres' spring training camp in Yuma, Arizona. Smith credited Padres manager Alvin Dark for giving him confidence by telling reporters the shortstop job was Smith's until he proved he can't handle it. Even though Dark was fired in the middle of training camp, Smith made his Major League Baseball (MLB) debut on April 7, 1978.
It did not take long for Smith to earn recognition in the major leagues, making what some consider his greatest fielding play only ten games into his rookie season. The Padres played host to the Atlanta Braves on April 20, 1978, and with two out in the top of the fourth inning, Atlanta's Jeff Burroughs hit a ground ball up the middle. Smith described the play by saying, "He hit a ball back up the middle that everybody thought was going into center field. I instinctively broke to my left and dove behind second. As I was in the air, the ball took a bad hop and caromed behind me, but I was able to catch it with my bare hand. I hit the ground, bounced back up, and threw Burroughs out at first."
During a roadtrip to Houston, later in the season, Smith met a part-time usherette at the Astrodome named Denise while making his way to the team bus outside the stadium. The couple developed a relationship that was sometimes long-distance in nature, and eventually decided to marry. It was also during the 1978 season that Smith introduced a signature move. Padres promotion director Andy Strasberg knew Smith could perform backflips, but that he only did them during practice before fans entered the stadium. Strasberg asked Smith to do a backflip for fans during Fan Appreciation Day on October 1, the Padres' last home game of the season. After conferring with veteran teammate Gene Tenace, Smith went ahead with the backflip, and it proved to be wildly popular. Smith finished the 1978 season with a .258 batting average and .970 fielding percentage, placing second in National League Rookie of the Year voting to Bob Horner.
After working with a hitting instructor during the offseason, Smith failed to record a base hit in his first 32 at-bats of the 1979 season. Among players with enough at-bats to qualify for the 1979 National League Triple Crown, Smith finished the season last in batting average (.211), home runs (0), and RBI (27). Off the field, conflict developed between Padres' ownership and the combination of Smith and his agent, Ed Gottlieb. The parties entered into a contract dispute before the 1980 season, and when negotiations lasted into spring training, the Padres renewed Smith's contract at his 1979 salary of $72,500 Smith's agent told the Padres the shortstop would forgo the season to race in the Tour de France, despite the fact Smith admitted to The Break Room on 96.5 WCMF in Rochester, NY he had never heard of the Tour. Angered by the Padres' attitude during those contract talks, Gottlieb took out a help-wanted ad in the "San Diego Union", part of which read, "Padre baseball player wants part-time employment to supplement income." When Joan Kroc, wife of Padres owner Ray Kroc, publicly offered Smith a job as an assistant gardener on her estate, Smith and Gottlieb's relationship with the organization deteriorated further.
Meanwhile, Smith was winning recognition for his accomplishments on the field. In 1980, he set the single-season record for most assists by a shortstop (621), and began his string of 13 consecutive Gold Glove awards. Smith's fielding play prompted the "Yuma Daily Sun" to use the nickname "The Wizard of Oz" in a March 1981 feature article about Smith. While "The Wizard of Oz" nickname was an allusion to the 1939 motion picture of the same name, Smith also came to be known as simply "The Wizard" during his playing career, as Smith's Baseball Hall of Fame plaque would later attest. In 1981, Smith made his first All-Star Game appearance as a reserve player.
Trade.
While Smith was having problems with the Padres' owners, the St. Louis Cardinals also found themselves unhappy with their shortstop. During a game at Busch Stadium on August 26, 1981, Garry Templeton made obscene gestures at fans before being pulled off the field by manager Whitey Herzog. Given the task of overhauling the Cardinals by owner Gussie Busch, Herzog was looking to trade Templeton when he was approached by Padres General Manager Jack McKeon at the 1981 baseball winter meetings. While McKeon had previously told Herzog that Smith was untouchable in any trade, the Padres were now so angry at Smith's agent Gottlieb that McKeon was willing to deal.
McKeon and Herzog agreed in principle to a six-player trade, with Templeton for Smith as the centerpiece. It was then that Padres manager Dick Williams informed Herzog that a no-trade clause had been included in Smith's 1981 contract. Upon learning of the trade, Smith's initial reaction was to invoke the clause and stay in San Diego, but he was still interested to hear what the Cardinals had to say. While the deal for the players beside Templeton and Smith went through, Herzog flew to San Diego to meet with Smith and Gottlieb over the Christmas holiday. Smith later recalled that, "Whitey told me that with me playing shortstop for the St. Louis Cardinals, we could win the pennant. He made me feel wanted, which was a feeling I was quickly losing from the Padres. The mere fact that Whitey would come all the way out there to talk to us was more than enough to convince me that St. Louis was the place I wanted to be."
St. Louis Cardinals.
1982–84.
After more behind-the-scenes contract wrangling, Smith became a St. Louis Cardinal on February 11, 1982. Herzog believed Smith could improve his offensive production by hitting more ground balls, and subsequently created a motivational tool designed to help Smith concentrate on that task. Approaching Smith one day during spring training, Herzog said, "Every time you hit a fly ball, you owe me a buck. Every time you hit a ground ball, I owe you a buck. We'll keep that going all year." Smith agreed to the wager, and by the end of the season had won close to $300 from Herzog. As the 1982 season got underway, Herzog's newly assembled team won 12 games in a row during the month of April, and finished the season atop the National League East division. Herzog would later say of Smith's contributions that, "If he saved two runs a game on defense, which he did many a night, it seemed to me that was just as valuable to the team as a player who drove in two runs a game on offense."
Smith became a father for the first time during the 1982 season with the birth of his son O.J., today known as Nikko, on April 28. Smith also developed a lasting friendship with teammate Willie McGee during the season, and Smith said he likes to think he "helped Willie get over some of the rough spots of adjusting to the major leagues". Smith later participated in the postseason for the first time when the Cardinals faced the Atlanta Braves in the best-of-five 1982 National League Championship Series (NLCS). Smith drove in the series' first run by hitting a sacrifice fly that scored McGee in Game 1, ultimately going five for nine in St. Louis' three-game series sweep.
Just as Herzog had predicted when he told Smith the Cardinals would win the pennant with him on the team, Smith found himself as the team's starting shortstop in the best-of-seven 1982 World Series against the Milwaukee Brewers. During the contest Smith scored three runs, had five hits, and did not commit an error in the field. When St. Louis was trailing 3–1 with one out in the sixth inning of Game 7, Smith started a rally with a base hit to left field, eventually scoring the first of the team's three runs that inning. The Cardinals scored two more runs in the 8th inning for a 6-3 win and the championship.
After the World Series championship, Smith and the Cardinals agreed on a new contract in January 1983 that paid Smith $1 million per year. Smith was voted in as the National League's starting shortstop in the All-Star Game for the first time in 1983, and at season's end won a fourth consecutive Gold Glove Award. During July of the 1984 season, Smith went on the disabled list with a broken wrist after being hit by a pitch during a game against the Padres. Smith's return to the lineup a month later was not enough to propel the Cardinals to a postseason berth.
1985–86.
In 1985, Smith amassed a .276 batting average, 31 stolen bases, and 591 assists in the field. The Cardinals as a team won 101 games during the season and earned another postseason berth. Facing the Los Angeles Dodgers in the now best-of-seven NLCS, a split of the first four games set the stage for Game 5 at Busch Stadium. With the score tied at two runs apiece in the bottom of the ninth inning, Dodgers manager Tommy Lasorda called upon closer Tom Niedenfuer to pitch. Smith batted left-handed against Niedenfuer with one out. Smith, who had never hit a home run in his previous 3,009 left-handed major league at-bats, pulled an inside fastball down the right-field line for a home run, ending Game 5 in a 3–2 Cardinals victory. Smith said, "I was trying to get an extra-base hit and get into scoring position. Fortunately, I was able to get the ball up." The home run not only prompted broadcaster Jack Buck's "Go crazy folks" play-by-play call, but was also later voted the greatest moment in Busch Stadium history by Cardinals fans.
After Smith's teammate Jack Clark hit a late-inning home run of his own in Game 6 to defeat the Dodgers, the Cardinals moved on to face the Kansas City Royals in the 1985 World Series. Once again sportswriters were quick to draw attention to Smith's outstanding defensive play instead of his 2 for 23 effort at the plate. After the Cardinals took a three-games-to-two advantage, a controversial Game 6 call by umpire Don Denkinger overshadowed the remainder of the Series (which the Royals won in seven games).
What was not publicly known during the regular season and playoffs was that Smith had torn his rotator cuff after suffering an impingement in his right shoulder during the July 11–14 homestand against the Padres. After suffering the impingement diving back into first base on a pickoff throw, Smith altered his throwing motion to such a degree that the rotator cuff tear subsequently developed. The 5'10" (1.78 m), 180-pound (82 kg) Smith opted to forgo surgery and instead built up his arm strength via weightlifting, playing through whatever pain he encountered. Said Smith, "I didn't tell anybody about the injury, because I wanted to keep playing and didn't want anybody thinking they could run on me or take advantage of the injury. I tried to do almost everything, except throw a baseball, left-handed: opening a door, turning on the radio—everything. It didn't get any better, but it was good enough that I didn't have to have surgery."
Because of his injury, Smith let his then four-year-old son Nikko perform his traditional Opening Day backflip before the Cardinals' first home game of the 1986 season. Smith made an "eye-popping" play later that season on August 5, during a game against the Philadelphia Phillies at Busch Stadium. In the top of the ninth inning, Phillies first baseman Von Hayes hit a short fly ball to left field, which was pursued by both Smith and left fielder Curt Ford. Running with his back to home plate, Smith dove forward, simultaneously catching the ball while parallel to the ground and flying over the diving Ford, avoiding a collision by inches.
1987–90.
After hitting in either the second or eighth spot in the batting order for most of his time in St. Louis, Herzog made Smith the number-two hitter full-time during the 1987 season. Over the course of the year, Smith accrued a .303 batting average, 43 stolen bases, 75 RBIs, 104 runs scored, and 40 doubles, good enough to earn him the Silver Slugger Award at shortstop. In addition to winning the Gold Glove Award at shortstop for the eighth consecutive time, Smith posted a career-high on-base percentage of .392. Smith was also the leading vote-getter in the 1987 All-Star Game. The Cardinals earned a postseason berth with 95 wins, and subsequently faced the San Francisco Giants in the 1987 National League Championship Series. Smith contributed a triple during the series, and the Cardinals won the contest in seven games.
The 1987 World Series matched the Cardinals against the American League champion Minnesota Twins. The home team won every game of the contest, as Minnesota won the series. In 28 at-bats during the Series, Smith scored three runs and had two RBIs. Smith finished second in MVP balloting to Andre Dawson, who had played on the last-place Chicago Cubs, largely because Smith and teammate Jack Clark split the first-place vote. Following the 1987 season, Smith was awarded the largest contract in the National League at $2,340,000.
While the team did not see the postseason for the remainder of the decade, Smith continued to rack up All-Star appearances and Gold Gloves. Combined with the attention he received from his contract, Smith continued to be a national figure. Known as a savvy dresser, he made the April 1988 cover of "GQ" magazine. Smith was witness to change within the Cardinal organization when owner Gussie Busch died in 1989 and Herzog quit as manager during the 1990 season.
1990–95.
Joe Torre became Smith's new manager in 1990, but the team did not reach the postseason during Torre's nearly five-year tenure. While the Cardinals celebrated their 100th anniversary in 1992, Smith marked milestones of his own, stealing his 500th career base on April 26, then notching a triple on May 26 in front of the home crowd for his 2,000th hit. St. Louis had a one-game lead in the National League East division on June 1, 1992, but injuries took their toll on the team, including Smith's two-week illness in late July after contracting chicken pox for the first time. As a testament to his national visibility during this time, Smith appeared in a 1992 episode of "The Simpsons" titled "Homer at the Bat". Smith became a free agent for the first time in his career on November 2, 1992, only to sign a new contract with the Cardinals on December 6.
Smith won his final Gold Glove in 1992, and his 13 consecutive Gold Gloves at shortstop in the National League has yet to be matched. The 1993 season marked the only time between 1981 and 1996 that Smith failed to make the All-Star team, and Smith finished the 1993 season with a .288 batting average and .974 fielding percentage. He appeared in 98 games during the strike-shortened 1994 season, and later missed nearly three months of the 1995 season after shoulder surgery on May 31. Smith was recognized for his community service efforts with the 1994 Branch Rickey Award and the 1995 Roberto Clemente Award. In February 1994, Smith took on the role of honorary chairman and official spokesman for the Missouri Governor's Council on Physical Fitness and Health.
1996.
As Smith entered the 1996 season, he finalized a divorce from his wife Denise during the first half of the year. Meanwhile, manager Tony La Russa began his first season with the Cardinals in tandem with a new ownership group. After General Manager Walt Jocketty acquired shortstop Royce Clayton during the offseason, La Russa emphasized an open competition for the spot that would give the Cardinals the best chance to win. When spring training concluded, Smith had amassed a .288 batting average and zero errors in the field, and Clayton batted .190 with eight errors. Smith believed he had earned the position with his spring training performance, but La Russa disagreed, and awarded Clayton the majority of playing time in the platoon situation that developed, where Smith typically saw action every third game. La Russa said, "I think it's fair to say he misunderstood how he compared to Royce in spring training...When I and the coaches evaluated the play in spring training—the whole game—Royce started very slowly offensively and you could see him start to get better. By what he was able to do defensively and on the bases, Royce deserved to play the majority of the games."
Smith missed the first month of the season with a hamstring injury, and continued to harbor ill feelings toward La Russa that had developed after spring training ended. In a closed-door meeting in mid-May, La Russa asked Smith if he would like to be traded. Instead, Smith and his agent negotiated a compromise with Cardinals management, agreeing to a buyout of special provisions in his contract in conjunction with Smith announcing his retirement. The agreement prompted a press conference at Busch Stadium on June 19, 1996, during which Smith announced he would retire from baseball at season's end.
As Smith made his final tour of the National League, he was honored by many teams, and received a standing ovation at the 1996 All-Star Game in Philadelphia. Between June 19 and September 1, Smith's batting average increased from .239 to .286. On September 2 Smith tied a career high by scoring four runs, one of which was a home run, and another on a close play at home plate in the bottom of the 10th inning against division leader Houston. The victory moved the Cardinals to within a half game of Houston in the National League Central Division, and the Cardinals went on to win the division by six games. The Cardinals held a special ceremony at Busch Stadium on September 28, 1996, before a game against the Cincinnati Reds, honoring Smith by retiring his uniform number. Noted for his ritual backflip before Opening Days, All-Star Games, and postseason games, Smith chose this occasion to perform it for one of the last times.
In the postseason, the Cardinals first faced the San Diego Padres in the 1996 National League Division Series. After sitting out Game 1, Smith got the start in Game 2 at Busch Stadium, helping his team go up two games in the series by notching a run, a hit and two walks at the plate, along with an assist and a putout in the field. The Cardinals then swept the series by winning Game 3 in San Diego.
The Cardinals faced the Atlanta Braves in the 1996 National League Championship Series. Smith started Game 1 and subsequently registered three putouts and one assist in the field, but went hitless in four at-bats in the Cardinals' 4–2 loss. The Cardinals then won Games 2, 3, and 4, contests in which Smith did not appear. Upon receiving the start in Game 5, Smith nearly duplicated his Game 1 performance with four putouts, one assist, and zero hits in four at-bats as part of another Cardinals defeat. The Cardinals also failed to win Game 6 or Game 7 in Atlanta, ending their season. When the Cardinals were trailing by ten runs during Game 7 on October 17, Smith flied out to right field while pinch-hitting in the sixth inning, marking the end of his playing career. Smith finished his career with distinctions ranging from the accumulation of more than 27.5 million votes in All-Star balloting, to holding the record for the most MLB at-bats without hitting a grand slam.
Post-playing career.
Upon retirement, Smith took over for Mel Allen as the host of the television series "This Week in Baseball" ("TWIB") in 1997. Smith also became color commentator for the local broadcast of Cardinals games on KPLR-TV from 1997 to 1999. When his stint on "This Week in Baseball" concluded, Smith then moved on to do work for CNN-SI beginning in 1999. After La Russa retired as manager of the Cardinals in 2011, Smith became active in the organization again, starting with his stint as a special instructor for the team's 2012 spring training camp.
On January 8, 2002 Smith learned via a phone call he had been elected to the Baseball Hall of Fame on his first ballot by receiving 91.7% of the votes cast. As it happened, the Olympic torch was passing through St. Louis on its way to Salt Lake City for the 2002 Winter Olympics, and Smith served as a torchbearer in a ceremony with St. Louis Rams' quarterback Kurt Warner that evening. Smith was inducted into the Hall of Fame during ceremonies on July 28, 2002. During his speech, he compared his baseball experiences with the characters from the novel "The Wonderful Wizard of Oz", after which his son Dustin presented his Hall of Fame plaque. Days later on August 11, Smith was back at Busch Memorial Stadium for the unveiling of a statue in his likeness made by sculptor Harry Weber. Weber chose to emphasize Smith's defensive skills by showing Smith stretched horizontal to the ground while fielding a baseball. At the ceremony Weber told Smith, "You spent half of your career up in the air. That makes it difficult for a sculptor to do something with it."
Smith has also been an entrepreneur in a variety of business ventures. Smith opened "Ozzie's" restaurant and sports bar in 1988, started a youth sports academy in 1990, became an investor in a grocery store chain in 1999, and partnered with David Slay to open a restaurant in the early 2000s. Of those businesses the youth academy remains in operation, with the restaurant having closed in 2010 after changing ownership and locations once. Aside from appearing in numerous radio and television commercials in the St. Louis area since retiring from baseball, Smith authored a children's book in 2006 and launched his own brand of salad dressing in 2008.
Besides the National Baseball Hall of Fame, Smith has been also inducted or honored in other halls of fame and recognitions. In 1999, he ranked number 87 on "The Sporting News"' list of the 100 Greatest Baseball Players, and finished third in voting at shortstop for the Major League Baseball All-Century Team. He was honored with induction into the Missouri Sports Hall of Fame, Alabama Sports Hall of Fame and the St. Louis Walk of Fame, and received an honorary Doctor of Humane Letters degree from Cal Poly. In January 2014, the Cardinals announced Smith among 22 former players and personnel to be inducted into the St. Louis Cardinals Hall of Fame Museum for the inaugural class of 2014.
Personal life.
Smith is the father to three children from his marriage to former wife Denise; sons Nikko and Dustin, and daughter Taryn. Smith remains a visible figure around the St. Louis area, making varied appearances like playing the role of the Wizard in the St. Louis Municipal Opera's summer 2001 production of "The Wizard of Oz". Smith cheered on his son Nikko as he cracked the top ten finalists of the 2005 edition of "American Idol". In 2012, Smith made news headlines again, when he sold all of his Gold Gloves at auction together for more than $500,000.

</doc>
<doc id="22791" url="https://en.wikipedia.org/wiki?curid=22791" title="Boeing OC-135B Open Skies">
Boeing OC-135B Open Skies

The OC-135B Open Skies United States Air Force observation aircraft supports the Treaty on Open Skies. The aircraft, a modified WC-135B, flies unarmed observation flights over participating parties of the treaty. Three OC-135B aircraft were modified by the Aeronautical Systems Center's 4950th Test Wing at Wright-Patterson Air Force Base in Ohio. The first operationally capable OC-135B was assigned to the 24th Reconnaissance Squadron at Offutt AFB in October 1993. It is now fitted with a basic set of navigational and sensor equipment, and placed in inviolate storage at the Aerospace Maintenance and Regeneration Center at Davis-Monthan Air Force Base near Tucson, Arizona. Two fully operational OC-135B aircraft were delivered in 1996 with the full complement of treaty allowed sensors, which includes an infrared line scanner, synthetic aperture radar and video scanning sensors.
Description of aircraft.
The interior seats 35 people, including the cockpit crew, aircraft maintenance crew, foreign country representatives and crew members from the U.S. Department of Defense's Defense Threat Reduction Agency (DTRA). Cameras installed include one vertical and two oblique KS-87E framing cameras used for low-altitude photography approximately 3,000 feet (900 m) above the ground, and one KA-91C panoramic camera, which scans from side to side to provide a wide sweep for each picture used for high-altitude photography at approximately .
The data annotation and recording system (DARMS) processes navigational, altitude, time and camera signals to annotate each picture with correct position, altitude, time, roll angle and other information. In addition, this system records every picture taken according to camera, frame and navigational position and downloads these data to a 3.5-inch floppy disk. A keyboard with trackball is the input device for operation of this system. Two Barco VGA color monitors display camera annotation and other camera data on screen for the sensor operator and observer use.
Camera control, located in the sensor operator's console, operates and adjusts individual cameras for cloud cover, frame overlap and other functions. The sensor operator console seats four and has all the equipment listed above plus camera bay heating control, chronometers, emergency oxygen, interphone and individual lighting. The flight following console also seats four and includes most of the equipment listed above except for DARMS and camera controls.
Seven commercial Norcold Tek II coolers with individual refrigeration units maintain temperature and humidity control to maintain peak film performance. The units can be removed, if necessary, from the aircraft in order to transport film. The coolers are capable of storing of film.
Flight path.
The aircraft flies on its intended flight path throughout the entire mission with no reliance on ground-based navigation devices. A top-of-the-line commercial system, Litton 92 INS/GPS, which is an integrated inertial navigation system (INS) with a global positioning system (GPS), provides continuous updates. The GPS updates the INS several times per second to correct any deviations in the flight path. The INS also feeds precise latitude, longitude, time, roll angle and barometric altitude to the DARMS and camera systems. A true airspeed computer feeds true airspeed data to the INS.
A combined altitude radar altimeter provides precise height above ground information to the pilot for navigational purposes as well as a signal to DARMS for film annotation. It is accurate from above the ground level. Plus, a metric altimeter is installed on the pilot's instrument panel for altitude reference when flying in countries that use meters for altitude reference.
The aircraft are being upgraded with the Block 30 Pacer Crag Navigational System upgrade, a first step in making them compliant with ICAO mandated Global Air Traffic Management and Global Air Navigation Standards guidelines.
Modifications.
The OC-135B modifications center around four cameras installed in the rear of the aircraft. Since its primary mission is to take pictures, most of the installed equipment and systems provide direct support to the cameras and the camera operator. Other modifications to the aircraft also included installing an auxiliary power unit, crew luggage compartment, sensor operator console, flight following console and upgraded avionics.
Other modifications support the aircrew. A gaseous oxygen system replaced the liquid oxygen system to be more compatible with foreign airfields, and fluorescent lighting system was added throughout the cabin to provide adequate lighting for operation and inspections. Four upgraded seats with a conference table, interphone, lighting and oxygen comprise the mission commanders' station for both countries' mission commanders. A four channel interphone system enables segregated communications between various elements on board.
The auxiliary power unit enables the aircraft to start engines and provides electrical power and cabin heat independent of ground support equipment. It was manufactured by Allied Signal with the installation and design of the installation by E-Systems and World Auxiliary Power Company.
The aircraft are assigned to Air Combat Command at the 55th Wing, 45th Reconnaissance Squadron, Offutt Air Force Base near Omaha, Nebraska, for operations, training and maintenance. When tasked, ACC's role is to transport a DTRA observation team to an Open Skies point of entry airport, and conduct the observation flight, then return the team to the continental United States.
References.
This article includes public domain text from the following United States Government source:

</doc>
<doc id="22792" url="https://en.wikipedia.org/wiki?curid=22792" title="Treaty on Open Skies">
Treaty on Open Skies

The Treaty on Open Skies entered into force on January 1, 2002, and currently has 34 States Parties. It establishes a program of unarmed aerial surveillance flights over the entire territory of its participants. The treaty is designed to enhance mutual understanding and confidence by giving all participants, regardless of size, a direct role in gathering information about military forces and activities of concern to them. Open Skies is one of the most wide-ranging international efforts to date promoting openness and transparency of military forces and activities. The concept of "mutual aerial observation" was initially proposed to Soviet Premier Nikolai Bulganin at the Geneva Conference of 1955 by President Dwight D. Eisenhower; however, the Soviets promptly rejected the concept and it lay dormant for several years. The treaty was eventually signed as an initiative of US president (and former Director of Central Intelligence) George H. W. Bush in 1989. Negotiated by the then-members of NATO and the Warsaw Pact, the agreement was signed in Helsinki, Finland, on March 24, 1992.
This treaty is not related to civil-aviation open skies agreements.
Membership.
The 34 State Parties to the Open Skies Treaty are: Belarus, Belgium, Bosnia and Herzegovina, Bulgaria, Canada, Croatia, Czech Republic, Denmark, Estonia, Finland, France, Georgia, Germany, Greece, Hungary, Iceland, Italy, Latvia, Lithuania, Luxembourg, Netherlands, Norway, Poland, Portugal, Romania, Russian Federation, Slovak Republic, Slovenia, Spain, Sweden, Turkey, Ukraine, United Kingdom, and United States. Kyrgyzstan has signed but not yet ratified. Canada and Hungary are the depositories of the treaty in recognition of their special contribution to the Open Skies process. "Depository" countries maintain treaty documents and provide administrative support.
The treaty is of unlimited duration and open to accession by other States. States of the former Soviet Union that have not already become States Parties to the treaty may accede to it at any time. Applications from other interested States are subject to a consensus decision by the Open Skies Consultative Commission (OSCC), the Vienna-based organization charged with facilitating implementation of the treaty, to which all States Parties belong. The Organization for Security and Co-Operation in Europe meets monthly at its Vienna headquarters. Eight states have acceded to the treaty since entry into force: Finland, Sweden, Latvia, Bosnia and Herzegovina, Croatia, Slovenia, Estonia, and Lithuania.
Basic elements of the treaty.
Territory.
The Open Skies regime covers the territory over which the State Party exercises sovereignty, including land, islands, and internal and territorial waters. The treaty specifies that the entire territory of a State Party is open to observation. Observation flights may only be restricted for reasons of flight safety; not for reasons of national security.
Aircraft.
Observation aircraft may be provided by either the observing Party or (the "taxi option") by the observed Party, at the latter's choice. All Open Skies aircraft and sensors must pass specific certification and pre-flight inspection procedures to ensure that they are compliant with treaty standards. The official certified U.S. Open Skies aircraft is the OC-135B Open Skies.
Canada uses a C-130 Hercules aircraft equipped with a "SAMSON" sensor pod to conduct flights over other treaty nations. The pod is a converted CC-130 fuel tank modified to carry the permitted sensors, along with associated on-board mission systems. A consortium of nations consisting of Belgium, Netherlands, Luxemburg, Canada, France, Greece, Italy, Portugal, and Spain own and operate this system. The costs of maintaining the SAMSON Pod are shared, based on each nation's flight quota and actual use.
Bulgaria, Romania, Russia and Ukraine use the Antonov An-30 for their flights. The Czech Republic also used to use the An-30 for this purpose but they apparently retired all of theirs from service in 2003.
Russia also uses the Tu-154M-ON Monitoring Aircraft. Germany formerly used this type as well until the aircraft was lost in a 1997 accident.
Sweden uses a SAAB 340 aircraft ("OS-100") that was certified in 2004.
Sensors.
Open Skies aircraft may have video, optical panoramic and framing cameras for daylight photography, infra-red line scanners for a day/night capability, and synthetic aperture radar for a day/night all weather capability. Photographic image quality will permit recognition of major military equipment (e.g., permit a State Party to distinguish between a tank and a truck), thus allowing significant transparency of military forces and activities. Sensor categories may be added and capabilities improved by agreement among States Parties. All sensors used in Open Skies must be commercially available to all signatories. Imagery resolution is limited to 30 centimetres.
Quotas.
Each State Party is obligated to receive observation flights per its passive quota allocation. Each State Party may conduct as many observation flights - its active quota - as its passive quota. During the first three years after entry into force, each State will be obligated to accept no more than seventy-five percent of its passive quota. Since the overall annual passive quota for the United States is 42, this means that it will be obligated to accept no more than 31 observation flights a year during this three-year period. Only two flights were requested over the United States during 2005, by the Russian Federation and Republic of Belarus Group of States Parties (which functions as a single entity for quota allocation purposes). The United States is entitled to 8 of the 31 annual flights available over Russia/Belarus. Additionally, the United States is entitled to one flight over Ukraine, which is shared with Canada.
Data sharing and availability.
Imagery collected from Open Skies missions is available to any State Party upon request for the cost of reproduction. As a result, the data available to each State Party is much greater than that which it can collect itself under the treaty quota system.
History.
At a Geneva Conference meeting with Soviet Premier Nikolai Bulganin in 1955, President Eisenhower proposed that the United States and Soviet Union conduct surveillance overflights of each other's territory to reassure each country that the other was not preparing to attack. The fears and suspicions of the Cold War led Soviet General Secretary Nikita Khrushchev to reject Eisenhower's proposal. 
During a five-day summit conference held in Geneva, Switzerland at the end of July 1955, the Soviet Union and United States held serious talks about disarmament and the United States put forward proposals for mutual reconnaissance flights over each other's air space, known as the Open Skies proposal. The United States had a large number of RB-47s and RB-36 reconnaissance aircraft at its disposal for such activities, however the Soviets turned down this proposal. However, this Geneva Conference was universally accepted as a turning point in the Cold War. The tensions in Europe were felt to be a stalemate; however both the Soviet Union and United States were willing to talk about their differences, rather than increase them into a state of war.
Thirty-four years later, the Open Skies concept was reintroduced by President George H. W. Bush as a means to build confidence and security between all North Atlantic Treaty Organisation (NATO) and Warsaw Pact countries. In February 1990, an international Open Skies conference involving all NATO and Warsaw Pact countries opened in Ottawa, Canada. Subsequent rounds of negotiations were held in Budapest, Hungary, Vienna, Austria, and Helsinki, Finland.
On March 24, 1992, the Open Skies Treaty was signed in Helsinki by Secretary of State James Baker and foreign ministers from 23 other countries. The treaty entered into force on January 2, 2002, after Russia and Belarus completed ratification procedures.
In November 1992, President Bush assigned responsibility for overall training, management, leadership, coordination and support for U.S. Open Skies observation missions to the On-Site Inspection Agency (OSIA), now a part of the Defense Threat Reduction Agency (DTRA). Until entry into force in January 2002, DTRA support for the treaty involved participating in training and joint trial flights (JTFs). The U.S. has conducted over 70 JTFs since 1993. By March 2003, DTRA had successfully certified 16 camera configurations on the OC-135B aircraft. They also had contributed to the certification of the Bulgarian An-30, Hungarian An-26, POD Group (consisting of Belgium, Canada, France, Greece, Italy, Luxembourg, Netherlands, Norway, Portugal and Spain) C-130H, Romanian An-30, Russian An-30, and Ukrainian An-30. The United States successfully flew its first Open Skies mission over Russia in December 2002.
With entry into force of the treaty, formal observation flights began in August 2002. During the first treaty year, States Parties conducted 67 observation flights. In 2004, States Parties conducted 74 missions, and planned 110 missions for 2005. On March 8 and 9, 2007, Russia conducted overflights of Canada under the Treaty. The OSCC continues to address modalities for conducting observation missions and other implementation issues.
Since 2002 a total of 40 missions have taken place over the UK there were 24 quota missions conducted by: Russia—20; Ukraine—three; and Sweden—one. There were 16 training flights conducted by: Benelux (joint with Estonia); Estonia (joint with Benelux); Georgia—three (one joint with Sweden); Sweden—three (one joint with Georgia); USA - three; Latvia; Lithuania; Romania; Slovenia; and Yugoslavia. Also since 2002 the UK has undertaken a total of 51 open skies missions. 38 were quota missions to the following countries: Ukraine (five); Georgia (seven) and Russia (26). 13 missions were training missions to the following nations: Bulgaria; Yugoslavia; Estonia; Slovenia (three); Sweden (three); USA; Latvia, Lithuania and the Benelux. Until 2008 they used an Andover C.1(PR) aircraft but since then they have used a variety of aircraft including a Saab 340, An-30, and an OC-135. The flights cost approximately £50,000 per operational mission, and approximately £25,000 for training missions with an approximate annual cost of £175,000.
References.
This article includes public domain text from the following United States Government sources:
External links.
[[Category:1990 in aviation]]
[[Category:1990 in Finland]]
[[Category:2002 in aviation]]
[[Category:Aviation agreements]]
[[Category:Cold War treaties]]
[[Category:Surveillance]]
[[Category:Treaties concluded in 1990]]
[[Category:Treaties entered into force in 2002]]
[[Category:Organization for Security and Co-operation in Europe]]
[[Category:Treaties of Belarus]]
[[Category:Treaties of Belgium]]
[[Category:Treaties of Bosnia and Herzegovina]]
[[Category:Treaties of Bulgaria]]
[[Category:Treaties of Canada]]
[[Category:Treaties of Croatia]]
[[Category:Treaties of the Czech Republic]]
[[Category:Treaties of Denmark]]
[[Category:Treaties of Estonia]]
[[Category:Treaties of Finland]]
[[Category:Treaties of France]]
[[Category:Treaties of Georgia (country)]]
[[Category:Treaties of Germany]]
[[Category:Treaties of Greece]]
[[Category:Treaties of Hungary]]
[[Category:Treaties of Iceland]]
[[Category:Treaties of Italy]]
[[Category:Treaties of Latvia]]
[[Category:Treaties of Lithuania]]
[[Category:Treaties of Luxembourg]]
[[Category:Treaties of the Netherlands]]
[[Category:Treaties of Norway]]
[[Category:Treaties of Poland]]
[[Category:Treaties of Portugal]]
[[Category:Treaties of Romania]]
[[Category:Treaties of Russia]]
[[Category:Treaties of Slovakia]]
[[Category:Treaties of Slovenia]]
[[Category:Treaties of Spain]]
[[Category:Treaties of Sweden]]
[[Category:Treaties of Turkey]]
[[Category:Treaties of Ukraine]]
[[Category:Treaties of the United Kingdom]]
[[Category:Treaties of the United States]]
[[Category:Treaties extended to Aruba]]
[[Category:Treaties extended to the Netherlands Antilles]]
[[Category:Treaties extended to the Faroe Islands]]
[[Category:Treaties extended to Greenland]]
[[Category:Treaties extended to Akrotiri and Dhekelia]]
[[Category:Treaties extended to Anguilla]]
[[Category:Treaties extended to Bermuda]]
[[Category:Treaties extended to the British Indian Ocean Territory]]
[[Category:Treaties extended to the British Virgin Islands]]
[[Category:Treaties extended to the Cayman Islands]]
[[Category:Treaties extended to the Falkland Islands]]
[[Category:Treaties extended to Gibraltar]]
[[Category:Treaties extended to Guernsey]]
[[Category:Treaties extended to the Isle of Man]]
[[Category:Treaties extended to Jersey]]
[[Category:Treaties extended to Montserrat]]
[[Category:Treaties extended to the Pitcairn Islands]]
[[Category:Treaties extended to Saint Helena, Ascension and Tristan da Cunha]]
[[Category:Treaties extended to South Georgia and the South Sandwich Islands]]
[[Category:Treaties extended to the Turks and Caicos Islands]]

</doc>
<doc id="22794" url="https://en.wikipedia.org/wiki?curid=22794" title="Limited overs cricket">
Limited overs cricket

Limited overs cricket, also known as one-day cricket and in a slightly different context as List A cricket, is a version of the sport of cricket in which a match is generally completed in one day, whereas Test and first-class matches can take up to five days to complete. The name reflects the rule that in the match each team bowls a set maximum number of overs, usually between 20 and 50, although shorter and longer forms of limited overs cricket have been played.
One-day cricket is popular with spectators as it can encourage aggressive, risky, entertaining batting, often results in cliffhanger endings, and ensures that a spectator can watch an entire match without committing to five days of continuous attendance.
Structure.
Each team bats only once, and each innings is limited to a set number of overs, usually fifty in a One Day International and between forty and sixty in a List A. List A is a classification of the limited-overs (one-day) form of cricket, technically as the domestic level.
Despite its name, important one-day matches, international and domestic, often have two days set aside, the second day being a "reserve" day to allow more chance of the game being completed if a result is not possible on the first day (for instance if play is prevented or interrupted by rain).
Bowling restrictions.
As mentioned above, in almost all competitive one-day games, a restriction is placed on the number of overs that may be bowled by any one bowler. This is to prevent a side playing two top-class bowlers with extremely good stamina who can bowl throughout their opponents' innings. The usual limitation is set so that a side must include at least five players who bowl. For example, the usual limit for twenty-over cricket is four overs per bowler, for forty-over cricket eight per bowler and for fifty-over cricket ten per bowler. There are exceptions: Pro Cricket in the United States restricts bowlers to five overs each, thus leaving a side requiring only four bowlers.
History.
The idea for a one-day, limited 50-over cricket tournament, was first played in the inaugural match of the All India Pooja Cricket Tournament in 1951 in the small town of Tripunithura, Kerala, India. It is thought to be the brain child of KV Kelappan Thampuran, a former cricketer and the first Secretary of the Kerala Cricket Association. The one day limited over cricket game was later adapted and played between English county teams for the first instance on 2 May 1962. Leicestershire beat Derbyshire and Northamptonshire beat Nottinghamshire over 65 overs in the "Midlands Knock-Out Cup", which Northamptonshire went on to win a week later. The following year, the first full-scale one-day competition between first-class teams was played, the knock-out Gillette Cup, won by Sussex. The number of overs was reduced to 60 for the 1964 season. League one-day cricket also began in England, when the John Player Sunday League was started in 1969 with forty over matches. Both these competitions have continued every season since inauguration, though the sponsorship has changed. The knock-out cup is now the Friends Provident Trophy. The league is not exclusive to Sundays, with the competition now over 40 overs after some tinkering in the 1990s. It is now called the Natwest Pro40.
The first Limited Overs International (LOI) or One-Day International (ODI) match was played in Melbourne in 1971, and the quadrennial cricket World Cup began in 1975. Many of the "packaging" innovations, such as coloured clothing, were as a result of World Series Cricket, a "rebel" series set up outside the cricketing establishment by Australian entrepreneur Kerry Packer. For more details, see History of cricket.
Twenty20, a curtailed form of one-day cricket with 20 overs per side, was first played in England in 2003. It has proven very popular, and several Twenty20 matches have been played between national teams. It makes several changes to the usual laws of cricket, including the addition of a "bowl-out" (similar to a penalty shoot-out in football) to decide the result of tied matches, which was subsequently dispensed in favour of a Super Over.
One Day Internationals.
One Day International matches are usually played in brightly coloured clothing often in a "day-night" format where the first innings of the day occurs in the afternoon and the second occurs under stadium lights.
One Day International tournaments.
Every four years, the Cricket World Cup involves all the Test-playing nations and other national sides who qualify through the ICC World Cup Qualifier. It usually consists of round-robin stages, followed by semi-finals and a final. The International Cricket Council (ICC) determines the venue far in advance.
The ICC Champions Trophy also involves all the Test-playing nations, and is held between World Cups. It usually consists of a round-robin group stage, semifinals, and a final.
Each Test-playing country often hosts triangular tournaments, between the host nation and two touring sides. There is usually a round-robin group stage, and then the leading two teams play each other in a final, or sometimes a best-of-three final. When there is only one touring side, there is still often a best-of-five or best-of-seven series of limited overs matches.
Domestic one-day competitions.
Domestic one-day competitions exist in almost every country where cricket is played.
List A status.
List A cricket is a classification of the limited-overs (one-day) form of the sport of cricket. Much as domestic first-class cricket is the level below international Test match cricket, so List A cricket is the domestic level of one-day cricket below One Day Internationals. Twenty20 matches do not qualify for the present.
Most cricketing nations have some form of domestic List A competition. The number of overs in List A cricket ranges from forty to sixty overs per side.
The Association of Cricket Statisticians and Historians created this category for the purpose of providing an equivalent to first-class cricket, to allow the generation of career records and statistics for comparable one-day matches. Only the more important one-day competitions in each country, plus matches against a touring Test team, are included. The categorisation of cricket matches as "List A" was not officially endorsed by the International Cricket Council until 2006, when the ICC announced that it and its member associations would be determining this classification in a manner similar to that done for first class matches.
Australia.
The Ryobi One Day Cup is a 50 overs tournament held since 1969. The sides that compete are the following: 
In 2006 Cricket Australia introduced the KFC Twenty20 Big Bash which was amongst the state teams (as above). In 2011 this was expanded to the KFC Twenty20 Big Bash League, consisting of teams based in the capital cities of Australia. The teams are as follows:
Bangladesh.
The National One Day Cricket League is sponsored by Mirzapore Tea. It currently runs from November to March, with each team playing the other home and away once in a round-robin format. These six teams compete for the League title:
Pakistan.
The Pakistani domestic competition changes regularly, but for 2005–06 there are plans for three one-day tournaments for men:
South Africa.
The local competition in South Africa is the Standard Bank Cup (formerly Benson & Hedges Series) played between 6 teams:
The games are 45-overs, and based on a home-and-away round-robin match system (each team plays ten matches) with semi-finals and a final. The Eagles were the winners of the 2004/2005 and 2005/2006 competitions.
Sri Lanka.
20 teams compete in the Premier Limited-Overs Tournament, which is an expansion from 16 in the last season. Games are played over 50 overs per side, and the teams are divided into two groups, where each team meets the other once over a period of a month. The four top teams from each group qualify for the quarter-finals, and there is then a direct knock-out system until a winner is found after three knock-out stages. The competing teams are:
West Indies.
The KFC Cup is the main regional one-day competition in the West Indies, named after its chief sponsor, the fast food chain KFC. In recent years, it has been run over a week's time as a group stage followed by knock-out stages. Guyana are the current holders, after they beat Barbados in the final, and they are also the team to have won it most, with nine titles, although two of them have been shared. Trinidad and Tobago are second in that history, having won seven titles.
In the 2005–06 edition of the KFC Cup, the six permanent first class regions of the West Indies contested the tournament:
One-day records.
The world record for the highest innings total in any List A limited overs match is 496 for 4 by Surrey against Gloucestershire in their Friends Provident Trophy 50-overs match at the Oval, London on 29 April 2007. That surpassed the 443 for nine by Sri Lanka against the Netherlands in their One Day International 50-overs match at Amstelveen on 4 July 2006, which is currently the highest ODI score. The lowest ever total is 23 by Yorkshire against Middlesex at Headingley in 1974 in a 40-overs match.
The most runs scored by both sides in any List A limited overs match is 872: Australia, batting first, scored 434 for four in 50 overs, and yet were beaten by South Africa who scored 438 for nine with a ball to spare during their One Day International at Johannesburg in 2006.
The highest individual innings is 268 by Ali Brown for Surrey against Glamorgan in a 50-overs match at The Oval in 2002. The best bowling figures are eight for 15 by Rahul Sanghvi for Delhi against Himachal Pradesh in a 50-overs match at Una in 1997.
The highest international individual innings is by Rohit Sharma who scored 264.
The highest score in any formal limited overs match is believed to be United's 630 for five against Bay Area in a 45 overs match at Richmond, California in August 2006.
The most runs in an over was scored by Herschelle Gibbs of the South African cricket team when, in the 2007 Cricket World Cup in the West Indies, he hit 6 sixes in one over bowled by Daan van Bunge of the Netherlands.
This record is shared by Yuvraj Singh of India who achieved this feat in the 2007 ICC World Twenty20 in South Africa, he hit 6 sixes in an over bowled by Stuart Broad of England.
Sachin Tendulkar holds the record of being the first male cricketer to score a double century in ODIs (200 not out). He achieved this feat against South Africa on 24 February 2010, at Gwalior, India. Virender Sehwag is the second male cricketer to score a double century, when he scored 219 before being caught out against West Indies on 8 December 2011, at Indore, India. Rohit Sharma became the third male cricketer to score a double century,when he scored 264 against Sri Lanka on 13 November 2014.

</doc>
<doc id="22796" url="https://en.wikipedia.org/wiki?curid=22796" title="Organization for Security and Co-operation in Europe">
Organization for Security and Co-operation in Europe

The Organization for Security and Co-operation in Europe (OSCE) is the world's largest security-oriented intergovernmental organization. Its mandate includes issues such as arms control and the promotion of human rights, freedom of the press and fair elections. It employs around 400 people in its secretariat in Vienna, Austria, 200 in its institutions and 2,100 field staff. It has its origins in the 1975 Conference on Security and Co-operation in Europe (CSCE) held in Helsinki, Finland.
The OSCE is concerned with early warning, conflict prevention, crisis management, and post-conflict rehabilitation. Its 57 participating states are located in Europe, northern and central Asia and North America and cover much of the land area of the Northern Hemisphere. It was created during the Cold War era as an East–West forum.
History.
The Organization has its roots in the 1973 Conference on Security and Co-operation in Europe (CSCE). Talks had been mooted about a European security grouping since the 1950s but the Cold War prevented any substantial progress until the talks at Dipoli in Espoo began in November 1972. These talks were held at the suggestion of the Soviet Union which wished to use the talks to maintain its control over the communist countries in Eastern Europe, and President of Finland Urho Kekkonen hosted them in order to bolster his policy of neutrality. Western Europe, however, saw these talks as a way to reduce the tension in the region, furthering economic cooperation and obtaining humanitarian improvements for the populations of the Communist bloc.
The recommendations of the talks, in the form of "The Blue Book", gave the practical foundations for a three-stage conference called the "Helsinki process". The CSCE opened in Helsinki on 3 July 1973 with 35 states sending representatives. Stage I only took five days to agree to follow the Blue Book. Stage II was the main working phase and was conducted in Geneva from 18 September 1973 until 21 July 1975. The result of Stage II was the Helsinki Final Act which was signed by the 35 participating states during Stage III, which took place in Finlandia Hall from 30 July – 1 August 1975. It was opened by Holy See’s diplomat Cardinal Agostino Casaroli, who was chairman of the conference.
The concepts of improving relations and implementing the act were developed over a series of follow-up meeting, with major gatherings in Belgrade (4 October 19778 March 1978), Madrid (11 November 19809 September 1983) and Vienna (4 November 198619 January 1989).
The collapse of the Soviet Union required a change of role for the CSCE. The Charter of Paris for a New Europe, signed on 21 November 1990, marked the beginning of this change. With the changes capped by the renaming of the CSCE to the OSCE on 1 January 1995, accordingly to the results of the conference held in Budapest, Hungary, in 1994. The OSCE now had a formal secretariat, Senior Council, Parliamentary Assembly, Conflict Prevention Centre, and Office for Free Elections (later becoming the Office for Democratic Institutions and Human Rights).
In December 1996, the "Lisbon Declaration on a Common and Comprehensive Security Model for Europe for the Twenty-First Century" affirmed the universal and indivisible nature of security on the European continent.
In Istanbul on 19 November 1999, the OSCE ended a two-day summit by calling for a political settlement in Chechnya and adopting a Charter for European Security. According to then Minister of Foreign Affairs Igor Ivanov, this summit marked a turning point in Russian perception of the OSCE, from an organization that expressed Europe's collective will, to an organization that serves as a Western tool for "forced democratization".
After a group of thirteen Democratic United States senators petitioned Secretary of State Colin Powell to have foreign election monitors oversee the 2004 presidential election, the State Department acquiesced, and President George W. Bush invited the OSCE to do so.
Languages.
The six official languages of the OSCE are English, French, German, Italian, Russian and Spanish.
Legal status.
A unique aspect of the OSCE is the non-binding status of its constitutive charter. Rather than being a formal treaty ratified by national legislatures, the Helsinki Final Act represents a political commitment by the heads of government of all signatories to build security and cooperation in Europe on the basis of its provisions. This allows the OSCE to remain a flexible "process" for the evolution of improved cooperation which avoids disputes and/or sanctions over implementation. By agreeing to these commitments, signatories for the first time accepted that treatment of citizens "within" their borders was also a matter of legitimate international concern. This open process of the OSCE is often given credit for helping build democracy in the Soviet Union and Eastern Europe, thus leading to the end of the Cold War. Unlike most international intergovernmental organizations, however, the OSCE does not have international legal personality on account of the lack of legal effect of its charter. As a result, its headquarters’ host, Austria, had to confer legal personality on the organization in order to be able to sign a legal agreement regarding its presence in Vienna.
Structure and institutions.
Political direction to the organization is given by heads of state or government during summits. Summits are not regular or scheduled but held as needed. The last summit took place in Astana (Kazakhstan), on 1 and 2 December 2010. The high-level decision-making body of the organization is the Ministerial Council, which meets at the end of every year. At ambassadorial level the Permanent Council convenes weekly in Vienna and serves as the regular negotiating and decision-making body. The chairperson of the Permanent Council is the ambassador to the Organization of the participating State which holds the chairmanship. From 1 January 2015 to 31 December 2015 the Chairman-in-Office is Minister for Foreign Affairs of Serbia, Ivica Dačić, who succeeded Swiss Foreign Minister Didier Burkhalter.
In addition to the Ministerial Council and Permanent Council, the Forum for Security Co-operation is also an OSCE decision-making body. It deals predominantly with matters of military co-operation, such as modalities for inspections according to the Vienna Document of 1999.
The OSCE's Secretariat is located in Vienna, Austria. The current Secretary General is Lamberto Zannier of Italy, who took over from Marc Perrin de Brichambaut of France. The organization also has offices in Copenhagen, Geneva, The Hague, Prague and Warsaw.
The OSCE employs approximately 400 people in its secretariat, 200 in its institutions and 2,100 in field operations.
The Parliamentary Assembly of the Organization for Security and Co-operation in Europe passes resolutions on matters such as political and security affairs, economic and environmental issues, and democracy and human rights. Representing the collective voice of OSCE parliamentarians, these resolutions and recommendations are meant to ensure that all participating states live up to their OSCE commitments. The Parliamentary Assembly also engages in parliamentary diplomacy, and has an extensive election observation program.
The oldest OSCE institution is the Office for Democratic Institutions and Human Rights (ODIHR), established in 1991 following a decision made at the 1990 Summit of Paris. It is based in Warsaw, Poland, and is active throughout the OSCE area in the fields of election observation, democratic development, human rights, tolerance and non-discrimination, rule of law, and Roma and Sinti issues. The ODIHR has observed over 150 elections and referendums since 1995, sending some 35,000 observers. It has operated outside its own area twice, sending a team that offered technical support to the 9 October 2004 presidential elections in Afghanistan, an OSCE Partner for Co-operation, and an election support team to assist with parliamentary and provincial council elections on 18 September 2005. ODIHR is headed by Michael Georg Link.
The Office of the OSCE Representative on Freedom of the Media, established in December 1997, acts as a watchdog to provide early warning on violations of freedom of expression in OSCE participating States. The representative also assists participating States by advocating and promoting full compliance with OSCE norms, principles and commitments regarding freedom of expression and free media. As of 2011, the current representative is expert in media law from Bosnia and Herzegovina Dunja Mijatovic.
The High Commissioner on National Minorities was created on July 8, 1992 by the Helsinki Summit Meeting of the Conference on Security and Cooperation in Europe. It is charged with identifying and seeking early resolution of ethnic tension that might endanger peace, stability or friendly relations between participating states.
Secretary-General.
The incumbent of this post acts as the representative of the Chairperson-in-Office, and as the OSCE's chief administrative officer. Since the post was created in 1992, Secretaries-General of the OSCE have been:
Chairmanship.
The responsibilities of the Chairman-in-Office (CiO) include
The chairmanship rotates annually, and the post of the chairman-in-office is held by the foreign minister of the participating State which holds the chairmanship. The CiO is assisted by the previous and incoming chairman-in-office; the three of them together constitute the Troika. The origin of the institution lies with the Charter of Paris for a New Europe (1990), the Helsinki Document 1992 formally institutionalized this function.
The 2015 Troika consists of the current CiO, Serbian Foreign Minister Ivica Dačić; the former CiO, Head of the Swiss Department of Foreign Affairs Didier Burkhalter; and incoming CiO, German Foreign Minister Frank-Walter Steinmeier.
Chairmanship history.
Chairmanship of the OSCE is held by a member state on a calendar-year basis, with the minister for foreign affairs of that state performing the function of Chairman-in-Office. The table below shows the holders since 1991.
Fiscal history.
Since 1993, the OSCE's budget by year (in millions of [euro]s,) has been:
Relations with the United Nations.
The OSCE considers itself a regional organization in the sense of Chapter VIII of the United Nations Charter and is an observer in the United Nations General Assembly. The Chairman-in-Office gives routine briefings to the United Nations Security Council.
Politico-military dimension (first dimension).
The OSCE takes a comprehensive approach to the politico-military dimension of security, which includes a number of commitments by participating States and mechanisms for conflict prevention and resolution. The organization also seeks to enhance military security by promoting greater openness, transparency and co-operation.
The end of the Cold War resulted in a huge amount of surplus weapons becoming available in what is known as the international grey market for weapons. The OSCE helps to stop the - often illegal - spread of such weapons and offers assistance with their destruction. The OSCE hosts the annual exchange of information under the Conventional Forces in Europe treaty. The OSCE has also implemented two additional exchanges of information, the Vienna Document and the Global Exchange of Military Information. The Open Skies Consultative Commission, the implementing body for the Treaty on Open Skies, meets monthly at its Vienna headquarters.
The actions taken by the OSCE in border monitoring range from conflict prevention to post-conflict management, capacity building and institutional support.
With its expertise in conflict prevention, crisis management and early warning, the OSCE contributes to worldwide efforts in combating terrorism.
The OSCE works to prevent conflicts from arising and to facilitate lasting comprehensive political settlements for existing conflicts. It also helps with the process of rehabilitation in post-conflict areas.
The OSCE's Forum for Security Co-operation provides a framework for political dialogue on military reform, while practical activities are conducted by field operations, as well as the Conflict Prevention Centre.
OSCE police operations are an integral part of the organization's efforts in conflict prevention and post-conflict rehabilitation.
The OSCE was a rather small organization until selection by the international community to provide electoral organization to post war Bosnia and Herzegovina in early 1996. Ambassador Frowick was the first OSCE representative to initiate national election in September 1996, human rights issues and rule of law specifically designed to provide a foundation for judicial organization within Bosnia and Herzegovina.
The OSCE had regional offices and field offices, to include the office in Brcko in northeastern Bosnia and Herzegovina which remained in limbo until the Brcko Arbitration Agreement could be decided, finalized and implemented.
Brcko become a "special district" and remains so today.
The OSCE essentially took the place of the United Nations in Bosnia and Herzegovina in part because the Bosnian leadership felt deep contempt for the UN efforts to stop the war which began in 1991 and ended in 1995. During the time the United Nations were attempting a political solution, thousands of UN troops were posted in and around Bosnia and Herzegovina with special emphasis on Sarajevo. Between the inclusive dates of 1991 through 1995, over 200,000 Bosnians were killed and over one million displaced and another million as refugees.
The OSCE continues to have a presence and a number of initiatives to bring a sustained peace to the region.
Economic and environmental dimension (second dimension).
Activities in the economic and environmental dimension include the monitoring of developments related to economic and environmental security in OSCE participating States, with the aim of alerting them to any threat of conflict; assisting States in the creation of economic and environmental policies, legislation and institutions to promote security in the OSCE region.
Among the economic activities of the OSCE feature activities related to migration management, transport and energy security. Most activities are implemented in co-operation with partner organizations.
The OSCE has developed a range of activities in the environmental sphere aimed at addressing ecologic threats to security in its participating States. Among the activities feature projects in the area of hazardous waste, water management and access to information under the Aarhus Convention.
Human dimension (third dimension).
The commitments made by OSCE participating States in the human dimension aim to ensure full respect for human rights and fundamental freedoms; to abide by the rule of law; to promote the principles of democracy by building, strengthening and protecting democratic institutions; and to promote tolerance throughout the OSCE region.
Since 2003 the OSCE has had an established mechanism for combating trafficking in human beings, as defined by Article 3 of the Palermo Protocol, which is aimed at raising public awareness of the problem and building the political will within participating states to tackle it effectively.
The OSCE actions against trafficking in human beings are coordinated by the Office of the Special Representative and Co-ordinator for Combating Trafficking in Human Beings. Maria Grazia Giammarinaro, a judge in the Criminal Court of Rome, took Office as the Special Representative in March 2010. From 2006 to 2009 this Office was held by Eva Biaudet, a former Finnish Minister of Health and Social Services. Biaudet currently serves as Finnish Ombudsman for Minorities. Her predecessor was former Austrian Minister Helga Conrad, who served as the first OSCE Special Representative for Combating Trafficking in Human Beings.
The activities around Combating Trafficking in Human Beings in the OSCE Region of the Office of the Special Representative include:
The OSCE claims to promote democracy and assist the participating states in building democratic institutions. In practice, however, few states have more power in decision-making than others.
Education programmes are an integral part of the organization's efforts in conflict prevention and post-conflict rehabilitation.
As part of its democratization activities, the OSCE carries out election assistance projects in the run-up to, during, and following elections. However, the effectiveness of such assistance is arguable—Kazakhstan, for example, despite being the former chair of the OSCE, is considered by many to be one of the least democratic countries in the world. Moreover, the recent democratic advances made in other Central Asian republics, notably Kyrgyzstan, have led to rumours of Soviet-style disruption of the Kyrgyz democratic process by, in particular, Kazakhstan and Russia. This may be in large part due to fears over the long-term stability of these countries' own quasi-dictatorships.
The equality of men and women is an integral part of sustainable democracy. The OSCE aims to provide equal opportunities for men and women and to integrate gender equality in policies and practices.
The OSCE's human rights activities focus on such priorities as freedom of movement and religion, preventing torture and trafficking in persons.
OSCE could grant consultive status to NGOs and INGOs in the form of "Researcher-in-residence programme" (run by the Prague Office of the OSCE Secretariat): accredited representatives of national and international NGOs are granted access to all records and to numerous topical compilations related to OSCE field activities.
The OSCE observes relevant media developments in its participating states with a view to addressing and providing early warning on violations of freedom of expression.
Ethnic conflict is one of the main sources of large-scale violence in Europe today. The OSCE's approach is to identify and to seek early resolution of ethnic tensions, and to set standards for the rights of persons belonging to minority groups and High Commissioner on National Minorities has been established.
Criticism.
Following an unprecedented period of activity in the 1990s and early 2000s (decade), the OSCE has in the past few years faced accusations from the CIS states (primarily Russia) of being a tool for the Western states to advance their own interests. For instance, the events in Ukraine in 2004 (the "Orange Revolution") led to allegations by Russia of OSCE involvement on behalf of the pro-Western Viktor Yushchenko. At the 2007 Munich Conference on Security Policy, Vladimir Putin made this position very clear:
Russia and its allies are advancing the concept of a comprehensive OSCE reform, which would make the Secretariat, institutions and field presences more centralized and accountable to collective consensus-based bodies and focus the work of the Organization on topical security issues (human trafficking, terrorism, non-proliferation, arms control, etc.), at the expense of the "Human Dimension", or human rights issues. The move to reduce the autonomy of the theoretically independent OSCE institutions, such as ODIHR, would effectively grant a Russian veto over any OSCE activity. Western participating States are opposing this process, which they see as an attempt to prevent the OSCE from carrying out its democratization agenda in post-Soviet countries.
Following the 2008 U.S. presidential election, OSCE's ODIHR was accused of having double standards by Russia's lawmaker Slutsky. The point was made that while numerous violations of the voting process were registered, its criticism came only from within the United States (media, human rights organizations, McCain's election staff), while the OSCE known for its bashing criticism of elections on the post-Soviet space remained silent.
OSCE Parliamentary Assembly.
In 2004 the OSCE Parliamentary Assembly sent election observers to the U.S. Presidential elections. The OSCE Parliamentary Assembly’s president at the time was Democratic Congressman Alcee Hastings. Hastings had previously been impeached for corruption by the U.S. Congress. The OSCE faced criticism of partisanship and double standards due to Hastings's past and the fact that the OSCE's mandate was to promote democracy and the values of civil society.
In 2010 the Parliamentary Assembly of the Organization for Security and Co-operation in Europe was criticized from within by the Latvian delegation for lacking transparency and democracy. Spencer Oliver (b. 1938) secretary general of the OSCE Parliamentary Assembly, who has held the post since the organization's inception in 1992, faced a challenge from the Latvian Artis Pabriks. According to the rules of the OSCE Parliamentary Assembly the incumbent general secretary can only be replaced with a full consensus minus one. Pabriks called the rules "quite shocking from the perspective of an organization that's monitoring elections".
In 2014 Ilkka Kanerva was elected the president of the OSCE PA. Kanerva had previously been fired from his post as foreign minister of Finland after lying about sending over 200 text messages to an erotic dancer.
2012 Texas controversy.
Before the U.S. presidential elections of November 2012, the OSCE announced its intention to send electoral observers to Texas and to other U.S. states. In response, Greg Abbott, the Attorney General of Texas, sent letters to U.S. Secretary of State Hillary Clinton threatening to arrest OSCE officials if they should enter electoral premises in Texas and break Texas law, and to the OSCE. In response, the U.S. Department of State indicated that OSCE observers enjoyed immunities. However no incidents between OSCE and Texas authorities were recorded during the elections.
Allegations of pro-Russian bias (2014).
The organization has come under increasing criticism in the Russian–Ukraine conflict. During the War in Donbass, an OSCE observer allowed Russian separatists to use the organization's marked vehicle, which prompted the belief that the OSCE was biased in the war and not interested in carrying out its duties of mediating a ceasefire. The organization issued a statement regretting the incident. The organization has also been criticized by Ukraine for failing to monitor the implementation of the Minsk Protocol. The agreement called for a creation of a 40 km buffer zone, but upon Ukrainian forces withdrawing from their 20 km portion of the buffer, Russian separatists simply occupied the abandoned territory without withdrawing from their own 20 km buffer. Likewise, there continues to be reports of separatists using OSCE marked vehicles for transportation. Moreover, the mission also received criticism that only 2 checkpoints on the Russian–Ukrainian border are currently being monitored, which has been described as "seriously inadequate" by Daniel Baerm the US ambassador to the OSCE. The mission has also been criticized for waiting months to deploy drones to help monitor the border as well as withdrawing them after only several weeks of use due to Russian electronic attacks. Ukraine has stated that approximately 80% of the OSCE observers located near Mariupol were Russian citizens and many had ties to Russian security agencies such as the FSB and GRU. The organization has also been accused of revealing the locations of Ukrainian troops to Russian forces during the conflict and that Russian OSCE observers may be directly coordinating separatist artillery strikes on Ukrainian positions. On 1 December 2014, an OSCE observer was injured by Ukrainian counter artillery fire while observing militants firing at Ukrainian forces. The OSCE team was located next to two pro Russian mortar teams. The OSCE team did not radio in or record the Russian mortar team firing on Ukrainian positions. Critics stated that the unorthodox behavior of being located next to an active separatist artillery position and not reporting the incident showed that the OSCE team was not acting in an impartial manner. On 27 October 2015 a suspended OSCE monitor confirmed he was a former employee of Russia's Main Intelligence Directorate. The suspended SMM stated he had no trouble receiving the position and neither the OSCE nor Ukraine's Security Service thoroughly checked his background. Following the report the OSCE issued a comment stating the monitor has been fired due to violations of the organization's code of conduct.

</doc>
<doc id="22798" url="https://en.wikipedia.org/wiki?curid=22798" title="Omri">
Omri

Omri () (fl. 9th century BC) was the sixth king of Israel after Jeroboam, a successful military campaigner, and the founder of the House of Omri, an Israelite royal house which included other monarchs such as Ahab, Ahaziah, Joram, and Athaliah. Along with his predecessor king Zimri who ruled for only seven days, Omri is the first king mentioned in the Bible without a statement of his tribal origin: although some scholars speculate that Omri was from the tribe of Issachar, this is not yet confirmed by any biblical account or scientific or historical evidence.
Mentioned in the Hebrew Bible as well as extra-biblical sources such as the Mesha stele and the Black Obelisk of Shalmaneser III, Omri is also credited with the construction of Samaria and establishing it as his capital.
Struggle for the succession.
Omri was "commander of the army" of King Elah when Zimri, "commander of half the king's chariots", murdered Elah and made himself king. Instead, the troops at Gibbethon chose Omri as king, and he led them to Tirzah where they trapped Zimri in the royal palace. To avoid the certain tortures of capture, Zimri set fire to the palace and died after a reign of only seven days. Although Zimri was eliminated, "half of the people" supported Tibni in opposition to Omri. () It took Omri four years to subdue Tibni and at last proclaim himself undisputed king of Israel. Nothing is said in Scripture about the lineage of Omri. His name is either Amorite or Arabic, suggesting he was a foreign mercenary.
Reign.
Omri became king of Israel in the 31st year of Asa, king of Judah and reigned for 12 years, 6 years of which were in Tirzah. () The biblical reference to the period of rivalry with Tibni is from the 27th year of Asa () to the 31st year. () William F. Albright has dated his reign to 876 – 869 BC, while E. R. Thiele offers the dates of 888 BC to 880 BC for his rivalry with Tibni and 880 – 874 BC for his sole reign.
Initially, Omri's capital was in Tirzah, but the associations of Tirzah were so repellent and the location so poor for a capital, that Omri purchased a new site on a hill, from Shemer for two talents of silver (about 60 kg), after which he built a new capital of the kingdom in Samaria.
Omri's rule over Israel was secure enough that he could bequeath his kingdom to his son Ahab, thus beginning a new dynasty (sometimes called the "Omrides'), and his descendants not only ruled over the kingdom of Israel for the next forty years, but also briefly over Judah.
Omri in archaeological sources.
Bryant G. Wood mentions three archaeological sites indicating buildings constructed by Omri: a well-built, but unfinished structure at Tirzah, a subsequent royal house at Samaria, and a third palace at Jezreel. The fortress at Jezreel was situated on one of the main east-west routes through kingdom. Hugh Williamson believes it served not only a military function, but also a political one; a very visible example of grandiose public works used as a means of social control and to assert claims of legitimacy.
The Moabite Mesha stele (on display in the Louvre) indicates that Omri expanded his holdings to include northern Moab east of the Jordan River. It makes reference to the oppression of Moab by "Omri King of Israel". Israel would later become identified in sources as the "House of Omri" ("Bit-Humria"), with the term "Israel" being used less and less as history progressed (the other defining term for "Israel" is "Samaria", beginning in the reign of Joash). Thomas L. Thompson ("The Bible in History"), however, interprets the Mesha stele as suggesting that Omri is an eponym, or legendary founder of the kingdom rather than an historical person.
The Omride Dynasty.
The short-lived dynasty founded by Omri constitutes a new chapter in the history of the Northern Kingdom of Israel. It ended almost fifty years of constant civil war over the throne. There was peace with the Kingdom of Judah to the south, and even cooperation between the two rival states, while relations with neighboring Sidon to the north were bolstered by marriages negotiated between the two royal courts. This state of peace with two powerful neighbors enabled the Kingdom of Israel to expand its influence and even political control in Transjordan, and these factors combined brought economic prosperity to the kingdom.
On the other hand, peace with Sidon also resulted in the penetration of Phoenician religious ideas into the kingdom and led to a "kulturkampf" between traditionalists (as personified by the prophet Elijah and his followers) and the aristocracy (as personified by Omri's son and heir Ahab and his consort Jezebel). In foreign affairs, this period paralleled the rise of the Kingdom of Aram based in Damascus, and Israel soon found itself at war in the northeast. Most threatening, however, was the ascendancy of Assyria, which was beginning to expand westward from Mesopotamia: the Battle of Qarqar (853 BC), which pitted Shalmaneser III of Assyria against a coalition of local kings, including Ahab, was the first clash between Assyria and Israel. It was the first in a series of wars that would eventually lead to the destruction of the Kingdom of Israel in 722 BC and the reduction of the Kingdom of Judah to an Assyrian tributary state.
In 841 BC, the Assyrian king Shalmaneser III campaigned along the Mediterranean coast and forced Jehu to pay tribute. Assyrian kings frequently referred to Omri's successors as belonging to the "House of Omri" ("Bit Hu-um-ri-a"). Despite the fact that Jehu ended the Omrid dynasty, the Assyrian Black Obelisk in the British Museum credits Jehu as being the "son of Omri" while the Bible describes him to be "the son of Jehoshaphat the son of Nimshi".
In accounts of Tiglath-Pileser III's 732 BC campaign in Israel, Assyrian scribes referred to Israel as "Omri-Land".
Attitude in contemporary Israel.
The Bible displays a negative attitude to King Omri, and it has been followed by later rabbinical tradition. Modern secular Israelis, however, have re-evaluated many Biblical and later Jewish historical characters in accord with the criteria of a national movement in need of heroes. As in many European national movements, ancient warriors in general and warrior kings in particular have come to be regarded more positively. Omri, a successful warrior king and the founder of a strong dynasty, is a conspicuous example.

</doc>
<doc id="22799" url="https://en.wikipedia.org/wiki?curid=22799" title="Oxycodone">
Oxycodone

Oxycodone is a semisynthetic opioid synthesized from thebaine, an opioid alkaloid found in the Persian poppy and one of the many opioid alkaloids found in the opium poppy. It is an analgesic generally indicated for relief of moderate to severe pain. It was developed in 1917 in Germany as one of several new semi-synthetic opioids in an attempt to improve on the existing opioids.
Oxycodone is available as single-ingredient medication in immediate release and controlled release. Parenteral formulations of 10 mg/mL and 50 mg/mL are available in the U.K. for IV/IM administration. Combination products are also available as immediate release formulations, with non-narcotic ingredients such as nonsteroidal anti-inflammatory drugs (NSAID) and paracetamol (acetaminophen); a combination with naloxone is available in managed-release tablets. The naloxone precipitates opioid withdrawal symptoms and blocks the faster onset were the tablet to be crushed and filtered for injection or otherwise tampered with in a manner not intended.
Medical uses.
Oxycodone has been in clinical use since 1916, and it is used for managing moderate to moderately severe acute or chronic pain. It has been found to improve quality of life for those with many types of pain. However, prescribing errors, diversion and misuse can lead to severe addiction and accidental overdose possibly resulting in death.
The controlled-release oral tablet form is intended to be taken every 12 hours. Oxycodone is clearly useful for acute pain, as is the case with other opioids, and in some instances of chronic pain, cancer-related and otherwise. Experts are divided regarding the efficacy of all opioids in non-malignant chronic pain. Opioids induce acute pain relief, but most of them have the strong potential for dependence, withdrawal, and the induction of pain sensitivity and hyperalgesia, thereby causing the symptom (pain) that they are being used to treat.
An Italian study concluded from investigating multiple studies that controlled-release oxycodone is comparable to instant-release oxycodone, morphine, and hydromorphone in management of moderate to severe cancer pain. The study indicated that side effects appear to be less than those associated with morphine and that it is a valid alternative to morphine and a first-line treatment for cancer pain.
In 2014, the European Association for Palliative Care recommended that oral oxycodone could be taken as a second-line alternative to oral morphine for cancer pain.
Administration.
In the United States, Oxycodone is medically approved only for administration orally, and is only supplied in the form of oral tablets and oral (liquid) concentrates. In the United Kingdom, Oxycodone is also medically approved for intravenous therapy (IV) and intramuscular (IM) injection. When first introduced in Germany in 1917, IV/IM became common for post-operative pain management of soldiers of the Central Powers during World War I.
Off-label use.
Oxycodone appears to have a significant anti-depressant effect. However, its use for this purpose may be illegal: see Legal Status below.
Side effects.
Common side effects include euphoria, constipation, fatigue, dizziness, nausea, vomiting, dry mouth, anxiety, itching, and sweating. Less common side effects (experienced by less than 5% of patients) include loss of appetite, nervousness, abdominal pain, diarrhea, urine retention, dyspnea, and hiccups.
In high doses, overdoses, or in patients not tolerant to opiates, oxycodone can cause shallow breathing, bradycardia, cold-clammy skin, apnea, hypotension, miosis, circulatory collapse, respiratory arrest, and death.
Oxycodone in combination with naloxone in managed-release tablets, has been formulated to reduce side effects.
Dependence, addiction and withdrawal.
The risk of experiencing severe withdrawal symptoms is high if a patient has become physically dependent or addicted and discontinues oxycodone abruptly. Therefore, particularly in cases where the drug has been taken regularly over an extended period, use should be discontinued gradually rather than abruptly. People who use oxycodone in a recreational, hazardous, or harmful fashion (not as intended by the prescribing physician) are at even higher risk of severe withdrawal symptoms, as they tend to use higher-than-prescribed doses. The symptoms of oxycodone withdrawal are the same as for other opiate-based painkillers, and may include "anxiety, panic attack, nausea, insomnia, muscle pain, muscle weakness, fevers, and other flu-like symptoms".
Withdrawal symptoms have also been reported in newborns whose mothers had been either injecting or orally taking oxycodone during pregnancy.
Hormone imbalance.
As with other opioids, oxycodone (particularly during chronic heavy use) often causes temporary hypogonadism or hormone imbalance.
Detection in biological fluids.
Oxycodone and/or its major metabolites may be measured in blood or urine to monitor for clearance, abuse, confirm a diagnosis of poisoning, or assist in a medicolegal death investigation. Many commercial opiate screening tests cross-react appreciably with oxycodone and its metabolites, but chromatographic techniques can easily distinguish oxycodone from other opiates.
Pharmacology.
Mechanism of action.
In 1997, a group of Australian researchers proposed (based on a study in rats) that oxycodone acts on κ-opioid receptors, unlike morphine, which acts upon μ-opioid receptors. Further research by this group indicated the drug appears to be a κ2b-opioid agonist. However, this conclusion has been disputed, primarily on the basis that oxycodone produces effects that are typical of μ-opioid agonists, mainly because oxycodone is metabolized in the liver to oxymorphone as a metabolite, which is a more potent opioid agonist with stronger/higher binding affinity to μ-opioid receptors compared to oxycodone.
In 2006, research by a Japanese group suggested the effect of oxycodone is mediated by different receptors in different situations. Specifically in diabetic mice, the κ-opioid receptor appears to be involved in the antinociceptive effects of oxycodone, while in nondiabetic mice, the μ1-opioid receptor seems to be primarily responsible for these effects.
After oxycodone binds to the opioid receptor, a G-protein complex is released, which inhibits the release of neurotransmitters by the cell by reducing the amount of cAMP produced, closing the Ca++ channels, and opening the K channels.
Absorption.
After a dose of conventional oral oxycodone, peak plasma levels of the drug are attained in about one hour; in contrast, after a dose of OxyContin (an oral controlled-release formulation), peak plasma levels of oxycodone occur in about three hours.
Distribution.
Oxycodone in the blood is distributed to skeletal muscle, liver, intestinal tract, lungs, spleen, and brain. Conventional oral preparations start to reduce pain within 10–15 minutes on an empty stomach; in contrast, OxyContin starts to reduce pain within one hour.
Metabolism.
Oxycodone is metabolized to α and β oxycodol; oxymorphone, then α and β oxymorphol and noroxymorphone; and noroxycodone, then α and β noroxycodol and noroxymorphone (N-desmethyloxycodone). (14-Methoxymetopon that in turn becomes 14-Hydroxydihydromorphine) These metabolites are true only for humans. As many as six metabolites for oxycodone (14-hydroxydihydromorphinone, 14-hydroxydihydrocodeine, 14-hydroxydihydrocodeinone N-oxide {oxycodone N-oxide}, 14-hydroxydihydroisocodeine, 14-hydroxydihydrocodeine N-oxide, and noroxycodone) have been found in rabbits, several of which are thought to be active metabolites to some extent, although a study using conventional oral oxycodone concluded oxycodone itself, and not its metabolites, is predominantly responsible for the drug's opioid effects on the brain.
Oxycodone is metabolized by the cytochrome P450 enzyme system in the liver, making it vulnerable to drug interactions. Some people are fast metabolizers, resulting in reduced analgesic effect, but increased adverse effects, while others are slow metabolisers, resulting in increased toxicity without improved analgesia. The dose of OxyContin must be reduced in patients with reduced hepatic function.
Elimination.
Oxycodone and its metabolites are mainly excreted in the urine and sweat; therefore, it accumulates in patients with renal impairment.
Dosage and administration.
Oxycodone can be administered orally, intranasally, via intravenous, intramuscular, or subcutaneous injection, or rectally. The bioavailability of oral administration of oxycodone averages 60–87%, with rectal administration yielding the same results; intranasal varies between individuals with a mean of 46%.
Equivalency.
Taken orally, the conversion ratio between morphine to extended release oxycodone is reported as 2:1.
Chemistry.
Oxycodone's chemical name is derived from codeine. The chemical structures are very similar, differing only in that
It is also similar to hydrocodone, differing only in that it has a hydroxyl group at carbon-14.
Expanded expression for the compound oxycodone in the academic literature include "dihydrohydroxycodeinone", "Eucodal", "Eukodal", "14-hydroxydihydrocodeinone", and "Nucodan". In a UNESCO convention, the translations of "oxycodone" are "oxycodon" (Dutch), "oxycodone" (French), "oxicodona" (Spanish), الأوكسيكودون (Arabic), 羟考酮 (Chinese), and оксикодон (Russian). The word "oxycodone" should not be confused with "oxandrolone", "oxazepam", "oxybutynin", "oxytocin", or "Roxanol".
In terms of biosynthesis, oxycodone has been found naturally in nectar extracts from the orchid family "Epipactis helleborine"; together along with another opioid: 3-{2-{3-{3-benzyloxypropyl}-3-indol, 7,8-didehydro- 4,5-epoxy-3,6-d-morphinan.
History.
Freund and Speyer of the University of Frankfurt in Germany first synthesized oxycodone from thebaine in 1916, a few years after the German pharmaceutical company Bayer had stopped the mass production of heroin due to hazardous use, harmful use, and dependence. It was hoped that a thebaine-derived drug would retain the analgesic effects of morphine and heroin with less dependence. To some extent this was achieved, as oxycodone does not have the same immediate effect as heroin or morphine, nor does it last as long.
The first clinical use of the drug was documented in 1917, the year after it was first developed. It was first introduced to the US market in May 1939. In early 1928, Merck introduced a combination product containing scopolamine, oxycodone and ephedrine under the German initials for the ingredients SEE, which was later renamed Scophedal (SCOpolamine ePHEDrine and eukodAL). This combination is essentially an oxycodone analogue of the morphine-based Twilight Sleep with ephedrine added to reduce circulatory and respiratory effects.
In the early 1960s the United States government classified oxycodone as a schedule II drug. In 1995 the FDA approved OxyContin.
As of May 2013 an extended release version in the United States is only available as OxyContin brand.
Statistics.
The International Narcotics Control Board estimated 11.5 short tons (23,000 lbs) of oxycodone were manufactured worldwide in 1998; by 2007 this figure had grown to 75.2 tons (150,400 lbs). United States accounted for 82% of consumption in 2007 at 51.6 tons. Canada, Germany, Australia and France combined accounted for 13% of consumption in 2007. In 2010, 122.5 tons of oxycodone were manufactured, according to the International Narcotics Control Board. This number had decreased slightly from the all-time high in 2009 of 135.9 tons.
Recreational use.
Effects.
Oxycodone, like other opioid analgesics, tends to induce feelings of euphoria, relaxation and reduced anxiety in those who are occasional users. These effects make it one of the most commonly abused pharmaceutical drugs in the United States.
Preventive measures.
In August 2010, Purdue Pharma reformulated their long-acting oxycodone line, marketed as OxyContin, to use a misuse-resistant polymer designed to decrease abuse potential by defeating the release mechanism. The FDA approved relabeling the reformulated version as abuse-resistant in April 2013.
Pfizer manufactures a preparation of short-acting oxycodone, marketed as Oxecta, which contains inactive ingredients designed to induce nasal irritation if the tablet is crushed and snorted.
Australia.
The non-medical use of oxycodone existed from the early 1970s, but by 2015, 91% of a national sample of injecting drug users in Australia had reported using oxycodone, and 27% had injected it in the last six months.
Canada.
Opioid-related deaths in Ontario had increased by 242 per cent from 1969 to 2014. By 2009 in Ontario there were more deaths from oxycodone overdose than from cocaine overdose, Deaths from opioid pain relievers had increased from 13.7 deaths per million residents in 1991 to 27.2 deaths per million residents in 2004. The abuse of oxycodone in Canada became a problem. Areas where oxycodone is most problematic are Atlantic Canada and Ontario, where its abuse is prevalent in rural towns, and in many smaller to medium-sized cities. Oxycodone is also widely available across Western Canada, but methamphetamine and heroin are more serious problems in the larger cities, while oxycodone is more common in rural towns. Oxycodone is diverted through doctor shopping, prescription forgery, pharmacy theft, and overprescribing.
The Blood Tribe police claimed that from the fall of 2014 through January 2015, oxycodone pills or a lethal fake variation containing fentanyl made in illegal labs by members of organized crime were responsible for ten deaths on the Blood Reserve, which is located southwest of Lethbridge, Alberta.
United Kingdom.
Abuse and diversion of oxycodone in the UK commenced in the early- to mid-2000s. The first known death due to overdose in the UK occurred in 2002. However, recreational use remains relatively rare.
United States.
In the United States, more than 12 million people abuse opioid drugs. In 2010, 16,652 deaths were related to opioid overdose in combination with other drugs such as benzodiazepines and alcohol. In September 2013, the FDA released new labeling guidelines for long acting and extended release opioids requiring manufacturers to remove moderate pain as indication for use, instead stating the drug is for "pain severe enough to require daily, around-the-clock, long term opioid treatment." The updated labeling will not restrict physicians from prescribing opioids for moderate, as needed use.
Based on statistical estimates by the US Department of Health and Human Services, about 11 million people in the US will consume at least one dose of this opioid in a non-medical way illegally sold under slang names "cotton", "pills", "kickers", or "orange county". About 100,000 men or women per year are admitted to US hospitals due to misuse of this drug, making it the most widely abused opioid substance in America. Diverted oxycodone is taken orally or ingested through insufflation, it can also be prepared for injection and administered intravenously, while some abusers will heat the pills on aluminum foil and inhale the smoke as a means of ingesting oxycodone. Other ways of abuse include intravenous injection of oral dosage forms, which are not designed for parenteral use. In 2008, oxycodone and hydrocodone misuse caused 14,800 deaths. Some of the cases, however, were due to the hepatotoxic effect of acetaminophen.
The FDA authorized OxyContin, the extended-release form of oxycodone, for conditional use in children (pediatric use) as young as 11, for treatment of cancer pain, trauma pain, or pain due to major surgery; the only other approved opioid (morphine-like) narcotic painkiller (analgesic) for children is Duragesic (fentanyl), and both of these drugs can be and are abused — though OxyContin has been reformulated, and heroin is cheaper and easier to obtain. The FDA has said OxyContin is permissible to prescribe and use specifically in children who have been on other opiate painkillers, and who can be judged to tolerate at least 20 milligrams (mg) of the OxyContin a day. 
Legal status.
General.
Oxycodone is subject to international conventions on narcotic drugs. In addition, oxycodone is subject to national laws that differ by country. The 1931 Convention for Limiting the Manufacture and Regulating the Distribution of Narcotic Drugs of the League of Nations included oxycodone. The 1961 Single Convention on Narcotic Drugs of the United Nations, which replaced the 1931 convention, categorized oxycodone in Schedule I. Global restrictions on Schedule I drugs include "limit[ing] exclusively to medical and scientific purposes the production, manufacture, export, import, distribution of, trade in, use and possession of" these drugs; "requir[ing] medical prescriptions for the supply or dispensation of [these] drugs to individuals"; and "prevent[ing] the accumulation" of quantities of these drugs "in excess of those required for the normal conduct of business".
Australia.
Oxycodone is in Schedule I (derived from the Single Convention on Narcotic Drugs) of the Commonwealth's Narcotic Drugs Act 1967. In addition, it is in Schedule 8 of the Australian Standard for the Uniform Scheduling of Drugs and Poisons ("Poisons Standard"), meaning it is a "controlled drug... which should be available for use but require[s] restriction of manufacture, supply, distribution, possession and use to reduce abuse, misuse and physical or psychological dependence".
Canada.
Oxycodone is a controlled substance under Schedule I of the Controlled Drugs and Substances Act (CDSA).
Canada - Legislative changes.
In February 2012, Ontario passed legislation to allow the expansion of an already existing drug-tracking system for publicly funded drugs to include those that are privately insured. This database will function to identify and monitor patient’s attempts to seek prescriptions from multiple doctors or retrieve from multiple pharmacies. Other provinces have proposed similar legislation, while some, such as Nova Scotia, have legislation already in effect for monitoring prescription drug use. These changes have coincided with other changes in Ontario’s legislation to target the misuse of painkillers and high addiction rates to drugs such as oxycodone. As of February 29, 2012, Ontario passed legislation delisting oxycodone from the province’s public drug benefit program. This was a first for any province to delist a drug based on addictive properties. The new law prohibits prescriptions for OxyNeo except to certain patients under the Exceptional Access Program including palliative care and in other extenuating circumstances. Patients already prescribed oxycodone will receive coverage for an additional year for OxyNeo, and after that, it will be disallowed unless designated under the exceptional access program.
Much of the legislative activity has stemmed from Purdue Pharma’s decision in 2011 to begin a modification of oxycodone’s composition to make it more difficult to crush for snorting or injecting. The new formulation, OxyNeo, is intended to be preventative in this regard and retain its effectiveness as a pain killer. Since introducing its "Narcotics Safety and Awareness Act", Ontario has committed to focusing on drug addiction, particularly in the monitoring and identification of problem opioid prescriptions, as well as the education of patients, doctors, and pharmacists. This Act, introduced in 2010, commits to the establishment of a unified database to fulfil this intention. Both the public and medical community have received the legislation positively, though concerns about the ramifications of legal changes have been expressed. Because laws are largely provincially regulated, many speculate a national strategy is needed to prevent smuggling across provincial borders from jurisdictions with looser restrictions.
Canada - Lawsuits.
Several class action suits across Canada have been launched against the Purdue group of companies and affiliates. Claimants argue the pharmaceutical manufacturers did not meet a standard of care and were negligent in doing so. These lawsuits reference earlier judgments in the United States, which held that Purdue was liable for wrongful marketing practices and misbranding. Since 2007, the Purdue companies have paid over $650 million in settling litigation or facing criminal fines.
Germany.
The drug is in Appendix III of the Narcotics Act ("Betäubungsmittelgesetz" or BtMG). The law allows only physicians, dentists, and veterinarians ("Ärzte, Zahnärzte und Tierärzte") to prescribe oxycodone and the federal government to regulate the prescriptions (e.g., by requiring reporting).
Hong Kong.
Oxycodone is regulated under Part I of Schedule 1 of Hong Kong's Chapter 134 Dangerous Drugs Ordinance.
Japan.
Oxycodone is a restricted drug in Japan. Its import / export is strictly restricted to specially designated organizations having prior permit to import it. In a high-profile case a top Toyota executive, who claimed to be unaware of the law, was arrested for importing Oxycodone into Japan.
Singapore.
Oxycodone is listed as a Class A drug in the Misuse of Drugs Act of Singapore, which means offences in relation to the drug attract the most severe level of punishment. A conviction for unauthorized manufacture of the drug attracts a minimum sentence of 10 years of imprisonment and corporal punishment of five strokes of the cane, and a maximum sentence of life imprisonment or 30 years of imprisonment and 15 strokes of the cane. The minimum and maximum penalties for unauthorized trafficking in the drug are respectively five years of imprisonment and five strokes of the cane, and 20 years of imprisonment and 15 strokes of the cane.
United Kingdom.
Oxycodone is a Class A drug under the Misuse of Drugs Act. For Class A drugs, which are "considered to be the most likely to cause harm", possession without a prescription is punishable by up to seven years in prison, an unlimited fine, or both. Dealing of the drug illegally is punishable by up to life imprisonment, an unlimited fine, or both. In addition, oxycodone is a Schedule 2 drug per the Misuse of Drugs Regulations 2001 which "provide certain exemptions from the provisions of the Misuse of Drugs Act 1971".
United States.
Under the Controlled Substances Act, enacted in 1971 by President Richard Nixon, oxycodone is a Schedule II controlled substance whether by itself or part of a multi-ingredient medication. The DEA lists oxycodone both for sale and for use in manufacturing other opioids as ACSCN 9143 and in 2013 approved the following annual aggregate manufacturing quotas: 131.5 metric tons for sale, down from 153.75 in 2012, and 10.25 metric tons for conversion, unchanged from the previous year. The salts in use are hydrochloride (free base conversion ratio .896), bitartrate (.667), tartrate (.750), camphosulphonate (.576), pectinate (.588), phenylpriopionate (.678), sulphate, (.887), phosphate (.763), and terephthalate (.792); the first and last are found together in Percodan and hydrochloride by itself is the basis of most American oxycodone products whilst bitartrate, tartrate, pectinate, and phosphate are also used alongside the other two in Europe. Methyiodide and hydroiodide are mentioned in older European publications.

</doc>
<doc id="22800" url="https://en.wikipedia.org/wiki?curid=22800" title="Occidental College">
Occidental College

Occidental College is a private, co-educational liberal arts college located in the Eagle Rock, Los Angeles, California, United States. Founded in 1887 by clergy and members of the Presbyterian Church, it is one of the oldest liberal arts colleges on the West Coast. Occidental College is often referred to as "Oxy" for short.
Occidental College is the oldest liberal arts college in Los Angeles and one of the few liberal arts colleges located in a major city. In 2014, "U.S. News and World Report" ranked Occidental as No. 44 on the list of National Liberal Arts Colleges. "The New York Times" ranked Occidental No. 20 on its list of the most economically diverse U.S. colleges and universities. The Carnegie Foundation for the Advancement of Teaching selected Occidental as a "community engagement institution". The college was named to the 2014 President's Higher Education Community Service Honor Roll "with distinction".
History.
Early history.
Occidental College was founded on April 20, 1887, by a group of Presbyterian clergy, missionaries, and laymen, including James George Bell, Lyman Stewart, and Thomas Bard. The cornerstone of the school's first building was laid in September 1887 in the Boyle Heights neighborhood of Los Angeles. The college's first term began a year later with 27 men and 13 women students, and tuition of $50 a year.
In 1896, the Boyle Heights building was destroyed by fire. The college temporarily relocated to the old St. Vincent's College campus on Hill Street before a new site was selected in Highland Park in 1898. Eventually, the college erected three main buildings: the Academy Building, the Stimson Library, and the Hall of Arts and Letters (converted to apartments, the hall still stands today). The Highland Park site was also bisected by the tracks of the Santa Fe Railroad, and was the site of two presidential visits, first by William Howard Taft in 1909 and subsequently by President Theodore Roosevelt in 1911.
In 1909, the Pomona College Board of Trustees suggested a merger between Pomona and Occidental, but the proposal came to nothing. The following year, the college severed formal ties with the Presbyterian Church and became a non-sectarian, non-denominational institution. The small size of the 15-acre campus and the disruption caused by frequent freight trains pushed the college's trustees to find a new location.
1900s.
In 1912, the school began construction of a new campus located in Los Angeles' Eagle Rock neighborhood. The Eagle Rock campus was designed by noted California architect Myron Hunt, also known as the planner of the Caltech campus and as designer of the Huntington Library and Art Gallery and the Rose Bowl. That same year, Occidental President John Willis Baer announced the trustees' decision to convert Occidental College into an all-men's institution. However, students and faculty protested, and the idea was abandoned.
Two weeks after Booker T. Washington came to visit Occidental, on March 27, 1914, Swan, Fowler, and Johnson Halls were dedicated at its new Eagle Rock campus. Patterson Field, today one of the oldest collegiate sports stadiums in Los Angeles, was opened in 1916. In April 1917, shortly after the United States entered World War I, the college formed a Students Army Training Corps to aid the war effort.
Under Occidental President Remsen Bird, the school opened a series of new Hunt-designed buildings, including Clapp Library (1924), Hillside Theatre and a women's dormitory (Orr Hall) in 1925, Alumni Gymnasium (1926), the Freeman Student Union (1928) and a music and speech building (1929). The Delta of California Chapter of Phi Beta Kappa was established at Occidental in 1926, at a time when the only other chapters in California were at Stanford, UC Berkeley, and Pomona.
During World War II, many students left Occidental to fight in the war. In July 1943, the U.S. Navy established a Navy V-12 officer training program on campus that produced hundreds of graduates before it was disbanded at the end of the war in 1945. Occidental President Remsen Bird worked behind the scenes to help Oxy students of Japanese descent continue their education despite mandatory evacuation orders; his letters are included in the Japanese American Relocation Collection in Clapp Library.
After having its first Rhodes Scholar, Clarence Spaulding, named in 1908, Oxy seniors John Paden and Aaron Segal were awarded Rhodes Scholarships in 1958; the first and only time Occidental has produced two Rhodes Scholars in a single year. Rhodes scholars Aaron Segal and John Paden were among the 10 Occidental students who participated in Crossroads Africa that year, a forerunner to the Peace Corps that later became a national program.
In 1969, 42 students were suspended for peacefully protesting military recruiting on campus. One year later, faculty voted to suspend classes in the wake of the Kent State shootings and America's invasion of Cambodia. Subsequently, Oxy students wrote 7,000 letters to Washington D.C., protesting U.S. involvement in the war in Southeast Asia. Occidental launched one of the country's first Upward Bound programs in 1966, aimed at increasing the number of low-income, underrepresented high school students who become the first in their family to go to college.
Also in 1969, the school opened its first two co-ed dormitories, and two more followed a year later. In 1988, John Brooks Slaughter became Occidental's first black president. Building on faculty and student advocacy and a series of grants the college had received previously to increase the diversity of the Occidental student body, Slaughter led the process of creating a new mission statement that is still used today. Also, Slaughter led the college's community outreach expansion with the creation of the Center for Volunteerism and Community Service, the predecessor for the current Center for Community Based Learning.
2000s.
In July 2006, Susan Prager became Occidental's first female president. She left her position in 2007 during the fall term. Robert Skotheim the former president of Whitman College and the Huntington Library, then served as interim president. In July 2009, Jonathan Veitch, formerly dean of The New School's Eugene Lang College, became Occidental's 15th president and the first to be a native Angeleno.
Campus.
Architect Myron Hunt created the original campus master plan for Occidental's Eagle Rock campus in 1911. He structured the campus in a Mediterranean style, with covered walkways and tile roofs. The campus landscape was designed and developed by Beatrix Farrand in the late 1930s. All of the 19 buildings designed by Hunt remain in use today, including Johnson Hall, now the home for the McKinnon Center for Global Affairs.
Built on a hillside, the Eagle Rock campus covers over , of which is undeveloped land that includes a local landmark known as Fiji Hill. There are 12 on-campus residence halls and the main dining facility is The Marketplace, which is located in the Johnson Student Center. Some buildings, such as the Hameetman Science Center (designed by Anshen + Allen, 2003), deviates from the original architecture with its large glass windows and metal balconies (its lobby houses a large Foucault pendulum). In 1979, Occidental installed "Water Forms II" (see image below), a kinetic fountain designed by professor George Baker. The fountain is a campus landmark and was featured prominently in the 1984 film "".
Occidental College was ranked as the sixth "Most Beautiful" campus by "Newsweek" in 2012. The school is home to a 1-megawatt ground-mounted solar array on an American college campus, as well as the largest in Los Angeles. The 4,886-panel installation was completed in Spring 2013 and inaugurated on the school's 126 year anniversary.
Academics.
There are 31 majors offered on campus and there is a 10:1 student-faculty ratio. The average class size is 19 students and most students take four classes per semester.
Since 1908, Occidental has graduated 10 Rhodes Scholars. The 2015 edition of The Fiske Guide to Colleges gave Occidental four-star ratings (out of five) in academics and quality of life. In "Forbes" 2014 rankings of America's Top Colleges, Occidental ranks 44th. In "U.S. News and World Report"'s 2014 rankings of American liberal arts colleges, Occidental is ranked 44th. Kiplinger’s Best College Values 2015 rankings places Occidental 55th among liberal arts colleges.
Core program.
Divided in three parts, the Core Program was designed by the faculty of Occidental to unify and enhance the liberal arts education offered by the school. The Core Program requires students to achieve the following:
First-year seminars (eight course hours in total) are the centerpiece of the Core Program. Students are given a variety of class choices to fulfill the seminar requirement and to satisfy the first-year writing requirement. While the classes range in topic, each is based on a curriculum of cultural studies. The classes are designed to expose students to the rigor of college academics and to the four principles of the college mission—Excellence, Equity, Community, and Service.
The Core Program's emphasis on global literacy requires students to take a minimum of three courses that touch on at least three of the following geographical areas: Africa and the Middle East; Asia and the Pacific; Europe; Latin America; the United States; and Intercultural. Students are also required to demonstrate proficiency in writing and in a foreign language and take courses in the fine arts and in the sciences, mathematics, or other courses that address formal methods of reasoning.
The final portion of the Core Program requires students to pass a senior comprehensive examination in their chosen field. Comprehensive examinations may include seminars, creative projects, fieldwork, oral exams, theses, or field research projects.
Exchange and cooperative joint degree programs.
California Institute of Technology and Columbia University.
Students at Occidental can take courses at the California Institute of Technology (Caltech) in nearby Pasadena free of charge. In addition, a 3-2 engineering program allows qualified students the opportunity to study at Occidental for three years, completing their undergraduate experience with an additional two years either at Caltech or Columbia University. At the end of the five years, the student receives two degrees, a Bachelor of Arts in the Combined Plan from Occidental and a Bachelor of Science in the selected field of engineering from the engineering school.
Art Center College of Design.
Art majors at Occidental College can take courses at the Art Center College of Design in Pasadena, one of the country's top-ranked art schools. The program is not open to first-year students, but as with the Caltech exchange program, students receive full course credit. No additional tuition payments are required.
Columbia University School of Law.
With a competitive GPA and LSAT scores, Columbia Law School admits students upon completion of their junior year at Occidental into its Accelerated Interdisciplinary Program in Legal Education. Admittance to the program enables students to earn a bachelor's degree from Occidental and a law degree from Columbia in six years.
Keck Graduate Institute.
Students who are interested in biotechnology and who become a biochemistry major maintaining a 3.2 GPA in the necessary courses will be guaranteed admission to the Keck master's in bioscience program. The Keck Graduate Institute is part of the Claremont Colleges consortium.
Student life.
At the beginning of every school year, freshmen participate in Convocation, a formal ceremony welcoming new students to the college in which the faculty wear their full academic regalia and students don robes. Founders Day is celebrated annually at the school on April 20, the day in 1887 when Occidental's incorporation papers were officially signed by the California Secretary of State.
For the first three years at Occidental, all students are required to live on campus and for seniors it is optional. Freshmen do not get to choose where they live; the Office of Residential Education & Housing Services arranges housing by pairing students based on a short form students fill in the summer before they arrive on campus. The Occidental College dorm life consists of 13 co-ed residential housing facilities.
After a student's first year, he or she can choose to live in a number of dorms that house sophomores, juniors, and seniors; one-third of all these halls are reserved for each grade. These dorms include Bell-Young Hall, Wylie Hall, Erdman Hall, Haines Hall, Rangeview Hall and Stearns Hall.
There are also themed-living communities which consist of the Multicultural Hall in Pauley (open to all years), all-women housing (Berkus House, named after alumnus Dave Berkus), the E. Norris Hall, the Pet House (where currently students get to live with a dog), and the Food Justice house.
Student activities.
Occidental College has various student-run clubs, organizations and ventures such as the Green Bean Coffee Lounge, organic garden, and the student-managed bike sharing and repairing program. There are also traditional groups such as glee club, Greek organizations, and student media outlets.
Media.
The campus newspaper is the Occidental Weekly, an independent, student-run publication. It has been published continuously since 1893.
KOXY is a student-run campus radio station, in operation in the 1960s and 1970s, and again since 2000. It originally operated on the frequency 104.7 in and around campus from 1968 to 2009, but switched to only being available by webstream in 2009. KOXY sponsors several on-campus events.
In 2010, Occidental College launched a TV station called CatAList, launched by then-students Daniel Watson and Raffy Cortina; Cortina was also the first Occidental student to be awarded with a Student Academy Award from the Academy of Motion Picture Arts and Sciences for his short "Bottled Up". The station produces 20–30 minutes of student-run content weekly on a variety of topics.
Greek life.
Occidental College's Greek Council consists of 8 members: local sororities Alpha Lambda Phi Alpha, Delta Omicron Tau; national sororities Sigma Lambda Gamma and Kappa Alpha Theta; local fraternity Zeta Tau Zeta (co-ed), and national fraternities Kappa Alpha Psi, Phi Kappa Psi, Sigma Alpha Epsilon.
Local involvement.
There are various entities at Occidental College that promote local community involvement opportunities in Eagle Rock, Highland Park and Los Angeles. These include the Urban and Environmental Policy Institute (UEPI), the Office of Community Engagement (OCE), the Center for Community Based Learning (CCBL), the Neighborhood Partnership Program (NPP), and Upward Bound.
Athletics.
Occidental is one of the five schools that founded the Southern California Intercollegiate Athletic Conference (SCIAC) in 1915 and is currently a member of the SCIAC and NCAA Division III. Occidental features 21 varsity sports teams and a program of club sports and intramural competition. Approximately 25 percent of the student body participates in a varsity sports program.
During the 2006–2007 athletic season, the Tigers cross country, American football and basketball teams were Southern California Intercollegiate Athletic Conference champions. The school's Blackshirts Rugby union team was also league champion for the first time in five years. In 2011, Jeremy Castro ('99) and Patrick Guthrie ('86) steered the squad to a NSCRO final falling to Longwood University 36-27 in Virginia Beach, Virginia. In addition the college boasts a competitive and growing elite dance team that also performs at every home football and basketball game.
Occidental has long-standing football rivalries with Pomona College and Whittier College; the Tigers have played both the Sagehens and the Poets over 100 times. In 1982, the Occidental College football team had the rare opportunity for national prominence when, due to the 1982 National Football League strike, their game with San Diego was broadcast on national television.
In 2011, Occidental College lost a Basketball game to Caltech with a score of 46 to 45 giving the Caltech Beavers their first conference win in 26 years and putting an end to their 310-game losing streak.
Famous Occidental College Tigers include NFL coach Jim E. Mora, former American Football League Most Valuable Player and politician Jack Kemp, former NFL player Vance Mueller, 2011 U.S. Senior Open Champion Olin Browne, CFL player Justin Goltz (Winnipeg Blue Bombers).
Controversy.
In 1913, the Occidental College Board of Trustees announced plans to convert the college exclusively to a men's school. The plans were met with widespread backlash from students and faculty who protested the change. The community outcry garnered national headlines and the board later dropped the proposal.
English novelist Aldous Huxley, who spoke at Occidental's convocation ceremony in the then-new Thorne Hall in 1938, lampooned President Remsen Bird as Dr. Herbert Mulge of Tarzana College in his 1939 novel, "After Many a Summer Dies the Swan". Huxley was never again invited back to campus.
In November 1990, the college, initially established as a Presbyterian institution, rededicated the campus' main chapel as the Herrick Memorial Chapel and Interfaith Center. The school also took down the crosses in the chapel in an attempt to "broaden Occidental's appeal among non-Christian students."
President Barack Obama attended Occidental for two years prior to transferring to Columbia University. Several "birther" conspiracies surfaced after he was elected as the 44th president of the U.S., some of which stemmed from a fictitious report produced in 2009 claiming his Occidental College transcripts revealed that Obama received financial aid as a foreign student from Indonesia. In 2012, Donald Trump offered the President $5 million to donate to the charity of his choice if he would provide his college transcripts and passport application.
A Federal civil rights complaint was filed in April 2013 by 37 students stating that the school "deliberately discouraged victims from reporting sexual assaults” as well as misled some students about their rights during campus investigations and possibly retaliated against whistle-blowers. This complaint is currently under active investigation by the Federal Department of Education's Office of Civil Rights. On September 18, 2013, the college settled a lawsuit brought by 10 students also alleging improper treatment of their sexual assault cases, on undisclosed terms. On May 1, 2014, Occidental was named one of fifty-five higher education institutions under investigation by the Office of Civil Rights “for possible violations of federal law over the handling of sexual violence and harassment complaints” by President Obama's White House Task Force To Protect Students from Sexual Assault. In response to student and faculty outcry the college has taken various actions to combat sexual assault such as adopting a new interim sexual misconduct policy, hiring a former assistant district attorney, Ruth Jones, as a full-time, independent Title IX coordinator, and the school added a new 24-hour, 7-days-a-week telephone hotline. The school also created a permanent Sexual Misconduct Advisory Board made up of students, faculty and staff.
In October 2014, a male Occidental College student filed a Title IX complaint against the college for its handling of a sexual assault complaint against him, alleging in part that Occidental was biased against him due to the April 2013 Title IX complaint. His accuser had verbally expressed her intent to have sex in text messages to him and a friend, came to his dorm room under her own power, told acquaintances that she was fine when they checked on her during part of the sexual activity, and texted smiley faces to friends immediately afterwards. A police investigation found there was no basis for bringing charges against the male. The college still found him responsible on the basis that he should have known that she was too drunk to consent despite her explicit statements and behavior. When the man, who was also very drunk the night in question, attempted to file an assault claim based on the incapacitated standard, the college refused to accept his complaint.
Notable alumni and faculty.
Notable graduates of Occidental College include filmmaker Terry Gilliam, football player and politician Jack Kemp, former New Orleans Saints and Indianapolis Colts head coach Jim E. Mora, and Warner Music Group CEO Stephen Cooper. Notable attendees include current US President Barack Obama, Academy Award–winning actor and filmmaker Ben Affleck, actor Luke Wilson, producer Todd Garner, and actress Emily Osment.
Film and television at Occidental.
Occidental's campus, architecture, and proximity to Hollywood have made it a desired location for a number of film and television productions.
Film credits include:
TV credits include:

</doc>
<doc id="22801" url="https://en.wikipedia.org/wiki?curid=22801" title="1986 United States bombing of Libya">
1986 United States bombing of Libya

The 1986 United States bombing of Libya, code-named Operation El Dorado Canyon, comprised air strikes by the United States against Libya on Tuesday, 15 April 1986. The attack was carried out by the U.S. Air Force, U.S. Navy and U.S. Marine Corps via air strikes, in response to the 1986 Berlin discotheque bombing. There were 40 reported Libyan casualties, and one US plane was shot down, resulting in the death of two airmen.
Origins.
Libya represented a high priority for President Ronald Reagan shortly after his 1981 inauguration. Libyan leader Muammar Gaddafi was firmly anti-Israel and had supported violent organizations in the Palestinian territories and Syria. There were reports that Libya was attempting to become a nuclear power and Gaddafi's occupation of Chad, which was rich in uranium, was of major concern to the United States. Gaddafi's alignment with the Soviet Union and his ambitions to set up a federation of Arab and Muslim states in North Africa were also alarming to US interests. Furthermore, then-Secretary of State Alexander Haig wanted to take proactive measures against Gaddafi because he had been using former Central Intelligence Agency (CIA) operatives to help set up terrorist camps (most notably Edwin P. Wilson and Frank E. Terpil).
After the December 1985 Rome and Vienna airport attacks, which killed 19 and wounded approximately 140, Gaddafi indicated that he would continue to support the Red Army Faction, the Red Brigades, and the Irish Republican Army as long as the European governments supported anti-Gaddafi Libyans.
The Foreign Minister of Libya also called the massacres "heroic acts".
After years of occasional skirmishes with Libya over Libyan territorial claims to the Gulf of Sidra, the United States contemplated a military attack to strike targets within the Libyan mainland. In March 1986, the United States, asserting the limit to territorial waters according to international law, sent a carrier task force to the region. Libya responded with aggressive counter-maneuvers on 24 March that led to the Gulf of Sidra incident.
On 5 April 1986, Libyan agents bombed "La Belle" nightclub in West Berlin, killing three people, one being a U.S. Serviceman, and injuring 229 people who were spending the evening there. West Germany and the United States obtained cable transcripts from Libyan agents in East Germany who were involved in the attack.
More detailed information was retrieved years later when Stasi archives were investigated by the reunited Germany. Libyan agents who had carried out the operation from the Libyan embassy in East Germany were identified and prosecuted by Germany in the 1990s.
After several unproductive days of meeting with European and Arab nations, and influenced by an American serviceman's death, Ronald Reagan, on the 14th of April, ordered an air raid on Libya. Eighteen F-111F strike aircraft of the 48th Tactical Fighter Wing, flying from RAF Lakenheath and supported by four EF-111A Ravens of the 20th Tactical Fighter Wing from RAF Upper Heyford in England, in conjunction with fifteen A-6, A-7, F/A-18 attack aircraft and EA-6B Prowler Electronic Warfare Aircraft from the aircraft carriers USS "Saratoga", USS "America" and USS "Coral Sea" on station in the Gulf of Sidra, struck five targets at 02:00 on 15 April, with the stated objectives of sending a message and reducing Libya's ability to support and train terrorists. Reagan warned that "if necessary, [they] shall do it again."
The attack mission against Libya had been preceded in October 1985 by an exercise in which the 20th TFW stationed at RAF Upper Heyford airbase in the UK, which was equipped with F-111Es, received a top secret order to launch a simulated attack mission on 18 October, with ten F-111Es armed with eight 500 lb practice bombs, against a simulated airfield located in Newfoundland, Canada south of CFB Goose Bay. The mission was designated Operation Ghost Rider. The mission was a full rehearsal for a long range strike against Libya. The mission was completed successfully, with the exception of one aircraft that had all but one of its eight bombs hang up on one of its wing racks. The lessons learned were passed on to the 48th TFW which was equipped with the newer "F" models of the F-111.
Elements of the then-secret 4450th Tactical Group (USAF) were put on standby to fly the strike mission against Libya. Over 30 F-117s had already been delivered to Tactical Air Command (USAF) and were operating from Tonopah Test Range Airport in Nevada. Commanders in the North Africa/Mediterranean theaters knew nothing about the capabilities of the F-117, or that the aircraft even existed. Within an hour of the planned launch of the F-117s, the Secretary of Defense scrubbed the stealth mission, fearing a compromise of the secret aircraft and its development program. The air strike was carried out with conventional US Navy and US Air Force aircraft. The F-117 would remain completely unknown to the world for several more months, before being unveiled in 1988 and featured prominently in media coverage of Operation Desert Storm.
For the Libyan raid, the United States was denied overflight rights by France, Spain, and Italy as well as the use of European continental bases, forcing the Air Force portion of the operation to be flown around France and Spain, over Portugal and through the Straits of Gibraltar, adding 1,300 miles (2,100 km) each way and requiring multiple aerial refuelings. The French refusal alone added 2,800 km and was imposed despite the fact that France had itself been the target of terrorism directed by the Gaddafi government in Libya. French president Mitterrand refused overflight clearance because the United States was interested in limited action in Libya while France was more interested in major action that would remove Gaddafi from power.
The raid.
The attack began at 0200 hours (Libyan time), and lasted about twelve minutes, with 60 tons of munitions dropped. Eighteen F-111 bombers supported by four EF-111 electronic countermeasures aircraft flying from the United Kingdom bombed Tripoli airfield, a frogman training center at a naval academy, and the Bab al-Azizia barracks in Tripoli. During the bombing of the Bab al-Azizia barracks, an American F-111 was shot down by a Libyan surface-to-air missile (SAM) over the Gulf of Sidra. Some bombs landed off-target, striking diplomatic and civilian sites in Tripoli, and narrowly missing the French embassy. Some Libyan soldiers abandoned their positions in fright and confusion, and officers were slow to give orders. Libyan anti-aircraft fire did not begin until after the planes had passed over their targets. Twenty-four A-6 Intruders and F/A-18 Hornets launched from aircraft carriers bombed radar and antiaircraft sites in Benghazi before bombing the Benina and Jamahiriya barracks.
Libyan air defenses.
The Libyan air defense network was extensive, and included:
Covering Tripoli alone were:
Casualties.
Libyan.
Forewarned by a telephone call, Libyan leader Muammar Gaddafi and his family rushed out of their residence in the Bab al-Azizia compound moments before the bombs dropped. It was long thought that the call came from Malta's Prime Minister, Karmenu Mifsud Bonnici. However, Italian Prime Minister Bettino Craxi was the person who actually warned Gaddafi, according to Giulio Andreotti, Italy's foreign minister at the time, and to Abdel Rahman Shalgham, Libya's then-ambassador to Italy. Shalgham's statement was also confirmed by Margherita Boniver, foreign affairs chief of Craxi's Socialist Party at the time.
According to medical staff in a nearby hospital, two dozen casualties were brought in wearing military uniforms, and two without uniforms. Total Libyan casualties were estimated at 60, including those at the bombed airbases. An infant girl was among the casualties; her body was shown to American reporters, who were told she was Gaddafi's recently adopted daughter Hanna. However, there was and remains much skepticism over the claim.
American.
Two U.S. Air Force captains — Fernando L. Ribas-Dominicci and Paul F. Lorence — were killed when their F-111 fighter-bomber was shot down over the Gulf of Sidra. In the hours following the attack, the U.S. military refused to speculate as to whether or not the fighter-bomber had been shot down, with Defense Secretary Caspar Weinberger suggesting that it could have experienced radio trouble or been diverted to another airfield. The next day, the Pentagon had announced it was no longer searching for the F-111 believed to be downed by a Libyan missile. On 25 December 1988, Gaddafi offered to release the body of Lorence to his family through Pope John Paul II. The body, returned in 1989, was identified as Ribas-Dominicci's from dental records. An autopsy conducted in Spain confirmed that he had drowned after his plane was shot down over the Gulf of Sidra. Libya denies that it held Lorence's body. However, Lorence's brother said that he and his mother saw television footage of a Libyan holding a white helmet with the name "Lorence" stenciled on the back. Furthermore, William C. Chasey, who toured the Bab al-Azizia barracks, claimed to have seen two flight suits and helmets engraved with the names "Lorence" and "Ribas-Dominicci", as well as the wreckage of their F-111.
In 2001, Theodore D. Karantsalis, a reference librarian at Miami-Dade College, enlisted the aid of Congressman Wally Herger's office to petition Libya to return Lorence's remains on behalf of his family and friends. Karantsalis also created a website and invited visitors to sign a petition to Congressman Lincoln Diaz-Balart seeking the return of Capt. Lorence's remains. On 27 January 2005, Karantsalis filed a federal lawsuit under the Freedom of Information Act (FOIA) against the Department of Defense and the Department of the Air Force seeking "to know where Captain Paul Lorence's remains are located." Karantsalis had hoped to locate the remains before the 20th anniversary of Lorence's death.
Aftermath.
In Libya.
Gaddafi's announcements.
Gaddafi announced that he had "won a spectacular military victory over the United States" and the country was officially renamed the "Great Socialist People's Libyan Arab Jamahiriyah".
Gaddafi said reconciliation between Libya and the United States was impossible so long as Reagan was in the White House; of the president he said, "He is mad. He is foolish. He is an Israeli dog." He said he had no plans to attack the United States or U.S. targets. He claimed that Reagan wanted to kill him, stating "Was Reagan trying to kill me? Of course. The attack was concentrated on my house and I was in my house", he also described how he rescued his family.
When asked that if he is in danger of losing power, he told "Really, these reports and writings are not true. As you can see I am fine, and there has been no change in our country."
Other events.
The Government of Libya said that the United States had fallen prey to arrogance and madness of power and wanted to become the world's policeman. It charged that any party that did not agree to become an American vassal was an outlaw, a terrorist, and a devil.
Gaddafi quashed an internal revolt, the organization of which he blamed on the United States, although Gaddafi appeared to have left the public sphere for a time in 1986 and 1987.
The Libyan Post dedicated several postage stamps issues to the event, from 1986 until 2001. The first issue was released in 1986, 13 July (ref. Scott catalogue n.1311 – Michel catalogue n.1699). The last issue was released in 2001, 15 April (ref. Scott catalogue n.1653 – Michel catalogue n.2748–2763).
Libyan retaliation.
Immediate.
Libya responded by firing two Scud missiles at a United States Coast Guard station on the Italian island of Lampedusa which passed over the island and landed in the sea.
Later Libyan-connected terrorism.
There was only limited change in Libyan-connected terrorism.
The Libyan government was alleged to have ordered the hijacking of Pan Am Flight 73 in Pakistan on 5 September 1986, which resulted in the deaths of 20 people. The allegation did not come to light until it was reported by "The Sunday Times" in March 2004—days after British Prime Minister Tony Blair paid the first official visit to Tripoli by a Western leader in a generation.
In May 1987, Australia deported diplomats and broke off relations with Libya, claiming Libya sought to fuel violence in Australia and Oceania.
In late 1987 French authorities stopped a merchant vessel, the MV "Eksund", which was delivering 150 tons of Soviet arms from Libya to the Irish Republican Army (IRA).
In Beirut, Lebanon, two British hostages held by the Libyan-supported Abu Nidal Organization, Leigh Douglas and Philip Padfield, along with an American named Peter Kilburn, were shot dead in revenge. In addition, journalist John McCarthy was kidnapped, and tourist Paul Appleby was murdered in Jerusalem, Israel. Another British hostage named Alec Collett was also killed in retaliation for the bombing of Libya. Collett was shown being hanged in a video tape. His body was found in November 2009.
On 21 December 1988, came the bombing of Pan Am Flight 103, which exploded in mid-air and crashed on the town of Lockerbie in Scotland after a bomb detonated, killing all 259 people aboard, and 11 people in Lockerbie. Iran was initially thought to have been responsible for the bombing in revenge for the downing of the Iranian Airbus by the USS "Vincennes", but in 1991 two Libyans were charged, one of whom was convicted of the crime in a controversial judgement on 31 January 2001. The Libyan Government accepted responsibility for the Pan Am Flight 103 bombing on 29 May 2002, and offered $2.7 billion to compensate the families of the 270 victims. The convicted Libyan, Abdelbaset al-Megrahi, who was suffering from terminal prostate cancer, was released in August 2009 by the Scottish Government on compassionate grounds. He died in 2012. In May 2014 a group of relatives of the Lockerbie victims continued to campaign for al-Megrahi's name to be cleared by reopening the case.
International response.
Immediate.
The attack was condemned by many countries. By a vote of 79 in favor to 28 against with 33 abstentions, the United Nations General Assembly adopted resolution 41/38 which "condemns the military attack perpetrated against the Socialist People's Libyan Arab Jamahiriya on 15 April 1986, which constitutes a violation of the Charter of the United Nations and of international law."
A meeting of the Non-Aligned Movement said that it condemned the "dastardly, blatant and unprovoked act of aggression". The League of Arab States expressed that it was outraged at the United States aggression and that it reinforced an element of anarchy in international relations. The Assembly of Heads of State of the African Union in its declaration said that the deliberate attempt to kill Libyans violated the principles of international law. The Government of Iran asserted that the attack constituted a policy of aggression, gunboat diplomacy, an act of war, and called for an extensive political and economic boycott of the United States. Others saw the United States motive as an attempt to eliminate Libya's revolution.
China stated that the US attack violated norms of international relations and had aggravated tension in the region. The Soviet Union said that there was a clear link between the attack and U.S. policy aimed at stirring up existing hotbeds of tension and creating new ones, and at destabilizing the international situation. West Germany stated that international disputes required diplomatic and not military solutions, and France also criticized the bombing. Italy, Spain, and France all denied the US use of their airspace en route to Libya. This forced the USAF's F-111s, stationed at RAF Lakenheath in Great Britain, to circumnavigate continental Europe and approach Libya via the Strait of Gibraltar.
Some observers held the opinion that Article 51 of the UN Charter set limitations on the use of force in exercising the legitimate right of self-defense in the absence of an act of aggression, and affirmed that there was no such act by Libya. It was charged that the United States did not bother to exhaust the Charter provisions for settling disputes under Article 33. Others asserted that Libya was innocent in the bombing of the West Berlin discotheque.
The U.S. received support from the United Kingdom, Canada, Australia, Israel, and 25 other countries. Its doctrine of declaring a war on what it called "terrorist havens" was not repeated until 1998, when President Bill Clinton ordered strikes on six terrorist camps in Afghanistan. Margaret Thatcher's approval of the use of Royal Air Force bases led to substantial criticism, including an unprecedented story in "The Sunday Times" suggesting the Queen was upset by an "uncaring" Prime Minister. Widespread criticism of the raid caused a temporary rift in UK-US relations and American tourists stayed away from Britain during the spring. Gaddafi himself responded by saying "Thatcher is a murderer...Thatcher is a prostitute. She sold herself to Reagan."
Although the Soviet Union was ostensibly in cooperation with Libya, it had, by the time of the Libya bombing, made its increasing ambivalence toward Libya apparent in public communications. Gaddafi had a history of verbally attacking the policy agendas and ideology of the Soviet Union, and he often engaged in various international interventions and meddling that conflicted with Soviet goals in a variety of spheres. During a period where the Soviet Union was apparently attempting to lead a subtle diplomatic effort that could impact its global status, close association with the whims of Gaddafi became a liability.
In the entire crisis, the Soviet Union explicitly announced that it would not provide additional help to Libya beyond resupplying basic armaments and munitions. It made no attempt to militarily intimidate the United States, despite the ongoing American operations in the Gulf of Sidra and its previous knowledge that the United States might launch an attack. The Soviet Union did not completely ignore the event, issuing a denunciation of this 'wild' and 'barbaric' act by the United States.
After the raid, Moscow did cancel a planned visit to the United States by foreign affairs minister Eduard Shevardnadze. At the same time, it clearly signaled that it did not want this action to affect negotiations about the upcoming summer summit between the United States and the Soviet Union and its plans for new arms control agreements.
Former U.S. Attorney General Ramsey Clark, acting for Libyan citizens who had been killed or injured in the bombing raid by the U.S. using British air bases, brought suit under international law against the United States and the United Kingdom in U.S. federal court. The lawsuit was dismissed as frivolous. A subsequent appeal was denied, and monetary sanctions against Clark were allowed. Saltany v. Reagan, 886 F. 2d 438 (D.C. Cir. 1989).
UN response.
Every year, between at least 1994 and 2006, the United Nations General Assembly scheduled a declaration from the Organization of African Unity about the incident, but systematically deferred the discussion year after year until formally putting it aside (along with several other issues which had been similarly rescheduled for years) in 2005.
First anniversary.
On the first anniversary of the bombing, April 1987, European and North American left-wing activists gathered to commemorate the anniversary. After a day of social and cultural networking with local Libyans, including a tour of Gaddafi's bombed house, the group gathered with other Libyans for a commemoration event.
20th anniversary.
Early on 15 April 2006 – to mark the 20th anniversary of the bombing raid – a concert involving U.S. singer Lionel Richie and Spanish tenor José Carreras was held in front of Gaddafi's bombed house in Tripoli. Diplomats, businessmen and politicians were among the audience of what Libya dubbed the "concert for peace". The BBC reported Lionel Richie as telling the audience, regarding Gaddafi's supposed adopted daughter, "Hanna will be honored tonight because of the fact that you've attached peace to her name."
2009 comment.
In June 2009, during a visit to Italy, Colonel Gaddafi criticized American foreign policy and, asked as to the difference between al-Qaeda attacks and the 1986 US bombing of Tripoli, he commented: "If al-Qaeda leader Osama Bin Laden has no state and is an outlaw, America is a state with international rules."
Settlement of claims.
On 28 May 2008, the United States began negotiations with Libya on a comprehensive claims settlement agreement to resolve outstanding claims of American and Libyan nationals against each country in their respective courts. Gaddafi's son Saif al-Islam publicly announced that an agreement was being negotiated in July of that year. On 14 August 2008, the resulting U.S.-Libya Comprehensive Claims Settlement Agreement was signed in Tripoli by Assistant Secretary of State for Near Eastern Affairs David Welch and by Libyan Secretary for American Affairs Ahmad Fituri.
In October 2008, Libya paid US$1.5 billion (in three installments of $300 million on 9 October 2008, $600 million on 30 October 2008, and US$600 million 31 October 2008) into a fund used to compensate the following victims and their relatives:
To pay the settlement, Libya demanded US$1.5 billion from global oil companies operating in Libya's oil fields, under threat of "serious consequences" to their leases. Libya's settlement was at least partially funded by several companies, including some based in the U.S., that chose to cooperate with Libya's demand.
On 4 August 2008, President George W. Bush signed into law the Libyan Claims Resolution Act, which had unanimously passed Congress on 31 July. The Act provided for the restoration of Libya’s sovereign, diplomatic, and official immunities before U.S. courts if the Secretary of State certified that the United States Government has received sufficient funds to resolve outstanding terrorism-related death and physical injury claims against Libya.
On 14 August 2008, the United States and Libya signed a comprehensive claims settlement agreement. Full diplomatic relations were restored between the two nations.

</doc>
<doc id="22804" url="https://en.wikipedia.org/wiki?curid=22804" title="Operational amplifier">
Operational amplifier

An operational amplifier (a.k.a. "op-amp") is a DC-coupled high-gain electronic voltage amplifier with a differential input and, usually, a single-ended output. In this configuration, an op-amp produces an output potential (relative to circuit ground) that is typically hundreds of thousands of times larger than the potential difference between its input terminals.
Operational amplifiers had their origins in analog computers, where they were used to do mathematical operations in many linear, non-linear and frequency-dependent circuits. 
The popularity of the op-amp as a building block in analog circuits is due to its versatility. Due to negative feedback, the characteristics of an op-amp circuit, its gain, input and output impedance, bandwidth etc. are determined by external components and have little dependence on temperature coefficients or manufacturing variations in the op-amp itself.
Op-amps are among the most widely used electronic devices today, being used in a vast array of consumer, industrial, and scientific devices. Many standard IC op-amps cost only a few cents in moderate production volume; however some integrated or hybrid operational amplifiers with special performance specifications may cost over $100 US in small quantities. Op-amps may be packaged as components, or used as elements of more complex integrated circuits.
The op-amp is one type of differential amplifier. Other types of differential amplifier include the fully differential amplifier (similar to the op-amp, but with two outputs), the instrumentation amplifier (usually built from three op-amps), the isolation amplifier (similar to the instrumentation amplifier, but with tolerance to common-mode voltages that would destroy an ordinary op-amp), and negative feedback amplifier (usually built from one or more op-amps and a resistive feedback network).
Operation.
The amplifier's differential inputs consist of a non-inverting input (+) with voltage "V"+ and an inverting input (–) with voltage "V"−; ideally the op-amp amplifies only the difference in voltage between the two, which is called the "differential input voltage". The output voltage of the op-amp "V"out is given by the equation:
where "A"OL is the open-loop gain of the amplifier (the term "open-loop" refers to the absence of a feedback loop from the output to the input).
Open loop amplifier.
The magnitude of "A"OL is typically very large—100,000 or more for integrated circuit op-amps—and therefore even a quite small difference between "V"+ and "V"− drives the amplifier output nearly to the supply voltage. Situations in which the output voltage is equal to or greater than the supply voltage are referred to as "saturation" of the amplifier. The magnitude of "A"OL is not well controlled by the manufacturing process, and so it is impractical to use an open loop amplifier as a stand-alone differential amplifier.
Without negative feedback, and perhaps with positive feedback for regeneration, an op-amp acts as a comparator. If the inverting input is held at ground (0 V) directly or by a resistor Rg, and the input voltage Vin applied to the non-inverting input is positive, the output will be maximum positive; if Vin is negative, the output will be maximum negative. Since there is no feedback from the output to either input, this is an "open loop" circuit acting as a comparator.
Closed loop.
If predictable operation is desired, negative feedback is used, by applying a portion of the output voltage to the inverting input. The "closed loop" feedback greatly reduces the gain of the circuit. When negative feedback is used, the circuit's overall gain and response becomes determined mostly by the feedback network, rather than by the op-amp characteristics. If the feedback network is made of components with values small relative to the op amp's input impedance, the value of the op-amp's open loop response "A"OL does not seriously affect the circuit's performance. The response of the op-amp circuit with its input, output, and feedback circuits to an input is characterized mathematically by a transfer function; designing an op-amp circuit to have a desired transfer function is in the realm of electrical engineering. The transfer functions are important in most applications of op-amps, such as in analog computers. High input impedance at the input terminals and low output impedance at the output terminal(s) are particularly useful features of an op-amp.
In the non-inverting amplifier on the right, the presence of negative feedback via the voltage divider "R"f, "R"g determines the "closed-loop gain" "A"CL = "V"out / "V"in. Equilibrium will be established when "V"out is just sufficient to "reach around and pull" the inverting input to the same voltage as "V"in. The voltage gain of the entire circuit is thus 1 + "R"f/"R"g. As a simple example, if "V"in = 1 V and Rf = Rg, Vout will be 2 V, exactly the amount required to keep "V"− at 1 V. Because of the feedback provided by the "R"f, "R"g network, this is a "closed loop" circuit.
Another way to analyze this circuit proceeds by making the following (usually valid) assumptions:
The input signal "V"in appears at both (+) and (−) pins, resulting in a current "i" through "R"g equal to "V"in/"R"g. 
Since Kirchhoff's current law states that the same current must leave a node as enter it, and since the impedance into the (−) pin is near infinity, we can assume practically all of the same current "i" flows through "R"f, creating an output voltage
By combining terms, we determine the closed-loop gain "A"CL:
Op-amp characteristics.
Ideal op-amps.
An ideal op-amp is usually considered to have the following properties:
These ideals can be summarized by the two "golden rules":
The first rule only applies in the usual case where the op-amp is used in a closed-loop design (negative feedback, where there is a signal path of some sort feeding back from the output to the inverting input). These rules are commonly used as a good first approximation for analyzing or designing op-amp circuits.
None of these ideals can be perfectly realized. A real op-amp may be modeled with non-infinite or non-zero parameters using equivalent resistors and capacitors in the op-amp model. The designer can then include these effects into the overall performance of the final circuit. Some parameters may turn out to have negligible effect on the final design while others represent actual limitations of the final performance that must be evaluated.
Real op-amps.
Real op-amps differ from the ideal model in various aspects.
DC imperfections.
Real operational amplifiers suffer from several non-ideal effects:
AC imperfections.
The op-amp gain calculated at DC does not apply at higher frequencies. Thus, for high-speed operation, more sophisticated considerations must be used in an op-amp circuit design.
Power considerations.
Modern integrated FET or MOSFET op-amps approximate more closely the ideal op-amp than bipolar ICs when it comes to input impedance and input bias currents. Bipolars are generally better when it comes to input "voltage" offset, and often have lower noise. Generally, at room temperature, with a fairly large signal, and limited bandwidth, FET and MOSFET op-amps now offer better performance.
Internal circuitry of 741-type op-amp.
Sourced by many manufacturers, and in multiple similar products, an example of a bipolar transistor operational amplifier is the 741 integrated circuit designed in 1968 by David Fullagar at Fairchild Semiconductor after Bob Widlar's LM301 integrated circuit design. 
In this discussion, we use the parameters of the Hybrid-pi model to characterize the small-signal, grounded emitter characteristics of a transistor. In this model, the current gain of a transistor is denoted "h"fe, more commonly called the β.
Architecture.
A small-scale integrated circuit, the 741 op-amp shares with most op-amps an internal structure consisting of three gain stages:
Additionally, it contains current mirror (outlined red) bias circuitry and a gain-stabilization capacitor (30 pF).
Differential amplifier.
The input stage consists of a cascaded differential amplifier (outlined in blue) followed by a current-mirror active load. This constitutes a transconductance amplifier, turning a differential voltage signal at the bases of Q1, Q2 into a current signal into the base of Q15.
It entails two cascaded transistor pairs, satisfying conflicting requirements. 
The first stage consists of the matched NPN emitter follower pair Q1, Q2 that provide high input impedance. 
The second is the matched PNP common-base pair Q3, Q4 that eliminates the undesirable Miller effect; it drives an active load Q7 plus matched pair Q5, Q6.
That active load is implemented as a modified Wilson current mirror; its role is to convert the (differential) input current signal to a single-ended signal without the attendant 50% losses (increasing the op-amp's open-loop gain by 3 dB). 
Thus, a small-signal differential current in Q3 versus Q4 appears summed (doubled) at the base of Q15, the input of the voltage gain stage. 
Voltage amplifier.
The (class-A) voltage gain stage (outlined in magenta) consists of the two NPN transistors Q15/Q19 connected in a Darlington configuration and uses the output side of current mirror Q12/Q13 as its collector (dynamic) load to achieve its high voltage gain. The output sink transistor Q20 receives its base drive from the common collectors of Q15 and Q19; the level-shifter Q16 provides base drive for the output source transistor Q14. .
The transistor Q22 prevents this stage from delivering excessive current to Q20 and thus limits the output sink current.
Output amplifier.
The output stage (Q14, Q20, outlined in cyan) is a Class AB push-pull emitter follower amplifier. It provides an output drive with impedance of ≈50Ω, in essence, current gain. 
Transistor Q16 (outlined in green) provides the quiescent current for the output transistors, and Q17 provides output current limiting. 
Biasing circuits.
Provide appropriate quiescent current for each stage of the op-amp.
The resistor (39 kΩ) connecting the (diode-connected) Q11 and Q12, and the given supply voltage ("V""S"+−"V""S"−), determine the current in the current mirrors, (matched pairs) Q10/Q11 and Q12/Q13.
The collector current of Q11, "i"11 * 39 kΩ = "V""S"+ − "V""S"− − 2 "V"BE. For the typical "V""S" = ±20 V, the standing current in Q11/Q12 (as well as in Q13) would be ≈1 mA. 
A supply current for a typical 741 of about 2 mA agrees with the notion that these two bias currents dominate the quiescent supply current.
Transistors Q11 and Q10 form a Widlar current mirror, with quiescent current in Q10 "i"10 such that ln( "i"11 / "i"10 ) = "i"10 * 5 kΩ / 28 mV, where 5 kΩ represents the emitter resistor of Q10, and 28 mV is VT, the thermal voltage at room temperature. In this case "i"10 ≈ 20 μA.
Differential amplifier.
The biasing circuit of this stage is set by a feedback loop that forces the collector currents of Q10 and Q9 to (nearly) match. The small difference in these currents provides the drive for the common base of Q3/Q4 (note that the base drive for input transistors Q1/Q2 is the input bias current and must be sourced externally).
The summed quiescent currents of Q1/Q3 plus Q2/Q4 is mirrored from Q8 into Q9, where it is summed with the collector current in Q10, the result being applied to the bases of Q3/Q4.
The quiescent currents of Q1/Q3 (resp., Q2/Q4) "i"1 will thus be half of "i"10, of order ≈ 10 μA. 
Input bias current for the base of Q1 (resp. Q2) will amount to "i"1 / β; typically ≈50 nA, implying a current gain "h"fe ≈ 200 for Q1(Q2).
This feedback circuit tends to draw the common base node of Q3/Q4 to a voltage "V"com − 2 * "V"BE, where "V"com is the input common-mode voltage. At the same time, the magnitude of the quiescent current is relatively insensitive to the characteristics of the components Q1–Q4, such as "h"fe, that would otherwise cause temperature dependence or part-to-part variations.
Transistor Q7 drives Q5 and Q6 into conduction until their (equal) collector currents match that of Q1/Q3 and Q2/Q4. The quiescent current in Q7 is "V"BE / 50 kΩ, about 35μA, as is the quiescent current in Q15, with its matching operating point.
Thus, the quiescent currents are pairwise matched in Q1/Q2, Q3/Q4, Q5/Q6, and Q7/Q15. 
Voltage amplifier.
Quiescent currents in Q16 and Q19 are set by the current mirror Q12/Q13, which is running at ≈ 1 mA. Through some (?) mechanism, the collector current in Q19 tracks that standing current.
Output amplifier.
In the circuit involving Q16 (variously named rubber diode or "V"BE multiplier), the 4.5 kΩ resistor must be conducting about 100 μA, with the Q16 "V"BE roughly 700 mV. Then the "V"CB must be about 0.45 V and "V"CE at about 1.0 V. Because the Q16 collector is driven by a current source and the Q16 emitter drives into the Q19 collector current sink, the Q16 transistor establishes a voltage difference between Q14 base and Q20 base of ≈ 1 V, regardless of the common-mode voltage of Q14/Q20 base. The standing current in Q14/Q20 will be a factor exp(100 mV / VT ) ≈ 36 smaller than the 1 mA quiescent current in the class A portion of the op amp. This (small) standing current in the output transistors establishes the output stage in class AB operation and reduces the crossover distortion of this stage. 
Small-signal differential mode.
A small differential input voltage signal gives rise, through multiple stages of current amplification, to a much larger voltage signal on output.
Input impedance.
The input stage with Q1 and Q3 is similar to an emitter-coupled pair (long-tailed pair), with Q2 and Q4 adding some degenerating impedance. The input impedance is relatively high because of the small current through Q1-Q4.
A typical 741 op amp has an differential input impedance of about 2 MΩ. 
The common mode input impedance is even higher, as the input stage works at an essentially constant current.
Differential amplifier.
A differential voltage "V"In at the op-amp inputs (pins 3 and 2, respectively) gives rise to a small differential current in the bases of Q1 and Q2 "i"In ≈ "V"In / ( 2 "h"ie * "h"fe). 
This differential base current causes a change in the differential collector current in each leg by "i"In * "h"fe. Introducing the transconductance of Q1, "g""m" = "h"fe / "h"ie, the (small-signal) current at the base of Q15 (the input of the voltage gain stage) is "V"In * "g""m" / 2.
This portion of the op amp cleverly changes a differential signal at the op amp inputs to a single-ended signal at the base of Q15, and in a way that avoids wastefully discarding the signal in either leg. To see how, notice that a small negative change in voltage at the inverting input (Q2 base) drives it out of conduction, and this incremental decrease in current passes directly from Q4 collector to its emitter, resulting in an decrease in base drive for Q15. On the other hand, a small positive change in voltage at the non-inverting input (Q1 base) drives this transistor into conduction, reflected in an increase in current at the collector of Q3. This current drives Q7 further into conduction, which turns on current mirror Q5/Q6. Thus, the increase in Q3 emitter current is mirrored in an increase in Q6 collector current, resulting also in a decrease in base drive for Q15. Besides avoiding wasting 3 dB of gain here, this technique decreases common-mode gain and feedthrough of power supply noise. 
Voltage amplifier.
A current signal "i" at Q15's base gives rise to a current in Q19 of order "i" * β2 (the product of the "h"fe of each of Q15 and Q19, which are connected in a Darlington pair). This current signal develops a voltage at the bases of output transistors Q14/Q20 proportional to the "h"ie of the respective transistor.
Output amplifier.
Output transistors Q14 and Q20 are each configured as an emitter follower, so no voltage gain occurs there; instead, this stage provides current gain, equal to the "h"fe of Q14 (resp. Q20).
The output impedance is not zero, as it would be in an ideal op-amp, but with negative feedback it approaches zero at low frequencies.
Overall open-loop voltage gain.
The net open-loop small-signal voltage gain of the op amp involves the product of the current gain "h"fe of some 4 transistors. 
In practice, the voltage gain for a typical 741-style op amp is of order 200,000, and the current gain, the ratio of input impedance (≈2−6 MΩ) to output impedance (≈50Ω) provides yet more (power) gain.
Other linear characteristics.
Small-signal common mode gain.
The ideal op amp has infinite common-mode rejection ratio, or zero common-mode gain.
In the present circuit, if the input voltages change in the same direction, the negative feedback makes Q3/Q4 base voltage follow (with 2"V"BE below) the input voltage variations. Now the output part (Q10) of Q10-Q11 current mirror keeps up the common current through Q9/Q8 constant in spite of varying voltage. Q3/Q4 collector currents, and accordingly the output current at the base of Q15, remain unchanged.
In the typical 741 op amp, the common-mode rejection ratio is 90 dB, implying an open-loop common-mode voltage gain of about 6.
Frequency compensation.
The innovation of the Fairchild μA741 was the introduction of frequency compensation via an on-chip (monolithic) capacitor, simplifying application of the op amp by eliminating the need for external components for this function. 
The 30 pF capacitor stabilizes the amplifier via Miller compensation and functions in a manner similar to an op-amp integrator circuit. Also known as 'dominant pole compensation' because it introduces a pole that masks (dominates) the effects of other poles into the open loop frequency response; in a 741 op amp this pole can be as low as 10 Hz (where it causes a −3 dB loss of open loop voltage gain).
This internal compensation is provided to achieve unconditional stability of the amplifier in negative feedback configurations where the feedback network is non-reactive and the closed loop gain is unity or higher. 
By contrast, amplifiers requiring external compensation, such as the μA748, may require external compensation or closed-loop gains significantly higher than unity.
Input offset voltage.
The "offset null" pins may be used to place external resistors (typically in the form of the two ends of a potentiometer, with the slider connected to "V""S"–) in parallel with the emitter resistors of Q5 and Q6, to adjust the balance of the Q5/Q6 current mirror. The potentiometer is adjusted such that the output is null (midrange) when the inputs are shorted together.
Non-linear characteristics.
Input breakdown voltage.
The transistors Q3, Q4 help to increase the reverse "V"BE rating: the base-emitter junctions of the NPN transistors Q1 and Q2 break down at around 7V, but the PNP transistors Q3 and Q4 have "V"BE breakdown voltages around 50 V.
Output-stage voltage swing and current limiting.
Variations in the quiescent current with temperature, or between parts with the same type number, are common, so crossover distortion and quiescent current may be subject to significant variation.
The output range of the amplifier is about one volt less than the supply voltage, owing in part to "V"BE of the output transistors Q14 and Q20.
The 25 Ω resistor at the Q14 emitter, along with Q17, acts to limit Q14 current to about 25 mA; otherwise, Q17 conducts no current.
Current limiting for Q20 is performed in the voltage gain stage: Q22 senses the voltage across Q19's emitter resistor (50Ω); as it turns on, it diminishes the drive current to Q15 base.
Later versions of this amplifier schematic may show a somewhat different method of output current limiting.
Applicability considerations.
"Note: while the 741 was historically used in audio and other sensitive equipment, such use is now rare because of the improved noise performance of more modern op-amps. Apart from generating noticeable hiss, 741s and other older op-amps may have poor common-mode rejection ratios and so will often introduce cable-borne mains hum and other common-mode interference, such as switch 'clicks', into sensitive equipment.
The "741" has come to often mean a generic op-amp IC (such as μA741, LM301, 558, LM324, TBA221 — or a more modern replacement such as the TL071). The description of the 741 output stage is qualitatively similar for many other designs (that may have quite different input stages), except:
Classification.
Op-amps may be classified by their construction:
IC op-amps may be classified in many ways, including:
Applications.
Use in electronics system design.
The use of op-amps as circuit blocks is much easier and clearer than specifying all their individual circuit elements (transistors, resistors, etc.), whether the amplifiers used are integrated or discrete circuits. In the first approximation op-amps can be used as if they were ideal differential gain blocks; at a later stage limits can be placed on the acceptable range of parameters for each op-amp.
Circuit design follows the same lines for all electronic circuits. A specification is drawn up governing what the circuit is required to do, with allowable limits. For example, the gain may be required to be 100 times, with a tolerance of 5% but drift of less than 1% in a specified temperature range; the input impedance not less than one megohm; etc.
A basic circuit is designed, often with the help of circuit modeling (on a computer). Specific commercially available op-amps and other components are then chosen that meet the design criteria within the specified tolerances at acceptable cost. If not all criteria can be met, the specification may need to be modified.
A prototype is then built and tested; changes to meet or improve the specification, alter functionality, or reduce the cost, may be made.
Applications without using any feedback.
That is, the op-amp is being used as a voltage comparator. Note that a device designed primarily as a comparator may be better if, for instance, speed is important or a wide range of input voltages may be found, since such devices can quickly recover from full on or full off ("saturated") states.
A "voltage level detector" can be obtained if a reference voltage "V"ref is applied to one of the op-amp's inputs. This means that the op-amp is set up as a comparator to detect a positive voltage. If the voltage to be sensed, "E"i, is applied to op amp's (+) input, the result is a noninverting positive-level detector: when "E"i is above "V"ref, "V"O equals +"V"sat; when "E"i is below "V"ref, "V"O equals −"V"sat. If "E"i is applied to the inverting input, the circuit is an inverting positive-level detector: When "E"i is above "V"ref, "V"O equals −"V"sat.
A "zero voltage level detector" ("E"i = 0) can convert, for example, the output of a sine-wave from a function generator into a variable-frequency square wave. If "E"i is a sine wave, triangular wave, or wave of any other shape that is symmetrical around zero, the zero-crossing detector's output will be square. Zero-crossing detection may also be useful in triggering TRIACs at the best time to reduce mains interference and current spikes.
Positive feedback applications.
Another typical configuration of op-amps is with positive feedback, which takes a fraction of the output signal back to the non-inverting input. An important application of it is the comparator with hysteresis, the Schmitt trigger. Some circuits may use "Positive" feedback and "Negative" feedback around the same amplifier, for example Triangle wave oscillators and active filters.
Because of the wide slew-range and lack of positive feedback, the response of all the open-loop level detectors described above will be relatively slow. External overall positive feedback may be applied but (unlike internal positive feedback that may be applied within the latter stages of a purpose-designed comparator) this markedly affects the accuracy of the zero-crossing detection point. Using a general-purpose op-amp, for example, the frequency of "E"i for the sine to square wave converter should probably be below 100 Hz.
Negative feedback applications.
Non-inverting amplifier.
"In a non-inverting amplifier, the output voltage changes in the same direction as the input voltage."
The gain equation for the op-amp is:
However, in this circuit "V"− is a function of "V"out because of the negative feedback through the "R"1 "R"2 network. "R"1 and "R"2 form a voltage divider, and as "V"− is a high-impedance input, it does not load it appreciably. Consequently:
where
Substituting this into the gain equation, we obtain:
Solving for formula_9:
If formula_11 is very large, this simplifies to
The non-inverting input of the operational amplifier needs a path for DC to ground; if the signal source does not supply a DC path, or if that source requires a given load impedance, then the circuit will require another resistor from the non-inverting input to ground. When the operational amplifier's input bias currents are significant, then the DC source resistances driving the inputs should be balanced. The ideal value for the feedback resistors (to give minimum offset voltage) will be such that the two resistances in parallel roughly equal the resistance to ground at the non-inverting input pin. That ideal value assumes the bias currents are well-matched, which may not be true for all op-amps.
Inverting amplifier.
"In an inverting amplifier, the output voltage changes in an opposite direction to the input voltage."
As with the non-inverting amplifier, we start with the gain equation of the op-amp:
This time, "V"− is a function of both "V"out and "V"in due to the voltage divider formed by "R"f and "R"in. Again, the op-amp input does not apply an appreciable load, so:
Substituting this into the gain equation and solving for formula_9:
If formula_11 is very large, this simplifies to
A resistor is often inserted between the non-inverting input and ground (so both inputs "see" similar resistances), reducing the input offset voltage due to different voltage drops due to bias current, and may reduce distortion in some op-amps.
A DC-blocking capacitor may be inserted in series with the input resistor when a frequency response down to DC is not needed and any DC voltage on the input is unwanted. That is, the capacitive component of the input impedance inserts a DC zero and a low-frequency pole that gives the circuit a bandpass or high-pass characteristic.
The potentials at the operational amplifier inputs remain virtually constant (near ground) in the inverting configuration. The constant operating potential typically results in distortion levels that are lower than those attainable with the non-inverting topology.
Other applications.
Most single, dual and quad op-amps available have a standardized pin-out which permits one type to be substituted for another without wiring changes. A specific op-amp may be chosen for its open loop gain, bandwidth, noise performance, input impedance, power consumption, or a compromise between any of these factors.
Historical timeline.
1941: A vacuum tube op-amp. An op-amp, defined as a general-purpose, DC-coupled, high gain, inverting feedback amplifier, is first found in "Summing Amplifier" filed by Karl D. Swartzel Jr. of Bell Labs in 1941. This design used three vacuum tubes to achieve a gain of and operated on voltage rails of . It had a single inverting input rather than differential inverting and non-inverting inputs, as are common in today's op-amps. Throughout World War II, Swartzel's design proved its value by being liberally used in the M9 artillery director designed at Bell Labs. This artillery director worked with the SCR584 radar system to achieve extraordinary hit rates (near 90%) that would not have been possible otherwise.
1947: An op-amp with an explicit non-inverting input. In 1947, the operational amplifier was first formally defined and named in a paper by John R. Ragazzini of Columbia University. In this same paper a footnote mentioned an op-amp design by a student that would turn out to be quite significant. This op-amp, designed by Loebe Julie, was superior in a variety of ways. It had two major innovations. Its input stage used a long-tailed triode pair with loads matched to reduce drift in the output and, far more importantly, it was the first op-amp design to have two inputs (one inverting, the other non-inverting). The differential input made a whole range of new functionality possible, but it would not be used for a long time due to the rise of the chopper-stabilized amplifier.
1949: A chopper-stabilized op-amp. In 1949, Edwin A. Goldberg designed a chopper-stabilized op-amp. This set-up uses a normal op-amp with an additional AC amplifier that goes alongside the op-amp. The chopper gets an AC signal from DC by switching between the DC voltage and ground at a fast rate (60 Hz or 400 Hz). This signal is then amplified, rectified, filtered and fed into the op-amp's non-inverting input. This vastly improved the gain of the op-amp while significantly reducing the output drift and DC offset. Unfortunately, any design that used a chopper couldn't use their non-inverting input for any other purpose. Nevertheless, the much improved characteristics of the chopper-stabilized op-amp made it the dominant way to use op-amps. Techniques that used the non-inverting input regularly would not be very popular until the 1960s when op-amp ICs started to show up in the field.
1953: A commercially available op-amp. In 1953, vacuum tube op-amps became commercially available with the release of the model K2-W from George A. Philbrick Researches, Incorporated. The designation on the devices shown, GAP/R, is an acronym for the complete company name. Two nine-pin 12AX7 vacuum tubes were mounted in an octal package and had a model K2-P chopper add-on available that would effectively "use up" the non-inverting input. This op-amp was based on a descendant of Loebe Julie's 1947 design and, along with its successors, would start the widespread use of op-amps in industry.
1961: A discrete IC op-amp. With the birth of the transistor in 1947, and the silicon transistor in 1954, the concept of ICs became a reality. The introduction of the planar process in 1959 made transistors and ICs stable enough to be commercially useful. By 1961, solid-state, discrete op-amps were being produced. These op-amps were effectively small circuit boards with packages such as edge connectors. They usually had hand-selected resistors in order to improve things such as voltage offset and drift. The P45 (1961) had a gain of 94 dB and ran on ±15 V rails. It was intended to deal with signals in the range of .
1961: A varactor bridge op-amp. There have been many different directions taken in op-amp design. Varactor bridge op-amps started to be produced in the early 1960s. They were designed to have extremely small input current and are still amongst the best op-amps available in terms of common-mode rejection with the ability to correctly deal with hundreds of volts at their inputs.
1962: An op-amp in a potted module. By 1962, several companies were producing modular potted packages that could be plugged into printed circuit boards. These packages were crucially important as they made the operational amplifier into a single black box which could be easily treated as a component in a larger circuit.
1963: A monolithic IC op-amp. In 1963, the first monolithic IC op-amp, the μA702 designed by Bob Widlar at Fairchild Semiconductor, was released. Monolithic ICs consist of a single chip as opposed to a chip and discrete parts (a discrete IC) or multiple chips bonded and connected on a circuit board (a hybrid IC). Almost all modern op-amps are monolithic ICs; however, this first IC did not meet with much success. Issues such as an uneven supply voltage, low gain and a small dynamic range held off the dominance of monolithic op-amps until 1965 when the μA709 (also designed by Bob Widlar) was released.
1968: Release of the μA741. The popularity of monolithic op-amps was further improved upon the release of the LM101 in 1967, which solved a variety of issues, and the subsequent release of the μA741 in 1968. The μA741 was extremely similar to the LM101 except that Fairchild's facilities allowed them to include a 30 pF compensation capacitor inside the chip instead of requiring external compensation. This simple difference has made the 741 "the" canonical op-amp and many modern amps base their pinout on the 741s. The μA741 is still in production, and has become ubiquitous in electronics—many manufacturers produce a version of this classic chip, recognizable by part numbers containing "741". The same part is manufactured by several companies.
1970: First high-speed, low-input current FET design.
In the 1970s high speed, low-input current designs started to be made by using FETs. These would be largely replaced by op-amps made with MOSFETs in the 1980s. 
1972: Single sided supply op-amps being produced. A single sided supply op-amp is one where the input and output voltages can be as low as the negative power supply voltage instead of needing to be at least two volts above it. The result is that it can operate in many applications with the negative supply pin on the op-amp being connected to the signal ground, thus eliminating the need for a separate negative power supply.
The LM324 (released in 1972) was one such op-amp that came in a quad package (four separate op-amps in one package) and became an industry standard. In addition to packaging multiple op-amps in a single package, the 1970s also saw the birth of op-amps in hybrid packages. These op-amps were generally improved versions of existing monolithic op-amps. As the properties of monolithic op-amps improved, the more complex hybrid ICs were quickly relegated to systems that are required to have extremely long service lives or other specialty systems.
Recent trends. Recently supply voltages in analog circuits have decreased (as they have in digital logic) and low-voltage op-amps have been introduced reflecting this. Supplies of 5 V and increasingly 3.3 V (sometimes as low as 1.8 V) are common. To maximize the signal range modern op-amps commonly have rail-to-rail output (the output signal can range from the lowest supply voltage to the highest) and sometimes rail-to-rail inputs.

</doc>
<doc id="22807" url="https://en.wikipedia.org/wiki?curid=22807" title="Oh Hell">
Oh Hell

Oh Hell is a trick-taking card game in which the object is to take "exactly" the number of tricks bid, unlike contract bridge and spades: taking more tricks than bid is a loss. Its first appearance dates to the early 1930s and it is sometimes credited to the McCandless family.
Concept.
The game of Oh Hell explores the idea of taking an exact number of tricks specified by a bid before the hand. It differs from other trick-taking games in that players play a fixed number of hands. The game uses trump, often decided by a cut of the deck after the hand's cards have been distributed.
Like many popular social card games, Oh Hell has many local variants, in both rules and names.
Famous players.
President Bill Clinton and Steven Spielberg are high profile Oh Hell players.
Rules.
There are many variations to this game; a common set of regulations is given here.
Oh Hell can be played with almost any number of players (3+) although 4-7 is considered optimal. The game is played using a standard 52-card deck, with ace (A) being the highest rank, two (2) the lowest. With six or more players, the game can be played with two decks combined or with a 63-card deck from six-player 500.
A game consists of a fixed number of hands, and each hand consists of dealing a certain number of cards to each player, depending on the variation and the number of players. During a hand, each player bids for a number of tricks, then attempts to take exactly that many tricks during the hand.
The dealer (initially determined by cutting cards) deals out the cards one by one, starting with the player to his left, in a clockwise direction, until the required number of cards has been dealt. After the dealing is complete, the next card is turned face up, and the suit of this card determines the trump suit for the deal, which is why only up to 12 cards are dealt in a four-player match. (If there are no unused cards, the largest hand is played without a trump suit. Alternatively, the maximal round trump suit can be determined in a variety of ways: for instance, by revealing the dealer's last card as in whist, by cutting the pack before dealing or the dealer can decide the trump before seeing his own cards.)
Each player now bids for the number of tricks he believes he can win. The player to the left of the dealer bids first. Bidding is unrestricted except for the "screw the dealer" rule: the number of tricks bid cannot equal the number available. That is, every deal must in total be either overbid or underbid. For example, if five cards are dealt, and the first three bids are two, zero and one, then the dealer may not bid two. However, if five cards are dealt, and the first three bids are three, one and two, then the dealer is free to make any bid. The "Screw the Dealer" rule is not used in the version played in West Virginia, South Carolina, Rural Maryland, and Pennsylvania with the dealer being free to make any bid. In an alternative style of bidding, all players simultaneously hold out fingers for the number of tricks they want to bid (similar in style to a rock-paper-scissors shoot). The players bids are recorded on the score sheet next to players score.
When every player has made a bid, the player to the left of the dealer makes the opening lead. Play then proceeds as usual in a trick-taking game, with each player in turn playing one card. Players must follow suit, unless they have no cards of the led suit, in which case they may play any card. The highest card of the led suit wins the trick unless ruffed, when the highest trump card wins.
In multi-deck games, the first of identical cards to be played (say two queens of clubs) wins the trick. In a more complicated variant, identical cards cancel each other, leading to the possibility (if the number of players is even) of an entire trick being canceled out.
The player who wins the trick leads to the next trick.
Cooperative version.
In this variant, all bids must add up exactly to the number of cards dealt for that round. Players must then "make it work" to move on to the next round. If anyone takes more or less than their bid, the deal moves to the left and the round is re-dealt. With four players, a second deck may be used to specify the round to be played—the value of the upcard determines the number of cards dealt and the suit determines the trump suit for the round.
Prospect version.
This variant is played for money. Prior to dealing the first hand, players agree on the amount of money the “losers” will have to pay to the winner. The last place finisher pays the most and the second-place finisher pays the least. The sliding scale in the Prospect version keeps all the players invested in the outcome of every hand, since their finishing rank corresponds to how much money they will owe the winner.
Tournaments.
The WPOHL (World Prospect Oh Hell League) Championship is usually held in December in Rehoboth Beach Delaware using “Prospect” rules (e.g. 5 players make up a full table, blind bidding and drinking are allowed, smoking is not). The deal begins with 10 cards, plays down to 1, then back up to 10 for a total of 19 hands per round. Depending on the size of the field, the five or ten lowest scoring players in the room are eliminated each round until there is a five-person "final table." The entry fee is typically under $50.00 (plus $10.00 to join the WPOHL, if not a member).
On December 15, 2013, Shawn O’Brien won the 2013 WPOHL Championship, earning $45.00 in prize money and temporary ownership of the Peterson Cup. The 46-year-old Pennsylvania native is the first official world champion in WPOHL history. The championship consisted of a series three games played in Montrose, Pennsylvania. The 2014 Championship is scheduled to take place December 13–14 in Rehoboth Beach, Delaware.
O'Brien easily defended his title on December 20, 2014 with commanding tournament play that earned him the nickname “Shawnicus Maximus” and laid the groundwork for a possible dynasty. The Pennsylvanian led the championship from wire to wire and clinched the Peterson Cup by winning the first two of three final rounds of play. With only one blind bid over the course of the 57 hand final series, Shawn made his bid an astounding 82% of the time.
In the early 1990s, the International Oh-Hell League’s annual Championship Tournament of All Creation was held each March in the Riverton, PA Fire Hall. Little current information is available about the tournament. Players vied for the league trophy, a 2-inch bronze reproduction of the Belgian landmark sculpture Manneken Pis - a naked, urinating urchin - which resided permanently in the home of tournament founder, Jack Mathews, regardless of who won the tournament. Thus, to "win" the trophy was not to possess it. Additional idiosyncratic tournament rules included the use of alcohol being off limits, but the use of tobacco being encouraged. A full table consisted of four players. Play began with a one card hand, went up to 13, then back down to one for a total of 25 hands. In each hand, except the 13th, when the entire deck was dealt, the first undealt card was turned over to establish the trump suit. The tournament entry fee was $5.00.
The Annual Cartier 'Oh Hell!' Tournament began in 1995. The tournament formula was created by Tessa Kennedy and Tomasz Starzewski. Cartier Ltd. sponsors the tournament with all money raised going to charity.
Tournament Organization: Two decks of cards are assigned to each table. As one deck is dealt, the other is shuffled in preparation for the following hand. The person to shuffle the cards is always the player sitting opposite the dealer in that hand. Players pick a random card from the deck to select the Dealer for the first hand (highest card is first Dealer).
The tournament is played with 32 people. The first round has all 32 people playing on 8 tables of 4 players each. The winner and first runner up from each table go on to play in the second round. The second round is therefore played with 16 people on 4 tables of 4 players. First round winners and runners-up are split up so they do not play each other again in the second round. The single winner from each table then goes on to the final round the final table of 4 players. The winner is the tournament champion.
Scoring.
There are several alternative methods of scoring:
Names.
Oh Hell is also known by a variety of names, including:
Dutch names.
Boerenbridge, Boerenlullen, Chinees poepen, Chinees dekken, Chinees bridgen, Koreaanse poker, 10 op en neer, jodelen, pronostieken, Slagenvragen, Hellen, Bollen, op-en-affen.

</doc>
<doc id="22808" url="https://en.wikipedia.org/wiki?curid=22808" title="On War">
On War

Vom Kriege () is a book on war and military strategy by Prussian general Carl von Clausewitz (1780–1831), written mostly after the Napoleonic wars, between 1816 and 1830, and published posthumously by his wife Marie von Brühl in 1832. It has been translated into English several times as On War. "On War" is actually an unfinished work; Clausewitz had set about revising his accumulated manuscripts in 1827, but did not live to finish the task. His wife edited his collected works and published them between 1832 and 1835. His 10-volume collected works contain most of his larger historical and theoretical writings, though not his shorter articles and papers or his extensive correspondence with important political, military, intellectual and cultural leaders in the Prussian state. "On War" is formed by the first three volumes and represents his theoretical explorations. It is one of the most important treatises on political-military analysis and strategy ever written, and remains both controversial and an influence on strategic thinking.
History.
Clausewitz was among those intrigued by the manner in which the leaders of the French Revolution, especially Napoleon, had changed the conduct of war through their ability to motivate the populace and to gain access to the full resources of the state; thus unleashing war on a greater scale than had previously been seen in Europe. Clausewitz was well educated and had strong interests in art, history, science, and education. He was a professional soldier who spent a considerable part of his life fighting against Napoleon. The insights he gained from his political and military experiences, combined with a solid grasp of European history, provided the basis for the book.
Synopsis.
The book contains a wealth of historical examples used to illustrate its various concepts. Frederick II of Prussia (the Great) figures prominently for having made very efficient use of the limited forces at his disposal, though Napoleon is perhaps the central figure.
According to Azar Gat, the "general message" of the book was that "the conduct of war could not be reduced to universal principles." Among many strands of thought, three stand out as essential to Clausewitz's concept:
Some of the key ideas (not necessarily original to Clausewitz or even to his mentor Gerhard von Scharnhorst) discussed in "On War" include (in no particular order of importance):
Clausewitz used a dialectical method to construct his argument, leading to frequent modern misinterpretation because he explores various—often opposed—ideas before coming to conclusions.
Modern perception of war are based on the concepts Clausewitz put forth in "On War", though these have been very diversely interpreted by various leaders (e.g., Moltke, Vladimir Lenin, Dwight D. Eisenhower, Mao Zedong, etc.), thinkers, armies, and peoples. Modern military doctrine, organization, and norms are all based on Napoleonic premises, even to this day—though whether these premises are necessarily also "Clausewitzian" is debatable.
The "dualism" of Clausewitz's view of war (i.e., that wars can vary a great deal between the two "poles" he proposed, based on the political objectives of the opposing sides and the context) seems simple enough, but few commentators have proven willing to accept this crucial variability—they insist that Clausewitz "really" argued for one end of the scale or the other. "On War" has been seen by some prominent critics as an argument for "total war". It has been blamed for the level of destruction involved in the First and Second World Wars, but it seems rather that Clausewitz (who did not actually use the term "total war") had merely foreseen the inevitable development that started with the huge, patriotically motivated armies of the Napoleonic wars. These wars resulted (though war's evolution has not yet ended) in the atomic bombing of Hiroshima and Nagasaki, with all the forces and capabilities of the state devoted to destroying forces and capabilities of the enemy state (thus "total war"). Conversely, Clausewitz has also been seen as "The preeminent military and political strategist of limited war in modern times." (Robert Osgood, 1979)
Clausewitz and his proponents have been severely criticized by competing theorists--Antoine-Henri Jomini in the 19th century, B. H. Liddell Hart in the mid-20th century, and Martin van Creveld and John Keegan more recently. "On War" is a work rooted solely in the world of the nation state, says historian Martin Van Creveld, who alleges that Clausewitz takes the state "almost for granted" as he rarely looks at anything previous to Westphalia. He alleges that Clausewitz does not address any form of intra/supra-state conflict, such as rebellion and revolution, because he could not theoretically account for warfare before the existence of the state. Previous kinds of conflict were demoted to criminal activities without legitimacy and not worthy of the label "war." Van Creveld argues that "Clausewitzian war" requires the state to act in conjunction with the people and the army, the state becoming a massive engine built to exert military force against an identical opponent. He supports this statement by pointing to the conventional armies in existence throughout the 20th century. This view ignores, among many other things, the facts that Clausewitz died in the early "19th" century, that Prussia itself was not a "nation-state," and that the Napoleonic Wars included many non-conventional conflicts of which Clausewitz was well aware. In any case, revolutionaries like Karl Marx, Friedrich Engels, Vladimir Lenin, Leon Trotsky and Mao Zedong had no trouble adapting Clausewitz's concepts to their own purposes. Nor did conservatives like the Elder Moltke and Dwight D. Eisenhower. Much of Clausewitz's thinking was based on his experience as a Prussian war planner concerned with how to use popular forces in an insurrectionary struggle against the much-superior French forces which occupied Prussia after 1806—how, in short, to wage a "Spanish War in Germany."
Clausewitz himself never saw the 20th-century states and armies to which Creveld refers—the states with which he himself was familiar were quite different. In any case, the "Clausewitzian Trinity" that Van Creveld condemns as consisting of a rigid, static hierarchy of "People, Army, and Government," does not in fact consist of those three concrete actors. In fact, the words people, army, and government appear nowhere in the paragraph in which Clausewitz defines his famous Trinity. Rather, the Trinity of forces that drive the course of real-world war in Clausewitz's view are 1) violent emotion, 2) the interplay of chance and probability, and 3) political calculations driven by reason. It seems unlikely that emotion, chance, and rationality will cease to play a role in war any time soon, whatever the fate of the state.

</doc>
<doc id="22810" url="https://en.wikipedia.org/wiki?curid=22810" title="Orange Alternative">
Orange Alternative

Orange Alternative (Polish: "Pomarańczowa Alternatywa") - Polish anti-communist underground movement which was started in Wrocław, a city in south-west Poland and led by Waldemar Fydrych (sometimes misspelled as Frydrych), commonly known as "Major (Commander of Festung Breslau)" in the 1980s. Its main purpose was to offer a wider group of citizens an alternative way of opposition against the authoritarian communist regime by means of a peaceful protest that used absurd and nonsensical elements.
By doing this, Orange Alternative participants could not be arrested by the police for opposition to the regime without the authorities becoming a laughing stock. Orange Alternative has been viewed as part of the broader Solidarity movement. Academics Dennis Bos and Marjolein 't Hart have asserted it was the most effective of all Solidarity's factions in bringing about the movement's success.
Initially it painted ridiculous graffiti of dwarves on paint spots covering up anti-government slogans on city walls. Afterwards, beginning with 1985 through 1990, it organized a series of more than sixty happenings in several Polish cities, including Wrocław, Warsaw, Łódź, Lublin and Tomaszów Mazowiecki.
It was the most picturesque element of Polish opposition to Stalinist authoritarianism. It suspended activity in 1989, but reactivated in 2001 and has been active on a small scale ever since.
A statue of a dwarf, dedicated to the memory of the movement, stands today on Świdnicka Street in Wrocław, in the place where events took place.
Orange Alternative movement has inspired several other similar movements in authoritarian countries including Czechoslovakia and Hungary and it has also inspired and influenced the Pora and the so-called Orange Revolution movement in Ukraine, which was in turn supported by Poland.
Some utterances ascribed to Waldemar Fydrych:
Beginnings.
The beginning of the Orange Alternative are in a student movement called the Movement for New Culture created in 1980 at the University of Wrocław. It is in that year that Waldemar "Major" Fydrych, one of the movement's founders, proclaims the Socialist Surrealism Manifesto, which becomes the ideological backbone behind a gazette known as "The Orange Alternative." Seven out of the total fifteen issues of this gazette appear during student strikes organized in November and December 1980 as part of the Solidarity upheaval. The first number is edited jointly by Major Waldemar Fydrych and Wiesław Cupała (a.k.a. "Captain") simply with an idea to have fun. The editors treat the strike and the surrounding reality as forms of Art. For the ensuing numbers, the editorial committee is joined by Piotr Adamcio, known as "Lieutenant Pablo," Andrzej Dziewit and Zenon Zegarski, nicknamed "Lieutenant Zizi Top." Although its avantgarde character, according to the student strike organizers, was a threat to the "higher aims of the strike", and notwithstanding attempts by the strike committee to censor it, the gazette became rapidly very popular among the students.
Dwarves.
The first known actions of the Orange Alternative consisted of painting dwarf graffiti on spots created by the police's covering up anti-regime slogans on walls of the Polish cities. The first graffiti was painted by Major Waldemar Fydrych and Wiesław Cupała on the night from the 30 to 31 August 1982 on one of the residences in the Wrocław district of Biskupin and Sępolno.
Altogether more than one thousand of such graffiti were painted in the major Polish cities such as Wrocław, Kraków, Warsaw, Łódź, and Gdańsk.
Dwarves appearing in numbers all over Poland aroused the interest of both Polish pedestrians and the militia, whose intervention led to short term arrests of the graffiti artists.
During one of these incidents, Major, a detainee at a police station in Łódź, proclaimed, in reference to the Marxist and Hegelian dialectics, yet another artistic manifesto and referred to his graffiti art as "dialectic painting" stating: "The Thesis is the Anti-Regime Slogan. The Anti-thesis is the Spot and the Synthesis is the Dwarf. Quantity evolves into Quality. The more Dwarves there are, the better it is."
After Revolutions of 1989.
Since the beginning of the 21st century in Wrocław began to appear Dwarfs figurines made of bronze. Over time they have become one of the major tourist attractions in Wrocław.
Happenings.
What brought the Orange Alternative the biggest fame were its street happenings which it organized throughout the second half of the 1980s. These actions gained it enormous popularity among the Polish youth, who joined the movement, seeing it an alternative to the opposition style presented by the Solidarity, which they viewed as more stiff and boring.
The first modest happening called the "Burning of Tubes" was organized as early as 1985 in Wrocław by Major Waldemar Fydrych accompanied by a small group of artists to which belonged: Krzysztof Skarbek, Piotr Petyszkowski, Andrzej Głuszek and Sławomir Monkiewicz.
The break-through moment came in the fall of 1987, during the Open Theatre Festival in Wrocław, when the Village Voice reported the Orange Alternative's action known as "Distribution of Toilet Paper" – a happening that satirized the annoying lack of that consumer product at the time. After the publication of this article, the Orange Alternative became of interest to a number of Polish and foreign media.
The biggest happenings however took place in the years 1987 through 1989, with the "orange" wave spilling over Poland into cities such as Warsaw, Łódź, Lublin and Tomaszów Mazowiecki following Major Fydrych's arrest on 8 March 1988.
The actions of the Orange Alternative – although its leaders and participants often expressed anarchistic viewpoints – were not inherently ideological. No serious demands were ever expressed. Rather, the slogans were surrealist in character (such as "Vivat Sorbovit" (Sorbovit being a popular soft drink at that time)) or "There is no freedom without dwarves." Often they paraphrased slogans used by the Solidarity Union or the communists. Their role was to laugh at absurdities and pompousness of both sides of the system and provoke independent thinking.
The open street formula allowed all individuals to take part in the happenings. This openness drew thousands of pedestrians to participate in the group's actions. In such a way, the majority of the happenings could assemble thousands of participants, of whom many were accidental passers-by. The culmination point in the movement's history was the action organized on 1 June 1988, known as the "Revolution of Dwarves", during which more than 10 thousand people marched through the center of Wrocław wearing orange dwarf hats.
The happenings usually terminated with the arrest of hundreds of participants, who did not manage to escape in time from the hands of the militia. At one point, the participants were even able to provoke the Communist militia to arrest 77 Santa Clauses or, on another occasion, anyone wearing anything orange.
For every one of its actions, the Orange Alternative printed leaflets and posters, featuring slogans like "Every militiaman is a piece of Art" or "Citizen, help the militia, beat yourself up."

</doc>
<doc id="22811" url="https://en.wikipedia.org/wiki?curid=22811" title="Otto IV, Holy Roman Emperor">
Otto IV, Holy Roman Emperor

Otto IV (1175 – May 19, 1218) was one of two rival kings of Germany from 1198 on, sole king from 1208 on, and Holy Roman Emperor from 1209 until he was forced to abdicate in 1215. The only German king of the Welf dynasty, he incurred the wrath of Pope Innocent III and was excommunicated in 1210.
Career.
Early life.
Otto was the third son of Henry the Lion, Duke of Bavaria and Saxony, and Matilda Plantagenet. His exact birthplace is not given by any original source. He grew up in England in the care of his grandfather King Henry II. Otto was fluent in French as well as German. He became the foster son of his maternal uncle, Richard I of England. In 1190, after he left England to join the Third Crusade, Richard appointed Otto Earl of York. The authenticity (or authority) of this grant was doubted by the vassals of Yorkshire, who prevented Otto taking possession of his earldom. Still, he probably visited Yorkshire in 1191, and he continued to claim the revenues of the earldom after becoming king of Germany, although he never secured them. Neither did he succeed in getting the 25,000 silver marks willed to him by his uncle in 1199.
In 1195, Richard began negotiations to marry Otto to Margaret, daughter and heiress of King William the Lion of Scotland. Lothian, as Margaret's dowry, would be handed over to Richard for safekeeping and the counties of Northumberland and Cumberland (Carlisle) would be granted to Otto and turned over to the king of Scotland. The negotiations dragged on until August 1198, when the birth of an heir to William rendered them unnecessary. Having failed in his efforts to secure Otto an English earldom or else a Scottish kingdom, in September 1196 Richard, as duke of Aquitaine, enfeoffed Otto with the county of Poitou. There is some disagreement over whether Otto received Poitou in exchange for or in addition to the earldom of York.
Otto was in Poitou from September 1196 until mid-1197, when he joined Richard in Normandy to confer over the appointment of bishops to the vacant sees of Poitiers, Limoges and Périgueux. He then participated in the war against Philip II of France on the side of Richard. In October he returned to Poitou. The German historian Jens Ahlers, taking into account Otto's life prior to 1198, considers that he might have been the first foreign king of Germany.
Conflict with Philip of Swabia.
After the death of Emperor Henry VI, the majority of the princes of the Empire, situated in the south, elected Henry’s brother, Philip, Duke of Swabia, king in March 1198, after receiving money and promises from Philip in exchange for their support. Those princes opposed to the Staufen dynasty also decided, on the initiative of Richard of England, to elect instead a member of the House of Welf. Otto's elder brother, Henry, was on a crusade at the time, and so the choice fell to Otto. Otto, soon recognized throughout the northwest and the lower Rhine region, was elected king by his partisans in Cologne on June 9, 1198. Otto took control of Aachen, the place of coronation, and was crowned by Adolf, Archbishop of Cologne, on July 12, 1198. This was of great symbolic importance, since the Archbishop of Cologne alone could crown the King of the Romans. Nevertheless, the coronation was done with fake regalia, because the actual materials were in the hands of the Staufen.
Otto's election pulled the empire into the conflict between England and France. Philip had allied himself with the French king, Philip II, while Otto was supported at first by Richard I, and after his death in 1199 by his brother John.
The papacy meanwhile, under Innocent III, determined to prevent the continued unification of Sicily and the Holy Roman Empire under one monarch seized the opportunity to extend its influence. Therefore, Innocent III favoured Otto, whose family had always been opposed to the house of Hohenstaufen. Otto himself also seemed willing to grant any demands that Innocent would make. The confusion in the empire allowed Innocent to drive out the imperial feudal lords from Ancona, Spoleto, and Perugia, who had been installed by Emperor Henry VI. At the same time, Innocent encouraged the cities in Tuscany to form a league, called the League of San Genesio, against imperial interests in Italy, and they placed themselves under Innocent’s protection. In 1201, Innocent announced that he recognized Otto as the only legitimate king. In return, Otto promised to support the pope's interests in Italy. Otto also had the support of Ottokar I, the king of Bohemia, who although at first siding with Philip of Swabia, eventually threw in his lot with Otto. Otto’s cause was further strengthened by the support of the Danish king, Valdemar II. But Philip achieved a great deal of success in the civil war that followed, allowing him in 1204 to be again crowned king, this time by the archbishop of Cologne.
In the following years, Otto's situation worsened because after England's defeat by France he lost England's financial support. Many of his allies changed sides to Philip, including his brother Henry. Otto was defeated and wounded in battle by Philip on July 27, 1206, near Wassenberg, and as a consequence he also lost the support of the pope, who began to favour the apparent winner in the conflict. Otto was forced to retire to his possessions near Braunschweig, leaving Philip virtually uncontested as German king.
Innocent III forced the two warring parties into negotiations at Cologne, and in exchange for renouncing his claim to the throne, Philip promised Otto the hand of his daughter Beatrix in marriage, together with the Duchy of Swabia and an enormous dowry. Otto refused, and as the civil war was again about to recommence, Philip was murdered on June 21, 1208.
After Philip's death, Otto made amends with the Staufen party and became engaged to Philip's daughter Beatrix. In an election in Frankfurt on November 11, 1208, he gained the support of all the electoral princes, as he promised he would not make hereditary claims to the imperial crown on behalf of any children he might father. Now fully reconciled with Innocent, Otto made preparations to be crowned Holy Roman Emperor. To secure Innocent’s support, he promised to restore to the Papal States all territory that it had possessed under Louis the Pious, including the March of Ancona, the Duchy of Spoleto, the former Exarchate of Ravenna, and the Pentapolis. Travelling down via Verona, Modena, and Bologna, he eventually arrived at Milan where he received the Iron Crown of Lombardy and the title of King of Italy in 1208. He was met at Viterbo by Pope Innocent and was taken to St. Peter's Basilica, where he was crowned emperor by Pope Innocent on October 21, 1209, before rioting broke out in Rome, forcing Otto to abandon the city.
Conflict with Innocent III.
Not content with his successes so far, Innocent also obtained from Otto further written concessions to the Papal See, including to allow all elections of German bishops to be conducted according to Church ordinances, and not to prevent any appeals to Rome. He also promised to hand over to the Church all income from any vacant sees which had been flowing into the imperial treasury.
After abandoning Rome, Otto marched north, reaching Pisa by November 20. Here, probably advised by Peter of Celano and Dipold, Count of Acerra, he was convinced to abandon his earlier promises, and Otto immediately worked to restore imperial power in Italy. After his consecration by the pope, he promised to restore the lands bequeathed to the church by the countess Matilda of Tuscany nearly a century before, and to not move against Frederick Roger, the King of Sicily. But he quickly broke all his promises. He threw out the papal troops from Ancona and Spoleto, reclaiming the territory as imperial fiefs. He then demanded that Frederick of Sicily do homage for the duchies of Calabria and Apulia, and when Frederick refused to appear, Otto declared those fiefs forfeited. Otto then marched on Rome, and commanded Innocent to annul the Concordat of Worms, and to recognise the imperial crown’s right to make nominations to all vacant benefices.
Such actions infuriated Innocent and Otto was promptly excommunicated by the pope for this on November 18, 1210. Subsequently, he tried to conquer Sicily, which was held by the Staufen king Frederick, under the guardianship of Innocent III. Parallel to this, the German nobility by this time were growing ever more frustrated with Otto. They felt that instead of wasting his time in Italy, and playing power politics with the pope, it was his first duty to defend the northern provinces of the empire against Valdemar II of Denmark, who had taken advantage of Otto’s distractions by invading the northern provinces of the empire and possessing the whole Baltic coast from Holstein to Livonia. So while Otto was in southern Italy, several princes of the empire, including the archbishops of Mainz and Magdeburg, at the instigation of King Philip II of France and with the consent of the pope, elected Frederick King of the Romans at the Diet of Nuremberg in 1211.
Otto’s ambassadors from Milan appeared before the Fourth Lateran Council, pleading his case for his excommunication to be lifted. Although he claimed he had repented for his offences, and declared his willingness to be obedient to the Pope in all things, Innocent III had already recognised Frederick as emperor-elect.
Otto returned to Germany to deal with the situation, hopeful to salvage something from the looming disaster. He found most of the German princes and bishops had turned against him, and that Frederick, who had made his way up the Italian peninsula, had avoided Otto’s men who were guarding the passes through the Alps and had arrived at Constance. Otto soon discovered that after Beatrix died in the summer of 1212, and Frederick arrived in Germany with his army in September 1212, most of the former Staufen supporters deserted Otto for Frederick, forcing Otto to withdraw to Cologne. On December 5, 1212, Frederick was elected king for a second time by a majority of the princes.
The support that Philip II of France was giving to Frederick forced King John of England to throw his weight behind his nephew Otto. The destruction of the French fleet in 1213 by the English saw John begin preparations for an invasion of France, and Otto saw a way of both destroying Frederick’s French support as well as bolstering his own prestige. He agreed to join John in the invasion, and in February 1214, as John advanced from the Loire, Otto was supposed to make a simultaneous attack from Flanders, together with the Count of Flanders. Unfortunately, the three armies could not coordinate their efforts effectively. It was not until John, who had been disappointed in his hope for an easy victory after being driven from Roche-au-Moine and had retreated to his transports that the Imperial Army, with Otto at its head, assembled in the Low Countries.
On 27 July 1214, the opposing armies suddenly discovered they were in close proximity to each other, on the banks of the little river Marque (a tributary of the river Deûle), near the Bridge of Bouvines. Philip's army numbered some 15,000, while the allied forces possessed around 25,000 troops, and the armies clashed at the Battle of Bouvines. It was a tight battle, but it was lost when Otto was carried off the field by his wounded and terrified horse, causing his forces to abandon the field. It is said that Philip II had sent to Frederick the imperial eagle which Otto had left lying on the battlefield.
This defeat allowed Frederick to take Aachen and Cologne, as Otto was forced again to withdraw to his private possessions around Brunswick, and he was forced to abdicate the imperial throne in 1215. He died of disease, at Harzburg castle on May 19, 1218, requesting that he be mortally expiated in atonement of his sins. Historian Kantorowicz described the death as "gruesome": "deposed, dethroned, he was flung full length on the ground by the Abbot, confessing his sins, while the reluctant priests beat him bloodily to death. Such was the end of the first and last Welf Emperor." 
He is entombed in Brunswick Cathedral.
Family.
Otto was related to every other King of Germany. He married twice:
He had no children by either Beatrice or Marie.
References.
 
 
 
<BR>

</doc>
<doc id="22812" url="https://en.wikipedia.org/wiki?curid=22812" title="Octavian (disambiguation)">
Octavian (disambiguation)

Octavian may refer to:

</doc>
<doc id="22816" url="https://en.wikipedia.org/wiki?curid=22816" title="Outcome-based education">
Outcome-based education

Outcome-based education (OBE) is an educational theory that bases each part of an educational system around goals (outcomes). By the end of the educational experience each student should have achieved the goal. There is no specified style of teaching or assessment in OBE; instead classes, opportunities, and assessments should all help students achieve the specified outcomes.
Outcome-based methods have been adopted in education systems around the world, at multiple levels. 
Australia and South Africa adopted OBE policies in the early 1990s but have since been phased out. The United States has had an OBE program in place since 1994 that has been adapted over the years. In 2005 Hong Kong adopted an outcome-based approach for its universities. Malaysia implemented OBE in all of their public schools systems in 2008. The European Union has proposed an education shift to focus on outcomes, across the EU. In an international effort to accept OBE The Washington Accord was created in 1989, it is an agreement to accept undergraduate engineering degrees that were obtained using OBE methods. As of 2014 the signatories Australia, Canada, Taiwan, Hong Kong, India, Ireland, Japan, Korea, Malaysia, New Zealand, Russia, Singapore, South Africa, Sri Lanka, Turkey, the United Kingdom and the United States.
Differences from traditional education methods.
In a traditional education system, students are given grades and rankings compared to each other. Content and performance expectations are based primarily on what was taught in the past to students of a given age. The goal of traditional education was to present the knowledge and skills of an older generation to the new generation of students, and to provide students with an environment in which to learn. The process paid little attention (beyond the classroom teacher) to whether or not students learn any of the material.
Benefits of OBE.
Clarity.
The focus on outcomes creates a clear expectation of what needs to be accomplished by the end of the course. Students will understand what is expected of them and teachers will know what they need to teach during the course. Clarity is important over years of schooling and when team teaching is involved. Each team member, or year in school, will have a clear understanding of what needs to be accomplished in each class, or at each level, allowing students to progress. Those designing and planning the curriculum are expected to work backwards once an outcome has been decided upon, they must determine what knowledge and skills will be required to reach the outcome.
Flexibility.
With a clear sense of what needs to be accomplished, instructors will be able to structure their lessons around the student’s needs. OBE does not specify a specific method of instruction, leaving instructors free to teach their students using any method. Instructors will also be able to recognize diversity among students by using various teaching and assessment techniques during their class. OBE is meant to be a student-centered learning model. Teachers are meant to guide and help the students understand the material in any way necessary, study guides, and group work are some of the methods instructors can use to facilitate students learning.
Comparison.
OBE provides an opportunity for comparison across institutions. On an individual level, institutions can look at what outcomes a student has achieved to decide what level the student would be at within a new institution. On an institutional level, institutions can compare themselves, by checking to see what outcomes they have in common, and find places where they may need improvement, based on the achievement of outcomes at other institutions. The ability to compare easily across institutions allows students to move between institutions with relative ease. The institutions can compare outcomes to determine what credits to award the student. The clearly articulated outcomes should allow institutions to assess the student’s achievements rapidly, leading to increased movement of students. These outcomes also work for school to work transitions. A potential employer can look at records of the potential employee to determine what outcomes they have achieved. They can then determine if the potential employee has the skills necessary for the job.
Involvement.
Student involvement in the classroom is a key part of OBE, students are expected to do their own learning, so that they gain a full understanding of the material. Increased student involvement allows students to feel responsible for their own learning, and they should learn more through this individual learning. Another aspect of involvement is parental, and community involvement, while developing curriculum, or making changes to it. OBE outcomes are meant to be decided upon within a school system, or at a local level. Parents and community members are asked to give input in order to uphold the standards of education within a community, and to ensure that students will be prepared for life after school.
Drawbacks of OBE.
Definition.
The definitions of the outcomes decided upon are subject to interpretation by those implementing them. Across different programs or even different instructors outcomes could be interpreted differently, leading to a difference in education, even though the same outcomes were said to be achieved. By outlining specific outcomes, a holistic approach to learning is lost. Learning can find itself reduced to something that is specific, measurable, and observable. As a result, outcomes are not yet widely recognized as a valid way of conceptualizing what learning is about.
Assessment problems.
When determining if an outcome has been achieved assessments may become too mechanical, looking only to see if the student has acquired the knowledge. The ability to use and apply the knowledge in different ways may not be the focus of the assessment. The focus on determining if the outcome has been achieved leads to a loss of understanding and learning for students, who may never be shown how to use the knowledge they have gained. Instructors are faced with a challenge, they must learn to manage an environment that can become fundamentally different from what they are accustomed to. In regards to giving assessments they must be willing to put in the time required to create a valid, reliable assessment, that ideally would allow students to demonstrate their understanding of the information, while remaining objective.
Generality.
Education outcomes can lead to a constrained nature of teaching and assessment. Assessing liberal outcomes such as creativity, respect for self and others, responsibility, and self-sufficiency, can become problematic. There is not a measurable, observable, or specific way to determine if a student has achieved these outcomes. Due to the nature of specific outcomes, OBE may actually work against its ideals of serving and creating individuals that have achieved many outcomes.
Involvement.
Parental involvement, as discussed in the benefits section can also be a drawback, if parents and community members are not willing to express their opinions on the quality of the education system, the system may not see a need for improvement, and not change to meet student’s needs. Parents may also become too involved, requesting too many changes, so that important improvements get lost with other changes that are being suggested. Instructors will also find that their work is increased; they must work to first understand the outcome, then build a curriculum around each outcome they are required to meet. Instructors have found that implementing multiple outcomes is difficult to do equally, especially in primary school. Instructors will also find their work load increased if they chose to use an assessment method that evaluates students holistically.
Adoption and removal.
Australia.
In the early 1990s all states and territories in Australia developed intended curriculum documents largely based on OBE for their primary and secondary schools. Criticism arose shortly after implementation. Critics argued that no evidence existed that OBE could be implemented successfully on a large scale, in either the United States or Australia. An evaluation of Australian schools found that implementing OBE was difficult. Teachers felt overwhelmed by the amount of expected achievement outcomes. Educators believed that the curriculum outcomes did not attend to the needs of the students or teachers. Critics felt that too many expected outcomes left students with shallow understanding of the material. Many of Australia’s current education policies have moved away from OBE and towards a focus on fully understanding the essential content, rather than learning more content with less understanding.
European Union.
In December 2012, the European Commission presented a new strategy to decrease youth unemployment rate, which is close to 23% across the European Union. The European Qualifications Framework calls for a shift towards learning outcomes in primary and secondary schools throughout the EU. Students are expected to learn skills that they will need when they complete their education. It also calls for lessons to have a stronger link to employment through work-based learning. Work-based learning for students should also lead to recognition of vocational training for these students. The program also sets goals for learning foreign languages, and for teachers continued education. It also highlights the importance of using technology, especially the internet, in learning to make it relevant to students.
Hong Kong.
Hong Kong’s University Grants Committee adopted an outcomes-based approach to teaching and learning in 2005. No specific approach was created leaving universities to design the approach themselves. Universities were also left with a goal of ensuring an education for their students that will contribute to social and economic development, as defined by the community in which the university resides. With little to no direction or feedback from the outside universities will have to determine if their approach is achieving its goals on their own.
Malaysia.
OBE has been practiced in Malaysia since the 1950s; however, as of 2008 OBE is being implemented at all levels of education, especially tertiary education. This change is a result of the belief that the education system used prior to OBE inadequately prepared graduates for life outside of school. The Ministry of Higher Education has pushed for this change because of the number of unemployed graduates. Findings in 2006 state that nearly 70% of graduates from public universities were considered unemployed. A further study of those graduates found that they felt they lacked, job experience, communication skills, and qualifications relevant to the current job market. The Malaysian Qualifications Agency (MQA) was created to oversee quality of education and to ensure outcomes were being reached. The MQA created a framework that includes eight levels of qualification within higher education, covering three sectors; skills, vocational and technical, and academic. Along with meeting the standards set by the MQA, universities set and monitor their own outcome expectations for students 
South Africa.
OBE was introduced to South Africa in the late 1990s by the post-apartheid government as part of its Curriculum 2005 program. , Initial support for the program derived from anti-apartheid education policies. The policy also gained support from the labor movements that borrowed ideas about competency-based education, and Vocational education from New Zealand and Australia, as well as the labor movement that critiqued the apartheid education system. With no strong alternative proposals, the idea of outcome-based education, and a national qualification framework, became the policy of the African National Congress government. This policy was believed to be a democratization of education, people would have a say in what they wanted the outcomes of education to be. It was also believed to be a way to increase education standards and increase the availability of education. The National Qualifications Framework (NQF) went into effect in 1997. In 2001 people realized that the intended effects were not being seen. By 2006 no proposals to change the system had been accepted by the government, causing a hiatus of the program. The program came to be viewed as a failure and a new curriculum improvement process was announced in 2010, slated to be implemented between 2012 and 2014.
United States.
In 1983 a report from the National Commission on Excellence in Education declared that American education standards were eroding, that young people in the United States were not learning enough. In 1989 President Bush and the nation’s governors set national goals to be achieved by the year 2000. GOALS 2000: Educate America Act was signed in March 1994. The goal of this new reform was to show that results were being achieved in schools. In 2001 the No Child Left Behind Act took the place of Goals 2000. It mandated certain measurements as a condition of receiving federal education funds. States are free to set their own standards, but the federal law mandates public reporting of math and reading test scores for disadvantaged demographic subgroups, including racial minorities, low-income students, and special education students. Various consequences for schools that do not make "adequate yearly progress" are included in the law. In 2010 President Obama proposed improvements for the program. In 2012 the U.S. Department of Education invited states to request flexibility waivers in exchange for rigorous plans designed to improve students education in the state.
Pakistan.
In 2010 Pakistan has become a provisional member of the prestigious Washington Accord and since then Universities are working to implement OBE. 

</doc>
<doc id="22817" url="https://en.wikipedia.org/wiki?curid=22817" title="Olga of Kiev">
Olga of Kiev

Saint Olga (, born c. 890 died 11 July 969, Kiev) was a ruler of Kievan Rus' as regent (945–c. 963) for her son, Svyatoslav.
Early life.
Olga, a woman from Pskov, married the future Igor of Kiev, arguably in 903 but perhaps as early as 901-902. The "Primary Chronicle" gives 879 as her date of birth, which is unlikely, given the birth of her only son probably some 65 years after that date. After Igor's death, Olga ruled Kievan Rus as regent (945-c. 963) on behalf of their son Svyatoslav. She was, hypothetically, of Varangian extraction Old Norse: "Helga"
Drevlian Uprising.
The following account is taken from the Primary Chronicle. Princess Olga was the wife of Igor of Kiev, who was killed by the Drevlians. At the time of her husband's death, their son Svyatoslav was three years old, making Olga the official ruler of Kievan Rus until he reached adulthood. The Drevlians wanted Olga to marry their Prince Mal, making him the ruler of Kievan Rus, but Olga was determined to remain in power and preserve it for her son.
The Drevlians sent twenty of their best men to persuade Olga to marry their Prince Mal and give up her rule of Kievan Rus. She had them buried alive. Then she sent word to Prince Mal that she accepted the proposal, but required their most distinguished men to accompany her on the journey in order for her people to accept the offer of marriage. The Drevlians sent their best men who governed their land. Upon their arrival, she offered them a warm welcome and an invitation to clean up after their long journey in a bathhouse. After they entered, she locked the doors and set fire to the building, burning them alive.
With the best and wisest men out of the way, she planned to destroy the remaining Drevlians. She invited them to a funeral feast so she could mourn over her husband's grave, where her servants waited on them. After the Drevlians were drunk, Olga's soldiers killed over 5,000 of them. She returned to Kiev and prepared an army to attack the survivors. The Drevlians begged for mercy and offered to pay for their freedom with honey and furs. She asked for three pigeons and three sparrows from each house, since she did not want to burden the villagers any further after the siege. They were happy to comply with such a reasonable request.
Now Olga gave to each soldier in her army a pigeon or a sparrow, and ordered them to attach by thread to each pigeon and sparrow a piece of sulfur bound with small pieces of cloth. When night fell, Olga bade her soldiers release the pigeons and the sparrows. So the birds flew to their nests, the pigeons to the cotes, and the sparrows under the eaves. The dove-cotes, the coops, the porches, and the haymows were set on fire. There was not a house that was not consumed, and it was impossible to extinguish the flames, because all the houses caught on fire at once. The people fled from the city, and Olga ordered her soldiers to catch them. Thus she took the city and burned it, and captured the elders of the city. Some of the other captives she killed, while some she gave to others as slaves to her followers. The remnant she left to pay tribute.
Regency.
In 947, Princess Olga launched a punitive expedition against the tribal elites between the Luga and the Msta River. Following this successful campaign, a number of forts were erected at Olga’s orders. One of them is supposed to be Gorodets in the Luga region a fortification dated to the middle of the tenth century. Because of its isolated location, Gorodets does not seem to have been in any way associated with the pre-existing settlement pattern. Moreover, the fort produced another example of square timber frames designed to consolidate the rampart that was seen at Ryurikovo Gorodishche. The same building technique was in use a century later in the Novgorod fortifications.
Olga remained regent ruler of Kievan Rus with the support of the army and her people. She changed the system of tribute gathering (poliudie) in the first legal reform recorded in Eastern Europe. She continued to evade proposals of marriage, defended the city during the Siege of Kiev in 968, and saved the power of the throne for her son.
Christianity.
Olga was the first ruler of Rus' to convert to Christianity, in either 945 or 957. The ceremonies of her formal reception in Constantinople were minutely described by Emperor Constantine VII in his book "De Ceremoniis". Following her baptism, Olga took the Christian name Yelena, after the reigning Empress Helena Lekapena. The Slavonic chronicles add apocryphal details to the account of her baptism, such as the story of how she charmed and "outwitted" Constantine and spurned his proposals of marriage. In actuality, at the time of her baptism, Olga was an old woman, while Constantine already had a wife.
Olga was one of the first people of Rus' to be canonized, proclaimed a saint for her efforts to spread Christianity throughout the country. Because of her proselytizing influence, the Orthodox Church calls Saint Olga by the honorific "Isapóstolos", "Equal to the Apostles". However, she failed to convert Svyatoslav, and it was left to her grandson and pupil, Vladimir I, to make Christianity the lasting state religion. During her son's prolonged military campaigns, she remained in charge of Kiev, residing in the castle of Vyshgorod together with her grandsons. She died soon after the Pechenegs' siege of the city, in 969.
Relations with the Holy Roman Emperor.
Seven Latin sources document Olga's embassy to Holy Roman Emperor Otto I in 959. The continuation of Regino of Prüm mentions that the envoys requested the Emperor to appoint a bishop and priests for their nation. The chronicler accuses the envoys of lies, commenting that their trick was not exposed until later. Thietmar of Merseburg says that the first archbishop of Magdeburg, Saint Adalbert of Magdeburg, before being promoted to this high rank, was sent by Emperor Otto to the country of the Rus' ("Rusciae") as a simple bishop but was expelled by pagan allies of Svyatoslav I. The same data is duplicated in the annals of Quedlinburg and Hildesheim, among others.

</doc>
<doc id="22818" url="https://en.wikipedia.org/wiki?curid=22818" title="Olympus Mons">
Olympus Mons

Olympus Mons (Latin for Mount Olympus) is a very large shield volcano on the planet Mars. By one measure, it has a height of nearly 25 km (16 mi). Olympus Mons
stands almost three times as tall as Mount Everest's height above sea level. It is the youngest of the large volcanoes on Mars, having formed during Mars's Amazonian Period. It is currently the largest volcano discovered in the Solar System and had been known to astronomers since the late 19th century as the albedo feature Nix Olympica (Latin for "Olympic Snow"). Its mountainous nature was suspected well before space probes confirmed its identity as a mountain.
The volcano is located in Mars's western hemisphere at approximately , just off the northwestern edge of the Tharsis bulge. The western portion of the volcano lies in the Amazonis quadrangle (MC-8) and the central and eastern portions in the adjoining Tharsis quadrangle (MC-9). Two impact craters on Olympus Mons have been assigned provisional names by the International Astronomical Union. They are the -diameter Karzok crater () and the -diameter Pangboche crater (). The craters are notable for being two of several suspected source areas for shergottites, the most abundant class of Martian meteorites.
Description.
As a shield volcano, Olympus Mons resembles in its morphology the large volcanoes making up the Hawaiian Islands. The edifice is about wide. Because the mountain is so large, with complex structure at its edges, allocating a height to the structure is difficult. It stands above the Mars global datum, and its local relief, from the foot of the cliffs which form its margin to the northwest to its peak, is nearly (a little over twice the height of Mauna Kea as measured from its base on the ocean floor). The total elevation change from the plains of Amazonis Planitia, over to the northwest, to the summit approaches . The summit of the mountain has six nested calderas (collapse craters) forming an irregular depression × across and up to deep. The volcano's outer edge consists of an escarpment, or cliff, up to tall, a feature unique among the shield volcanoes of Mars. Olympus Mons covers an area approximately the size of Arizona, or about .
Being a shield volcano, Olympus Mons has a very low profile. The average slope on the volcano's flanks is only 5°. Slopes are highest near the middle part of the flanks and grow shallower toward the base, giving the flanks a concave upward profile. The shape of Olympus Mons is distinctly unsymmetrical. Its flanks are shallower and extend out further from the summit in the northwestern direction than they do to the southeast. The volcano's shape and profile have been likened to a "circus tent" held up by a single pole that is shifted off center.
Because of the size of Olympus Mons and its shallow slopes, an observer standing on the Martian surface would be unable to view the entire profile of the volcano, even from a great distance. The curvature of the planet and the volcano itself would obscure such a synoptic view. Similarly, an observer near the summit would be unaware of standing on a high mountain, as the slope of the volcano would extend beyond the horizon, a mere 3 kilometers away.
The typical atmospheric pressure at the top of Olympus Mons is 72 pascal, about 12% of the average Martian surface pressure of 600 pascal. Both are exceedingly low by terrestrial standards. By comparison, the atmospheric pressure at the summit of Mount Everest is 32,000 pascals, or about 32% of Earth's sea level pressure. Even so, high-altitude orographic clouds frequently drift over the Olympus Mons summit, and airborne Martian dust is still present. Although the average Martian surface atmospheric pressure is less than one percent of Earth's, the much lower gravity on Mars increases the atmosphere's scale height; in other words, Mars's atmosphere is expansive and does not drop off in density with height as sharply as Earth's.
Olympus Mons is an unlikely landing location for automated space probes in the near future. The high elevations preclude parachute-assisted landings because of insufficient atmospheric thickness to slow the spacecraft down. Moreover, Olympus Mons stands in one of the dustiest regions of Mars. A mantle of fine dust covers much of the terrain, obscuring the underlying bedrock (rock samples might be hard to come by). The dust layer would also likely cause severe maneuvering problems for rovers.
Geology.
Olympus Mons is the result of many thousands of highly fluid, basaltic lava flows that poured from volcanic vents over a long period of time. (The Hawaiian Islands exemplify similar shield volcanoes on a smaller scale – see Mauna Kea.) The extraordinary size of Olympus Mons is likely because Mars lacks mobile tectonic plates. Unlike on Earth, the crust of Mars remains fixed over a stationary hotspot, and a volcano can continue to discharge lava until it reaches an enormous height.
The flanks of Olympus Mons are made up of innumerable lava flows and lava channels. Many of the flows have levees along their margins (pictured). Levees are parallel ridges formed at the edges of lava flows. The cooler, outer margins of the flow solidify, leaving a central trough of molten, flowing lava. Partially collapsed lava tubes are visible as chains of pit craters, and broad lava fans formed by lava emerging from intact, subsurface tubes are also common. In places along the volcano's base, lava flows can be seen spilling out into the surrounding plains, forming broad aprons, and burying the basal escarpment. (Note: Lava flows refer to both actively flowing lava and the solidified landforms they produce. The meaning here is the latter, since Mars has no active lava flows at the present time.) Crater counts from high-resolution images taken by the Mars Express orbiter in 2004 indicate that lava flows on the northwestern flank of Olympus Mons range in age from 115 million years old (Mya) to only 2 Mya. These ages are very recent in geological terms, suggesting that the mountain may still be volcanically active, though in a very quiescent and episodic fashion.
The caldera complex at the peak of the volcano is made of at least six overlapping calderas and caldera segments (pictured). Calderas are formed by roof collapse following depletion and withdrawal of the subsurface magma chamber after an eruption. Each caldera thus represents a separate pulse of volcanic activity on the mountain. The largest and oldest caldera segment appears to have formed as a single, large lava lake. The size of a caldera is a reflection of the size of the underlying magma chamber. Using geometric relationships of caldera dimensions from laboratory models, scientists have estimated that the magma chamber associated with the largest caldera on Olympus Mons lies at a depth of about below the caldera floor. Crater size-frequency distributions on the caldera floors indicate the calderas range in age from 350 Mya to about 150 Mya. All probably formed within 100 million years of each other.
Olympus Mons is asymmetrical structurally as well as topographically. The longer, more shallow northwestern flank displays extensional features, such as large slumps and normal faults. In contrast, the volcano's steeper southeastern side has features indicating compression. They include step-like terraces in the volcano's mid-flank region (interpreted as thrust faults) and a number of wrinkle ridges located at the basal escarpment. Why opposite sides of the mountain should show different styles of deformation is puzzling. The answer may lie in understanding how large shield volcanoes grow laterally and on how variations within the substrate of the volcano affect the final shape of the mountain.
Large shield volcanoes grow not only by adding material to their flanks as erupted lava, but also by spreading laterally at their bases. As a volcano grows in size, the stress field underneath the volcano changes from compressional to extensional. A subterranean rift may develop at the base of the volcano, causing the underlying crust to spread apart. If the volcano rests on sediments containing mechanically weak layers (e.g., beds of water-saturated clay), detachment zones (decollements) may develop in the weak layers. The extensional stresses in the detachment zones can produce giant landslides and normal faults on the volcano's flanks, leading to the formation of a basal escarpment. Further from the volcano, these detachment zones can express themselves as a succession of overlapping, gravity driven thrust faults. This mechanism has long been cited as an explanation of the Olympus Mons aureole deposits (discussed below).
Olympus Mons lies at the edge of the Tharsis bulge, a vast volcanic plateau that is very ancient. The formation of Tharsis was likely complete by the end of the Noachian Period. At the time Olympus Mons began to form in Hesperian times, the volcano was located on a shallow slope that descended from the high in Tharsis into the northern lowland basins. Over time, these basins would have received large volumes of sediment eroded from Tharsis and the southern highlands. The sediments likely contained abundant Noachian-aged phyllosilicates (clays) formed during an early period on Mars when surface water was abundant. The sediments would be thickest in the northwest where basin depth was greatest. As the volcano grew through lateral spreading, low-friction detachment zones preferentially developed in the thicker sediment layers to the northwest, creating the basal escarpment and widespread lobes of aureole material (Lycus Sulci). Spreading also occurred to the southeast; however, it was more constrained in that direction by the Tharsis rise, which presented a higher-friction zone at the volcano's base. Friction was higher in that direction because the sediments were thinner and probably consisted of coarser grained material resistant to sliding. The competent and rugged basement rocks of Tharsis acted as an additional source of friction. Thus, basal spreading of Olympus Mons was inhibited in the southeast direction, accounting for the structural and topographic asymmetry of the mountain. Numerical models of particle dynamics involving lateral differences in friction along the base of Olympus Mons have been shown to reproduce the volcano's present shape and asymmetry fairly well.
The detachment along the weak layers was likely aided by the presence of high-pressure water in the sediment pore spaces. This possibility has interesting astrobiological implications. If water-saturated zones still exist in sediments under the volcano, they would likely have been kept warm by a high geothermal gradient and residual heat from the volcano's magma chamber. Potential springs or seeps around the volcano would offer exciting possibilities for detecting microbial life.
Early observations and naming.
Olympus Mons and a few other volcanoes in the Tharsis region stand high enough to reach above the frequent Martian dust-storms recorded by telescopic observers as early as the 19th century. The astronomer Patrick Moore pointed out that Schiaparelli (1835–1910) "had found that his "Nodus Gordis" and "Olympic Snow" [Nix Olympica] were almost the only features to be seen" during dust storms, and "guessed correctly that they must be high".
The Mariner 9 spacecraft arrived in orbit around Mars in 1971 during a global dust-storm. The first objects to become visible as the dust began to settle, the tops of the Tharsis volcanoes, demonstrated that the altitude of these features greatly exceeded that of any mountain found on Earth, as astronomers expected. Observations of the planet from Mariner 9 confirmed that Nix Olympica was not just a mountain, but a volcano. Ultimately, astronomers adopted the name "Olympus Mons" for the albedo feature known as Nix Olympica.
Regional setting and surrounding features.
Olympus Mons is located between the northwestern edge of the Tharsis region and the eastern edge of Amazonis Planitia. It stands about from the other three large Martian shield volcanoes, collectively called the Tharsis Montes (Arsia Mons, Pavonis Mons, and Ascraeus Mons). The Tharsis Montes are slightly smaller than Olympus Mons.
A wide, annular depression or moat about deep surrounds the base of Olympus Mons and is thought to be due to the volcano's immense weight pressing down on the Martian crust. The depth of this depression is greater on the northwest side of the mountain than on the southeast side.
Olympus Mons is partially surrounded by a region of distinctive grooved or corrugated terrain known as the Olympus Mons aureole. The aureole consists of several large lobes. Northwest of the volcano, the aureole extends a distance of up to and is known as Lycus Sulci (). East of Olympus Mons, the aureole is partially covered by lava flows, but where it is exposed it goes by different names (Gigas Sulci, for example). The origin of the aureole remains debated, but it was likely formed by huge landslides or gravity-driven thrust sheets that sloughed off the edges of the Olympus Mons shield.

</doc>
<doc id="22820" url="https://en.wikipedia.org/wiki?curid=22820" title="Odobenidae">
Odobenidae

Odobenidae is a family of Pinnipeds. The only living species is the walrus.
In the past, however, the group was much more diverse, and includes more than ten fossil genera.
Taxonomy.
All genera, except "Odobenus", are extinct.

</doc>
<doc id="22826" url="https://en.wikipedia.org/wiki?curid=22826" title="Object database">
Object database

An object database (also object-oriented database management system) is a database management system in which information is represented in the form of objects as used in object-oriented programming. Object databases are different from relational databases which are table-oriented. Object-relational databases are a hybrid of both approaches.
Object databases have been considered since the early 1980s.
Overview.
Object-oriented database management systems (OODBMSs) combine database capabilities with object-oriented programming language capabilities.
OODBMSs allow object-oriented programmers to develop the product, store them as objects, and replicate or modify existing objects to make new objects within the OODBMS. Because the database is integrated with the programming language, the programmer can maintain consistency within one environment, in that both the OODBMS and the programming language will use the same model of representation. Relational DBMS projects, by way of contrast, maintain a clearer division between the database model and the application.
As the usage of web-based technology increases with the implementation of Intranets and extranets, companies have a vested interest in OODBMSs to display their complex data. Using a DBMS that has been specifically designed to store data as objects gives an advantage to those companies that are geared towards multimedia presentation or organizations that utilize computer-aided design (CAD).
Some object-oriented databases are designed to work well with object-oriented programming languages such as Delphi, Ruby, Python, Perl, Java, C#, Visual Basic .NET, C++, Objective-C and Smalltalk; others have their own programming languages. OODBMSs use exactly the same model as object-oriented programming languages.
History.
Object database management systems grew out of research during the early to mid-1970s into having intrinsic database management support for graph-structured objects. The term "object-oriented database system" first appeared around 1985. Notable research projects included Encore-Ob/Server (Brown University), EXODUS (University of Wisconsin–Madison), IRIS (Hewlett-Packard), ODE (Bell Labs), ORION (Microelectronics and Computer Technology Corporation or MCC), Vodak (GMD-IPSI), and Zeitgeist (Texas Instruments). The ORION project had more published papers than any of the other efforts. Won Kim of MCC compiled the best of those papers in a book published by The MIT Press.
Early commercial products included Gemstone (Servio Logic, name changed to GemStone Systems), Gbase (Graphael), and Vbase (Ontologic). The early to mid-1990s saw additional commercial products enter the market. These included ITASCA (Itasca Systems), Jasmine (Fujitsu, marketed by Computer Associates), Matisse (Matisse Software), Objectivity/DB (Objectivity, Inc.), ObjectStore (Progress Software, acquired from eXcelon which was originally Object Design), ONTOS (Ontos, Inc., name changed from Ontologic), O2 (O2 Technology, merged with several companies, acquired by Informix, which was in turn acquired by IBM), POET (now FastObjects from Versant which acquired Poet Software), Versant Object Database (Versant Corporation), VOSS (Logic Arts) and JADE (Jade Software Corporation). Some of these products remain on the market and have been joined by new open source and commercial products such as InterSystems Caché.
Object database management systems added the concept of persistence to object programming languages. The early commercial products were integrated with various languages: GemStone (Smalltalk), Gbase (LISP), Vbase (COP) and VOSS (Virtual Object Storage System for Smalltalk). For much of the 1990s, C++ dominated the commercial object database management market. Vendors added Java in the late 1990s and more recently, C#.
Starting in 2004, object databases have seen a second growth period when open source object databases emerged that were widely affordable and easy to use, because they are entirely written in OOP languages like Smalltalk, Java, or C#, such as Versant's db4o (db4objects), DTS/S1 from Obsidian Dynamics and Perst (McObject), available under dual open source and commercial licensing.
Adoption of object databases.
Object databases based on persistent programming acquired a niche in application areas such as
engineering and spatial databases, telecommunications, and scientific areas such as high energy physics and molecular biology.
Another group of object databases focuses on embedded use in devices, packaged software, and real-time systems.
Technical features.
Most object databases also offer some kind of query language, allowing objects to be found using a declarative programming approach. It is in the area of object query languages, and the integration of the query and navigational interfaces, that the biggest differences between products are found. An attempt at standardization was made by the ODMG with the Object Query Language, OQL.
Access to data can be faster because joins are often not needed (as in a tabular implementation of a relational database). This is because an object can be retrieved directly without a search, by following pointers.
Another area of variation between products is in the way that the schema of a database is defined. A general characteristic, however, is that the programming language and the database schema use the same type definitions.
Multimedia applications are facilitated because the class methods associated with the data are responsible for its correct interpretation.
Many object databases, for example Gemstone or VOSS, offer support for versioning. An object can be viewed as the set of all its versions. Also, object versions can be treated as objects in their own right. Some object databases also provide systematic support for triggers and constraints which are the basis of active databases.
The efficiency of such a database is also greatly improved in areas which demand massive amounts of data about one item. For example, a banking institution could get the user's account information and provide them efficiently with extensive information such as transactions, account information entries etc. The Big O Notation for such a database paradigm drops from O(n) to O(1), greatly increasing efficiency in these specific cases.
Standards.
The Object Data Management Group was a consortium of object database and object-relational mapping vendors, members of the academic community, and interested parties. Its goal was to create a set of specifications that would allow for portable applications that store objects in database management systems. It published several versions of its specification. The last release was ODMG 3.0. By 2001, most of the major object database and object-relational mapping vendors claimed conformance to the ODMG Java Language Binding. Compliance to the other components of the specification was mixed. In 2001, the ODMG Java Language Binding was submitted to the Java Community Process as a basis for the Java Data Objects specification. The ODMG member companies then decided to concentrate their efforts on the Java Data Objects specification. As a result, the ODMG disbanded in 2001.
Many object database ideas were also absorbed into and have been implemented in varying degrees in object-relational database products.
In 2005 Cook, Rai, and Rosenberger proposed to drop all standardization efforts to introduce additional object-oriented query APIs but rather use the OO programming language itself, i.e., Java and .NET, to express queries. As a result, Native Queries emerged. Similarly, Microsoft announced Language Integrated Query (LINQ) and DLINQ, an implementation of LINQ, in September 2005, to provide close, language-integrated database query capabilities with its programming languages C# and VB.NET 9.
In February 2006, the Object Management Group (OMG) announced that they had been granted the right to develop new specifications based on the ODMG 3.0 specification and the formation of the Object Database Technology Working Group (ODBT WG). The ODBT WG planned to create a set of standards that would incorporate advances in object database technology (e.g., replication), data management (e.g., spatial indexing), and data formats (e.g., XML) and to include new features into these standards that support domains where object databases are being adopted (e.g., real-time systems). The work of the ODBT WG was suspended in March 2009 when, subsequent to the economic turmoil in late 2008, the ODB vendors involved in this effort decided to focus their resources elsewhere.
In January 2007 the World Wide Web Consortium gave final recommendation status to the XQuery language. XQuery uses XML as its data model. Some of the ideas developed originally for object databases found their way into XQuery, but XQuery is not intrinsically object-oriented. Because of the popularity of XML, XQuery engines compete with object databases as a vehicle for storage of data that is too complex or variable to hold conveniently in a relational database. XQuery also allows modules to be written to provide encapsulation features that have been provided by Object-Oriented systems.
Comparison with RDBMSs.
An object database stores complex data and relationships between data directly, without mapping to relational rows and columns, and this makes them suitable for applications dealing with very complex data. Objects have a many to many relationship and are accessed by the use of pointers. Pointers are linked to objects to establish relationships. Another benefit of an OODBMS is that it can be programmed with small procedural differences without affecting the entire system.

</doc>
<doc id="22827" url="https://en.wikipedia.org/wiki?curid=22827" title="Ovo-lacto vegetarianism">
Ovo-lacto vegetarianism

An ovo-lacto vegetarian (or lacto-ovo vegetarian) is a vegetarian who does not eat any meat, fish, or poultry. A typical ovo-lacto vegetarian diet includes fruits, vegetables, grains, legumes, nuts, seeds, dairy, and egg products.
Etymology.
The terminology stems from the Latin ' meaning "milk" (as in 'lactation'), ' meaning "egg", and the English term "vegetarian", so as giving the definition of a vegetarian diet containing milk and eggs.
Diet.
In the Western World, ovo-lacto vegetarians are the most common type of vegetarian. Generally speaking, when one uses the term "vegetarian" an ovo-lacto vegetarian is assumed. Ovo-lacto vegetarians are often well-catered to in restaurants and shops, especially in some parts of Europe and metropolitan cities in North America.
Religion.
In Jainism, all individuals eat only food materials derived from plant sources and milk/milk products, and are therefore lacto vegetarians. Jainism prohibits causing harm to any animal, even eggs, as hurting a living being is against the values of Jainism.
In Hinduism, many individuals are either raised as ovo-lacto vegetarians or lacto vegetarians.
The Bible Christian Church was a Christian vegetarian sect founded by William Cowherd in 1809. Cowherd was one of the philosophical forerunners of the Vegetarian Society founded in 1847. The Bible Christian Church promoted the use of eggs, dairy and honey as God's given food per "the promised land flowing with milk and honey" (Exodus 3:8).
Many Seventh-day Adventist followers are lacto-ovo vegetarians. For over 130 years, Seventh-day Adventists have recommended a vegetarian diet which may include milk products and eggs.

</doc>
<doc id="22829" url="https://en.wikipedia.org/wiki?curid=22829" title="Orgy of the Dead">
Orgy of the Dead

Orgy of the Dead is a 1965 erotic horror film directed by Stephen C. Apostolof under the alias A. C. Stephen. The screenplay was adapted by cult film director Edward D. Wood Jr. from his own novel.
Genre.
The film belongs to the genre of nudie cuties, narrative-based films featuring female nudity. It was an evolution of earlier films, which featured striptease and burlesque shows. These predecessors mostly depicted actual stage performances, sometimes attached to a frame story.
Plot.
The film opens to two muscle-bound men dressed in loincloths approaching a crypt. They open the doors, revealing a coffin. They remove the lid and exit the crypt, then the inhabitant of the coffin (Criswell) sits up to deliver an opening narration. This narration mostly matches the prologue of "Night of the Ghouls" (1959), with one minor variation and an additional line. The phrase "world between the living and the dead" of the original is changed to "void between...". There is also a new line at the end: "A night with the ghouls, the ghouls reborn, from the innermost depths of the world!" The opening credits feature the image of "an immobile young woman clad in gold". The image was probably inspired by a memorable scene of "Goldfinger" (1964).
Following the credits, the camera shifts to a lone Chevrolet Corvair driving down a California desert road. Its passengers Bob (William Bates) and Shirley (Pat Barrington) are arguing over the decision to use this night to search for a cemetery. Bob is a horror writer who hopes that the scene of a cemetery at night will bring him inspiration. The conversation ends when Bob accidentally drives the car off the road and over a cliff.
The next scene opens to a nocturnal image of a fog-shrouded cemetery. The lonely figure of the Emperor (Criswell) walks towards a marble altar, sits, and then summons his "Princess of the Night", the Black Ghoul (Fawn Silver), who appears and bows before him. The Emperor warns that if the night's entertainment fails to please him, he will banish the souls of the entertainers to eternal damnation, indicating that he is an all-powerful demonic being.
As the full moon appears, the Black Ghoul summons the first dancer of the night, a Native American woman (Bunny Glaser). The Black Ghoul explains that this woman loved flames, and that both she and her lovers died in flames. The woman dances and strips before the flames of the cemetery. The Black Ghoul then introduces the second dancer of the night, a street walker in life. While the woman dances, Bob and Shirley make their way to the cemetery and start observing the dance from a distance. Shirley suspects that they are observing a college initiation, though Bob seriously doubts her theory.
The Emperor himself summons the third dancer, a woman who worshiped gold above else. The Golden Girl (Pat Barrington) dances in her turn, and the Emperor instructs his loin-clothed servants to reward her with gold. The supposed reward is soon revealed to be a punishment, as the servants place her in a cauldron with liquid gold. What emerges from the cauldron is a golden statue of the living woman who entered. The servants transport the immobile statue to a nearby crypt.
At this point, a werewolf (John Andrews) and mummy (Louis Ojena) appear and seize the intruding young couple. They are brought before the Emperor who decides to postpone deciding their fate. The intruders are tied up, side by side, and allowed to continue watching the dances. The Black Ghoul next introduces the fourth dancer, a "Cat Woman" (Texas Starr). She is depicted as a woman dressed in a leopard costume, which exposes her chest area. As she dances, a servant follows her around and thrashes her with a bullwhip. Offering a sadomasochistic show for the spectators.
The Emperor next calls for a Slave Girl (Nadejda Dobrev) to be whipped for his amusement. The slave wears a tunic and is chained to a wall. Following her torture session, the Slave Girl breaks free and becomes the fifth dancer of the night. Later, the Black Ghoul exhibits a fascination with Shirley and scratches a mark on her. She draws a knife and seems about to kill Shirley, when the Emperor decides it is not yet time for the intruders to properly join them. The female ghoul reluctantly obeys.
The Emperor is puzzled when a human skull appears instead of the next dancer. The Black Ghoul explains it is the symbol of the sixth dancer, who loved bullfighting and matadors. She used to dance over their demise, and now it's time to dance over her own. The dancer of apparent Spanish/Mexican heritage (Stephanie Jones) appears to perform. The Emperor and Ghoul briefly discuss the past of the dancer, who came to them on the Day of the Dead. The seventh dancer appears dressed in Polynesian garments. The Black Ghoul describes her as a worshiper of snakes, smoke, and flames. A rattlesnake is depicted along with her dance. The camera shifts to the mummy and the werewolf. The mummy voices his dislike of snakes and recalls the death of Cleopatra. He informs his companion that ancient Egypt had many snakes and they were the stuff of nightmares.
The Emperor next expresses his boredom and demands "unusual" entertainment, while the Black Ghoul notes that the night is almost over. She reminds her superior that they will be gone at the first sight of the morning sun. They proceed to argue over the fate of Shirley. The argument ends with the introduction of the eighth dancer (Barbara Nordin), a woman who murdered her husband on their wedding night. She dances with the skeleton of her spouse. The argument over Shirley then resumes, as the Ghoul claims her for her own. The Emperor feels the need to assert his own authority over the Black Ghoul.
The ninth dancer (Dene Starnes) was a zombie in life and remains zombie-like in death. The tenth and final dancer (Rene De Beau) is introduced as one who died for feathers, fur, and fluff. She starts her dance in clothing matching this style. When the final dance ends, the Emperor finally offers Shirley to the Ghoul. The Ghoul briefly dances herself as she prepares to claim her prize. But dawn arrives and with it sunlight. The Emperor and all his undead are reduced to bones. The final scene has Bob and Shirley waking up at the scene of the accident, surrounded by paramedics, suggesting it was all a dream. Criswell appears in his coffin to offer parting words to the audience.
Production and casting.
The film's graveyard prologue is a recreation of the opening scene from Ed Wood's then-unreleased 1958 film "Night of the Ghouls". Criswell reprises his role from the earlier film. The action begins when a young couple, Bob (William Bates) and Shirley (sexploitation actress Pat Barrington, billed as Pat Barringer) survive a car crash only to find themselves tied to posts in a misty cemetery where they are forced to watch dead spirits dance for the Emperor of the Night played by Criswell (best known for "Plan 9 from Outer Space"). Ten striptease performances by topless dancers from beyond the grave outfitted in various motifs comprise most of this movie. The Wolf Man (wearing a very obvious mask) and The Mummy are also tossed in for comic relief. Barrington doubles as the blond Gold Girl (inspired by Shirley Eaton in "Goldfinger") while her red-headed "Shirley" character watches her perform. Criswell's undead consort, the sexy Black Ghoul, was written for Maila Nurmi, a.k.a. Vampira, but was instead played by Fawn Silver, who wore a black bouffant wig.
Wood served as writer, production manager, casting agent, and even held up cue cards on this low-budget film, although he did not direct. An article on the making of this film was published in "Femme Fatales", 7:1 (June 1998).
The cape worn by Criswell as The Emperor is the same cape worn by Bela Lugosi as Count Dracula in Bud Abbott Lou Costello Meet Frankenstein (1948). 
The film based on the novel by Edward D. Wood Jr. has no werewolf character, like in the film. Wood received $600 for the novel.
The Black Ghoul appears to have "pasty white skin", with red fingernails and lipstick. She wears a black dress, implying the role of a funerary garment. Black, red, and white are the main colors associated with her.

</doc>
<doc id="22830" url="https://en.wikipedia.org/wiki?curid=22830" title="Ostwald process">
Ostwald process

The Ostwald process is a chemical process for making nitric acid (HNO3). Wilhelm Ostwald developed the process, and he patented it in 1902. The Ostwald process is a mainstay of the modern chemical industry, and it provides the main raw material for the most common type of fertilizer production. Historically and practically, the Ostwald process is closely associated with the Haber process, which provides the requisite raw material, ammonia (NH3).
Description.
Ammonia is converted to nitric acid in 2 stages. It is oxidized (in a sense "burnt") by heating with oxygen in the presence of a catalyst such as platinum with 10% rhodium, to form nitric oxide and water. This step is strongly exothermic, making it a useful heat source once initiated:
Stage two encompasses two reactions and is carried out in an absorption apparatus containing water. Initially nitric oxide is oxidized again to yield nitrogen dioxide: This gas is then readily absorbed by the water, yielding the desired product (nitric acid, albeit in a dilute form), while reducing a portion of it back to nitric oxide:
The NO is recycled, and the acid is concentrated to the required strength by distillation.
Alternatively, if the last step is carried out in air:
Typical conditions for the first stage, which contribute to an overall yield of about 98%, are:
A complication that needs to be taken into consideration involves a side-reaction in the first step that reverts the nitric oxide back to :
This is a secondary reaction that is minimised by reducing the time the gas mixtures are in contact with the catalyst.

</doc>
<doc id="22831" url="https://en.wikipedia.org/wiki?curid=22831" title="Oliver Heaviside">
Oliver Heaviside

Oliver Heaviside FRS (; 18 May 1850 – 3 February 1925) was a self-taught English electrical engineer, mathematician, and physicist who adapted complex numbers to the study of electrical circuits, invented mathematical techniques for the solution of differential equations (later found to be equivalent to Laplace transforms), reformulated Maxwell's field equations in terms of electric and magnetic forces and energy flux, and independently co-formulated vector analysis. Although at odds with the scientific establishment for most of his life, Heaviside changed the face of telecommunications, mathematics, and science for years to come.
Biography.
Early years.
Heaviside was born at 55 Kings Street (now Plender Street) in London's Camden Town. He was short and red-headed, and suffered from scarlet fever when young, which left him with a hearing impairment. A small legacy enabled the family to move to a better part of Camden when he was thirteen and he was sent to Camden House Grammar School. He was a good student (i.e. placed fifth out of five hundred students in 1865) but his parents couldn't keep him at school after he was 16 so he continued studying for a year by himself and had no further formal education.
Heaviside's uncle by marriage was Sir Charles Wheatstone (1802–1875), the original co-inventor of the first commercially successful telegraph in the mid-1830s, and an internationally celebrated expert in telegraphy and electromagnetism. Wheatstone took a strong interest in his nephew's education and in 1867 sent him north to work with his older brother Arthur who was managing one of Wheatstone's telegraph companies in Newcastle-upon-Tyne.
Two years later he took a job as a telegraph operator with the Danish Great Northern Telegraph Company laying a cable from Newcastle to Denmark using British contractors, soon becoming an electrician. Heaviside continued to study while working, and by the age of 22 he published an article in the prestigious Philosophical Magazine on "The Best Arrangement of Wheatstone's Bridge for measuring a Given Resistance with a Given Galvanometer and Battery" which received positive comments from physicists who had unsuccessfully tried to solve this algebraic problem, including Sir William Thomson, to whom he gave a copy of the paper, and James Clerk Maxwell. However, when he published an article on the duplex method of using a telegraph cable, he poked fun at R. S. Culley, the engineer in chief of the Post Office telegraph system who had been dismissing duplex as impractical. Later in 1873 his application to join the Society of Telegraph Engineers was turned down with the comment that "they didn't want telegraph clerks". This riled Heaviside who asked Thomson to sponsor him, and with the support also of the president he was admitted "despite the P.O. snobs".
In 1873 Heaviside had encountered Maxwell's newly published, and today famous, two-volume "Treatise on Electricity and Magnetism". In his old age Heaviside recalled:
Doing research from home, he helped develop transmission line theory (also known as the "telegrapher's equations"). Heaviside showed mathematically that uniformly distributed inductance in a telegraph line would diminish both attenuation and distortion, and that, if the inductance were great enough and the insulation resistance not too high, the circuit would be distortionless while currents of all frequencies would have equal speeds of propagation. Heaviside's equations helped further the implementation of the telegraph.
Middle years.
From 1882 to 1902, except for three years, he contributed regular articles to the trade paper "The Electrician", which wished to improve its standing, for which he was paid £40 per year. This was hardly enough to live on, but his demands were very small and he was doing what he most wanted to. Between 1883 and 1887 these averaged 2–3 articles per month and these articles later formed the bulk of his "Electromagnetic Theory" and "Electrical Papers".
In 1880, Heaviside researched the skin effect in telegraph transmission lines. That same year he patented, in England, the coaxial cable. In 1884 he recast Maxwell's mathematical analysis from its original cumbersome form (they had already been recast as quaternions) to its modern vector terminology, thereby reducing twelve of the original twenty equations in twenty unknowns down to the four differential equations in two unknowns we now know as Maxwell's equations. The four re-formulated Maxwell's equations describe the nature of electric charges (both static and moving), magnetic fields, and the relationship between the two, namely electromagnetic fields.
Between 1880 and 1887, Heaviside developed the operational calculus (involving the "D" notation for the differential operator, which he is credited with creating), a method of solving differential equations by transforming them into ordinary algebraic equations which caused a great deal of controversy when first introduced, owing to the lack of rigour in his derivation of it. He famously said, "Mathematics is an experimental science, and definitions do not come first, but later on." He was replying to criticism over his use of operators that were not clearly defined. On another occasion he stated somewhat more defensively, "I do not refuse my dinner simply because I do not understand the process of digestion."
In 1887, Heaviside worked with his brother Arthur on a paper entitled "The Bridge System of Telephony". However the paper was blocked by Arthur's superior, William Henry Preece of the Post Office, because part of the proposal was that loading coils (inductors) should be added to telephone and telegraph lines to increase their self-induction and correct the distortion which they suffered. Preece had recently declared self-inductance to be the great enemy of clear transmission. Heaviside was also convinced that Preece was behind the sacking of the editor of "The Electrician" which brought his long-running series of articles to a halt (until 1891). There was a long history of animosity between Preece and Heaviside. Heaviside considered Preece to be mathematically incompetent; an assessment supported by the biographer Paul J. Nahin: "Preece was a powerful government official, enormously ambitious, and in some remarkable ways, an utter blockhead." Preece's motivations in suppressing Heaviside's work were more to do with protecting Preece's own reputation and avoiding having to admit error than any perceived faults in Heaviside's work.
The importance of Heaviside's work remained undiscovered for some time after publication in "The Electrician", and so its rights lay in the public domain. In 1897, AT&T employed one of its own scientists, George A. Campbell, and an external investigator Michael I. Pupin to find some respect in which Heaviside's work was incomplete or incorrect. Campbell and Pupin extended Heaviside's work, and AT&T filed for patents covering not only their research, but also the technical method of constructing the coils previously invented by Heaviside. AT&T later offered Heaviside money in exchange for his rights; it is possible that the Bell engineers' respect for Heaviside influenced this offer. However, Heaviside refused the offer, declining to accept any money unless the company were to give him full recognition. Heaviside was chronically poor, making his refusal of the offer even more striking.
But this setback had the effect of turning Heaviside's attention towards electromagnetic radiation, and in two papers of 1888 and 1889, Heaviside calculated the deformations of electric and magnetic fields surrounding a moving charge, as well as the effects of it entering a denser medium. This included a prediction of what is now known as Cherenkov radiation, and inspired his friend George FitzGerald to suggest what now is known as the Lorentz–FitzGerald contraction.
In 1889, Heaviside first published a correct derivation of the magnetic force on a moving charged particle, which is now called the Lorentz Force.
In the late 1880s and early 1890s, Heaviside worked on the concept of electromagnetic mass. Heaviside treated this as material mass, capable of producing the same effects. Wilhelm Wien later verified Heaviside's expression (for low velocities).
In 1891 the British Royal Society recognized Heaviside's contributions to the mathematical description of electromagnetic phenomena by naming him a Fellow of the Royal Society, and the following year devoting more than fifty pages of the "Philosophical Transactions" of the Society to his vector methods and electromagnetic theory. In 1905 Heaviside was given an honorary doctorate by the University of Göttingen.
Later years and views.
In 1896, FitzGerald and John Perry obtained a civil list pension of £120 per year for Heaviside, who was now living in Devon, and persuaded him to accept it, after he had rejected other charitable offers from the Royal Society.
In 1902, Heaviside proposed the existence of what is now known as the Kennelly–Heaviside layer of the ionosphere. Heaviside's proposal included means by which radio signals are transmitted around the Earth's curvature. The existence of the ionosphere was confirmed in 1923. The predictions by Heaviside, combined with Planck's radiation theory, probably discouraged further attempts to detect radio waves from the Sun and other astronomical objects. For whatever reason, there seem to have been no attempts for 30 years, until Jansky's development of radio astronomy in 1932.
In later years his behavior became quite eccentric. According to associate B. A. Behrend, he became a recluse who was so averse to meeting people that he delivered the manuscripts of his "Electrician" papers to a grocery store, where the editors picked them up. Though he had been an active cyclist in his youth, his health seriously declined in his sixth decade. During this time Heaviside would sign letters with the initials "W.O.R.M."" after his name. Heaviside also reportedly started painting his fingernails pink and had granite blocks moved into his house for furniture. In 1922, he became the first recipient of the Faraday Medal, which was established that year.
On Heaviside's religious views, he was a Unitarian, but not a religious one. He was even said to have made fun of people who put their faith in a supreme being.
Heaviside died at Torquay in Devon, and is buried near the eastern corner of Paignton cemetery. He is buried with his father, Thomas Heaviside and his mother, Rachel Elizabeth Heaviside. The gravestone was cleaned thanks to an anonymous donor sometime in 2005. Most of his recognition was gained posthumously.
Heaviside Memorial Project.
In July 2014, academics at Newcastle University, UK and the Newcastle Electromagnetics Interest Group founded the Heaviside Memorial Project in a bid to fully restore the monument through public subscription. The restored memorial was ceremonially unveiled on 30 August 2014 by Alan Heather, a distant relative of Heaviside. The unveiling was attended by the Mayor of Torbay, the MP for Torbay, an ex-curator of the Science Museum (representing the Institution of Engineering and Technology), the Chairman of the Torbay Civic Society, and delegates from Newcastle University.
Innovations and discoveries.
Heaviside did much to develop and advocate vector methods and the vector calculus. Maxwell's formulation of electromagnetism consisted of 20 equations in 20 variables. Heaviside employed the curl and divergence operators of the vector calculus to reformulate 12 of these 20 equations into four equations in four variables (B, E, J, and ρ), the form by which they have been known ever since (see Maxwell's equations). Less well known is that Heaviside's equations and Maxwell's are not exactly the same, and in fact it is easier to modify the latter to make them compatible with quantum physics.
He invented the Heaviside step function and employed it to model the current in an electric circuit. He invented the operator method for solving linear differential equations, which resembles current Laplace transform methods (see inverse Laplace transform, also known as the "Bromwich integral"). The UK mathematician Thomas John I'Anson Bromwich later devised a rigorous mathematical justification for Heaviside's operator method.
Heaviside advanced the idea that the Earth's uppermost atmosphere contained an ionized layer known as the ionosphere; in this regard, he predicted the existence of what later was dubbed the Kennelly–Heaviside layer. In 1945 Edward Victor Appleton received the Nobel Prize in Physics for proving that this layer really existed. Heaviside developed the transmission line theory (also known as the "telegrapher's equations"), which had the effect of increasing the transmission rate over transatlantic cables by a factor of ten. It originally took ten minutes to transmit each character, and this immediately improved to one character per minute. Closely related to this was his discovery that telephone transmission could be greatly improved by placing electrical inductance in series with the cable. Heaviside also independently discovered the Poynting vector.
Electromagnetic terms.
Heaviside coined the following terms of art in electromagnetic theory:
Further reading.
Sorted by date.

</doc>
<doc id="22832" url="https://en.wikipedia.org/wiki?curid=22832" title="Book of Omni">
Book of Omni

The Book of Omni is one of the books that make up the Book of Mormon. The book contains only one chapter although it covers more than two centuries of Nephite history (from "ca" 323 BC to 130 BC, according to footnotes).
The record passes from generation to generation.
Nephi, who wrote First and Second Nephi forged the record, a book written on sheets, or plates of gold.
Nephi passed them to his brother Jacob,
Jacob passed them to his son Enos,
Enos passed them to his son Jarom,
Jarom passes them to his son Omni.
In the Book of Omni, we find that:
Omni passes them to his son Amaron, ()
Amaron passes them to his brother Chemish, ()
Chemish passes them to his son Abinadom, ()
Abinadom passes them to his son Amaleki ().
The moral and general civilizational decline of the Nephites is reflected in the fact that with the exception of Abinadom who writes slightly more than his father Chemish, each successive author from Nephi to Abinadom writes less than his predecessor. The final author of the Book of Omni and the Small Plates of Nephi, Amaleki, breaks this general rule. Much like Mormon (who may have taken Amaleki as his model), this last historian of the civilization that lasted for 400 years in the land of Nephi rose to the occasion and, filled with a sense of longing for what has been lost, eloquently recounted the last days of the Nephite people in their ancestral homeland, the land of Nephi.
Narrative.
The initial author was Omni, but several others were charged with keeping the record as time passed, though few made significant contributions. Verse 5 explains that "the more wicked part of the Nephites were destroyed." There is little detail about the destruction, except to say that the Lord did visit them in great judgment because of their wickedness.
Abinadom speaks of many wars between the people of Nephi and the Lamanites.
Amaleki speaks of the then current Nephite king, named Mosiah. As had happened previously, the Lord told the king (who appears to be a spiritual leader [prophet] as well as a secular leader) to lead the righteous Nephites out of the land of Nephi, their ancestral home for the previous 400 years, to a new place. At the end of their journey they discover the Mulekite people whose ancestors had also come from Jerusalem, but after it was attacked by the Babylonians. These people, however, did not bring religious or historical records with them which had two results—they had lost their religion, and they were unable to preserve their language from generation to generation. These people are known as the people of Zarahemla (the name of their then current king and also the name given to the land). Mosiah arranges for the people of Zarahemla to be taught the Nephite language, and Zarahemla is able to recount to him their oral history.
The two groups of people united themselves with Mosiah as their king, and they are all known as Nephites.
The first mention of the Jaredites is found here as well. A large stone is found with writing on it. Mosiah is able to "interpret the engravings by the gift and power of God." It tells of a man named Coriantumr and the downfall of his people. Their history is recounted more fully in the Book of Ether.
Mosiah, the king dies and his son, Benjamin, becomes king. There is a war between the Nephites led by Benjamin and the Lamanites, which by this time is nothing new.
It is apparent that many of the Nephites were reluctant to leave their long-time homeland. Ameliki describes how some of the Nephites wished to return to the land of Nephi, apparently in an attempt to reclaim it. At the time Ameliki stops writing, he has not received word of them, including his brother who is among them.
Amaleki closes with some words about Christ, asserting that his words are true and that it is his intent to help others come unto Christ. He states at the close of the book that, having no descendants to carry on the record-keeping, he will give the records to King Benjamin.
The plates.
The Book of Omni is notable also for being the last of the books contained on the Small Plates of Nephi, one of two major divisions of the gold plates which Joseph Smith translated to obtain the Book of Mormon.
From First Nephi to the end of Omni, the book is a first person narrative of the writers (although there are many quotations). The book immediately following Omni, the Words of Mormon, is an editorial insertion that explains how the first person narrative came to be inserted into the Book of Mormon and how subsequent narrative will differ, being mostly third person narration by Mormon that summarizes more lengthy accounts taken from the Large Plates of Nephi. This third person record extends from Mosiah to Fourth Nephi.

</doc>
<doc id="22834" url="https://en.wikipedia.org/wiki?curid=22834" title="Ozone layer">
Ozone layer

The ozone layer or ozone shield refers to a region of Earth's stratosphere that absorbs most of the Sun's ultraviolet (UV) radiation. It contains high concentrations of ozone (O3) relative to other parts of the atmosphere, although still very small relative to other gases in the stratosphere. The ozone layer contains less than 10 parts per million of ozone, while the average ozone concentration in Earth's atmosphere as a whole is only about 0.3 parts per million. The ozone layer is mainly found in the lower portion of the stratosphere, from approximately above Earth, though the thickness varies seasonally and geographically.
The ozone layer was discovered in 1913 by the French physicists Charles Fabry and Henri Buisson. Its properties were explored in detail by the British meteorologist G. M. B. Dobson, who developed a simple spectrophotometer (the Dobsonmeter) that could be used to measure stratospheric ozone from the ground. Between 1928 and 1958, Dobson established a worldwide network of ozone monitoring stations, which continue to operate to this day. The "Dobson unit", a convenient measure of the amount of ozone overhead, is named in his honor.
The ozone layer absorbs 97–99% of the Sun's medium-frequency ultraviolet light (from about 200 nm to 315 nm wavelength), which otherwise would potentially damage exposed life forms near the surface.
The United Nations General Assembly has designated September 16 as the International Day for the Preservation of the Ozone Layer.
Venus also has a thin ozone layer at an altitude of 100 kilometers from the planet's surface.
Sources.
The photochemical mechanisms that give rise to the ozone layer were discovered by the British physicist Sydney Chapman in 1930. Ozone in the Earth's stratosphere is created by ultraviolet light striking ordinary oxygen molecules containing two oxygen atoms (O2), splitting them into individual oxygen atoms (atomic oxygen); the atomic oxygen then combines with unbroken O2 to create ozone, O3. The ozone molecule is unstable (although, in the stratosphere, long-lived) and when ultraviolet light hits ozone it splits into a molecule of O2 and an individual atom of oxygen, a continuing process called the ozone-oxygen cycle.
Chemically, this can be described as:
About 90% of the ozone in our atmosphere is contained in the stratosphere. Ozone concentrations are greatest between about , where they range from about 2 to 8 parts per million. If all of the ozone were compressed to the pressure of the air at sea level, it would be only thick.
Ultraviolet light.
Although the concentration of the ozone in the ozone layer is very small, it is vitally important to life because it absorbs biologically harmful ultraviolet (UV) radiation coming from the sun. Extremely short or vacuum UV (10–100 nm) is screened out by nitrogen. UV radiation capable of penetrating nitrogen is divided into three categories, based on its wavelength; these are referred to as UV-A (400–315 nm), UV-B (315–280 nm), and UV-C (280–100 nm).
UV-C, which is very harmful to all living things, is entirely screened out by a combination of dioxygen (< 200 nm) and ozone (> about 200 nm) by around altitude. UV-B radiation can be harmful to the skin and is the main cause of sunburn; excessive exposure can also cause cataracts, immune system suppression, and genetic damage, resulting in problems such as skin cancer. The ozone layer (which absorbs from about 200 nm to 310 nm with a maximal absorption at about 250 nm) is very effective at screening out UV-B; for radiation with a wavelength of 290 nm, the intensity at the top of the atmosphere is 350 million times stronger than at the Earth's surface. Nevertheless, some UV-B, particularly at its longest wavelengths, reaches the surface, and is important for the skin's production of vitamin D.
Ozone is transparent to most UV-A, so most of this longer-wavelength UV radiation reaches the surface, and it constitutes most of the UV reaching the Earth. This type of UV radiation is significantly less harmful to DNA, although it may still potentially cause physical damage, premature aging of the skin, indirect genetic damage, and skin cancer.
Distribution in the stratosphere.
The thickness of the ozone layer—that is, the total amount of ozone in a column overhead—varies by a large factor worldwide, being in general smaller near the equator and larger towards the poles. It also varies with season, being in general thicker during the spring and thinner during the autumn. The reasons for this latitude and seasonal dependence are complicated, involving atmospheric circulation patterns as well as solar intensity.
Since stratospheric ozone is produced by solar UV radiation, one might expect to find the highest ozone levels over the tropics and the lowest over polar regions. The same argument would lead one to expect the highest ozone levels in the summer and the lowest in the winter. The observed behavior is very different: most of the ozone is found in the mid-to-high latitudes of the northern and southern hemispheres, and the highest levels are found in the spring, not summer, and the lowest in the autumn, not winter in the northern hemisphere. During winter, the ozone layer actually increases in depth. This puzzle is explained by the prevailing stratospheric wind patterns, known as the Brewer-Dobson circulation. While most of the ozone is indeed created over the tropics, the stratospheric circulation then transports it poleward and downward to the lower stratosphere of the high latitudes. However, owing to the ozone hole phenomenon, the lowest amounts of column ozone found anywhere in the world are over the Antarctic in the southern spring period of September and October and to a lesser extent over the Arctic in the northern spring period of March, April, and May.
The ozone layer is higher in altitude in the tropics, and lower in altitude outside the tropics, especially in the polar regions. This altitude variation of ozone results from the slow circulation that lifts the ozone-poor air out of the troposphere into the stratosphere. As this air slowly rises in the tropics, ozone is produced as the sun overhead photolyzes oxygen molecules. As this slow circulation levels off and flows towards the mid-latitudes, it carries the ozone-rich air from the tropical middle stratosphere to the mid-and-high latitudes lower stratosphere. The high ozone concentrations at high latitudes are due to the accumulation of ozone at lower altitudes.
The Brewer-Dobson circulation moves very slowly. The time needed to lift an air parcel by 1 km in the lower tropical stratosphere is about 2 months (18 m per day). However, horizontal poleward transport in the lower stratosphere is much faster and amounts to approximately 100 km per day in the northern hemisphere whilst it is only half as much in the southern hemisphere (~51 km per day). Even though ozone in the lower tropical stratosphere is produced at a very slow rate, the lifting circulation is so slow that ozone can build up to relatively high levels by the time it reaches .
Ozone amounts over the continental United States (25°N to 49°N) are highest in the northern spring (April and May). These ozone amounts fall over the course of the summer to their lowest amounts in October, and then rise again over the course of the winter. Again, wind transport of ozone is principally responsible for the seasonal changes of these higher latitude ozone patterns.
The total column amount of ozone generally increases as we move from the tropics to higher latitudes in both hemispheres. However, the overall column amounts are greater in the northern hemisphere high latitudes than in the southern hemisphere high latitudes. In addition, while the highest amounts of column ozone over the Arctic occur in the northern spring (March–April), the opposite is true over the Antarctic, where the lowest amounts of column ozone occur in the southern spring (September–October).
Depletion.
The ozone layer can be depleted by free radical catalysts, including nitric oxide (NO), nitrous oxide (N2O), hydroxyl (OH), atomic chlorine (Cl), and atomic bromine (Br). While there are natural sources for all of these species, the concentrations of chlorine and bromine increased markedly in recent decades due to the release of large quantities of man-made organohalogen compounds, especially chlorofluorocarbons (CFCs) and bromofluorocarbons. These highly stable compounds are capable of surviving the rise to the stratosphere, where Cl and Br radicals are liberated by the action of ultraviolet light. Each radical is then free to initiate and catalyze a chain reaction capable of breaking down over 100,000 ozone molecules. By 2009, nitrous oxide was the largest ozone-depleting substance (ODS) emitted through human activities.
The breakdown of ozone in the stratosphere results in reduced absorption of ultraviolet radiation. Consequently, unabsorbed and dangerous ultraviolet radiation is able to reach the Earth’s surface at a higher intensity. Ozone levels have dropped by a worldwide average of about 4% since the late 1970s. For approximately 5% of the Earth's surface, around the north and south poles, much larger seasonal declines have been seen, and are described as "ozone holes". The discovery of the annual depletion of ozone above the Antarctic was first announced by Joe Farman, Brian Gardiner and Jonathan Shanklin, in a paper which appeared in "Nature" on May 16, 1985.
Regulation.
To support successful regulation attempts, the ozone case was communicated to lay persons "with easy-to-understand bridging metaphors derived from the popular culture" and related to "immediate risks with everyday relevance". The specific metaphors used in the discussion (ozone shield, ozone hole) proved quite useful and, compared to global climate change, was much more seen as an "hot issue" and imminent risk. Lay people were cautious about a depletion of the ozone layer and the risks of skin cancer.
In 1978, the United States, Canada and Norway enacted bans on CFC-containing aerosol sprays that damage the ozone layer. The European Community rejected an analogous proposal to do the same. In the U.S., chlorofluorocarbons continued to be used in other applications, such as refrigeration and industrial cleaning, until after the discovery of the Antarctic ozone hole in 1985. After negotiation of an international treaty (the Montreal Protocol), CFC production was capped at 1986 levels with commitments to long-term reductions. Since that time, the treaty was amended to ban CFC production after 1995 in the developed countries, and later in developing countries. Today, all of the world's 197 countries have signed the treaty. Beginning January 1, 1996, only recycled and stockpiled CFCs were available for use in developed countries like the US. This production phaseout was possible because of efforts to ensure that there would be substitute chemicals and technologies for all ODS uses.
On August 2, 2003, scientists announced that the global depletion of the ozone layer may be slowing down due to the international regulation of ozone-depleting substances. In a study organized by the American Geophysical Union, three satellites and three ground stations confirmed that the upper-atmosphere ozone-depletion rate slowed down significantly during the previous decade. Some breakdown can be expected to continue due to ODSs used by nations which have not banned them, and due to gases which are already in the stratosphere. Some ODSs, including CFCs, have very long atmospheric lifetimes, ranging from 50 to over 100 years. It has been estimated that the ozone layer will recover to 1980 levels near the middle of the 21st century.
Compounds containing C–H bonds (such as hydrochlorofluorocarbons, or HCFCs) have been designed to replace CFCs in certain applications. These replacement compounds are more reactive and less likely to survive long enough in the atmosphere to reach the stratosphere where they could affect the ozone layer. While being less damaging than CFCs, HCFCs can have a negative impact on the ozone layer, so they are also being phased out. These in turn are being replaced by hydrofluorocarbons (HFCs) and other compounds that do not destroy stratospheric ozone at all.

</doc>
<doc id="22841" url="https://en.wikipedia.org/wiki?curid=22841" title="Public Enemy (music group)">
Public Enemy (music group)

Public Enemy is an American hip hop group consisting of Chuck D, Flavor Flav, Professor Griff, The S1W group, Khari Wynn and DJ Lord. Formed on Long Island, New York in 1982, they are known for their politically charged lyrics and criticism of the American media, with an active interest in the frustrations and concerns of the African American community.
Their first four albums during the late 1980s and early 1990s were all certified either gold or platinum and were, according to music critic Robert Hilburn in 1998, "the most acclaimed body of work ever by a rap act." In 2004, "Rolling Stone" magazine ranked Public Enemy number 44 on its list of the Immortals: 100 Greatest Artists of All Time. The group was inducted into the Long Island Music Hall of Fame in 2007. The band were announced as inductees for the 2013 class of the Rock and Roll Hall of Fame on December 11, 2012, making them the fourth hip-hop act to be inducted after Grandmaster Flash and the Furious Five, Run–D.M.C. and The Beastie Boys.
History.
Formation and early years (1982–1986).
Developing his talents as an MC with Flavor Flav while delivering furniture for his father's business, Chuck D (Carlton Douglas Ridenhour) and Spectrum City, as the group was called, released the record "Check Out the Radio", backed by "Lies", a social commentary—both of which would influence RUSH Productions' Run–D.M.C. and Beastie Boys. Chuck D put out a tape to promote WBAU (the radio station where he was working at the time) and to fend off a local MC who wanted to battle him. He called the tape "Public Enemy #1" because he felt like he was being persecuted by people in the local scene. This was the first reference to the notion of a public enemy in any of Chuck D's songs. The single was created by Chuck D with a contribution by Flavor Flav, though this was before the group "Public Enemy" was officially assembled. Around 1986, Bill Stephney, the former Program Director at WBAU, was approached by Ali Hafezi and offered a position with the label. Stephney accepted, and his first assignment was to help fledgling producer Rick Rubin sign Chuck D, whose song "Public Enemy Number One" Rubin had heard from Andre "Doctor Dré" Brown.
According to the book "The History of Rap Music" by Cookie Lommel, "Stephney thought it was time to mesh the hard-hitting style of Run DMC with politics that addressed black youth. Chuck recruited Spectrum City, which included Hank Shocklee, his brother Keith Shocklee, and Eric "Vietnam" Sadler, collectively known as the Bomb Squad, to be his production team and added another Spectrum City partner, Professor Griff, to become the group's Minister of Information. With the addition of Flavor Flav and another local mobile DJ named Terminator X, the group Public Enemy was born." According to Chuck, The S1W, which stands for Security of the First World, "represents that the black man can be just as intelligent as he is strong. It stands for the fact that we're not third-world people, we're first-world people; we're the original people." Public Enemy started out as opening act for the Beastie Boys during the latter's "Licensed to Ill" popularity, and in 1987 released their debut album "Yo! Bum Rush the Show". Over the next few years, Public Enemy released "It Takes a Nation of Millions to Hold Us Back", "Fear of a Black Planet", and "Apocalypse 91… The Enemy Strikes Black". In addition to ushering in the golden age of hip hop, during this time, Public Enemy reached the height of their popularity, adulation, and controversy. The group then separated from Def Jam and has since been independently producing, marketing, and publishing their music.
Mainstream success (1987–1994).
Their debut album, "Yo! Bum Rush the Show", was released in 1987 to critical acclaim. The album was the group's first step toward stardom. In October 1987, music critic Simon Reynolds dubbed Public Enemy "a superlative "rock" band". They released their second album "It Takes a Nation of Millions to Hold Us Back" in 1988, which performed better in the charts than their previous release, and included the hit single "Don't Believe the Hype" in addition to "Bring the Noise". "Nation of Millions..." was the first hip hop album to be voted album of the year in "The Village Voice"s influential Pazz & Jop critics' poll.
In 1989, the group returned to the studio to record "Fear of a Black Planet", which continued their politically charged themes. The album was supposed to be released in late 1989, but was pushed back to April 1990. It was the most successful of any of their albums and, in 2005, was selected for preservation in the Library of Congress. It included the singles "Welcome To The Terrordome", "911 Is a Joke", which criticized emergency response units for taking longer to arrive at emergencies in the black community than those in the white community, and "Fight the Power". "Fight the Power" is regarded as one of the most popular and influential songs in hip hop history. It was the theme song of Spike Lee's "Do the Right Thing".
The group's next release, "Apocalypse '91...The Enemy Strikes Black", continued this trend, with songs like "Can't Truss It", which addressed the history of slavery and how the black community can fight back against oppression; "I Don't Wanna be Called Yo Nigga", a track that takes issue with the use of the word "nigga" outside of its original derogatory context. The album also included the controversial song and video "By the Time I Get to Arizona", which chronicled the black community's frustration that some US states did not recognize Martin Luther King Jr.'s birthday as a national holiday. The video featured members of Public Enemy taking out their frustrations on politicians in the states not recognizing the holiday. In 1992, the group was one of the first rap acts to perform at the Reading Festival, in England, headlining the second day of the three day festival.
Terminator X's exit and DJ Lord's entrance (1998–current).
After a 1994 motorcycle accident shattered his left leg and kept him in the hospital for a full month, Terminator X relocated to his 15-acre farm in Vance County, North Carolina. By 1998, he was ready to retire from the group and focus full-time on raising African black ostriches on his farm. In late 1998, the group started looking for Terminator X's permanent replacement. Following several months of searching for a DJ, Professor Griff saw DJ Lord at a Vestax Battle and approached him about becoming the DJ for Public Enemy. DJ Lord joined as the group's full-time DJ just in time for Public Enemy's 40th World Tour. Since 1999, he has been the official DJ for Public Enemy on albums and world tours while winning numerous turntablist competitions, including multiple DMC finals.
In 2007, the group released an album entitled "How You Sell Soul to a Soulless People Who Sold Their Soul?". Public Enemy's single from the album was "Harder Than You Think". Four years after "How You Sell Soul...", in January 2011, Public Enemy released the album "Beats and Places", a compilation of remixes and "lost" tracks. On July 13, 2012, "Most of My Heroes Still Don't Appear on No Stamp" was released and was exclusively available on iTunes. In July 2012, on UK television an advert for the London 2012 Summer Paralympics featured a short remix of the song "Harder Than You Think". The advert caused the song to reach No. 4 in the UK Singles Chart on September 2, 2012. On July 30, 2012, Public Enemy performed a free concert with Salt-N-Pepa and Kid 'n Play at Wingate Park in Brooklyn, New York as part of the Martin Luther King Jr. Concert Series. On August 26, 2012, Public Enemy performed at South West Four music festival in Clapham Common in London. On October 1, 2012 "The Evil Empire of Everything" was released. On June 29, 2013, they performed at Glastonbury Festival 2013. On September 14, 2013 they performed at Riot Fest & Carnival 2013 in Chicago, Illinois. On September 20, 2013 they performed at Riot Fest & Side Show in Byers, Colorado.
In 2014 Chuck D launched PE 2.0 with Oakland rapper Jahi as a spiritual successor and "next generation" of Public Enemy. Jahi had met Chuck D backstage during a soundcheck at the 1999 Rock & Roll Hall of Fame and later appeared as a support act on Public Enemy's 20th Anniversary Tour in 2007. PE 2.0's task is twofold, Jahi says, to "take select songs from the PE catalog and cover or reVisit them" as well as new material with members of the original Public Enemy including DJ Lord, Davy DMX, Professor Griff and Chuck D. PE 2.0's first album "People Get Ready" was released on October 7, 2014. "InsPirEd" PE 2.0's second album and part two of a proposed trilogy was released a year later on October 11, 2015.
"Man Plans God Laughs", Public Enemy's thirteenth album, was released in July 2015.
Legacy.
Terminator X's innovative scratching tricks can be heard on the songs "Rebel Without a Pause", "Night of the Living Baseheads", and "Shut 'Em Down". The Bomb Squad offered up a web of innovative samples and beats. Critic Stephen Thomas Erlewine declared that PE "brought in elements of free jazz, hard funk, even musique concrète, via [its] producing team the Bomb Squad, creating a dense, ferocious sound unlike anything that came before."
Public Enemy made contributions to the hip-hop world with political, social and cultural consciousness, which infused itself into skilled and poetic rhymes, using raucous sound collages as a foundation. Public Enemy held a strong, pro-Black, political stance. Before PE, politically motivated hip-hop was defined by a few tracks by Ice-T, Grandmaster Flash and the Furious Five, and KRS-One. Other politically motivated opinions were shared by prototypical artists Gil Scott-Heron and the Last Poets. PE was a revolutionary hip-hop act, basing an entire image around a specified political stance. With the successes of Public Enemy, many hip-hop artists began to celebrate Afrocentric themes, such as Kool Moe Dee, Gang Starr, X Clan, Eric B. & Rakim, Queen Latifah, the Jungle Brothers, and A Tribe Called Quest.
Public Enemy was one of the first hip-hop groups to do well internationally. PE changed the Internet's music distribution capability by being one of the first groups to release MP3-only albums, a format virtually unknown at the time.
Public Enemy helped to create and define "rap metal" by collaborating with Living Colour in 1988 (Funny Vibe) and New York thrash metal outfit Anthrax in 1991. The single "Bring the Noise" was a mix of semi-militant black power lyrics, grinding guitars, and sporadic humor. The two bands, cemented by a mutual respect and the personal friendship between Chuck D and Anthrax's Scott Ian, introduced a hitherto alien genre to rock fans, and the two seemingly disparate groups toured together. Flavor Flav's pronouncement on stage that "They said this tour would never happen" (as heard on Anthrax's "Live: The Island Years" CD) has become a legendary comment in both rock and hip-hop circles. Metal guitarist Vernon Reid (of Living Colour) contributed to Public Enemy's recordings, and PE sampled Slayer's "Angel of Death" half-time riff on "She Watch Channel Zero?!"
Members of the Bomb Squad produced or remixed works for other acts, like Bell Biv DeVoe, Ice Cube, Vanessa Williams, Sinéad O'Connor, Blue Magic, Peter Gabriel, L.L. Cool J, Paula Abdul, Jasmine Guy, Jody Watley, Eric B & Rakim, Third Bass, Big Daddy Kane, EPMD, and Chaka Khan. According to Chuck D, "We had tight dealings with MCA Records and were talking about taking three guys that were left over from New Edition and coming up with an album for them. The three happened to be Ricky Bell, Michael Bivins, and Ronnie DeVoe, later to become Bell Biv DeVoe. Ralph Tresvant had been slated to do a solo album for years, Bobby Brown had left New Edition and experienced some solo success beginning in 1988, and Johnny Gill had just been recruited to come in, but [he] had come off a solo career and could always go back to that. At MCA, Hiram Hicks, who was their manager, and Louil Silas, who was running the show, were like, 'Yo, these kids were left out in the cold. Can y'all come up with something for them?' It was a task that Hank, Keith, Eric, and I took on to try to put some kind of hip-hop-flavored R&B shit down for them. Subsequently, what happened in the four weeks of December [1989] was that the Bomb Squad knocked out a large piece of the production and arrangement on Bell Biv DeVoe's three-million selling album "Poison". In January [1990], they knocked out "Fear of a Black Planet" in four weeks, and PE knocked out Ice Cube's album "AmeriKKKa's Most Wanted" in four to five weeks in February." They have also produced local talent such as Son of Bazerk, Young Black Teenagers, Kings of Pressure, and True Mathematics—and gave producer Kip Collins his start in the business.
Poet and hip-hop artist Saul Williams uses a sample from Public Enemy's "Welcome to the Terrordome" in his song "Tr[n]igger" on the "Niggy Tardust" album. He also used a line from the song in his poem, "amethyst rocks".
Public Enemy's brand of politically and socially conscious hip hop has been a direct influence on new hip hop artists such as The Cornel West theory.
The Manic Street Preachers track "Repeat (Stars And Stripes)" is a remix of the band's own anti-monarchy tirade by Public Enemy production team The Bomb Squad of whom James Dean Bradfield and Richey Edwards were big fans. The song samples "Countdown to Armageddon" from It Takes a Nation of Millions to Hold Us Back. The band had previously sampled Public Enemy on their 1991 single Motown Junk.
The influence of the band goes largely beyond hip-hop as the group was cited by artists as diverse as Autechre (selected in the All Tomorrow's Parties (music festival) in 2003), Nirvana (It Takes a Nation of Millions to Hold Us Back being cited by Kurt Cobain among his favorite albums), Nine Inch Nails (mentioned the band in Pretty Hate Machine credits), Björk (included Rebel Without a Pause in her The Breezeblock Mix in July 2007), Tricky (did a cover of Black Steel in the Hour of Chaos and appears in Do You Wanna Go Our Way ??? video), Prodigy (included Public Enemy No. 1 in The Dirtchamber Sessions Volume One), Ben Harper, Underground Resistance (cited by both Mad Mike and Jeff Mills), Orlando Voorn, M.I.A., Amon Tobin, Mathew Jonson and Aphex Twin (Welcome To The Terrordome being the first track played after the introduction at the Coachella festival in April 2008).
In September 2009, VH1 aired a show called "100 Greatest Hip Hop Songs" where Public Enemy earned the number one spot with their hit song, Fight the Power.
In December 2012, the group was announced as one of the inductees to the Rock and Roll Hall of Fame for its 2013 class.
Controversy.
Political activities.
In January 1987, Arizona governor Evan Mecham canceled a state holiday for Martin Luther King, Jr. because the holiday had not been properly authorized. In response to this action, the group wrote a song entitled "By the Time I Get to Arizona." In the video for the song, the group was seen assassinating Mecham by planting a bomb underneath his limousine and detonating it by remote control, perhaps intending an analogy or other reference to the 1976 murder of Don Bolles, an investigator reporter for the Arizona Republic newspaper.
Anti-Semitism.
In 1989, in an interview with Public Enemy for the "Washington Times", the interviewing journalist, David Mills, lifted some quotations from a UK magazine in which the band were asked their opinion on the Arab–Israeli conflict. Professor Griff's comments apparently sympathized with the Palestinians and he was accused of anti-Semitism. According to Rap Attack 2, he suggested that "Jews are responsible for the majority of the wickedness in the world" (p. 177). (In turn a quote from" The International Jew") Shortly after, Ridenhour expressed an apology on his behalf. At a June 21, 1989 press conference, Ridenhour announced Griff's dismissal from the group, and a June 28 statement by Russell Simmons, president of Def Jam Recordings and Rush Artists Management, stated that Chuck D. had disbanded Public Enemy "for an indefinite period of time." By August 10, however, Ridenhour denied that he had disbanded the group, and stated that Griff had been re-hired as "Supreme Allied Chief of Community Relations" (in contrast to his previous position with the group as Minister of Information). Griff later denied holding anti-Semitic views and apologized for the remarks. Several people who had worked with Public Enemy expressed concern about Ridenhour's leadership abilities and role as a social spokesman.
In his 2009 book, entitled "Analytixz", Griff criticized his 1989 statement: "to say the Jews are responsible for the majority of wickedness that went on around the globe I would have to know about the majority of wickedness that went on around the globe, which is impossible... I'm not the best knower. Then, not only knowing that, I would have to know who is at the crux of all of the problems in the world and then blame Jewish people, which is not correct." Griff also said that not only were his words taken out of context, but that the recording has never been released to the public for an unbiased listen.
The controversy and apologies on behalf of Griff spurred Chuck D to reference the negative press they were receiving. In 1990, Public Enemy issued the single "Welcome to the Terrordome", which contains the lyrics: "Crucifixion ain't no fiction / So-called chosen frozen / Apologies made to whoever pleases / Still they got me like Jesus". These lyrics have been cited by some in the media as anti-Semitic, making supposed references to the concept of the "chosen people" with the lyric "so-called chosen" and Jewish deicide with the last line.
In 1999 the group released an album entitled There's a Poison Goin' On. The title of the last song on the album is called "Swindler's Lust". The Anti-Defamation League (ADL) claimed that the title of the song was a word play on the title of the Steven Spielberg movie "Schindler’s List" about the genocide of Jews in World War II. Similarly in 2000 a Public Enemy spin off group under the name Confrontation Camp, a name according to the ADL, that is a pun on the term concentration camp, released an album. The group consisted of Kyle Jason, Chuck D (under the name Mistachuck) and Professor Griff.
The title of the 2015 album "Man Plans God Laughs" is a well known English translation of a Yiddish proverb "Der mentsh trakht un got lakht" Chuck D has not explained why a Yiddish proverb was used.
Homophobia.
In a letter to the editor, Leo Haber alludes to criticism by New York Times writer Peter Watrous of the group's supposed homophobia.
Reviewers John Alroy and David Wilson said that "Fear of a Black Planet" contained "homophobic babbling" which challenged politically correct thinking.
Zoe Williams defended Public Enemy against charges of homophobia by stating that:
Although "Spin" magazine noted that 'It only brings agony, ask James Cagney / He beat up on a guy when he found he was a fagney / Cagney is a favorite he is my boy' from "A Letter to the "New York Post"" on their album "Apocalypse '91" has also been accused of homophobia.
Public Enemy have also been supporters of Nation of Islam Supreme Minister Louis Farrakhan, who has been controversial for his commentary which is often interpreted as being black supremacist, racist, homophobic, and anti-Semitic.
Awards and nominations.
Grammy Awards
American Music Awards
Rock and Roll Hall of Fame
Bibliography.
White, Miles. "Race, Rap and the performance of Mascinity in American Popular Culture". 2011. University of Illinois. Urbana. ISBN 978-0-252-07832-3

</doc>
<doc id="22860" url="https://en.wikipedia.org/wiki?curid=22860" title="Paleolithic">
Paleolithic

The Paleolithic (American spelling; British spelling: Palaeolithic; pronunciation: or ) Age, Era or Period is a prehistoric period of human history distinguished by the development of the most primitive stone tools discovered (Grahame Clark's Modes I and II), and covers roughly 95% of human technological prehistory. It extends from the earliest known use of stone tools, probably by hominins such as australopithecines, 2.6 million years ago, to the end of the Pleistocene around 10,000 BP.
The Paleolithic era is followed by the Mesolithic. The date of the Paleolithic–Mesolithic boundary may vary by locality as much as several thousand years.
During the Paleolithic period, humans grouped together in small societies such as bands, and subsisted by gathering plants and fishing, hunting or scavenging wild animals. The Paleolithic is characterized by the use of knapped stone tools, although at the time humans also used wood and bone tools. Other organic commodities were adapted for use as tools, including leather and vegetable fibers; however, due to their nature, these have not been preserved to any great degree. Surviving artifacts of the Paleolithic era are known as paleoliths. 
Humankind gradually evolved from early members of the genus "Homo" such as "Homo habilis" – who used simple stone tools – into fully behaviorally and anatomically modern humans ("Homo sapiens)"during the Paleolithic era. During the end of the Paleolithic, specifically the Middle and or Upper Paleolithic, humans began to produce the earliest works of art and engage in religious and spiritual behavior such as burial and ritual. The climate during the Paleolithic consisted of a set of glacial and interglacial periods in which the climate periodically fluctuated between warm and cool temperatures.
The term "Paleolithic" was coined by archaeologist John Lubbock in 1865. It derives from Greek: παλαιός, "palaios", "old"; and λίθος, "lithos", "stone", meaning "old age of the stone" or "Old Stone Age."
Human evolution.
Human evolution is the part of biological evolution concerning the emergence of humans as a distinct species.
Paleogeography and climate.
The Paleolithic Period coincides almost exactly with the Pleistocene epoch of geologic time, which lasted from 2.6 million years ago to about 12,000 years ago. This epoch experienced important geographic and climatic changes that affected human societies.
During the preceding Pliocene, continents had continued to drift from possibly as far as 250 km from their present locations to positions only 70 km from their current location. South America became linked to North America through the Isthmus of Panama, bringing a nearly complete end to South America's distinctive marsupial fauna. The formation of the Isthmus had major consequences on global temperatures, because warm equatorial ocean currents were cut off, and the cold Arctic and Antarctic waters lowered temperatures in the now-isolated Atlantic Ocean. Most of Central America formed during the Pliocene to connect the continents of North and South America, allowing fauna from these continents to leave their native habitats and colonize new areas. Africa's collision with Asia created the Mediterranean Sea, cutting off the remnants of the Tethys Ocean. During the Pleistocene, the modern continents were essentially at their present positions; the tectonic plates on which they sit have probably moved at most 100 km from each other since the beginning of the period.
Climates during the Pliocene became cooler and drier, and seasonal, similar to modern climates. Ice sheets grew on Antarctica. The formation of an Arctic ice cap around three million years ago is signaled by an abrupt shift in oxygen isotope ratios and ice-rafted cobbles in the North Atlantic and North Pacific ocean beds. Mid-latitude glaciation probably began before the end of the epoch. The global cooling that occurred during the Pliocene may have spurred on the disappearance of forests and the spread of grasslands and savannas.
The Pleistocene climate was characterized by repeated glacial cycles during which continental glaciers pushed to the 40th parallel in some places. Four major glacial events have been identified, as well as many minor intervening events. A major event is a general glacial excursion, termed a "glacial". Glacials are separated by "interglacials". During a glacial, the glacier experiences minor advances and retreats. The minor excursion is a "stadial"; times between stadials are "interstadials". Each glacial advance tied up huge volumes of water in continental ice sheets 1500–3000 m deep, resulting in temporary sea level drops of 100 m or more over the entire surface of the Earth. During interglacial times, such as at present, drowned coastlines were common, mitigated by isostatic or other emergent motion of some regions.
The effects of glaciation were global. Antarctica was ice-bound throughout the Pleistocene and the preceding Pliocene. The Andes were covered in the south by the Patagonian ice cap. There were glaciers in New Zealand and Tasmania. The now decaying glaciers of Mount Kenya, Mount Kilimanjaro, and the Ruwenzori Range in east and central Africa were larger. Glaciers existed in the mountains of Ethiopia and to the west in the Atlas mountains. In the northern hemisphere, many glaciers fused into one. The Cordilleran ice sheet covered the North American northwest; the Laurentide covered the east. The Fenno-Scandian ice sheet covered northern Europe, including Great Britain; the Alpine ice sheet covered the Alps. Scattered domes stretched across Siberia and the Arctic shelf. The northern seas were frozen. During the late Upper Paleolithic (Latest Pleistocene) "c." 18,000 BP, the Beringia land bridge between Asia and North America was blocked by ice, which may have prevented early Paleo-Indians such as the Clovis culture from directly crossing Beringa to reach the Americas.
According to Mark Lynas (through collected data), the Pleistocene's overall climate could be characterized as a continuous El Niño with trade winds in the south Pacific weakening or heading east, warm air rising near Peru, warm water spreading from the west Pacific and the Indian Ocean to the east Pacific, and other El Niño markers.
The Paleolithic is often held to finish at the end of the ice age (the end of the Pleistocene epoch), and Earth's climate became warmer. This may have caused or contributed to the extinction of the Pleistocene megafauna, although it is also possible that the late Pleistocene extinctions were (at least in part) caused by other factors such as disease and overhunting by humans. New research suggests that the extinction of the woolly mammoth may have been caused by the combined effect of climatic change and human hunting. Scientists suggest that climate change during the end of the Pleistocene caused the mammoths' habitat to shrink in size, resulting in a drop in population. The small populations were then hunted out by Paleolithic humans. The global warming that occurred during the end of the Pleistocene and the beginning of the Holocene may have made it easier for humans to reach mammoth habitats that were previously frozen and inaccessible. Small populations of wooly mammoths survived on isolated Arctic islands, Saint Paul Island and Wrangel Island, till circa 3700 and 1700 BCE respectively. The Wrangel Island population went extinct around the same time the island was settled by prehistoric humans. There's no evidence of prehistoric human presence on Saint Paul island (though early human settlements dating as far back as 6500 BCE were found on nearby Aleutian Islands).
Human way of life.
Nearly all of our knowledge of Paleolithic human culture and way of life comes from archaeology and ethnographic comparisons to modern hunter-gatherer cultures such as the !Kung San who live similarly to their Paleolithic predecessors. The economy of a typical Paleolithic society was a hunter-gatherer economy. Humans hunted wild animals for meat and gathered food, firewood, and materials for their tools, clothes, or shelters. Human population density was very low, around only one person per square mile. This was most likely due to low body fat, infanticide, women regularly engaging in intense endurance exercise, late weaning of infants and a nomadic lifestyle. Like contemporary hunter-gatherers, Paleolithic humans enjoyed an abundance of leisure time unparalleled in both Neolithic farming societies and modern industrial societies. At the end of the Paleolithic, specifically the Middle and or Upper Paleolithic, humans began to produce works of art such as cave paintings, rock art and jewellery and began to engage in religious behavior such as burial and ritual.
Distribution.
At the beginning of the Paleolithic, hominids were found primarily in eastern Africa, east of the Great Rift Valley. Most known hominid fossils dating earlier than one million years before present are found in this area, particularly in Kenya, Tanzania, and Ethiopia.
By 1.5-2 million years before present, groups of hominids began leaving Africa and settling southern Europe and Asia. Southern Caucasus was occupied by 1.7 million years BP, and northern China was reached by 1.66 million years BP. By the end of the Lower Paleolithic, members of the hominid family were living in what is now China, western Indonesia, and, in Europe, around the Mediterranean and as far north as England, southern Germany, and Bulgaria. Their further northward expansion may have been limited by the lack of control of fire: studies of cave settlements in Europe indicate no regular use of fire prior to 300,000-400,000 BP. East Asian fossils from this period are typically placed in the genus Homo erectus. Very little fossil evidence is available at known Lower Paleolithic sites in Europe, but it is believed that hominids who inhabited these sites were likewise "Homo erectus". There is no evidence of hominids in America, Australia, or almost anywhere in Oceania during this time period.
Fates of these early colonists, and their relationships to modern humans, are still subject to debate. According to current archeological and genetic models, there were at least two notable expansion events subsequent to peopling of Eurasia 2-1.5 million years BP. Around 500,000 BP, a group of early humans, frequently called Homo heidelbergensis, came to Europe from Africa and eventually evolved into Neanderthals. Both "Homo erectus" and Neanderthals went extinct by the end of the Paleolithic, having been replaced by a new wave of humans, the anatomically modern Homo sapiens, which emerged in eastern Africa circa 200,000 BP, left Africa around 50,000 BP and expanded throughout the planet. It is likely that multiple groups coexisted for some time in certain locations. Neanderthals were still found in parts of Eurasia 30,000 years before present, and engaged in a limited degree of interbreeding with "Homo sapiens". Hominid fossils not belonging either to "Homo neanderthalensis" or to "Homo sapiens" geni, found in Altai and Indonesia, were radiocarbon dated to 30,000-40,000 BP and 17,000 BP respectively.
The technological revolution of the Middle and Upper Paleolithic allowed humans to reach places that weren't accessible earlier. In the Middle Paleolithic, Neanderthals were present in Poland. By 40,000-50,000 BP, first humans set foot in Australia. By 45,000 BP, humans lived at 61° north latitude in Europe. By 30,000 BP, Japan was reached, and by 27,000 BP humans were present in Siberia above the Arctic Circle. At the end of the Upper Paleolithic, a group of humans crossed the Bering land bridge and quickly expanded throughout North and South America. Northern Eurasia became depopulated during the last Glacial Maximum (27,000 to 16,000 BP), but was repopulated as the climate got warmer and glaciers retreated.
For the duration of the Paleolithic, human populations remained low, especially outside the equatorial region. The entire population of Europe between 16,000-11,000 BP likely averaged some 30,000 individuals, and, between 40,000-16,000 BP, it was even lower, at 4,000-6,000 individuals.
Technology.
Tools.
Paleolithic humans made tools of stone, bone, and wood. The early paleolithic hominids, Australopithecus, were the first users of stone tools. Excavations in Gona, Ethiopia have produced thousands of artifacts, and through radioisotopic dating and magnetostratigraphy, the sites can be firmly dated to 2.6 million years ago. Evidence shows these early hominids intentionally selected raw materials with good flaking qualities and chose appropriate sized stones for their needs to produce sharp-edged tools for cutting. The earliest Paleolithic stone tool industry, the Olduwan, began around 2.6 million years ago. It contained tools such as choppers, burins and awls. It was completely replaced around 250,000 years ago by the more complex Acheulean industry, which was first conceived by "Homo ergaster" around 1.8 or 1.65 million years ago. The most recent Lower Paleolithic (Acheulean) implements completely vanished from the archeological record around 100,000 years ago and were replaced by more complex Middle Paleolithic/Middle Stone Age tool kits such as the Mousterian and the Aterian industries.
Lower Paleolithic humans used a variety of stone tools, including hand axes and choppers. Although they appear to have used hand axes often, there is disagreement about their use. Interpretations range from cutting and chopping tools, to digging implements, flake cores, the use in traps and a purely ritual significance, maybe in courting behavior. William H. Calvin has suggested that some hand axes could have served as "killer Frisbees" meant to be thrown at a herd of animals at a water hole so as to stun one of them. There are no indications of hafting, and some artifacts are far too large for that. Thus, a thrown hand axe would not usually have penetrated deeply enough to cause very serious injuries. Nevertheless, it could have been an effective weapon for defense against predators. Choppers and scrapers were likely used for skinning and butchering scavenged animals and sharp ended sticks were often obtained for digging up edible roots. Presumably, early humans used wooden spears as early as five million years ago to hunt small animals, much as their relatives, chimpanzees, have been observed to do in Senegal, Africa. Lower Paleolithic humans constructed shelters such as the possible wood hut at Terra Amata.
Fire use.
Fire was used by the Lower Paleolithic hominid "Homo erectus"/"Homo ergaster" as early as 300,000 or 1.5 million years ago and possibly even earlier by the early Lower Paleolithic (Oldowan) hominid "Homo habilis" and/or by robust australopithecines such as "Paranthropus". However, the use of fire only became common in the societies of the following Middle Stone Age/Middle Paleolithic Period. Use of fire reduced mortality rates and provided protection against predators. Early hominids may have begun to cook their food as early as the Lower Paleolithic ("c." 1.9 million years ago) or at the latest in the early Middle Paleolithic ("c." 250,000 years ago). Some scientists have hypothesized that Hominids began cooking food to defrost frozen meat, which would help ensure their survival in cold regions.
Rafts.
The Lower Paleolithic hominid "Homo erectus" possibly invented rafts ("c." 800,000 or 840,000 BP) to travel over large bodies of water, which may have allowed a group of "Homo erectus" to reach the island of Flores and evolve into the small hominid "Homo floresiensis". However, this hypothesis is disputed within the anthropological community. The possible use of rafts during the Lower Paleolithic may indicate that Lower Paleolithic Hominids such as "Homo erectus" were more advanced than previously believed, and may have even spoken an early form of modern language. Supplementary evidence from Neanderthal and Modern human sites located around the Mediterranean Sea such as Coa de sa Multa ("c." 300,000 BP) has also indicated that both Middle and Upper Paleolithic humans used rafts to travel over large bodies of water (i.e. the Mediterranean Sea) for the purpose of colonizing other bodies of land.
Advanced tools.
Around 200,000 BP, Middle Paleolithic Stone tool manufacturing spawned a tool making technique known as the prepared-core technique, that was more elaborate than previous Acheulean techniques. This technique increased efficiency by allowing the creation of more controlled and consistent flakes. It allowed Middle Paleolithic humans to create stone tipped spears, which were the earliest composite tools, by hafting sharp, pointy stone flakes onto wooden shafts. In addition to improving tool making methods, the Middle Paleolithic also saw an improvement of the tools themselves that allowed access to a wider variety and amount of food sources. For example, microliths or small stone tools or points were invented around 70,000 or 65,000 BP and were essential to the invention of bows and spear throwers in the following Upper Paleolithic period. Harpoons were invented and used for the first time during the late Middle Paleolithic (c.90,000 years ago); the invention of these devices brought fish into the human diets, which provided a hedge against starvation and a more abundant food supply. Thanks to their technology and their advanced social structures, Paleolithic groups such as the Neanderthals who had a Middle Paleolithic level of technology, appear to have hunted large game just as well as Upper Paleolithic modern humans and the Neanderthals in particular may have likewise hunted with projectile weapons. Nonetheless, Neanderthal use of projectile weapons in hunting occurred very rarely (or perhaps never) and the Neanderthals hunted large game animals mostly by ambushing them and attacking them with mêlée weapons such as thrusting spears rather than attacking them from a distance with projectile weapons.
Other inventions.
During the Upper Paleolithic, further inventions were made, such as the net ("c." 22,000 or 29,000 BP) bolas, the spear thrower (c.30,000 BP), the bow and arrow ("c." 25,000 or 30,000 BP) and the oldest example of ceramic art, the Venus of Dolní Věstonice ("c." 29,000–25,000 BCE). Early dogs were domesticated, sometime between 30,000 BP and 14,000 BP, presumably to aid in hunting. However, the earliest instances of successful domestication of dogs may be much more ancient than this. Evidence from canine DNA collected by Robert K. Wayne suggests that dogs may have been first domesticated in the late Middle Paleolithic around 100,000 BP or perhaps even earlier. Archeological evidence from the Dordogne region of France demonstrates that members of the European early Upper Paleolithic culture known as the Aurignacian used calendars ("c." 30,000 BP). This was a lunar calendar that was used to document the phases of the moon. Genuine solar calendars did not appear until the following Neolithic period. Upper Paleolithic cultures were probably able to time the migration of game animals such as wild horses and deer. This ability allowed humans to become efficient hunters and to exploit a wide variety of game animals. Recent research indicates that the Neanderthals timed their hunts and the migrations of game animals long before the beginning of the Upper Paleolithic.
Social organization.
The social organization of the earliest Paleolithic (Lower Paleolithic) societies remains largely unknown to scientists, though Lower Paleolithic hominids such as "Homo habilis" and "Homo erectus" are likely to have had more complex social structures than chimpanzee societies. Late Oldowan/Early Acheulean humans such as "Homo ergaster"/"Homo erectus" may have been the first people to invent central campsites or home bases and incorporate them into their foraging and hunting strategies like contemporary hunter-gatherers, possibly as early as 1.7 million years ago; however, the earliest solid evidence for the existence of home bases or central campsites (hearths and shelters) among humans only dates back to 500,000 years ago.
Similarly, scientists disagree whether Lower Paleolithic humans were largely monogamous or polygynous. In particular, the Provisional model suggests that bipedalism arose in Pre Paleolithic australopithecine societies as an adaptation to monogamous lifestyles; however, other researchers note that sexual dimorphism is more pronounced in Lower Paleolithic humans such as "Homo erectus" than in Modern humans, who are less polygynous than other primates, which suggests that Lower Paleolithic humans had a largely polygynous lifestyle, because species that have the most pronounced sexual dimorphism tend more likely to be polygynous.
Human societies from the Paleolithic to the early Neolithic farming tribes lived without states and organized governments. For most of the Lower Paleolithic, human societies were possibly more hierarchical than their Middle and Upper Paleolithic descendants, and probably were not grouped into bands, though during the end of the Lower Paleolithic, the latest populations of the hominid "Homo erectus" may have begun living in small-scale (possibly egalitarian) bands similar to both Middle and Upper Paleolithic societies and modern hunter-gatherers.
Middle Paleolithic societies, unlike Lower Paleolithic and early Neolithic ones, consisted of bands that ranged from 20 to 30 or 25 to 100 members and were usually nomadic. These bands were formed by several families. Bands sometimes joined together into larger "macrobands" for activities such as acquiring mates and celebrations or where resources were abundant. By the end of the Paleolithic era, about 10,000 BP people began to settle down into permanent locations, and began to rely on agriculture for sustenance in many locations. Much evidence exists that humans took part in long-distance trade between bands for rare commodities (such as ochre, which was often used for religious purposes such as ritual) and raw materials, as early as 120,000 years ago in Middle Paleolithic. Inter-band trade may have appeared during the Middle Paleolithic because trade between bands would have helped ensure their survival by allowing them to exchange resources and commodities such as raw materials during times of relative scarcity (i.e. famine, drought). Like in modern hunter-gatherer societies, individuals in Paleolithic societies may have been subordinate to the band as a whole. Both Neanderthals and modern humans took care of the elderly members of their societies during the Middle and Upper Paleolithic.
Some sources claim that most Middle and Upper Paleolithic societies were possibly fundamentally egalitarian and may have rarely or never engaged in organized violence between groups (i.e. war).
Some Upper Paleolithic societies in resource-rich environments (such as societies in Sungir, in what is now Russia) may have had more complex and hierarchical organization (such as tribes with a pronounced hierarchy and a somewhat formal division of labor) and may have engaged in endemic warfare. Some argue that there was no formal leadership during the Middle and Upper Paleolithic. Like contemporary egalitarian hunter-gatherers such as the Mbuti pygmies, societies may have made decisions by communal consensus decision making rather than by appointing permanent rulers such as chiefs and monarchs. Nor was there a formal division of labor during the Paleolithic. Each member of the group was skilled at all tasks essential to survival, regardless of individual abilities. Theories to explain the apparent egalitarianism have arisen, notably the Marxist concept of primitive communism. Christopher Boehm (1999) has hypothesized that egalitarianism may have evolved in Paleolithic societies because of a need to distribute resources such as food and meat equally to avoid famine and ensure a stable food supply. Raymond C. Kelly speculates that the relative peacefulness of Middle and Upper Paleolithic societies resulted from a low population density, cooperative relationships between groups such as reciprocal exchange of commodities and collaboration on hunting expeditions, and because the invention of projectile weapons such as throwing spears provided less incentive for war, because they increased the damage done to the attacker and decreased the relative amount of territory attackers could gain. However, other sources claim that most Paleolithic groups may have been larger, more complex, sedentary and warlike than most contemporary hunter-gatherer societies, due to occupying more resource-abundant areas than most modern hunter-gatherers who have been pushed into more marginal habitats by agricultural societies.
Anthropologists have typically assumed that in Paleolithic societies, women were responsible for gathering wild plants and firewood, and men were responsible for hunting and scavenging dead animals. However, analogies to existent hunter-gatherer societies such as the Hadza people and the Australian aborigines suggest that the sexual division of labor in the Paleolithic was relatively flexible. Men may have participated in gathering plants, firewood and insects, and women may have procured small game animals for consumption and assisted men in driving herds of large game animals (such as woolly mammoths and deer) off cliffs. Additionally, recent research by anthropologist and archaeologist Steven Kuhn from the University of Arizona is argued to support that this division of labor did not exist prior to the Upper Paleolithic and was invented relatively recently in human pre-history.<ref name=NG2006/12/061207></ref> Sexual division of labor may have been developed to allow humans to acquire food and other resources more efficiently. Possibly there was approximate parity between men and women during the Middle and Upper Paleolithic, and that period may have been the most gender-equal time in human history. Archeological evidence from art and funerary rituals indicates that a number of individual women enjoyed seemingly high status in their communities, and it is likely that both sexes participated in decision making. The earliest known Paleolithic shaman ("c." 30,000 BP) was female. Jared Diamond suggests that the status of women declined with the adoption of agriculture because women in farming societies typically have more pregnancies and are expected to do more demanding work than women in hunter-gatherer societies. Like most contemporary hunter-gatherer societies, Paleolithic and the Mesolithic groups probably followed mostly matrilineal and ambilineal descent patterns; patrilineal descent patterns were probably rarer than in the following Neolithic period.
Art and music.
Early examples of artistic expression, such as the Venus of Tan-Tan and the patterns found on elephant bones from Bilzingsleben in Thuringia, may have been produced by Acheulean tool users such as "Homo erectus" prior to the start of the Middle Paleolithic period. However, the earliest undisputed evidence of art during the Paleolithic period comes from Middle Paleolithic/Middle Stone Age sites such as Blombos Cave –South Africa– in the form of bracelets, beads, rock art, and ochre used as body paint and perhaps in ritual. Undisputed evidence of art only becomes common in the following Upper Paleolithic period.
According to Robert G. Bednarik, Lower Paleolithic Acheulean tool users began to engage in symbolic behavior such as art around 850,000 BP and decorated themselves with beads and collected exotic stones for aesthetic rather than utilitarian qualities. According to Bednarik, traces of the pigment ochre from late Lower Paleolithic Acheulean archeological sites suggests that Acheulean societies, like later Upper Paleolithic societies, collected and used ochre to create rock art. Nevertheless, it is also possible that the ochre traces found at Lower Paleolithic sites is naturally occurring.
Vincent W. Fallio interprets Lower and Middle Paleolithic marking on rocks at sites such as Bilzingsleben (such as zig zagging lines) as accounts or representation of altered states of consciousness though some other scholars interpret them as either simple doodling or as the result of natural processes.
Upper Paleolithic humans produced works of art such as cave paintings, Venus figurines, animal carvings and rock paintings. Upper Paleolithic art can be divided into two broad categories: figurative art such as cave paintings that clearly depicts animals (or more rarely humans); and nonfigurative, which consists of shapes and symbols. Cave paintings have been interpreted in a number of ways by modern archeologists. The earliest explanation, by the prehistorian Abbe Breuil, interpreted the paintings as a form of magic designed to ensure a successful hunt. However, this hypothesis fails to explain the existence of animals such as saber-toothed cats and lions, which were not hunted for food, and the existence of half-human, half-animal beings in cave paintings. The anthropologist David Lewis-Williams has suggested that Paleolithic cave paintings were indications of shamanistic practices, because the paintings of half-human, half-animal paintings and the remoteness of the caves are reminiscent of modern hunter-gatherer shamanistic practices. Symbol-like images are more common in Paleolithic cave paintings than are depictions of animals or humans, and unique symbolic patterns might have been trademarks that represent different Upper Paleolithic ethnic groups. Venus figurines have evoked similar controversy. Archeologists and anthropologists have described the figurines as representations of goddesses, pornographic imagery, apotropaic amulets used for sympathetic magic, and even as self-portraits of women themselves.
R. Dale Guthrie has studied not only the most artistic and publicized paintings, but also a variety of lower-quality art and figurines, and he identifies a wide range of skill and ages among the artists. He also points out that the main themes in the paintings and other artifacts (powerful beasts, risky hunting scenes and the over-sexual representation of women) are to be expected in the fantasies of adolescent males during the Upper Paleolithic.
The Venus figurines have sometimes been interpreted as representing a mother goddess; the abundance of such female imagery has led some to believe that Upper Paleolithic (and later Neolithic) societies had a female-centered religion and a female-dominated society. For example, this was proposed by the archeologist Marija Gimbutas and the feminist scholar Merlin Stone who was the author of the 1978 book "When God Was a Woman." Various other explanations for the purpose of the figurines have been proposed, such as Catherine McCoid and LeRoy McDermott’s hypothesis that the figurines were created as self-portraits of actual women and R.Dale Gutrie's hypothesis that the venus figurines represented a kind of "stone age pornography".
The origins of music during the Paleolithic are unknown, since the earliest forms of music probably did not use musical instruments but instead used the human voice and or natural objects such as rocks, which leave no trace in the archaeological record. However, the anthropological and archeological designation suggests that human music first arose when language, art and other modern behaviors developed in the Middle or the Upper Paleolithic period. Music may have developed from rhythmic sounds produced by daily activities such as cracking nuts by hitting them with stones, because maintaining a rhythm while working may have helped people to become more efficient at daily activities. An alternative theory originally proposed by Charles Darwin explains that music may have begun as a hominid mating strategy as many birds and some other animals produce music like calls to attract mates. This hypothesis is generally less accepted than the previous hypothesis, but it nonetheless provides a possible alternative. Another explanation is that humans began to make music simply because of the pleasure it produced.
Upper Paleolithic (and possibly Middle Paleolithic) humans used flute-like bone pipes as musical instruments, and music may have played a large role in the religious lives of Upper Paleolithic hunter-gatherers. As with modern hunter-gatherer societies, music may have been used in ritual or to help induce trances. In particular, it appears that animal skin drums may have been used in religious events by Upper Paleolithic shamans, as shown by the remains of drum-like instruments from some Upper Paleolithic graves of shamans and the ethnographic record of contemporary hunter-gatherer shamanic and ritual practices.
Religion and beliefs.
According to James B. Harrod humankind first developed religious and spiritual beliefs during the Middle Paleolithic or Upper Paleolithic. Controversial scholars of prehistoric religion and anthropology, James Harrod and Vincent W. Fallio, have recently proposed that religion and spirituality (and art) may have first arisen in Pre-Paleolithic chimpanzees or Early Lower Paleolithic (Oldowan) societies. According to Fallio, the common ancestor of chimpanzees and humans experienced altered states of consciousness and partook in ritual, and ritual was used in their societies to strengthen social bonding and group cohesion.
Middle Paleolithic humans' use of burials at sites such as Krapina, Croatia ("c." 130,000 BP) and Qafzeh, Israel ("c." 100,000 BP) have led some anthropologists and archeologists, such as Philip Lieberman, to believe that Middle Paleolithic humans may have possessed a belief in an afterlife and a "concern for the dead that transcends daily life". Cut marks on Neanderthal bones from various sites, such as Combe-Grenal and Abri Moula in France, suggest that the Neanderthals like some contemporary human cultures may have practiced ritual defleshing for (presumably) religious reasons. According to recent archeological findings from "H. heidelbergensis" sites in Atapuerca, humans may have begun burying their dead much earlier, during the late Lower Paleolithic; but this theory is widely questioned in the scientific community.
Likewise, some scientists have proposed that Middle Paleolithic societies such as Neanderthal societies may also have practiced the earliest form of totemism or animal worship, in addition to their (presumably religious) burial of the dead. In particular, Emil Bächler suggested (based on archeological evidence from Middle Paleolithic caves) that a bear cult was widespread among Middle Paleolithic Neanderthals. A claim that evidence was found for Middle Paleolithic animal worship c 70,000 BCE originates from the Tsodilo Hills in the African Kalahari desert has been denied by the original investigators of the site. Animal cults in the following Upper Paleolithic period, such as the bear cult, may have had their origins in these hypothetical Middle Paleolithic animal cults. Animal worship during the Upper Paleolithic was intertwined with hunting rites. For instance, archeological evidence from art and bear remains reveals that the bear cult apparently involved a type of sacrificial bear ceremonialism, in which a bear was sliced with arrows, finished off by a blast in the lungs, and ritualistically worshipped near a clay bear statue covered by a bear fur with the skull and the body of the bear buried separately. Barbara Ehrenreich controversially theorizes that the sacrificial hunting rites of the Upper Paleolithic (and by extension Paleolithic cooperative big-game hunting) gave rise to war or warlike raiding during the following Epi-Paleolithic/Mesolithic or late Upper Paleolithic period.
The existence of anthropomorphic images and half-human, half-animal images in the Upper Paleolithic period may further indicate that Upper Paleolithic humans were the first people to believe in a pantheon of gods or supernatural beings, though such images may instead indicate shamanistic practices similar to those of contemporary tribal societies. The earliest known undisputed burial of a shaman (and by extension the earliest undisputed evidence of shamans and shamanic practices) dates back to the early Upper Paleolithic era ("c." 30,000 BP) in what is now the Czech Republic. However, during the early Upper Paleolithic it was probably more common for all members of the band to participate equally and fully in religious ceremonies, in contrast to the religious traditions of later periods when religious authorities and part-time ritual specialists such as shamans, priests and medicine men were relatively common and integral to religious life. Additionally, it is also possible that Upper Paleolithic religions, like contemporary and historical animistic and polytheistic religions, believed in the existence of a single creator deity in addition to other supernatural beings such as animistic spirits.
Vincent W. Fallio writes that ancestor cults first emerged in complex Upper Paleolithic societies. He argues that the elites of these societies (like the elites of many more contemporary complex hunter-gatherers such as the Tlingit) may have used special rituals and ancestor worship to solidify control over their societies, by convincing their subjects that they possess a link to the spirit world that also gives them control over the earthly realm. Secret societies may have served a similar function in these complex quasi-theocratic societies, by dividing the religious practices of these cultures into the separate spheres of Popular Religion and Elite Religion.
Religion was possibly apotropaic; specifically, it may have involved sympathetic magic. The Venus figurines, which are abundant in the Upper Paleolithic archeological record, provide an example of possible Paleolithic sympathetic magic, as they may have been used for ensuring success in hunting and to bring about fertility of the land and women. The Upper Paleolithic Venus figurines have sometimes been explained as depictions of an earth goddess similar to Gaia, or as representations of a goddess who is the ruler or mother of the animals. James Harrod has described them as representative of female (and male) shamanistic spiritual transformation processes.
Diet and nutrition.
Paleolithic hunting and gathering people ate varying proportions of leafy vegetables, fruit, nuts and insects, meat, fish, and shellfish. However, there is little direct evidence of the relative proportions of plant and animal foods. Although the term "paleolithic diet", without references to a specific timeframe or locale, is sometimes used with an implication that most humans shared a certain diet during the entire era, that is not entirely accurate. The Paleolithic was an extended period of time, during which multiple technological advances were made, many of which had impact on human dietary structure. For example, humans probably did not possess the control of fire until the Middle Paleolithic, or tools necessary to engage in extensive fishing. On the other hand, both these technologies are generally agreed to have been widely available to humans by the end of the Paleolithic (consequently, allowing humans in some regions of the planet to rely heavily on fishing and hunting). In addition, the Paleolithic involved a substantial geographical expansion of human populations. During the Lower Paleolithic, ancestors of modern humans are thought to have been constrained to Africa east of the Great Rift Valley. During the Middle and Upper Paleolithic, humans greatly expanded their area of settlement, reaching ecosystems as diverse as New Guinea and Alaska, and adapting their diets to whatever local resources available.
Another view is that until the Upper Paleolithic, humans were frugivores (fruit eaters) who supplemented their meals with carrion, eggs, and small prey such as baby birds and mussels, and only on rare occasions managed to kill and consume big game such as antelopes. This view is supported by studies of higher apes, particularly chimpanzees. Chimpanzees are the closest to humans genetically, sharing more than 96% of their DNA code with humans, and their digestive tract is functionally very similar to that of humans. Chimpanzees are primarily frugivores, but they could and would consume and digest animal flesh, given the opportunity. In general, their actual diet in the wild is about 95% plant-based, with the remaining 5% filled with insects, eggs, and baby animals. In some ecosystems, however, chimpanzees are predatory, forming parties to hunt monkeys. Some comparative studies of human and higher primate digestive tracts do suggest that humans have evolved to obtain greater amounts of calories from sources such as animal foods, allowing them to shrink the size of the gastrointestinal tract relative to body mass and to increase the brain mass instead.
A difficulty with the frugivore point of view is that humans are established to conditionally require certain long-chain polyunsaturated fatty acids (LC-PUFAs), such as AA and DHA, from the diet. Humans' LC-PUFA requirements are much greater than chimpanzees' because of humans' larger brain mass, and humans' abilities to synthesize them from other nutrients are poor, suggesting readily available external sources. Pregnant and lactating females require 100 mg of DHA per day. However, LC-PUFAs are almost nonexistent in plants and in most tissues of warm-climate animals.
Anthropologists have diverse opinions about the proportions of plant and animal foods consumed. Just as with still existing hunters and gatherers, there were many varied "diets" - in different groups - and also varying through this vast amount of time. Some paleolithic hunter-gatherers consumed a significant amount of meat and possibly obtained most of their food from hunting, while others are shown as a primarily plant-based diet, Most, if not all, are believed to have been opportunistic omnivores. One hypothesis is that carbohydrate tubers (plant underground storage organs) may have been eaten in high amounts by pre-agricultural humans. It is thought that the Paleolithic diet included as much as 1.65–1.9 kilograms per day of fruit and vegetables. The relative proportions of plant and animal foods in the diets of Paleolithic people often varied between regions, with more meat being necessary in colder regions (which weren't populated by anatomically modern humans until 30,000-50,000 BP). It is generally agreed that many modern hunting and fishing tools, such as fish hooks, nets, bows, and poisons, weren't introduced until the Upper Paleolithic and possibly even Neolithic. The only hunting tools widely available to humans during any significant part of the Paleolithic period were hand-held spears and harpoons. There's evidence of Paleolithic people killing and eating seals and elands as far as 100,000 years BP. On the other hand, buffalo bones found in African caves from the same period are typically of very young or very old individuals, and there's no evidence that pigs, elephants or rhinos were hunted by humans at the time.
Paleolithic peoples suffered less famine and malnutrition than the Neolithic farming tribes that followed them. This was partly because Paleolithic hunter-gatherers accessed to a wider variety natural foods, which allowed them a more nutritious diet and a decreased risk of famine. Many of the famines experienced by Neolithic (and some modern) farmers were caused or amplified by their dependence on a small number of crops. It is thought that wild foods can have a significantly different nutritional profile than cultivated foods. The greater amount of meat obtained by hunting big game animals in Paleolithic diets than Neolithic diets may have also allowed Paleolithic hunter-gatherers to enjoy a more nutritious diet than Neolithic agriculturalists. It has been argued that the shift from hunting and gathering to agriculture resulted in an increasing focus on a limited variety of foods, with meat likely taking a back seat to plants. It is also unlikely that Paleolithic hunter-gatherers were affected by modern diseases of affluence such as Type 2 diabetes, coronary heart disease and cerebrovascular disease, because they ate mostly lean meats and plants and frequently engaged in intense physical activity, and because the average lifespan was shorter than the age of common-onset of these conditions.
Large-seeded legumes were part of the human diet long before the Neolithic agricultural revolution, as evident from archaeobotanical finds from the Mousterian layers of Kebara Cave, in Israel.<ref name="doi10.1016/j.jas.2004.11.006"></ref> There is evidence suggesting that Paleolithic societies were gathering wild cereals for food use at least as early as 30,000 years ago. However, seeds, such as grains and beans, were rarely eaten and never in large quantities on a daily basis.<ref name=doi:10.1080/11026480510032043></ref> Recent archeological evidence also indicates that winemaking may have originated in the Paleolithic, when early humans drank the juice of naturally fermented wild grapes from animal-skin pouches. Paleolithic humans consumed animal organ meats, including the livers, kidneys and brains. Upper Paleolithic cultures appear to have had significant knowledge about plants and herbs and may have, albeit very rarely, practiced rudimentary forms of horticulture. In particular, bananas and tubers may have been cultivated as early as 25,000 BP in southeast Asia. Late Upper Paleolithic societies also appear to have occasionally practiced pastoralism and animal husbandry, presumably for dietary reasons. For instance, some European late Upper Paleolithic cultures domesticated and raised reindeer, presumably for their meat or milk, as early as 14,000 BP. Humans also probably consumed hallucinogenic plants during the Paleolithic period. The Australian Aborigines have been consuming a variety of native animal and plant foods, called bushfood, for an estimated 60,000 years, since the Middle Paleolithic.
People during the Middle Paleolithic, such as the Neanderthals and Middle Paleolithic Homo sapiens in Africa, began to catch shellfish for food as revealed by shellfish cooking in Neanderthal sites in Italy about 110,000 years ago and Middle Paleolithic "Homo sapiens" sites at Pinnacle Point, in Africa around 164,000 BP.<ref name=NYTIMES/10/08/07></ref> Although fishing only became common during the Upper Paleolithic, fish have been part of human diets long before the dawn of the Upper Paleolithic and have certainly been consumed by humans since at least the Middle Paleolithic. For example, the Middle Paleolithic "Homo sapiens" in the region now occupied by the Democratic Republic of the Congo hunted large -long catfish with specialized barbed fishing points as early as 90,000 years ago. The invention of fishing allowed some Upper Paleolithic and later hunter-gatherer societies to become sedentary or semi-nomadic, which altered their social structures. Example societies are the Lepenski Vir as well as some contemporary hunter-gatherers such as the Tlingit. In some instances (at least the Tlingit) they developed social stratification, slavery and complex social structures such as chiefdoms.
Anthropologists such as Tim White suggest that cannibalism was common in human societies prior to the beginning of the Upper Paleolithic, based on the large amount of “butchered human" bones found in Neanderthal and other Lower/Middle Paleolithic sites. Cannibalism in the Lower and Middle Paleolithic may have occurred because of food shortages. However, it may have been for religious reasons, and would coincide with the development of religious practices thought to have occurred during the Upper Paleolithic. Nonetheless, it remains possible that Paleolithic societies never practiced cannibalism, and that the damage to recovered human bones was either the result of ritual post-mortem bone cleaning or predation by carnivores such as saber tooth cats, lions and hyenas.

</doc>
<doc id="22873" url="https://en.wikipedia.org/wiki?curid=22873" title="Presidential Medal of Freedom">
Presidential Medal of Freedom

The Presidential Medal of Freedom is an award bestowed by the President of the United States and is—along with the 
comparable Congressional Gold Medal, bestowed by an act of U.S. Congress—the highest civilian award of the United States. It recognizes those individuals who have made "an especially meritorious contribution to the security or national interests of the United States, world peace, cultural or other significant public or private endeavors". The award is not limited to U.S. citizens and, while it is a civilian award, it can also be awarded to military personnel and worn on the uniform.
It was established in 1963 and replaced the earlier Medal of Freedom that was established by President Harry S. Truman in 1945 to honor civilian service during World War II.
History of the award.
Similar in name to the Medal of Freedom, but much closer in meaning and precedence to the Medal for Merit: the Presidential Medal of Freedom is currently the supreme civilian decoration in precedence, whereas the Medal of Freedom was inferior in precedence to the Medal for Merit; the Medal of Freedom was awarded by any of three Cabinet secretaries, whereas the Medal for Merit was awarded by the president, as is the Presidential Medal of Freedom. Another measure of the difference between these two similarly named but very distinct awards is their per-capita frequency of award: from 1946 to 1961 the average annual incidence of award of the Medal of Freedom was approximately 1 per every 86,500 adult U.S. citizens; from 1996 to 2011 the average annual incidence of award of the Presidential Medal of Freedom was approximately 1 per every 20,500,000 adult U.S. citizens (so on an annualized per capita basis, 240 Medals of Freedom have been awarded per one Presidential Medal of Freedom).
President John F. Kennedy established the current decoration in 1963 through , with unique and distinctive insignia, vastly expanded purpose, and far higher prestige. It was the first U.S. civilian neck decoration and, in the grade of Awarded With Distinction, is the only U.S. sash and star decoration (the Chief Commander degree of the Legion of Merit – which may only be awarded to foreign heads of state – is a star decoration, but without a sash). The Executive Order calls for the medal to be awarded annually on or around July 4, and at other convenient times as chosen by the president, but it has not been awarded every year (e.g., 2001, 2010). Recipients are selected by the president, either on his own initiative or based on recommendations. The order establishing the medal also expanded the size and the responsibilities of the Distinguished Civilian Service Awards Board so it could serve as a major source of such recommendations.
The medal may be awarded to an individual more than once; Colin Powell received two awards; Ellsworth Bunker received both of his awards With Distinction. It may also be awarded posthumously; examples (in chronological order) include John F. Kennedy, Pope John XXIII, Lyndon Johnson, Paul "Bear" Bryant, Thurgood Marshall, Cesar Chavez, Roberto Clemente, Jack Kemp, James Chaney, Andrew Goodman and Michael Schwerner. (Chaney, Goodman and Schwerner, civil rights workers murdered in 1964, were awarded their medals in 2014, 50 years later.)
Insignia.
The badge of the Presidential Medal of Freedom is in the form of a golden star with white enamel, with a red enamel pentagon behind it; the central disc bears thirteen gold stars on a blue enamel background (taken from the Great Seal of the United States) within a golden ring. Golden American bald eagles with spread wings stand between the points of the star. It is worn around the neck on a blue ribbon with white edge stripes.
A special, rarely given grade of the medal, known as the Presidential Medal of Freedom with Distinction, has a larger execution of the same medal design worn as a star on the left chest along with a sash over the right shoulder (similar to how the insignia of a Grand Cross is worn), with its rosette (blue with white edge, bearing the central disc of the medal at its center) resting on the left hip. When the medal With Distinction is awarded, the star may be presented descending from a neck ribbon and can be identified by its larger size than the standard medal (compare size of medals in pictures below; President Reagan's was awarded With Distinction).
Both medals may also be worn in miniature form on a ribbon on the left chest, with a silver American bald eagle with spread wings on the ribbon, or a golden American bald eagle for a medal awarded With Distinction. In addition, the medal is accompanied by a service ribbon for wear on military service uniform, a miniature medal pendant for wear on mess dress or civilian formal wear, and a lapel badge for wear on civilian clothes (all shown in the accompanying photograph of the full presentation set).

</doc>
<doc id="22915" url="https://en.wikipedia.org/wiki?curid=22915" title="Planet">
Planet

A planet () is an astronomical object orbiting a star or stellar remnant that
The term "planet" is ancient, with ties to history, science, mythology, and religion. Several planets in the Solar System can be seen with the naked eye. These were regarded by many early cultures as divine, or as emissaries of deities. As scientific knowledge advanced, human perception of the planets changed, incorporating a number of disparate objects. In 2006, the International Astronomical Union (IAU) officially adopted a resolution defining planets within the Solar System. This definition is controversial because it excludes many objects of planetary mass based on where or what they orbit. Although eight of the planetary bodies discovered before 1950 remain "planets" under the modern definition, some celestial bodies, such as Ceres, Pallas, Juno and Vesta (each an object in the solar asteroid belt), and Pluto (the first trans-Neptunian object discovered), that were once considered planets by the scientific community, are no longer viewed as such.
The planets were thought by Ptolemy to orbit Earth in deferent and epicycle motions. Although the idea that the planets orbited the Sun had been suggested many times, it was not until the 17th century that this view was supported by evidence from the first telescopic astronomical observations, performed by Galileo Galilei. By careful analysis of the observation data, Johannes Kepler found the planets' orbits were not circular but elliptical. As observational tools improved, astronomers saw that, like Earth, the planets rotated around tilted axes, and some shared such features as ice caps and seasons. Since the dawn of the Space Age, close observation by space probes has found that Earth and the other planets share characteristics such as volcanism, hurricanes, tectonics, and even hydrology.
Planets are generally divided into two main types: large low-density giant planets, and smaller rocky terrestrials. Under IAU definitions, there are eight planets in the Solar System. In order of increasing distance from the Sun, they are the four terrestrials, Mercury, Venus, Earth, and Mars, then the four giant planets, Jupiter, Saturn, Uranus, and Neptune. Six of the planets are orbited by one or more natural satellites.
More than two thousand planets around other stars ("extrasolar planets" or "exoplanets") have been discovered in the Milky Way: as of , known extrasolar planets in planetary systems (including multiple planetary systems), ranging in size from just above the size of the Moon to gas giants about twice as large as Jupiter. On December 20, 2011, the Kepler Space Telescope team reported the discovery of the first Earth-sized extrasolar planets, Kepler-20e and Kepler-20f, orbiting a Sun-like star, Kepler-20. A 2012 study, analyzing gravitational microlensing data, estimates an average of at least 1.6 bound planets for every star in the Milky Way.
Around one in five Sun-like stars is thought to have an Earth-sized planet in its habitable zone.
History.
The idea of planets has evolved over its history, from the divine wandering stars of antiquity to the earthly objects of the scientific age. The concept has expanded to include worlds not only in the Solar System, but in hundreds of other extrasolar systems. The ambiguities inherent in defining planets have led to much scientific controversy.
The five classical planets, being visible to the naked eye, have been known since ancient times and have had a significant impact on mythology, religious cosmology, and ancient astronomy. In ancient times, astronomers noted how certain lights moved across the sky in relation to the other stars. Ancient Greeks called these lights (, "wandering stars") or simply (, "wanderers"), from which today's word "planet" was derived. In ancient Greece, China, Babylon, and indeed all pre-modern civilizations, it was almost universally believed that Earth was the center of the Universe and that all the "planets" circled Earth. The reasons for this perception were that stars and planets appeared to revolve around Earth each day and the apparently common-sense perceptions that Earth was solid and stable and that it was not moving but at rest.
Babylon.
The first civilization known to have a functional theory of the planets were the Babylonians, who lived in Mesopotamia in the first and second millennia BC. The oldest surviving planetary astronomical text is the Babylonian Venus tablet of Ammisaduqa, a 7th-century BC copy of a list of observations of the motions of the planet Venus, that probably dates as early as the second millennium BC. The MUL.APIN is a pair of cuneiform tablets dating from the 7th century BC that lays out the motions of the Sun, Moon and planets over the course of the year. The Babylonian astrologers also laid the foundations of what would eventually become Western astrology. The "Enuma anu enlil", written during the Neo-Assyrian period in the 7th century BC, comprises a list of omens and their relationships with various celestial phenomena including the motions of the planets. Venus, Mercury and the outer planets Mars, Jupiter and Saturn were all identified by Babylonian astronomers. These would remain the only known planets until the invention of the telescope in early modern times.
Greco-Roman astronomy.
The ancient Greeks initially did not attach as much significance to the planets as the Babylonians. The Pythagoreans, in the 6th and 5th centuries BC appear to have developed their own independent planetary theory, which consisted of the Earth, Sun, Moon, and planets revolving around a "Central Fire" at the center of the Universe. Pythagoras or Parmenides is said to have been the first to identify the evening star (Hesperos) and morning star (Phosphoros) as one and the same (Aphrodite, Greek corresponding to Latin Venus). In the 3rd century BC, Aristarchus of Samos proposed a heliocentric system, according to which Earth and the planets revolved around the Sun. The geocentric system remained dominant until the Scientific Revolution.
By the 1st century BC, during the Hellenistic period, the Greeks had begun to develop their own mathematical schemes for predicting the positions of the planets. These schemes, which were based on geometry rather than the arithmetic of the Babylonians, would eventually eclipse the Babylonians' theories in complexity and comprehensiveness, and account for most of the astronomical movements observed from Earth with the naked eye. These theories would reach their fullest expression in the "Almagest" written by Ptolemy in the 2nd century CE. So complete was the domination of Ptolemy's model that it superseded all previous works on astronomy and remained the definitive astronomical text in the Western world for 13 centuries. To the Greeks and Romans there were seven known planets, each presumed to be circling Earth according to the complex laws laid out by Ptolemy. They were, in increasing order from Earth (in Ptolemy's order): the Moon, Mercury, Venus, the Sun, Mars, Jupiter, and Saturn.
India.
In 499 CE, the Indian astronomer Aryabhata propounded a planetary model that explicitly incorporated Earth's rotation about its axis, which he explains as the cause of what appears to be an apparent westward motion of the stars. He also believed that the orbits of planets are elliptical.
Aryabhata's followers were particularly strong in South India, where his principles of the diurnal rotation of Earth, among others, were followed and a number of secondary works were based on them.
In 1500, Nilakantha Somayaji of the Kerala school of astronomy and mathematics, in his "Tantrasangraha", revised Aryabhata's model. In his "Aryabhatiyabhasya", a commentary on Aryabhata's "Aryabhatiya", he developed a planetary model where Mercury, Venus, Mars, Jupiter and Saturn orbit the Sun, which in turn orbits Earth, similar to the Tychonic system later proposed by Tycho Brahe in the late 16th century. Most astronomers of the Kerala school who followed him accepted his planetary model.
Medieval Muslim astronomy.
In the 11th century, the transit of Venus was observed by Avicenna, who established that Venus was, at least sometimes, below the Sun. In the 12th century, Ibn Bajjah observed "two planets as black spots on the face of the Sun", which was later identified as a transit of Mercury and Venus by the Maragha astronomer Qotb al-Din Shirazi in the 13th century. Ibn Bajjah could not have observed a transit of Venus, because none occurred in his lifetime.
European Renaissance.
With the advent of the Scientific Revolution, use of the term "planet" changed from something that moved across the sky (in relation to the star field); to a body that orbited Earth (or that were believed to do so at the time); and by the 18th century to something that directly orbited the Sun when the heliocentric model of Copernicus, Galileo and Kepler gained sway.
Thus, Earth became included in the list of planets, whereas the Sun and Moon were excluded. At first, when the first satellites of Jupiter and Saturn were discovered in the 17th century, the terms "planet" and "satellite" were used interchangeably – although the latter would gradually become more prevalent in the following century. Until the mid-19th century, the number of "planets" rose rapidly because any newly discovered object directly orbiting the Sun was listed as a planet by the scientific community.
19th century.
In the 19th century astronomers began to realize that recently discovered bodies that had been classified as planets for almost half a century (such as Ceres, Pallas, and Vesta) were very different from the traditional ones. These bodies shared the same region of space between Mars and Jupiter (the asteroid belt), and had a much smaller mass; as a result they were reclassified as "asteroids". In the absence of any formal definition, a "planet" came to be understood as any "large" body that orbited the Sun. Because there was a dramatic size gap between the asteroids and the planets, and the spate of new discoveries seemed to have ended after the discovery of Neptune in 1846, there was no apparent need to have a formal definition.
20th century.
In the 20th century, Pluto was discovered. After initial observations led to the belief it was larger than Earth, the object was immediately accepted as the ninth planet. Further monitoring found the body was actually much smaller: in 1936, Raymond Lyttleton suggested that Pluto may be an escaped satellite of Neptune, and Fred Whipple suggested in 1964 that Pluto may be a comet. As it was still larger than all known asteroids and seemingly did not exist within a larger population, it kept its status until 2006.
In 1992, astronomers Aleksander Wolszczan and Dale Frail announced the discovery of planets around a pulsar, PSR B1257+12. This discovery is generally considered to be the first definitive detection of a planetary system around another star. Then, on October 6, 1995, Michel Mayor and Didier Queloz of the Geneva Observatory announced the first definitive detection of an exoplanet orbiting an ordinary main-sequence star (51 Pegasi).
The discovery of extrasolar planets led to another ambiguity in defining a planet: the point at which a planet becomes a star. Many known extrasolar planets are many times the mass of Jupiter, approaching that of stellar objects known as brown dwarfs. Brown dwarfs are generally considered stars due to their ability to fuse deuterium, a heavier isotope of hydrogen. Although objects more massive than 75 times that of Jupiter fuse hydrogen, objects of only 13 Jupiter masses can fuse deuterium. Deuterium is quite rare, and most brown dwarfs would have ceased fusing deuterium long before their discovery, making them effectively indistinguishable from supermassive planets.
21st century.
With the discovery during the latter half of the 20th century of more objects within the Solar System and large objects around other stars, disputes arose over what should constitute a planet. There were particular disagreements over whether an object should be considered a planet if it was part of a distinct population such as a belt, or if it was large enough to generate energy by the thermonuclear fusion of deuterium.
A growing number of astronomers argued for Pluto to be declassified as a planet, because many similar objects approaching its size had been found in the same region of the Solar System (the Kuiper belt) during the 1990s and early 2000s. Pluto was found to be just one small body in a population of thousands.
Some of them, such as Quaoar, Sedna, and Eris, were heralded in the popular press as the tenth planet, failing to receive widespread scientific recognition. The announcement of Eris in 2005, an object 27% more massive than Pluto, created the necessity and public desire for an official definition of a planet.
Acknowledging the problem, the IAU set about creating the definition of planet, and produced one in August 2006. The number of planets dropped to the eight significantly larger bodies that had cleared their orbit (Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune), and a new class of dwarf planets was created, initially containing three objects (Ceres, Pluto and Eris).
Extrasolar planet definition.
In 2003, the International Astronomical Union (IAU) Working Group on Extrasolar Planets made a position statement on the definition of a planet that incorporated the following working definition, mostly focused upon the boundary between planets and brown dwarfs:
This definition has since been widely used by astronomers when publishing discoveries of exoplanets in academic journals. Although temporary, it remains an effective working definition until a more permanent one is formally adopted. It does not address the dispute over the lower mass limit, and so it steered clear of the controversy regarding objects within the Solar System. This definition also makes no comment on the planetary status of objects orbiting brown dwarfs, such as 2M1207b.
One definition of a sub-brown dwarf is a planet-mass object that formed through cloud collapse rather than accretion. This formation distinction between a sub-brown dwarf and a planet is not universally agreed upon; astronomers are divided into two camps as whether to consider the formation process of a planet as part of its division in classification. One reason for the dissent is that often it may not be possible to determine the formation process. For example, a planet formed by accretion around a star may get ejected from the system to become free-floating, and likewise a sub-brown dwarf that formed on its own in a star cluster through cloud collapse may get captured into orbit around a star.
The 13 Jupiter-mass cutoff is a rule of thumb rather than something of precise physical significance. The question arises: what is meant by deuterium burning? This question arises because large objects will burn most of their deuterium and smaller ones will burn only a little, and the 13 value is somewhere in between. The amount of deuterium burnt depends not only on mass but also on the composition of the planet, on the amount of helium and deuterium present. The Extrasolar Planets Encyclopaedia includes objects up to 25 Jupiter masses, saying, "The fact that there is no special feature around 13 in the observed mass spectrum reinforces the choice to forget this mass limit." The Exoplanet Data Explorer includes objects up to 24 Jupiter masses with the advisory: "The 13 Jupiter-mass distinction by the IAU Working Group is physically unmotivated for planets with rocky cores, and observationally problematic due to the sin i ambiguity."
The NASA Exoplanet Archive includes objects with a mass (or minimum mass) equal to or less than 30 Jupiter masses.
Another criterion for separating planets and brown dwarfs, rather than deuterium burning, formation process or location, is whether the core pressure is dominated by coulomb pressure or electron degeneracy pressure.
2006 definition.
The matter of the lower limit was addressed during the 2006 meeting of the IAU's General Assembly. After much debate and one failed proposal, 232 members of the 10,000 member assembly, who nevertheless constituted a large majority of those remaining at the meeting, voted to pass a resolution. The 2006 resolution redefines planets within the Solar System as:
Under this definition, the Solar System is considered to have eight planets. Bodies that fulfill the first two conditions but not the third (such as Ceres, Pluto, and Eris) are classified as dwarf planets, provided they are not also natural satellites of other planets. Originally an IAU committee had proposed a definition that would have included a much larger number of planets as it did not include (c) as a criterion. After much discussion, it was decided via a vote that those bodies should instead be classified as dwarf planets.
This definition is based in theories of planetary formation, in which planetary embryos initially clear their orbital neighborhood of other smaller objects. As described by astronomer Steven Soter:
Beyond the scientific community, Pluto still holds cultural significance for many in the general public due to its historical classification as a planet from 1930 to 2006.
Objects formerly considered planets.
The table below lists Solar System bodies once considered to be planets.
A few astronomers, such as Alan Stern, consider dwarf planets and the larger moons to be planets, based on a purely geophysical definition of "planet".
Mythology and naming.
The names for the planets in the Western world are derived from the naming practices of the Romans, which ultimately derive from those of the Greeks and the Babylonians. In ancient Greece, the two great luminaries the Sun and the Moon were called "Helios" and "Selene"; the farthest planet (Saturn) was called "Phainon", the shiner; followed by "Phaethon" (Jupiter), "bright"; the red planet (Mars) was known as "Pyroeis", the "fiery"; the brightest (Venus) was known as "Phosphoros", the light bringer; and the fleeting final planet (Mercury) was called "Stilbon", the gleamer. The Greeks also made each planet sacred to one among their pantheon of gods, the Olympians: Helios and Selene were the names of both planets and gods; Phainon was sacred to Cronus, the Titan who fathered the Olympians; Phaethon was sacred to Zeus, Cronus's son who deposed him as king; Pyroeis was given to Ares, son of Zeus and god of war; Phosphoros was ruled by Aphrodite, the goddess of love; and Hermes, messenger of the gods and god of learning and wit, ruled over Stilbon.
The Greek practice of grafting of their gods' names onto the planets was almost certainly borrowed from the Babylonians. The Babylonians named Phosphoros after their goddess of love, "Ishtar"; Pyroeis after their god of war, "Nergal", Stilbon after their god of wisdom Nabu, and Phaethon after their chief god, "Marduk". There are too many concordances between Greek and Babylonian naming conventions for them to have arisen separately. The translation was not perfect. For instance, the Babylonian Nergal was a god of war, and thus the Greeks identified him with Ares. Unlike Ares, Nergal was also god of pestilence and the underworld.
Today, most people in the western world know the planets by names derived from the Olympian pantheon of gods. Although modern Greeks still use their ancient names for the planets, other European languages, because of the influence of the Roman Empire and, later, the Catholic Church, use the Roman (Latin) names rather than the Greek ones. The Romans, who, like the Greeks, were Indo-Europeans, shared with them a common pantheon under different names but lacked the rich narrative traditions that Greek poetic culture had given their gods. During the later period of the Roman Republic, Roman writers borrowed much of the Greek narratives and applied them to their own pantheon, to the point where they became virtually indistinguishable. When the Romans studied Greek astronomy, they gave the planets their own gods' names: "Mercurius" (for Hermes), "Venus" (Aphrodite), "Mars" (Ares), "Iuppiter" (Zeus) and "Saturnus" (Cronus). When subsequent planets were discovered in the 18th and 19th centuries, the naming practice was retained with "Neptūnus" (Poseidon). Uranus is unique in that it is named for a Greek deity rather than his Roman counterpart.
Some Romans, following a belief possibly originating in Mesopotamia but developed in Hellenistic Egypt, believed that the seven gods after whom the planets were named took hourly shifts in looking after affairs on Earth. The order of shifts went Saturn, Jupiter, Mars, Sun, Venus, Mercury, Moon (from the farthest to the closest planet). Therefore, the first day was started by Saturn (1st hour), second day by Sun (25th hour), followed by Moon (49th hour), Mars, Mercury, Jupiter and Venus. Because each day was named by the god that started it, this is also the order of the days of the week in the Roman calendar after the Nundinal cycle was rejected – and still preserved in many modern languages. In English, "Saturday, Sunday," and "Monday" are straightforward translations of these Roman names. The other days were renamed after "Tiw", (Tuesday) "Wóden" (Wednesday), "Thunor" (Thursday), and "Fríge" (Friday), the Anglo-Saxon gods considered similar or equivalent to Mars, Mercury, Jupiter, and Venus, respectively.
Earth is the only planet whose name in English is not derived from Greco-Roman mythology. Because it was only generally accepted as a planet in the 17th century, there is no tradition of naming it after a god. (The same is true, in English at least, of the Sun and the Moon, though they are no longer generally considered planets.) The name originates from the 8th century Anglo-Saxon word "erda", which means ground or soil and was first used in writing as the name of the sphere of Earth perhaps around 1300. As with its equivalents in the other Germanic languages, it derives ultimately from the Proto-Germanic word "ertho", "ground", as can be seen in the English "earth", the German "Erde", the Dutch "aarde", and the Scandinavian "jord". Many of the Romance languages retain the old Roman word "terra" (or some variation of it) that was used with the meaning of "dry land" as opposed to "sea". The non-Romance languages use their own native words. The Greeks retain their original name, "Γή" "(Ge)".
Non-European cultures use other planetary-naming systems. India uses a system based on the Navagraha, which incorporates the seven traditional planets (Surya for the Sun, Chandra for the Moon, and Budha, Shukra, Mangala, and Shani for Mercury, Venus, Mars, Jupiter and Saturn) and the ascending and descending lunar nodes Rahu and Ketu. China and the countries of eastern Asia historically subject to Chinese cultural influence (such as Japan, Korea and Vietnam) use a naming system based on the five Chinese elements: water (Mercury), metal (Venus), fire (Mars), wood (Jupiter) and earth (Saturn).
Formation.
It is not known with certainty how planets are formed. The prevailing theory is that they are formed during the collapse of a nebula into a thin disk of gas and dust. A protostar forms at the core, surrounded by a rotating protoplanetary disk. Through accretion (a process of sticky collision) dust particles in the disk steadily accumulate mass to form ever-larger bodies. Local concentrations of mass known as planetesimals form, and these accelerate the accretion process by drawing in additional material by their gravitational attraction. These concentrations become ever denser until they collapse inward under gravity to form protoplanets. After a planet reaches a diameter larger than the Moon, it begins to accumulate an extended atmosphere, greatly increasing the capture rate of the planetesimals by means of atmospheric drag.
When the protostar has grown such that it ignites to form a star, the surviving disk is removed from the inside outward by photoevaporation, the solar wind, Poynting–Robertson drag and other effects. Thereafter there still may be many protoplanets orbiting the star or each other, but over time many will collide, either to form a single larger planet or release material for other larger protoplanets or planets to absorb. Those objects that have become massive enough will capture most matter in their orbital neighbourhoods to become planets. Protoplanets that have avoided collisions may become natural satellites of planets through a process of gravitational capture, or remain in belts of other objects to become either dwarf planets or small bodies.
The energetic impacts of the smaller planetesimals (as well as radioactive decay) will heat up the growing planet, causing it to at least partially melt. The interior of the planet begins to differentiate by mass, developing a denser core. Smaller terrestrial planets lose most of their atmospheres because of this accretion, but the lost gases can be replaced by outgassing from the mantle and from the subsequent impact of comets. (Smaller planets will lose any atmosphere they gain through various escape mechanisms.)
With the discovery and observation of planetary systems around stars other than the Sun, it is becoming possible to elaborate, revise or even replace this account. The level of metallicity—an astronomical term describing the abundance of chemical elements with an atomic number greater than 2 (helium)—is now believed to determine the likelihood that a star will have planets. Hence, it is thought that a metal-rich population I star will likely have a more substantial planetary system than a metal-poor, population II star.
Solar System.
There are eight planets in the Solar System, which are in increasing distance from the Sun:
Jupiter is the largest, at 318 Earth masses, whereas Mercury is the smallest, at 0.055 Earth masses.
The planets of the Solar System can be divided into categories based on their composition:
Exoplanets.
An exoplanet (extrasolar planet) is a planet outside the Solar System. More than 2000 such planets have been discovered
( planets in planetary systems including multiple planetary systems as of ).
In early 1992, radio astronomers Aleksander Wolszczan and Dale Frail announced the discovery of two planets orbiting the pulsar PSR 1257+12. This discovery was confirmed, and is generally considered to be the first definitive detection of exoplanets. These pulsar planets are believed to have formed from the unusual remnants of the supernova that produced the pulsar, in a second round of planet formation, or else to be the remaining rocky cores of giant planets that survived the supernova and then decayed into their current orbits.
The first confirmed discovery of an extrasolar planet orbiting an ordinary main-sequence star occurred on 6 October 1995, when Michel Mayor and Didier Queloz of the University of Geneva announced the detection of an exoplanet around 51 Pegasi. From then until the Kepler mission most known extrasolar planets were gas giants comparable in mass to Jupiter or larger as they were more easily detected. The catalog of Kepler candidate planets consists mostly of planets the size of Neptune and smaller, down to smaller than Mercury.
There are types of planets that do not exist in the Solar System: super-Earths and mini-Neptunes, which could be rocky like Earth or a mixture of volatiles and gas like Neptune—a radius of 1.75 times that of Earth is a possible dividing line between the two types of planet. There are hot Jupiters that orbit very close to their star and may evaporate to become chthonian planets, which are the leftover cores. Another possible type of planet is carbon planets, which form in systems with a higher proportion of carbon than in the Solar System.
A 2012 study, analyzing gravitational microlensing data, estimates an average of at least 1.6 bound planets for every star in the Milky Way.
On December 20, 2011, the Kepler Space Telescope team reported the discovery of the first Earth-size exoplanets, Kepler-20e and Kepler-20f, orbiting a Sun-like star, Kepler-20.
Around 1 in 5 Sun-like stars have an "Earth-sized" planet in the habitable zone, so the nearest would be expected to be within 12 light-years distance from Earth.
The frequency of occurrence of such terrestrial planets is one of the variables in the Drake equation, which estimates the number of intelligent, communicating civilizations that exist in the Milky Way.
There are exoplanets that are much closer to their parent star than any planet in the Solar System is to the Sun, and there are also exoplanets that are much further from their star. Mercury, the closest planet to the Sun at 0.4AU, takes 88-days for an orbit, but the shortest known orbits for exoplanets take only a few hours, e.g. Kepler-70b. The Kepler-11 system has five of its planets in shorter orbits than Mercury. Neptune is 30AU from the Sun and takes 165 years to orbit, but there are exoplanets that are hundreds of AU from their star and take more than a thousand years to orbit, e.g. 1RXS1609 b.
The next few space telescopes to study exoplanets are expected to be Gaia launched in December 2013, CHEOPS in 2017, TESS in 2017, and the James Webb Space Telescope in 2018.
Planetary-mass objects.
A planetary-mass object (PMO), planemo , or planetary body is a celestial object with a mass that falls within the range of the definition of a planet: massive enough to achieve hydrostatic equilibrium (to be rounded under its own gravity), but not enough to sustain core fusion like a star. By definition, all planets are "planetary-mass objects", but the purpose of this term is to refer to objects that do not conform to typical expectations for a planet. These include dwarf planets, which are rounded by their own gravity but not massive enough to clear their own orbit, the larger moons, and free-floating planemos, which may have been ejected from a system (rogue planets) or formed through cloud-collapse rather than accretion (sometimes called sub-brown dwarfs).
Rogue planets.
Several computer simulations of stellar and planetary system formation have suggested that some objects of planetary mass would be ejected into interstellar space. Some scientists have argued that such objects found roaming in deep space should be classed as "planets", although others have suggested that they should be called low-mass brown dwarfs.
Sub-brown dwarfs.
Stars form via the gravitational collapse of gas clouds, but smaller objects can also form via cloud-collapse. Planetary-mass objects formed this way are sometimes called sub-brown dwarfs. Sub-brown dwarfs may be free-floating such as Cha 110913-773444 and OTS 44, or orbiting a larger object such as 2MASS J04414489+2301513.
For a brief time in 2006, astronomers believed they had found a binary system of such objects, Oph 162225-240515, which the discoverers described as "planemos", or "planetary-mass objects". Recent analysis of the objects has determined that their masses are probably each greater than 13 Jupiter-masses, making the pair brown dwarfs.
Former stars.
In close binary star systems one of the stars can lose mass to a heavier companion. Accretion-powered pulsars may drive mass loss. The shrinking star can then become a planetary-mass object. An example is a Jupiter-mass object orbiting the pulsar PSR J1719-1438. These shrunken white dwarfs may become a helium planet or diamond planet.
Satellite planets and belt planets.
Some large satellites are of similar size or larger than the planet Mercury, e.g. Jupiter's Galilean moons and Titan. Alan Stern has argued that location should not matter and that only geophysical attributes should be taken into account in the definition of a planet, and proposes the term "satellite planet" for a planet-sized satellite. Likewise, dwarf planets in the asteroid belt and Kuiper belt should be considered planets according to Stern.
Captured planets.
Free-floating planets in stellar clusters have similar velocities to the stars and so can be recaptured. They are typically captured into wide orbits between 100 and 105 AU. The capture efficiency decreases with increasing cluster volume, and for a given cluster size it increases with the host/primary mass. It is almost independent of the planetary mass. Single and multiple planets could be captured into arbitrary unaligned orbits, non-coplanar with each other or with the stellar host spin, or pre-existing planetary system.
Attributes.
Although each planet has unique physical characteristics, a number of broad commonalities do exist among them. Some of these characteristics, such as rings or natural satellites, have only as yet been observed in planets in the Solar System, whereas others are also commonly observed in extrasolar planets.
Dynamic characteristics.
Orbit.
According to current definitions, all planets must revolve around stars; thus, any potential "rogue planets" are excluded. In the Solar System, all the planets orbit the Sun in the same direction as the Sun rotates (counter-clockwise as seen from above the Sun's north pole). At least one extrasolar planet, WASP-17b, has been found to orbit in the opposite direction to its star's rotation. The period of one revolution of a planet's orbit is known as its sidereal period or "year". A planet's year depends on its distance from its star; the farther a planet is from its star, not only the longer the distance it must travel, but also the slower its speed, because it is less affected by its star's gravity. No planet's orbit is perfectly circular, and hence the distance of each varies over the course of its year. The closest approach to its star is called its periastron (perihelion in the Solar System), whereas its farthest separation from the star is called its apastron (aphelion). As a planet approaches periastron, its speed increases as it trades gravitational potential energy for kinetic energy, just as a falling object on Earth accelerates as it falls; as the planet reaches apastron, its speed decreases, just as an object thrown upwards on Earth slows down as it reaches the apex of its trajectory.
Each planet's orbit is delineated by a set of elements:
Axial tilt.
Planets also have varying degrees of axial tilt; they lie at an angle to the plane of their stars' equators. This causes the amount of light received by each hemisphere to vary over the course of its year; when the northern hemisphere points away from its star, the southern hemisphere points towards it, and vice versa. Each planet therefore has seasons; changes to the climate over the course of its year. The time at which each hemisphere points farthest or nearest from its star is known as its solstice. Each planet has two in the course of its orbit; when one hemisphere has its summer solstice, when its day is longest, the other has its winter solstice, when its day is shortest. The varying amount of light and heat received by each hemisphere creates annual changes in weather patterns for each half of the planet. Jupiter's axial tilt is very small, so its seasonal variation is minimal; Uranus, on the other hand, has an axial tilt so extreme it is virtually on its side, which means that its hemispheres are either perpetually in sunlight or perpetually in darkness around the time of its solstices. Among extrasolar planets, axial tilts are not known for certain, though most hot Jupiters are believed to have negligible to no axial tilt as a result of their proximity to their stars.
Rotation.
The planets rotate around invisible axes through their centres. A planet's rotation period is known as a stellar day. Most of the planets in the Solar System rotate in the same direction as they orbit the Sun, which is counter-clockwise as seen from above the Sun's north pole, the exceptions being Venus and Uranus, which rotate clockwise, though Uranus's extreme axial tilt means there are differing conventions on which of its poles is "north", and therefore whether it is rotating clockwise or anti-clockwise. Regardless of which convention is used, Uranus has a retrograde rotation relative to its orbit.
The rotation of a planet can be induced by several factors during formation. A net angular momentum can be induced by the individual angular momentum contributions of accreted objects. The accretion of gas by the giant planets can also contribute to the angular momentum. Finally, during the last stages of planet building, a stochastic process of protoplanetary accretion can randomly alter the spin axis of the planet. There is great variation in the length of day between the planets, with Venus taking 243 days to rotate, and the giant planets only a few hours. The rotational periods of extrasolar planets are not known. However, for "hot" Jupiters, their proximity to their stars means that they are tidally locked (i.e., their orbits are in sync with their rotations). This means, they always show one face to their stars, with one side in perpetual day, the other in perpetual night.
Orbital clearing.
The defining dynamic characteristic of a planet is that it has "cleared its neighborhood". A planet that has cleared its neighborhood has accumulated enough mass to gather up or sweep away all the planetesimals in its orbit. In effect, it orbits its star in isolation, as opposed to sharing its orbit with a multitude of similar-sized objects. This characteristic was mandated as part of the IAU's official definition of a planet in August, 2006. This criterion excludes such planetary bodies as Pluto, Eris and Ceres from full-fledged planethood, making them instead dwarf planets. Although to date this criterion only applies to the Solar System, a number of young extrasolar systems have been found in which evidence suggests orbital clearing is taking place within their circumstellar discs.
Physical characteristics.
Mass.
A planet's defining physical characteristic is that it is massive enough for the force of its own gravity to dominate over the electromagnetic forces binding its physical structure, leading to a state of hydrostatic equilibrium. This effectively means that all planets are spherical or spheroidal. Up to a certain mass, an object can be irregular in shape, but beyond that point, which varies depending on the chemical makeup of the object, gravity begins to pull an object towards its own centre of mass until the object collapses into a sphere.
Mass is also the prime attribute by which planets are distinguished from stars. The upper mass limit for planethood is roughly 13 times Jupiter's mass for objects with solar-type isotopic abundance, beyond which it achieves conditions suitable for nuclear fusion. Other than the Sun, no objects of such mass exist in the Solar System; but there are exoplanets of this size. The 13-Jupiter-mass limit is not universally agreed upon and the Extrasolar Planets Encyclopaedia includes objects up to 20 Jupiter masses, and the Exoplanet Data Explorer up to 24 Jupiter masses.
The smallest known planet is PSR B1257+12A, one of the first extrasolar planets discovered, which was found in 1992 in orbit around a pulsar. Its mass is roughly half that of the planet Mercury. The smallest known planet orbiting a main-sequence star other than the Sun is Kepler-37b, with a mass (and radius) slightly higher than that of the Moon.
Internal differentiation.
Every planet began its existence in an entirely fluid state; in early formation, the denser, heavier materials sank to the centre, leaving the lighter materials near the surface. Each therefore has a differentiated interior consisting of a dense planetary core surrounded by a mantle that either is or was a fluid. The terrestrial planets are sealed within hard crusts, but in the giant planets the mantle simply blends into the upper cloud layers. The terrestrial planets have cores of elements such as iron and nickel, and mantles of silicates. Jupiter and Saturn are believed to have cores of rock and metal surrounded by mantles of metallic hydrogen. Uranus and Neptune, which are smaller, have rocky cores surrounded by mantles of water, ammonia, methane and other ices. The fluid action within these planets' cores creates a geodynamo that generates a magnetic field.
Atmosphere.
All of the Solar System planets except Mercury have substantial atmospheres because their gravity is strong enough to keep gases close to the surface. The larger giant planets are massive enough to keep large amounts of the light gases hydrogen and helium, whereas the smaller planets lose these gases into space. The composition of Earth's atmosphere is different from the other planets because the various life processes that have transpired on the planet have introduced free molecular oxygen.
Planetary atmospheres are affected by the varying insolation or internal energy, leading to the formation of dynamic weather systems such as hurricanes, (on Earth), planet-wide dust storms (on Mars), an Earth-sized anticyclone on Jupiter (called the Great Red Spot), and holes in the atmosphere (on Neptune). At least one extrasolar planet, HD 189733 b, has been claimed to have such a weather system, similar to the Great Red Spot but twice as large.
Hot Jupiters, due to their extreme proximities to their host stars, have been shown to be losing their atmospheres into space due to stellar radiation, much like the tails of comets. These planets may have vast differences in temperature between their day and night sides that produce supersonic winds, although the day and night sides of HD 189733 b appear to have very similar temperatures, indicating that that planet's atmosphere effectively redistributes the star's energy around the planet.
Magnetosphere.
One important characteristic of the planets is their intrinsic magnetic moments, which in turn give rise to magnetospheres. The presence of a magnetic field indicates that the planet is still geologically alive. In other words, magnetized planets have flows of electrically conducting material in their interiors, which generate their magnetic fields. These fields significantly change the interaction of the planet and solar wind. A magnetized planet creates a cavity in the solar wind around itself called magnetosphere, which the wind cannot penetrate. The magnetosphere can be much larger than the planet itself. In contrast, non-magnetized planets have only small magnetospheres induced by interaction of the ionosphere with the solar wind, which cannot effectively protect the planet.
Of the eight planets in the Solar System, only Venus and Mars lack such a magnetic field. In addition, the moon of Jupiter Ganymede also has one. Of the magnetized planets the magnetic field of Mercury is the weakest, and is barely able to deflect the solar wind. Ganymede's magnetic field is several times larger, and Jupiter's is the strongest in the Solar System (so strong in fact that it poses a serious health risk to future manned missions to its moons). The magnetic fields of the other giant planets are roughly similar in strength to that of Earth, but their magnetic moments are significantly larger. The magnetic fields of Uranus and Neptune are strongly tilted relative the rotational axis and displaced from the centre of the planet.
In 2004, a team of astronomers in Hawaii observed an extrasolar planet around the star HD 179949, which appeared to be creating a sunspot on the surface of its parent star. The team hypothesized that the planet's magnetosphere was transferring energy onto the star's surface, increasing its already high 7,760 °C temperature by an additional 400 °C.
Secondary characteristics.
Several planets or dwarf planets in the Solar System (such as Neptune and Pluto) have orbital periods that are in resonance with each other or with smaller bodies (this is also common in satellite systems). All except Mercury and Venus have natural satellites, often called "moons". Earth has one, Mars has two, and the giant planets have numerous moons in complex planetary-type systems. Many moons of the giant planets have features similar to those on the terrestrial planets and dwarf planets, and some have been studied as possible abodes of life (especially Europa).
The four giant planets are also orbited by planetary rings of varying size and complexity. The rings are composed primarily of dust or particulate matter, but can host tiny 'moonlets' whose gravity shapes and maintains their structure. Although the origins of planetary rings is not precisely known, they are believed to be the result of natural satellites that fell below their parent planet's Roche limit and were torn apart by tidal forces.
No secondary characteristics have been observed around extrasolar planets. The sub-brown dwarf Cha 110913-773444, which has been described as a rogue planet, is believed to be orbited by a tiny protoplanetary disc and the sub-brown dwarf OTS 44 was shown to be surrounded by a substantial protoplanetary disk of at least 10 Earth masses.

</doc>
<doc id="22918" url="https://en.wikipedia.org/wiki?curid=22918" title="Paramount Pictures">
Paramount Pictures

Paramount Pictures Corporation (commonly known as Paramount Studios or simply Paramount, and formerly known as Famous Players-Lasky Corporation) is a film studio, television production company and motion picture distributor, consistently ranked as one of the "Big Six" film studios of Hollywood. It is a subsidiary of U.S. media conglomerate Viacom. Paramount is a member of the Motion Picture Association of America (MPAA).
In 2014, Paramount Pictures became the first major Hollywood studio to distribute all of its films in digital-form only.
Paramount is the fifth oldest surviving film studio in the world, and America's oldest running studio, founded in 1912.
History.
1911–1920: Early history.
Paramount is the fifth oldest surviving film studio in the world after the French studios Gaumont Film Company (1895) and Pathé (1896), followed by the Nordisk Film company (1906), and Universal Studios (1912). It is the last major film studio still headquartered in the Hollywood district of Los Angeles.
Paramount Pictures dates its existence from the 1912 founding date of the Famous Players Film Company. Hungarian-born founder, Adolph Zukor, who had been an early investor in nickelodeons, saw that movies appealed mainly to working-class immigrants. With partners Daniel Frohman and Charles Frohman he planned to offer feature-length films that would appeal to the middle class by featuring the leading theatrical players of the time (leading to the slogan "Famous Players in Famous Plays"). By mid-1913, Famous Players had completed five films, and Zukor was on his way to success. Its first film was "Les Amours de la reine Élisabeth", which starred Sarah Bernhardt.
That same year, another aspiring producer, Jesse L. Lasky, opened his Lasky Feature Play Company with money borrowed from his brother-in-law, Samuel Goldfish, later known as Samuel Goldwyn. The Lasky company hired as their first employee a stage director with virtually no film experience, Cecil B. DeMille, who would find a suitable location site in Hollywood, near Los Angeles, for his first feature film, "The Squaw Man".
Starting in 1914, both Lasky and Famous Players released their films through a start-up company, Paramount Pictures Corporation, organized early that year by a Utah theatre owner, W. W. Hodkinson, who had bought and merged several smaller firms. Hodkinson and actor, director, producer Hobart Bosworth had started production of a series of Jack London movies. Paramount was the first successful nationwide distributor; until this time, films were sold on a statewide or regional basis which had proved costly to film producers. Also, Famous Players and Lasky were privately owned while Paramount was a corporation.
In 1916, Zukor maneuvered a three-way merger of his Famous Players, the Lasky Company, and Paramount. Zukor and Lasky bought Hodkinson out of Paramount, and merged the three companies into one. The new company Lasky and Zukor founded, Famous Players-Lasky Corporation, grew quickly, with Lasky and his partners Goldwyn and DeMille running the production side, Hiram Abrams in charge of distribution, and Zukor making great plans. With only the exhibitor-owned First National as a rival, Famous Players-Lasky and its "Paramount Pictures" soon dominated the business.
1921–1930: The rise.
Because Zukor believed in stars, he signed and developed many of the leading early stars, including Mary Pickford, Marguerite Clark, Pauline Frederick, Douglas Fairbanks, Gloria Swanson, Rudolph Valentino, and Wallace Reid. With so many important players, Paramount was able to introduce "block booking", which meant that an exhibitor who wanted a particular star's films had to buy a year's worth of other Paramount productions. It was this system that gave Paramount a leading position in the 1920s and 1930s, but which led the government to pursue it on antitrust grounds for more than twenty years.
The driving force behind Paramount's rise was Zukor. Through the teens and twenties, he built the Publix Theatres Corporation, a chain of nearly 2,000 screens, ran two production studios (in Astoria, New York, now the Kaufman Astoria Studios, and Hollywood, California), and became an early investor in radio, taking a 50% interest in the new Columbia Broadcasting System in 1928 (selling it within a few years; this would not be the last time Paramount and CBS crossed paths).
In 1926, Zukor hired independent producer B. P. Schulberg, an unerring eye for new talent, to run the new West Coast operations. They purchased the Robert Brunton Studios, a 26-acre facility at 5451 Marathon Street for US$1 million. In 1927, Famous Players-Lasky took the name Paramount Famous Lasky Corporation. Three years later, because of the importance of the Publix Theatres, it became Paramount Publix Corporation.
In 1928, Paramount began releasing "Inkwell Imps," animated cartoons produced by Max and Dave Fleischer's Fleischer Studios in New York City. The Fleischers, veterans in the animation industry, were among the few animation producers capable of challenging the prominence of Walt Disney. The Paramount newsreel series Paramount News ran from 1927 to 1957. In 1929 Paramount Released their first musical "Innocents of Paris." Richard A. Whiting and Leo Robin composed the score for the film; Maurice Chevalier starred and sung the most famous song from the film, "Louise".
Publix, Balaban and Katz, Loew's competition, and wonder theaters.
By acquiring the successful Balaban & Katz chain in 1926, Zukor gained the services of Barney Balaban (who would eventually become Paramount's president in 1936), his brother A. J. Balaban (who would eventually supervise all stage production nationwide and produce talkie shorts), and their partner Sam Katz (who would run the Paramount-Publix theatre chain in New York City from the thirty-five-story Paramount Theatre Building on Times Square).
Balaban and Katz had developed the Wonder Theater concept, first publicized around 1918 in Chicago. The Chicago Theater was created as a very ornate theater and advertised as a "wonder theater." When Publix acquired Balaban, they embarked on a project to expand the wonder theaters, and starting building in New York in 1927. While Balaban and Public were dominant in Chicago, Loew's was the big player in New York, and did not want the Publix theaters to overshadow theirs. The two companies brokered a non-competition deal for New York and Chicago, and Loew's took over the New York area projects, developing five wonder theaters. Publix continued Balaban's wonder theater development in its home area.
1931–1940: Receivership.
Eventually, Zukor shed most of his early partners; the Frohman brothers, Hodkinson and Goldwyn were out by 1917 while Lasky hung on until 1932, when, blamed for the near-collapse of Paramount in the Depression years, he too was tossed out. Zukor's over-expansion and use of overvalued Paramount stock for purchases led the company into receivership in 1933. A bank-mandated reorganization team, led by John Hertz and Otto Kahn kept the company intact, and, miraculously, Zukor was kept on. In 1935, Paramount-Publix went bankrupt. In 1936, Barney Balaban became president, and Zukor was bumped up to chairman of the board. In this role, Zukor reorganized the company as Paramount Pictures, Inc. and was able to successfully bring the studio out of bankruptcy.
As always, Paramount films continued to emphasize stars; in the 1920s there were Swanson, Valentino, and Clara Bow. By the 1930s, talkies brought in a range of powerful new draws: Miriam Hopkins, Marlene Dietrich, Mae West, W.C. Fields, Jeanette MacDonald, Claudette Colbert, the Marx Brothers (whose first two films were shot at Paramount's Astoria, New York, studio), Dorothy Lamour, Carole Lombard, Bing Crosby, band leader Shep Fields, famous Argentine tango singer Carlos Gardel, and Gary Cooper among them. In this period Paramount can truly be described as a movie factory, turning out sixty to seventy pictures a year. Such were the benefits of having a huge theater chain to fill, and of block booking to persuade other chains to go along. In 1933, Mae West would also add greatly to Paramount's success with her suggestive movies "She Done Him Wrong" and "I'm No Angel". However, the sex appeal West gave in these movies would also lead to the enforcement of the Production Code, as the newly formed organization the Catholic Legion of Decency threatened a boycott if it was not enforced.
Paramount cartoons produced by Fleischer Studios continued to be successful, with characters such as Betty Boop and Popeye the Sailor becoming widely successful. One Fleischer series, "Screen Songs", featured live-action music stars under contract to Paramount hosting sing-alongs of popular songs. The animation studio would rebound with Popeye, and in 1935, polls showed that Popeye was even more popular than Mickey Mouse. After an unsuccessful expansion into feature films, as well as the fact that Max and Dave Fleischer were no longer speaking to one another, Fleischer Studios was acquired by Paramount, which renamed the operation Famous Studios. That incarnation of the animation studio continued cartoon production until 1967, but has been historically dismissed as having largely failed to maintain the artistic acclaim the Fleischer brothers achieved under their management.
1941–1950: United States v. Paramount Pictures, Inc..
In 1940, Paramount agreed to a government-instituted consent decree: block booking and "pre-selling" (the practice of collecting up-front money for films not yet in production) would end. Immediately Paramount cut back on production, from seventy-one pictures to a more modest nineteen annually in the war years. Still, with more new stars like Bob Hope, Alan Ladd, Veronica Lake, Paulette Goddard, and Betty Hutton, and with war-time attendance at astronomical numbers, Paramount and the other integrated studio-theatre combines made more money than ever. At this, the Federal Trade Commission and the Justice Department decided to reopen their case against the five integrated studios. Paramount also had a monopoly over Detroit movie theaters through subsidiary company United Detroit Theaters as well. This led to the Supreme Court decision United States v. Paramount Pictures, Inc. (1948) holding that movie studios could not also own movie theater chains. This decision broke up Adolph Zukor's creation and effectively brought an end to the classic Hollywood studio system.
1951–1966: Split and after.
With the separation of production and exhibition forced by the U.S. Supreme Court, Paramount Pictures Inc. was split in two. Paramount Pictures Corporation was formed to be the production distribution company, with the 1,500-screen theater chain handed to the new United Paramount Theaters on December 31, 1949. Leonard Goldenson, who had headed the chain since 1938, remained as the new company's president. The Balaban and Katz theatre division was spun off with UPT; its trademark eventually became the property of the Balaban and Katz Historical Foundation. The Foundation has recently acquired ownership of the Famous Players Trademark. Cash-rich and controlling prime downtown real estate, Goldenson began looking for investments. Barred from film-making by prior anti-trust rulings, he acquired the struggling ABC television network in February 1953, leading it first to financial health, and eventually, in the mid-1970s, to first place in the national Nielsen ratings, before selling out to Capital Cities in 1985 (Capital Cities would eventually sell out, in turn, to The Walt Disney Company in 1996). United Paramount Theaters was renamed ABC Theaters in 1965 and was sold to businessman Henry Plitt in 1974. The movie theater chain was renamed Plitt Theaters. In 1985, Cineplex Odeon Corporation merged with Plitt. In later years, Paramount's TV division would develop a strong relationship with ABC, providing many hit series to the network.
The DuMont Network.
Paramount Pictures had been an early backer of television, launching experimental stations in 1939 in Los Angeles and Chicago. The Los Angeles station eventually became KTLA, the first commercial station on the West Coast. The Chicago station got a commercial license as WBKB in 1943, but was sold to UPT along with Balaban & Katz in 1948 and was eventually resold to CBS as WBBM-TV.
In 1938, Paramount bought a stake in television manufacturer DuMont Laboratories. Through this stake, it became a minority owner of the DuMont Television Network. Also Paramount launched its own network, Paramount Television Network, in 1948 through its television unit, Television Productions, Inc.
Paramount management planned to acquire additional owned-and-operated stations ("O&Os"); the company applied to the FCC for additional stations in San Francisco, Detroit, and Boston. The FCC, however, denied Paramount's applications. A few years earlier, the federal regulator had placed a five-station cap on all television networks: no network was allowed to own more than five VHF television stations. Paramount was hampered by its minority stake in the DuMont Television Network. Although both DuMont and Paramount executives stated that the companies were separate, the FCC ruled that Paramount's partial ownership of DuMont meant that DuMont and Paramount were in theory branches of the same company. Since DuMont owned three television stations and Paramount owned two, the federal agency ruled neither network could acquire additional television stations. The FCC requested that Paramount relinquish its stake in DuMont, but Paramount refused. According to television historian William Boddy, "Paramount's checkered anti-trust history" helped convince the FCC that Paramount controlled DuMont. Both DuMont and Paramount Television Network suffered as a result, with neither company able to acquire five O&Os. Meanwhile, CBS, ABC, and NBC had each acquired the maximum of five stations by the mid-1950s.
When ABC accepted a merger offer from UPT in 1953, DuMont quickly realized that ABC now had more resources than it could possibly hope to match. It quickly reached an agreement in principle to merge with ABC.
In 1951, Paramount bought a stake in International Telemeter, an experimental pay TV service which operated with a coin inserted into a box. The service began operating in Palm Springs, California on November 27, 1953, but due to pressure from the FCC, the service ended on May 15, 1954.
With the loss of the theater chain, Paramount Pictures went into a decline, cutting studio-backed production, releasing its contract players, and making production deals with independents. By the mid-1950s, all the great names were gone; only Cecil B. DeMille, associated with Paramount since 1913, kept making pictures in the grand old style. Despite Paramount's losses, DeMille would, however, give the studio some relief and create his most successful film at Paramount, a 1956 remake of his 1923 film "The Ten Commandments". DeMille died in 1959. Like some other studios, Paramount saw little value in its film library, and sold 764 of its pre-1948 films to MCA Inc. (known today as Universal Studios Inc.) in February 1958.
1966–1970: Early Gulf+Western era.
By the early 1960s, Paramount's future was doubtful. The high-risk movie business was wobbly; the theater chain was long gone; investments in DuMont and in early pay-television came to nothing; and the end of the Golden Age of Hollywood, even the flagship Paramount building in Times Square was sold to raise cash, as was KTLA (sold to Gene Autry in 1964 for a then-phenomenal $12.5 million). Founding father Adolph Zukor (born in 1873) was still chairman emeritus; he referred to chairman Barney Balaban (born 1888) as "the boy." Such aged leadership was incapable of keeping up with the changing times, and in 1966, a sinking Paramount was sold to Charles Bluhdorn's industrial conglomerate, Gulf + Western Industries Corporation. Bluhdorn immediately put his stamp on the studio, installing a virtually unknown producer named Robert Evans as head of production. Despite some rough times, Evans held the job for eight years, restoring Paramount's reputation for commercial success with "The Odd Couple", "Rosemary's Baby", "Love Story", "The Godfather", "Chinatown", and "3 Days of the Condor".
Gulf + Western Industries also bought the neighboring Desilu television studio (once the lot of RKO Pictures) from Lucille Ball in 1967. Using some of Desilu's established shows such as ', ', and "Mannix" as a foot in the door at the networks, the newly reincorporated Paramount Television eventually became known as a specialist in half-hour situation comedies.
1971–1980: CIC formation and high-concept era.
In 1970, Paramount teamed with Universal Studios to form Cinema International Corporation, a new company that would distribute films by the two studios outside the United States. Metro-Goldwyn-Mayer would become a partner in the mid-1970s. Both Paramount and CIC entered the video market with Paramount Home Video (now Paramount Home Entertainment) and CIC Video, respectively.
Robert Evans abandoned his position as head of production in 1974; his successor, Richard Sylbert, proved to be too literary and too tasteful for Gulf + Western's Bluhdorn. By 1976, a new, television-trained team was in place headed by Barry Diller and his "Killer-Dillers", as they were called by admirers or "Dillettes" as they were called by detractors. These associates, made up of Michael Eisner, Jeffrey Katzenberg, Dawn Steel and Don Simpson would each go on and head up major movie studios of their own later in their careers.
The Paramount specialty was now simpler. "High concept" pictures such as "Saturday Night Fever" and "Grease" hit big, hit hard and hit fast all over the world, and Diller's television background led him to propose one of his longest-standing ideas to the board: Paramount Television Service, a fourth commercial network. Paramount Pictures purchased the Hughes Television Network (HTN) including its satellite time in planning for PTVS in 1976. Paramount sold HTN to Madison Square Garden in 1979. But Diller believed strongly in the concept, and so took his fourth-network idea with him when he moved to 20th Century Fox in 1984, where Fox's then freshly installed proprietor, Rupert Murdoch was a more interested listener.
However, the television division would be playing catch-up for over a decade after Diller's departure in 1984 before launching its own television network – UPN – in 1995. Lasting eleven years before being merged with The WB network to become The CW in 2006, UPN would feature many of the shows it originally produced for other networks, and would take numerous gambles on series such as ' and ' that would have otherwise either gone direct-to-cable or become first-run syndication to independent stations across the country (as ' and ' were).
Paramount Pictures was not connected to either Paramount Records (1910s-1935) or ABC-Paramount Records (1955–66) until it purchased the rights to use the name (but not the latter's catalog) in the late 1960s. The Paramount name was used for soundtrack albums and some pop re-issues from the Dot Records catalog which Paramount had acquired in 1958. By 1970, Dot had become an all-country label and in 1974, Paramount sold all of its record holdings to ABC Records, which in turn was sold to MCA (now Universal Music Group) in 1979.
1980–1994: Continuous success.
Paramount's successful run of pictures extended into the 1980s and 1990s, generating hits like "Airplane!", "American Gigolo", "Ordinary People", "An Officer and a Gentleman", "Flashdance", "Terms of Endearment", "Footloose", "Pretty in Pink", "Top Gun", ""Crocodile" Dundee", "Fatal Attraction", "Ghost", the "Friday the 13th" slasher series, as well as "Raiders of the Lost Ark" and its sequels. Other examples are the "Star Trek" film series and a string of films starring comedian Eddie Murphy like "Trading Places", "Coming to America", and "Beverly Hills Cop" and its sequels. While the emphasis was decidedly on the commercial, there were occasional less commercial but more artistic and intellectual efforts like "I'm Dancing as Fast as I Can", "Atlantic City", "Reds", "Witness", "Children of a Lesser God" and "The Accused". During this period, responsibility for running the studio passed from Eisner and Katzenberg to Frank Mancuso, Sr. (1984) and Ned Tanen (1984) to Stanley R. Jaffe (1991) and Sherry Lansing (1992). More so than most, Paramount's slate of films included many remakes and television spinoffs; while sometimes commercially successful, there have been few compelling films of the kind that once made Paramount the industry leader.
In August 25, 1983, fire struck the Paramount Studios. Two or three sound stages and four outdoor sets were destroyed, but the rest of the Studios were still intact.
When Charles Bluhdorn died unexpectedly, his successor Martin Davis dumped all of G+W's industrial, mining, and sugar-growing subsidiaries and refocused the company, renaming it Paramount Communications in 1989. With the influx of cash from the sale of G+W's industrial properties in the mid-1980s, Paramount bought a string of television stations and KECO Entertainment's theme park operations, renaming them Paramount Parks. These parks included Paramount's Great America, Paramount Canada's Wonderland, Paramount's Carowinds, Paramount's Kings Dominion, and Paramount's Kings Island.
In 1993, Sumner Redstone's entertainment conglomerate Viacom made a bid for a merger with Paramount Communications; this quickly escalated into a bidding war with Barry Diller's QVC. But Viacom prevailed, ultimately paying $10 billion for the Paramount holdings. Viacom and Paramount had planned to merge as early as 1989.
Paramount is the last major film studio located in Hollywood proper. When Paramount moved to its present home in 1927, it was in the heart of the film community. Since then, former next-door neighbor RKO closed up shop in 1957 (Paramount ultimately absorbed their former lot); Warner Bros. (whose old Sunset Boulevard studio was sold to Paramount in 1949 as a home for KTLA) moved to Burbank in 1930; Columbia joined Warners in Burbank in 1973 then moved again to Culver City in 1989; and the Pickford-Fairbanks-Goldwyn-United Artists lot, after a lively history, has been turned into a post-production and music-scoring facility for Warners, known simply as "The Lot". For a time the semi-industrial neighborhood around Paramount was in decline, but has now come back. The recently refurbished studio has come to symbolize Hollywood for many visitors, and its studio tour is a popular attraction.
1994–2004: Dolgen/Lansing and "old" Viacom era.
During this time period, Paramount Pictures went under the guidance of Jonathan Dolgen, chairman and Sherry Lansing, president. During their administration over Paramount, the studio had an extremely successful period of films with two of Paramount's ten highest grossing films being produced during this period. The most successful of these films, "Titanic", a joint production with 20th Century Fox, became the highest grossing film up to that time, grossing over $1.8 billion worldwide. Also during this time, three Paramount Pictures films won the Academy Award for Best Picture; "Titanic, Braveheart", and "Forrest Gump".
Paramount's most important property, however, was "Star Trek". Studio executives had begun to call it "the franchise" in the 1980s due to its reliable revenue, and other studios envied its "untouchable and unduplicatable" success. By 1998 "Star Trek" TV shows, movies, books, videotapes, and licensing provided so much of the studio's profit that "it is not possible to spend any reasonable amount of time at Paramount and not be aware of [its] presence"; filming for "Star Trek: Voyager" and "Star Trek: Deep Space Nine" required up to nine of the largest of the studio's 36 sound stages.
In 1995, Viacom and Chris-Craft Industries' United Television launched United Paramount Network (UPN) with "Star Trek: Voyager" as its flagship series, fulfilling Barry Diller's plan for a Paramount network from 25 years earlier. In 1999, Viacom bought out United Television's interests, and handed responsibility for the start-up network to the newly acquired CBS unit, which Viacom bought in 1999 – an ironic confluence of events as Paramount had once invested in CBS, and Viacom had once been the syndication arm of CBS as well. During this period the studio acquired some 30 TV stations to support the UPN network as well acquiring and merging in the assets of Republic Pictures, Spelling Television and Viacom Television, almost doubling the size of the studio's TV library. The TV division produced the dominant prime time show for the decade in "Frasier" as well as such long running hits as NCIS and "Becker" and the dominant prime time magazine show "Entertainment Tonight."
During this period, Paramount and its related subsidiaries and affiliates, operating under the name "Viacom Entertainment Group" also included the fourth largest group of theme parks in the United States and Canada which in addition to traditional rides and attractions launched numerous successful location based entertainment units including a long running "Star Trek" attraction at the Las Vegas Hilton. Famous Music – the company's celebrated music publishing arm almost doubled in size and developed artists including Pink, Bush, Green Day as well as catalog favorites including Duke Ellington and Henry Mancini. The Paramount/Viacom licensing group under the leadership of Tom McGrath created the "Cheers" franchise bars and restaurants and a chain of restaurants borrowing from the studio's Academy Award winning film "Forrest Gump" – "The Bubba Gump Shrimp Company". Through the combined efforts of Famous Music and the studio over ten "Broadway" musicals were created including Irving Berlin's "White Christmas", "Footloose, Saturday Night Fever", Andrew Lloyd Weber's "Sunset Boulevard" among others. The Company's international arm, United International Pictures (UIP), was the dominant distributor internationally for ten straight years representing Paramount, Universal and MGM. Simon and Schuster became part of the Viacom Entertainment Group emerging as the US' dominant trade book publisher.
In 2002, Paramount, Buena Vista Distribution, 20th Century Fox, Sony Pictures, Universal Studios, and Warner Bros. formed the Digital Cinema Initiatives. Operating under a waiver form the anti-trust law, the studios combined under the leadership of Paramount Chief Operating Officer Tom McGrath to develop technical standards for the eventual introduction of digital film projection – replacing the now 100-year-old film technology. DCI was created "to establish and document voluntary specifications for an open architecture for digital cinema that ensures a uniform and high level of technical performance, reliability and quality control." McGrath also headed up Paramount's initiative for the creation and launch of the Blu-ray DVD.
2005: Dissolution of the Viacom Entertainment Group and Paramount.
In 2005, Viacom announced the spinoff of CBS into a separate public entity. As part of this spinoff, the Entertainment Group that was led by Dolgen, Lansing and McGrath, was dissolved and Paramount broken up into its separate assets. Famous Music, part of the company since its founding by Jesse Lasky, was sold to Sony Music. The UPN network and its TV stations were transferred to CBS. Paramount itself was broken into two parts and the television production and assets were stripped and made part of CBS. The theme parks group was sold to Cedar Fair in 2006 and renamed the parks by taking out the "Paramount's" prefix. Simon and Schuster also became part of CBS. The company's three chains of movie theaters were divested – Famous Players Theaters, the dominant theater circuit in Canada was sold to its competitor Cineplex Odeon. UCI which dominated the international theater markets consisting of 1,300+ screens in 11 countries was sold to buyout firm Terra Firma. Mann Theaters was slowly divested screen by screen with the world famous "Graumann's Chinese Theater" being sold to a consortium led by Eli Samaha.
The resulting company, approximately 20% of its former size coalesced in 2006 under the leadership of its new CEO, Brad Grey who held the same title as Sherry Lansing despite the much smaller size of the business under his leadership.
2005–present: Paramount today.
CBS Corporation/Viacom split.
Reflecting in part the troubles of the broadcasting business, in 2005 Viacom wrote off over $18 billion from its radio acquisitions and, early that year, announced that it would split itself in two. The split was completed in January 2006.
With the announcement of the split of Viacom, Dolgen and Lansing were replaced by former television executives Brad Grey and Gail Berman. The Viacom Inc. board split the company into CBS Corporation and a separate company under the Viacom name. The board scheduled the division for the first quarter of 2006. Under the plan, CBS Corp. would comprise CBS and UPN networks, Viacom Television Stations Group, Infinity Broadcasting, Viacom Outdoor, Paramount Television, KingWorld, Showtime, Simon and Schuster, Paramount Parks, and CBS News. The revamped Viacom would include "MTV, VH1, Nickelodeon, BET and several other cable networks as well as the Paramount movie studio". Paramount's home entertainment unit continues to distribute the Paramount TV library through CBS DVD, as both Viacom and CBS Corporation are controlled by Sumner Redstone's National Amusements.
In 2009, CBS stopped using the Paramount name in its series and changed the name of the production arm to CBS Television Studios, eliminating the Paramount name from television, to distance itself from the latter.
DreamWorks purchased.
On December 11, 2005, The Paramount Motion Pictures Group announced that it had purchased DreamWorks SKG (which was co-founded by former Paramount executive Jeffrey Katzenberg) in a deal worth $1.6 billion. The announcement was made by Brad Grey, chairman and CEO of Paramount Pictures who noted that enhancing Paramount's pipeline of pictures is a "key strategic objective in restoring Paramount's stature as a leader in filmed entertainment." The agreement does not include DreamWorks Animation SKG Inc., the most profitable part of the company that went public the previous year.
On October 6, 2008, DreamWorks executives announced that they were leaving Paramount and relaunching an independent DreamWorks. The DreamWorks trademarks remained with DreamWorks Animation when that company was spun off before the Paramount purchase, and DreamWorks Animation transferred the license to the name to the new company.
UIP, Famous Music, and Digital Entertainment.
In 2007, Paramount sold another one of its "heritage" units, Famous Music, to Sony/ATV Music Publishing (best known for publishing many songs by The Beatles, and for being co-owned by Michael Jackson), ending a nearly-eight-decade run as a division of Paramount, being the studio's music publishing arm since the period when the entire company went by the name "Famous Players."
In early 2008, Paramount partnered with Los Angeles-based developer FanRocket to make short scenes taken from its film library available to users on Facebook. The application, called VooZoo, allows users to send movie clips to other Facebook users and to post clips on their profile pages. Paramount engineered a similar deal with Makena Technologies to allow users of vMTV and There.com to view and send movie clips.
In March 2010, Paramount founded Insurge Pictures, an independent distributor of "micro budget" films. The distributor planned ten movies with budgets of $100,000 each. The first release was "The Devil Inside", a movie with a budget of about US$1 million. In March 2015, following waning box office returns, Paramount shuttered Insurge Pictures and moved its operations to the main studio.
In July 2011, in the wake of critical and box office success of the animated feature, "Rango", and the departure of DreamWorks Animation upon completion of their distribution contract in 2012, Paramount announced the formation of a new division, devoted to the creation of animated productions. It marks Paramount's return to having its own animated division for the first time since 1967, when Paramount Cartoon Studios shut down (it was formerly Famous Studios until 1956).
In December 2013, The Walt Disney Studios (via its parent company's purchase of LucasFilm, Ltd. a year earlier) purchased Paramount's remaining distribution and marketing rights to future "Indiana Jones" films, while Paramount will continue to distribute the first four films for Disney, and will receive "financial participation" from any additional films.
Investments.
DreamWorks.
In 2006, Paramount became the parent of DreamWorks SKG. Soros Strategic Partners and Dune Entertainment II soon afterwards acquired controlling interest in the live-action films released through September 16, 2005, the latest film in this package was "Just Like Heaven". The remaining live-action films through March 2006 remained under direct Paramount control.
However, Paramount does own distribution (and other ancillary) rights to the Soros/Dune films.
On February 8, 2010, Viacom repurchased Soros' controlling stake in the pre-2005 DreamWorks Pictures library for around $400 million.
Even as DreamWorks switches distribution of live-action films that are not part of existing franchises to Walt Disney Studios Motion Pictures, Paramount will continue to own the films released before the merger, and the films that Paramount themselves distributed (including sequel rights; such films as "Little Fockers" will be distributed by Paramount and DreamWorks, since it is a sequel to an existing DreamWorks film – in this case, "Meet the Parents" and "Meet the Fockers", though Paramount will only own international rights to this title, whereas Universal Studios will handle domestic distribution).
As for the DreamWorks Animation library, Paramount owned distribution rights to the pre-2013 library, and their previous distribution deal to future DWA titles expired at the end of 2012 with the last Paramount-distributed feature, "Rise of the Guardians". 20th Century Fox now handles distribution on future titles beginning with "The Croods", though Paramount's rights to distribute every film released by DreamWorks Animation before 2013 will expire 16 years after each film's initial theatrical release date. However, in July 2014, DreamWorks Animation purchased Paramount's distribution rights to the pre-2013 library with DreamWorks Animation's current distributor 20th Century Fox to distribute the library.
The CBS library.
Independent company Hollywood Classics now represents Paramount in the theatrical distribution of all the films produced by the various motion picture divisions of CBS over the years, as a result of the Viacom/CBS merger.
Paramount (via CBS Home Entertainment) has outright video distribution to the aforementioned CBS library with few exceptions-for example, the original "Twilight Zone" DVDs are handled by Image Entertainment. Until 2009, the video rights to "My Fair Lady" were with original theatrical distributor Warner Bros., under license from CBS (the video license to that film has now reverted to CBS Home Entertainment under Paramount).
The CBS-produced/owned films, unlike other films in Paramount's library, are still distributed by CBS Television Distribution on TV, and not by Trifecta Entertainment & Media, because CBS (or a subdivision) is the copyright holder for these films.
Units.
Former divisions, subsidiaries, and joint ventures.
Original Paramount Television now CBS Television Studios
Other interests.
In March 2012, Paramount licensed their name and logo to a luxury hotel investment group which subsequently named the company Paramount Hotels and Resorts. The investors plan to build 50 hotels throughout the world based on the themes of Hollywood and the California lifestyle. Among the features are private screening rooms and the Paramount library available in the hotel rooms. On April 2013, Paramount Hotels and Dubai-based DAMAC Properties announced the building of the first resort: "DAMAC Towers by Paramount," in They bought 50% stake in India based PVR cinemas Dubai.
Logo.
The distinctively pyramidal Paramount mountain has been the company's logo since its inception and is the oldest surviving Hollywood film logo. In the sound era, the logo was accompanied by a fanfare called "Paramount on Parade" after the film of the same name, released in 1930. The words to the fanfare, originally sung in the 1930 film, were "Proud of the crowd that will never be loud, it's Paramount on Parade."
Legend has it that the mountain is based on a doodle made by W. W. Hodkinson during a meeting with Adolph Zukor. It is said to be based on the memories of his childhood in Utah. Some claim that Utah's Ben Lomond is the mountain Hodkinson doodled, and that Peru's Artesonraju is the mountain in the live-action logo, while others claim that the Italian side of Monviso inspired the logo. Some editions of the logo bear a striking resemblance to the Pfeifferhorn, another Wasatch Range peak.
The motion picture logo has gone through many changes over the years:
Visiting Paramount.
Those wishing to visit Paramount can take studio tours, which are offered seven days a week. Reservations are required, and can be made by visiting the tour website. The tour offers a behind-the-scenes look at the current operations of the studio, and what can be seen varies day to day. Most of the buildings on the tour are named for historical Paramount executives or the artists that worked at Paramount over the years. Many of the stars' dressing rooms have been converted into working offices. The stages where "Samson and Delilah, Sunset Blvd.", "White Christmas", "Rear Window", "Sabrina", "Breakfast at Tiffany's", and many other classic films were shot are still in use today. The studio's backlot set, "New York Street", features numerous blocks of facades that depict a number of New York locales: "Washington Square", (where some scenes in "The Heiress", starring Olivia de Havilland, were shot) "Brooklyn", "Financial District", and others. Led by a guide on a golf cart, the tour takes approximately two hours.
Film Library.
A few years after the ruling of the United States v. Paramount Pictures, Inc. case in 1948, Music Corporation of America (MCA) approached Paramount offering $50 million for 750 sound feature films released prior to December 1, 1949 with payment to be spread over a period of several years. Paramount saw this as a bargain since the fleeting movie studio saw very little value in its library at the time. To address any anti-trust concerns, MCA set up EMKA, Ltd. as a dummy corporation to sell these films to television. EMKA's/Universal Pictures library includes the five Paramount Marx Brothers films, most of the Bob Hope-Bing Crosby Road to... pictures, and other classics such as Trouble in Paradise, Shanghai Express, She Done Him Wrong, Sullivan's Travels, The Palm Beach Story, For Whom The Bell Tolls, Double Indemnity, The Lost Weekend and The Heiress.

</doc>
<doc id="22921" url="https://en.wikipedia.org/wiki?curid=22921" title="Psychology">
Psychology

Psychology is the study of mind and behavior. It is an academic discipline and an applied science which seeks to understand individuals and groups by establishing general principles and researching specific cases. In this field, a professional or researcher is called a psychologist and can be classified as a social, behavioral, or cognitive scientist. Psychologists attempt to understand the role of mental functions in individual and social behavior, while also exploring the physiological and biological processes that underlie cognitive functions and behaviors.
Psychologists explore concepts such as perception, cognition, attention, emotion, intelligence, phenomenology, motivation, brain functioning, personality, behavior, and interpersonal relationships, including psychological resilience, family resilience, and other areas. Psychologists of diverse orientations also consider the unconscious mind. Psychologists employ empirical methods to infer causal and correlational relationships between psychosocial variables. In addition, or in opposition, to employing empirical and deductive methods, some—especially clinical and counseling psychologists—at times rely upon symbolic interpretation and other inductive techniques. Psychology has been described as a "hub science", with psychological findings linking to research and perspectives from the social sciences, natural sciences, medicine, humanities, and philosophy.
While psychological knowledge is often applied to the assessment and treatment of mental health problems, it is also directed towards understanding and solving problems in several spheres of human activity. By many accounts psychology ultimately aims to benefit society. The majority of psychologists are involved in some kind of therapeutic role, practicing in clinical, counseling, or school settings. Many do scientific research on a wide range of topics related to mental processes and behavior, and typically work in university psychology departments or teach in other academic settings (e.g., medical schools, hospitals). Some are employed in industrial and organizational settings, or in other areas such as human development and aging, sports, health, and the media, as well as in forensic investigation and other aspects of law.
Etymology and definitions.
The word "psychology" derives from Greek roots meaning study of the psyche, or soul (ψυχή "psukhē", "breath, spirit, soul" and -λογία "-logia", "study of" or "research"). The Latin word "psychologia" was first used by the Croatian humanist and Latinist Marko Marulić in his book, "Psichiologia de ratione animae humanae" in the late 15th century or early 16th century. The earliest known reference to the word "psychology" in English was by Steven Blankaart in 1694 in "The Physical Dictionary" which refers to "Anatomy, which treats the Body, and Psychology, which treats of the Soul."
In 1890, William James defined "psychology" as "the science of mental life, both of its phenomena and their conditions". This definition enjoyed widespread currency for decades. However, this meaning was contested, notably by radical behaviorists such as John Watson, who in his 1913 manifesto defined the discipline of psychology as the acquisition of information useful to the control of behavior. Also since James defined it, the term more strongly connotes techniques of scientific experimentation. Folk psychology refers to the understanding of ordinary people, as contrasted with that of psychology professionals.
History.
The ancient civilizations of Egypt, Greece, China, India, and Persia all engaged in the philosophical study of psychology. Historians note that Greek philosophers, including Thales, Plato, and Aristotle (especially in his "De Anima" treatise), addressed the workings of the mind. As early as the 4th century BC, Greek physician Hippocrates theorized that mental disorders had physical rather than supernatural causes.
In China, psychological understanding grew from the philosophical works of Laozi and Confucius, and later from the doctrines of Buddhism. This body of knowledge involves insights drawn from introspection and observation, as well as techniques for focused thinking and acting. It frames the universe as a division of, and interaction between, physical reality and mental reality, with an emphasis on purifying the mind in order to increase virtue and power. An ancient text known as "The Yellow Emperor's Classic of Internal Medicine" identifies the brain as the nexus of wisdom and sensation, includes theories of personality based on yin–yang balance, and analyzes mental disorder in terms of physiological and social disequilibria. Chinese scholarship focused on the brain advanced in the Qing Dynasty with the work of Western-educated Fang Yizhi (1611–1671), Liu Zhi (1660–1730), and Wang Qingren (1768–1831). Wang Qingren emphasized the importance of the brain as the center of the nervous system, linked mental disorder with brain diseases, investigated the causes of dreams and insomnia, and advanced a theory of hemispheric lateralization in brain function.
Distinctions in types of awareness appear in the ancient thought of India, influenced by Hinduism. A central idea of the Upanishads is the distinction between a person's transient mundane self and their eternal unchanging soul. Divergent Hindu doctrines, and Buddhism, have challenged this hierarchy of selves, but have all emphasized the importance of reaching higher awareness. Yoga is a range of techniques used in pursuit of this goal. Much of the Sanskrit corpus was suppressed under the British East India Company followed by the British Raj in the 1800s. However, Indian doctrines influenced Western thinking via the Theosophical Society, a New Age group which became popular among Euro-American intellectuals.
Psychology was a popular topic in Enlightenment Europe. In Germany, Gottfried Wilhelm Leibniz (1646–1716) applied his principles of calculus to the mind, arguing that mental activity took place on an indivisible continuum—most notably, that among an infinity of human perceptions and desires, the difference between conscious and unconscious awareness is only a matter of degree. Christian Wolff identified psychology as its own science, writing "Psychologia empirica" in 1732 and "Psychologia rationalis" in 1734. This notion advanced further under Immanuel Kant, who established the idea of anthropology, with psychology as an important subdivision. However, Kant explicitly and notoriously rejected the idea of experimental psychology, writing that "the empirical doctrine of the soul can also never approach chemistry even as a systematic art of analysis or experimental doctrine, for in the manifold of inner observation can be separated only by mere division in thought, and cannot then be held separate and recombined at will (but still less does another thinking subject suffer himself to be experimented upon to suit our purpose), and even observation by itself already changes and displaces the state of the observed object." Having consulted philosophers Hegel and Herbart, in 1825 the Prussian state established psychology as a mandatory discipline in its rapidly expanding and highly influential educational system. However, this discipline did not yet embrace experimentation. In England, early psychology involved phrenology and the response to social problems including alcoholism, violence, and the country's well-populated mental asylums.
Beginning of experimental psychology.
Gustav Fechner began conducting psychophysics research in Leipzig in the 1830s, articulating the principle that human perception of a stimulus varies logarithmically according to its intensity. Fechner's 1950 "Elements of Psychophysics" challenged Kant's stricture against quantitative study of the mind. In Heidelberg, Hermann von Helmholtz conducted parallel research on sensory perception, and trained physiologist Wilhelm Wundt. Wundt, in turn, came to Leipzig University, establishing the psychological laboratory which brought experimental psychology to the world. Wundt focused on breaking down mental processes into the most basic components, motivated in part by an analogy to recent advances in chemistry, and its successful investigation of the elements and structure of material. Paul Flechsig and Emil Kraepelin soon created another influential psychology laboratory at Leipzig, this one focused on more on experimental psychiatry.
Psychologists in Germany, Denmark, Austria, England, and the United States soon followed Wundt in setting up laboratories. G. Stanley Hall who studied with Wundt, formed a psychology lab at Johns Hopkins University in Maryland, which became internationally influential. Hall, in turn, trained Yujiro Motora, who brought experimental psychology, emphasizing psychophysics, to the Imperial University of Tokyo. Wundt assistant Hugo Münsterberg taught psychology at Harvard to students such as Narendra Nath Sen Gupta—who, in 1905, founded a psychology department and laboratory at the University of Calcutta. Wundt students Walter Dill Scott, Lightner Witmer, and James McKeen Cattell worked on developing tests for mental ability. Catell, who also studied with eugenicist Francis Galton, went on to found the Psychological Corporation. Wittmer focused on mental testing of children; Scott, on selection of employees.
Another student of Wundt, Edward Titchener, created the psychology program at Cornell University and advanced a doctrine of "structuralist" psychology. Structuralism sought to analyze and classify different aspects of the mind, primarily through the method of introspection. William James, John Dewey and Harvey Carr advanced a more expansive doctrine called functionalism, attuned more to human–environment actions. In 1890 James wrote an influential book, "The Principles of Psychology", which expanded on the realm of structuralism, memorably described the human "stream of consciousness", and interested many American students in the emerging discipline. Dewey integrated psychology with social issues, most notably by promoting the cause progressive education to assimilate immigrants and inculcate moral values in children.
A different strain of experimentalism, with more connection to physiology, emerged in South America, under the leadership of Horacio G. Piñero at the University of Buenos Aires. Russia, too, placed greater emphasis on the biological basis for psychology, beginning with Ivan Sechenov's 1873 essay, "Who Is to Develop Psychology and How?" Sechenov advanced the idea of brain reflexes and aggressively promoted a deterministic viewpoint on human behavior.
Wolfgang Kohler, Max Wertheimer and Kurt Koffka co-founded the school of Gestalt psychology (not to be confused with the Gestalt therapy of Fritz Perls). This approach is based upon the idea that individuals experience things as unified wholes. Rather than breaking down thoughts and behavior into smaller elements, as in structuralism, the Gestaltists maintained that whole of experience is important, and differs from the sum of its parts. Other 19th-century contributors to the field include the German psychologist Hermann Ebbinghaus, a pioneer in the experimental study of memory, who developed quantitative models of learning and forgetting at the University of Berlin, and the Russian-Soviet physiologist Ivan Pavlov, who discovered in dogs a learning process that was later termed "classical conditioning" and applied to human beings.
Consolidation and funding.
One of the earliest psychology societies was "La Société de Psychologie Physiologique" in France, which lasted 1885–1893. The first meeting of the International Congress of Psychology took place in Paris, in August 1889, amidst the World's Fair celebrating the centennial of the French Revolution. William James was one of three Americans among the four hundred attendees. The American Psychological Association was founded soon after, in 1892. The International Congress continued to be held, at different locations in Europe, with wider international participation. The Sixth Congress, Geneva 1909, included presentations in Russian, Chinese, and Japanese, as well as Esperanto. After a hiatus for World War I, the Seventh Congress met in Oxford, with substantially greater participation from the war-victorious Anglo-Americans. In 1929, the Congress took place at Yale University in New Haven, Connecticut, attended by hundreds of members of the American Psychological Association Tokyo Imperial University led the way in bringing the new psychology to the East, and from Japan these ideas diffused into China.
American psychology gained status during World War I, during which a standing committee headed by Robert Yerkes administered mental tests ("Army Alpha" and "Army Beta") to almost 1.8 million GIs. Subsequent funding for behavioral research came in large part from the Rockefeller family, via the Social Science Research Council. Rockefeller charities funded the National Committee on Mental Hygiene, which promoted the concept of mental illness and lobbied for psychological supervision of child development. Through the Bureau of Social Hygiene and later funding of Alfred Kinsey, Rockefeller foundations established sex research as a viable discipline in the U.S. Under the influence of the Carnegie-funded Eugenics Record Office, the Draper-funded Pioneer Fund, and other institutions, the eugenics movement also had a significant impact on American psychology; in the 1910s and 1920s, eugenics became a standard topic in psychology classes.
During World War II and the Cold War, the U.S. military and intelligence agencies established themselves as leading funders of psychology—through the armed forces and in the new Office of Strategic Services intelligence agency. University of Michigan psychologist Dorwin Cartwright reported that university researchers began large-scale propaganda research in 1939–1941, and "the last few months of the war saw a social psychologist become chiefly responsible for determining the week-by-week-propaganda policy for the United States Government." Cartwright also wrote that psychologists had significant roles in managing the domestic economy. The Army rolled out its new General Classification Test and engaged in massive studies of troop morale. In the 1950s, the Rockefeller Foundation and Ford Foundation collaborated with the Central Intelligence Agency to fund research on psychological warfare. In 1965, public controversy called attention to the Army's Project Camelot—the "Manhattan Project" of social science—an effort which enlisted psychologists and anthropologists to analyze foreign countries for strategic purposes.
In Germany after World War I, psychology held institutional power through the military, and subsequently expanded along with the rest of the military under the Third Reich. Under the direction of Hermann Göring's cousin Matthias Göring, the Berlin Psychoanalytic Institute was renamed the Göring Institute. Freudian psychoanalysts were expelled and persecuted under the anti-Jewish policies of the Nazi Party, and all psychologists had to distance themselves from Freud and Adler. The Göring Institute was well-financed throughout the war with a mandate to create a "New German Psychotherapy". This psychotherapy aimed to align suitable Germans with the overall goals of the Reich; as described by one physician: "Despite the importance of analysis, spiritual guidance and the active cooperation of the patient represent the best way to overcome individual mental problems and to subordinate them to the requirements of the "Volk" and the "Gemeinschaft"." Psychologists were to provide "Seelenführung", leadership of the mind, to integrate people into the new vision of a German community. Harald Schultz-Hencke melded psychology with the Nazi theory of biology and racial origins, criticizing psychoanalysis as a study of the weak and deformed. Johannes Heinrich Schultz, a German psychologist recognized for developing the technique of autogenic training, prominently advocated sterilization and euthanasia of men considered genetically undesirable, and devised techniques for facilitating this process. After the war, some new institutions were created and some psychologists were discredited due to Nazi affiliation. Alexander Mitscherlich founded a prominent applied psychoanalysis journal called "Psyche" and with funding from the Rockefeller Foundation established the first clinical psychosomatic medicine division at Heidelberg University. In 1970, psychology was integrated into the required studies of medical students.
After the Russian Revolution, psychology was heavily promoted by the Bolsheviks as a way to engineer the "New Man" of socialism. Thus, university psychology departments trained large numbers of students, for whom positions were made available at schools, workplaces, cultural institutions, and in the military. An especial focus was pedology, the study of child development, regarding which Lev Vygotsky became a prominent writer. The Bolsheviks also promoted free love and embranced the doctrine of psychoanalysis as an antidote to sexual repression. Although pedology and intelligence testing fell out of favor in 1936, psychology maintained its privileged position as an instrument of the Soviet state. Stalinist purges took a heavy toll and instilled a climate of fear in the profession, as elsewhere in Soviet society. Following World War II, Jewish psychologists past and present (including Vygotsky, A. R. Luria, and Aron Zalkind) were denounced; Ivan Pavlov (posthumously) and Stalin himself were aggrandized as heroes of Soviet psychology. Soviet academics was speedily liberalized during the Khrushchev Thaw, and cybernetics, linguistics, genetics, and other topics became acceptable again. There emerged a new field called "engineering psychology" which studied mental aspects of complex jobs (such as pilot and cosmonaut). Interdisciplinary studies became popular and scholars such as Georgy Shchedrovitsky developed systems theory approaches to human behavior.
Twentieth-century Chinese psychology originally modeled the United States, with translations from American authors like William James, the establishment of university psychology departments and journals, and the establishment of groups including the Chinese Association of Psychological Testing (1930) and the Chinese Psychological Society (1937). Chinese psychologists were encouraged to focus on education and language learning, with the aspiration that education would enable modernization and nationalization. John Dewey, who lectured to Chinese audiences in 1918–1920, had a significant influence on this doctrine. Chancellor T'sai Yuan-p'ei introduced him at Peking University as a greater thinker than Confucius. Kuo Zing-yang who received a PhD at the University of California, Berkeley, became President of Zhejiang University and popularized behaviorism. After the Chinese Communist Party gained control of the country, the Stalinist USSR became the leading influence, with Marxism–Leninism the leading social doctrine and Pavlovian conditioning the approved concept of behavior change. Chinese psychologists elaborated on Lenin's model of a "reflective" consciousness, envisioning an "active consciousness" ("tzu-chueh neng-tung-li") able to transcend material conditions through hard work and ideological struggle. They developed a concept of "recognition" ("jen-shih") which referred the interface between individual perceptions and the socially accepted worldview. (Failure to correspond with party doctrine was "incorrect recognition".) Psychology education was centralized under the Chinese Academy of Sciences, supervised by the State Council. In 1951 the Academy created a Psychology Research Office, which in 1956 became the Institute of Psychology. Most leading psychologists were educated in the United States, and the first concern of the Academy was re-education of these psychologists in the Soviet doctrines. Child psychology and pedagogy for nationally cohesive education remained a central goal of the discipline.
Disciplinary organization.
Institutions.
In 1920, Édouard Claparède and Pierre Bovet created a new applied psychology organization called the International Congress of Psychotechnics Applied to Vocational Guidance, later called the International Congress of Psychotechnics and then the International Association of Applied Psychology. The IAAP is considered the oldest international psychology association. Today, at least 65 international groups deal specialized aspects of psychology. In response to male predominance in the field, female psychologists in the U.S. formed National Council of Women Psychologists in 1941. This organization became the International Council of Women Psychologists after World War II, and the International Council of Psychologists in 1959. Several associations including the Association of Black Psychologists and the Asian American Psychological Association have arisen to promote non-European racial groups in the profession.
The world federation of national psychological societies is the International Union of Psychological Science (IUPsyS), founded in 1951 under the auspices of UNESCO, the United Nations cultural and scientific authority. Psychology departments have since proliferated around the world, based primarily on the Euro-American model. Since 1966, the Union has published the "International Journal of Psychology". IAAP and IUPsyS agreed in 1976 each to hold a congress every four years, on a staggered basis.
The International Union recognizes 66 national psychology associations and at least 15 others exist. The American Psychological Association is the oldest and largest. Its membership has increased from 5,000 in 1945 to 100,000 in the present day. The APA includes 54 divisions, which since 1960 have steadily proliferated to include more specialties. Some of these divisions, such as the Society for the Psychological Study of Social Issues and the American Psychology–Law Society, began as autonomous groups.
The Interamerican Society of Psychology, founded in 1951, aspires to promote psychology and coordinate psychologists across the Western Hemisphere. It holds the Interamerican Congress of Psychology and had 1000 members in year 2000. The European Federation of Professional Psychology Associations, founded in 1981, represents 30 national associations with a total of 100,000 individual members. At least 30 other international groups organize psychologists in different regions.
In some places, governments legally regulate who can provide psychological services or represent themselves as a "psychologist". The American Psychological Association defines a psychologist as someone with a doctoral degree in psychology.
Boundaries.
Early practitioners of experimental psychology distinguished themselves from parapsychology, which in the late nineteenth century enjoyed great popularity (including the interest of scholars such as William James), and indeed constituted the bulk of what people called "psychology". Parapsychology, hypnotism, and psychism were major topics of the early International Congresses. But students of these fields were eventually ostractized, and more or less banished from the Congress in 1900–1905. Parapsychology persisted for a time at Imperial University, with publications such as "Clairvoyance and Thoughtography" by Tomokichi Fukurai, but here too it was mostly shunned by 1913.
As a discipline, psychology has long sought to fend off accusations that it is a "soft" science. Philosopher of science Thomas Kuhn's 1962 critique implied psychology overall was in a pre-paradigm state, lacking the agreement on overarching theory found in mature sciences such as chemistry and physics. Because some areas of psychology rely on research methods such as surveys and questionnaires, critics asserted that psychology is not an objective science. Skeptics have suggested that personality, thinking, and emotion, cannot be directly measured and are often inferred from subjective self-reports, which may be problematic. Experimental psychologists have devised a variety of ways to indirectly measure these elusive phenomenological entities.
Divisions still exist within the field, with some psychologists more oriented towards the unique experiences of individual humans, which cannot be understood only as data points within a larger population. Critics inside and outside the field have argued that mainstream psychology has become increasingly dominated by a "cult of empiricism" which limits the scope of its study by using only methods derived from the physical sciences. Feminist critiques along these lines have argued that claims to scientific objectivity obscure the values and agenda of (historically mostly male) researchers. Jean Grimshaw, for example, argues that mainstream psychological research has advanced a patriarchal agenda through its efforts to control behavior.
Major schools of thought.
Biological.
Psychologists generally consider the organism the basis of the mind, and therefore a vitally related area of study. Psychiatrists and neuropsychologists work at the interface of mind and body. 
Biological psychology, also known as physiological psychology, or neuropsychology is the study of the biological substrates of behavior and mental processes. Key research topics in this field include comparative psychology, which studies humans in relation to other animals, and perception which involves the physical mechanics of sensation as well as neural and mental processing. For centuries, a leading question in biological psychology has been whether and how mental functions might be localized in the brain. From Phineas Gage to H. M. and Clive Wearing, have inspired new discoveries in this area. Modern neuropsychology could be said to originate in the 1870s, when in France Paul Broca traced production of speech to the left frontal gyrus, thereby also demonstrating hemispheric lateralization of brain function. Soon after, Carl Wernicke identified a related area necessary for the understanding of speech.
The contemporary field of behavioral neuroscience focuses on physical causes underpinning behavior. For example, physiological psychologists use animal models, typically rats, to study the neural, genetic, and cellular mechanisms that underlie specific behaviors such as learning and memory and fear responses. Cognitive neuroscientists investigate the neural correlates of psychological processes in humans using neural imaging tools, and neuropsychologists conduct psychological assessments to determine, for instance, specific aspects and extent of cognitive deficit caused by brain damage or disease. The biopsychosocial model is an integrated perspective toward understanding consciousness, behavior, and social interaction. It assumes that any given behavior or mental process affects and is affected by dynamically interrelated biological, psychological, and social factors.
Evolutionary psychology examines cognition and personality traits from an evolutionary perspective. This perspective suggests that psychological adaptations evolved to solve recurrent problems in human ancestral environments. Evolutionary psychology offers complementary explanations for the mostly proximate or developmental explanations developed by other areas of psychology: that is, it focuses mostly on ultimate or "why?" questions, rather than proximate or "how?" questions.
The search for biological origins of psychological phenomena has long involved debates about the importance of race, and especially the relationship between race and intelligence. The idea of white supremacy and indeed the modern concept of race itself arose during the process of world conquest by Europeans. Carl von Linnaeus's four-fold classification of humans classifies Europeans as intelligent and severe, Americans as contented and free, Asians as ritualistic, and Africans as lazy and capricious. Race was also used to justify the construction of socially specific mental disorders such as "drapetomania" and "dysaesthesia aethiopica"—the behavior of uncooperative African slaves. After the creation of experimental psychology, "ethnical psychology" emerged as a subdiscipline, based on the assumption that studying primitive races would provide an important link between animal behavior and the psychology of more evolved humans.
Behavioral.
Psychologists take human behavior as a main area of study. Much of the research in this area began with tests on mammals, based on the idea that humans exhibit similar fundamental tendencies. Behavioral research ever aspires to improve the effectiveness of techniques for behavior modification.
Early behavioral researchers studied stimulus–response pairings, now known as classical conditioning. They demonstrated that behaviors could be linked through repeated association with stimuli eliciting pain or pleasure. Ivan Pavlov—known best for inducing dogs to salivate in the presence of a stimulus previous linked with food—became a leading figure in the Soviet Union and inspired followers to use his methods on humans. In the United States, Edward Lee Thorndike initiated "connectionism" studies by trapping animals in "puzzle boxes" and rewarding them for escaping. Thorndike wrote in 1911: "There can be no moral warrant for studying man's nature unless the study will enable us to control his acts." From 1910–1913 the American Psychological Association went through a sea change of opinion, away from mentalism and towards "behavioralism", and in 1913 John B. Watson coined the term behaviorism for this school of thought. Watson's famous Little Albert experiment in 1920 demonstrated that repeated use of upsetting loud noises could instill phobias (aversions to other stimuli) in an infant human. Karl Lashley, a close collaborator with Watson, examined biological manifestations of learning in the brain.
Embraced and extended by Clark L. Hull, Edwin Guthrie, and others, behaviorism became a widely used research paradigm. A new method of "instrumental" or "operant" conditioning added the concepts of reinforcement and punishment to the model of behavior change. Radical behaviorists avoided discussing the inner workings of the mind, especially the unconscious mind, which they considered impossible to assess scientifically. Operant conditioning was first described by Miller and Kanorski and popularized in the U.S. by B. F. Skinner, who emerged as a leading intellectual of the behaviorist movement.
Noam Chomsky delivered an influential critique of radical behaviorism on the grounds that it could not adequately explain the complex mental process of language acquisition. Martin Seligman and colleagues discovered that the conditioning of dogs led to outcomes ("learned helplessness") that opposed the predictions of behaviorism. Skinner's behaviorism did not die, perhaps in part because it generated successful practical applications. Edward C. Tolman advanced a hybrid "cognitive behaviorial" model, most notably with his 1948 publication discussing the cognitive maps used by rats to guess at the location of food at the end of a modified maze.
The Association for Behavior Analysis International was founded in 1974 and by 2003 had members from 42 countries. The field has been especially influential in Latin America, where it has a regional organization known as ALAMOC: "La Asociación Latinoamericana de Análisis y Modificación del Comportamiento". Behaviorism also gained a strong foothold in Japan, where it gave rise to the Japanese Society of Animal Psychology (1933), the Japanese Association of Special Education (1963), the Japanese Society of Biofeedback Research (1973), the Japanese Association for Behavior Therapy (1976), the Japanese Association for Behavior Analysis (1979), and the Japanese Association for Behavioral Science Research (1994). Today the field of behaviorism is also commonly referred to as behavior modification or behavior analysis.
Cognitive.
Green Red BluePurple Blue Purple
Blue Purple RedGreen Purple Green
The Stroop effect refers to the fact that naming the color of the first set of words is easier and quicker than the second.
Cognitive psychology studies cognition, the mental processes underlying mental activity. Perception, attention, reasoning, thinking, problem solving, memory, learning, language, and emotion are areas of research. Classical cognitive psychology is associated with a school of thought known as cognitivism, whose adherents argue for an information processing model of mental function, informed by functionalism and experimental psychology.
On a broader level, cognitive science is an interdisciplinary enterprise of cognitive psychologists, cognitive neuroscientists, researchers in artificial intelligence, linguists, human–computer interaction, computational neuroscience, logicians and social scientists. Computer simulations are sometimes used to model phenomena of interest.
Starting in the 1950s, the experimental techniques developed by Wundt, James, Ebbinghaus, and others re-emerged as experimental psychology became increasingly cognitivist—concerned with information and its processing—and, eventually, constituted a part of the wider cognitive science. Some called this development the cognitive revolution because it rejected the anti-mentalist dogma of behaviorism as well as the strictures of psychoanalysis.
Social learning theorists, such as Albert Bandura, argued that the child's environment could make contributions of its own to the behaviors of an observant subject.
Technological advances also renewed interest in mental states and representations. English neuroscientist Charles Sherrington and Canadian psychologist Donald O. Hebb used experimental methods to link psychological phenomena with the structure and function of the brain. The rise of computer science, cybernetics and artificial intelligence suggested the value of comparatively studying information processing in humans and machines. Research in cognition had proven practical since World War II, when it aided in the understanding of weapons operation.
A popular and representative topic in this area is cognitive bias, or irrational thought. Psychologists (and economists) have classified and described a sizeable catalogue of biases which recur frequently in human thought. The availability heuristic, for example, is the tendency to overestimate the importance of something which happens to come readily to mind.
Elements of behaviorism and cognitive psychology were synthesized to form cognitive behavioral therapy, a form of psychotherapy modified from techniques developed by American psychologist Albert Ellis and American psychiatrist Aaron T. Beck. Cognitive psychology was subsumed along with other disciplines, such as philosophy of mind, computer science, and neuroscience, under the cover discipline of cognitive science.
Social.
Social psychology is the study of how humans think about each other and how they relate to each other. Social psychologists study such topics as the influence of others on an individual's behavior (e.g. conformity, persuasion), and the formation of beliefs, attitudes, and stereotypes about other people. Social cognition fuses elements of social and cognitive psychology in order to understand how people process, remember, or distort social information. The study of group dynamics reveals information about the nature and potential optimization of leadership, communication, and other phenomena that emerge at least at the microsocial level. In recent years, many social psychologists have become increasingly interested in implicit measures, mediational models, and the interaction of both person and social variables in accounting for behavior. The study of human society is therefore a potentially valuable source of information about the causes of psychiatric disorder. Some sociological concepts applied to psychiatric disorders are the social role, sick role, social class, life event, culture, migration, social, and total institution.
Psychoanalysis.
Psychoanalysis comprises a method of investigating the mind and interpreting experience; a systematized set of theories about human behavior; and a form of psychotherapy to treat psychological or emotional distress, especially conflict originating in the unconscious mind. This school of thought originated in the 1890s with Austrian medical doctors including Josef Breuer (physician), Alfred Adler (physician), Otto Rank (psychoanalyst), and most prominently Sigmund Freud (neurologist). Freud's psychoanalytic theory was largely based on interpretive methods, introspection and clinical observations. It became very well known, largely because it tackled subjects such as sexuality, repression, and the unconscious. These subjects were largely taboo at the time, and Freud provided a catalyst for their open discussion in polite society. Clinically, Freud helped to pioneer the method of free association and a therapeutic interest in dream interpretation.
Swiss psychiatrist Carl Jung, influenced by Freud, elaborated a theory of the collective unconscious—a primordial force present in all humans, featuring archetypes which exerted a profound influence on the mind. Jung's competing vision formed the basis for analytical psychology, which later led to the archetypal and process-oriented schools. Other well-known psychoanalytic scholars of the mid-20th century include Erik Erikson, Melanie Klein, D. W. Winnicott, Karen Horney, Erich Fromm, John Bowlby, and Sigmund Freud's daughter, Anna Freud. Throughout the 20th century, psychoanalysis evolved into diverse schools of thought which could be called Neo-Freudian. Among these schools are ego psychology, object relations, and interpersonal, Lacanian, and relational psychoanalysis.
Psychologists such as Hans Eysenck and philosophers including Karl Popper criticized psychoanalysis. Popper argued that psychoanalysis had been misrepresented as a scientific discipline, whereas Eysenck said that psychoanalytic tenets had been contradicted by experimental data. By the end of 20th century, psychology departments in American universities mostly marginalized Freudian theory, dismissing it as a "desiccated and dead" historical artifact. However, researchers in the emerging field of [[neuro-psychoanalysis]] today defend some of Freud's ideas on scientific grounds, while scholars of the [[humanities]] maintain that Freud was not a "scientist at all, but ... an [[hermeneutics|interpreter]]".
Existential-humanistic theories.
[[File:Maslow's Hierarchy of Needs.svg|thumb|right|250px|Psychologist Abraham Maslow in 1943 posited that humans have a hierarchy of needs, and it makes sense to fulfill the basic needs first (food, water etc.) before higher-order needs can be met.]]
[[Humanistic psychology]] developed in the 1950s as a movement within academic psychology, in reaction to both behaviorism and psychoanalysis. The humanistic approach sought to glimpse the whole person, not just fragmented parts of the personality or isolated cognitions. Humanism focused on uniquely human issues, such as [[free will]], personal growth, [[self-actualization]], [[self-concept|self-identity]], [[death]], [[Loneliness#As human condition|aloneness]], [[freedom]], and [[meaning (existential)|meaning]]. It emphasized subjective meaning, rejection of determinism, and concern for positive growth rather than pathology. Some founders of the humanistic school of thought were American psychologists [[Abraham Maslow]], who formulated a [[Maslow's hierarchy of needs|hierarchy of human needs]], and [[Carl Rogers]], who created and developed [[client-centered therapy]]. Later, [[positive psychology]] opened up humanistic themes to scientific modes of exploration.
The "American Association for Humanistic Psychology", formed in 1963, declared:
Humanistic psychology is primarily an orientation toward the whole of psychology rather than a distinct area or school. It stands for respect for the worth of persons, respect for differences of approach, open-mindedness as to acceptable methods, and interest in exploration of new aspects of human behavior. As a "third force" in contemporary psychology, it is concerned with topics having little place in existing theories and systems: e.g., love, creativity, self, growth, organism, basic need-gratification, self-actualization, higher values, being, becoming, spontaneity, play, humor, affection, naturalness, warmth, ego-transcendence, objectivity, autonomy, responsibility, meaning, fair-play, transcendental experience, peak experience, courage, and related concepts.
In the 1950s and 1960s, influenced by philosophers [[Søren Kierkegaard]] and [[Martin Heidegger]] and, psychoanalytically trained American psychologist [[Rollo May]] pioneered an [[existential]] branch of psychology, which included [[existential therapy|existential psychotherapy]]: a method based on the belief that inner conflict within a person is due to that individual's confrontation with the givens of existence. Swiss psychoanalyst [[Ludwig Binswanger]] and American psychologist [[George Kelly (psychologist)|George Kelly]] may also be said to belong to the existential school. Existential psychologists differed from more "humanistic" psychologists in their relatively neutral view of [[human nature]] and their relatively positive assessment of anxiety. Existential psychologists emphasized the humanistic themes of death, free will, and meaning, suggesting that meaning can be shaped by [[myth]]s, or narrative patterns, and that it can be encouraged by an acceptance of the free will requisite to an [[authenticity (philosophy)|authentic]], albeit often anxious, regard for death and other future prospects.
Austrian existential psychiatrist and [[Holocaust]] survivor [[Viktor Frankl]] drew evidence of meaning's therapeutic power from reflections garnered from his own [[internment]]. He created a variation of existential psychotherapy called [[logotherapy]], a type of [[existentialism|existentialist]] analysis that focuses on a "[[Meaning (existential)|will to meaning]]" (in one's life), as opposed to Adler's [[Nietzsche]]an doctrine of "[[will to power]]" or Freud's "[[Pleasure principle (psychology)|will to pleasure]]".
Themes.
Personality.
[[Personality psychology]] is concerned with enduring patterns of behavior, thought, and emotion—commonly referred to as [[wikt:personality|personality]]—in individuals. Theories of personality vary across different psychological schools and orientations. They carry different assumptions about such issues as the role of the unconscious and the importance of childhood experience. According to Freud, personality is based on the dynamic interactions of the [[id, ego, and super-ego]]. [[Trait theorist]]s, in contrast, attempt to analyze personality in terms of a discrete number of key traits by the statistical method of [[factor analysis]]. The number of proposed traits has varied widely. An early model, proposed by [[Hans Eysenck]], suggested that there are three traits which comprise human personality: [[extraversion and introversion|extraversion–introversion]], [[neuroticism]], and [[psychoticism]]. [[Raymond Cattell]] proposed a theory of [[16 personality factors]]. Dimensional models of personality are receiving increasing support, and some version of dimensional assessment will be included in the forthcoming [[DSM-V]].
Myriad approach to systematically assess different personality types, with the [[Woodworth Personal Data Sheet]], developed during World War I, an early example of the modern technique. The [[Myers–Briggs Type Indicator]] sought to assess people according to the [[Psychological Types|personality theories of Carl Jung]]. Behaviorist resistance to introspection led to the development of the [[Strong Interest Inventory|Strong Vocational Interest Blank]] and [[Minnesota Multiphasic Personality Inventory]], tests which ask more empirical questions and focus less on the psychodynamics of the respondent.
Unconscious mind.
Study of the [[unconscious mind]], a part of the psyche outside the awareness of the individual which nevertheless influenced thoughts and behavior was a hallmark of early psychology. In one of the first psychology experiments conducted in the USA, [[C. S. Peirce]] and [[Joseph Jastrow]] found in 1884 that subjects could choose the minutely heavier of two weights even if consciously uncertain of the difference. Freud popularized this concept, with terms like [[Freudian slip]] entering popular culture, to mean an uncensored intrusion of unconscious thought into one's speech and action. His 1901 text "[[The Psychopathology of Everyday Life]]" catalogues hundreds of everyday events which Freud explains in terms of unconscious influence. [[Pierre Janet]] advanced the idea of a [[subconscious]] mind, which could contain autonomous mental elements unavailable to the scrutiny of the subject.
Behaviorism notwithstanding, the unconscious mind has maintained its importance in psychology. Cognitive psychologists have used a "filter" model of [[attention]], according to which much information processing takes place below the threshold of consciousness, and only certain processes, limited by nature and by simultaneous quantity, make their way through the filter. Copious research has shown that subconscious "[[priming (psychology)|priming]]" of certain ideas can covertly influence thoughts and behavior. A significant hurdle in this research is proving that a subject's conscious mind has not grasped a certain stimulus, due to the unreliability of self-reporting. For this reason, some psychologists prefer to distinguish between "[[implicit memory|implicit]]" and "[[explicit memory|explicit]]" memory. In another approach, one can also describe a [[subliminal stimulus]] as meeting an "objective" but not a "subjective" threshold.
The [[automaticity]] model, which became widespread following exposition by [[John Bargh]] and others in the 1980s, describes sophisticated processes for executing goals which can be selected and performed over an extended duration without conscious awareness. Some experimental data suggests that the [[Neuroscience of free will|brain begins to consider taking actions]] before the mind becomes aware of them. This influence of unconscious forces on people's choices naturally bears on philosophical questions [[free will]]. John Bargh, [[Daniel Wegner]], and [[Ellen Langer]] are some prominent contemporary psychologists who [[Illusion of control|describe free will as an illusion]].
Motivation.
Psychologists such as William James initially used the term "motivation" to refer to intention, in a sense similar to the concept of "[[Will (philosophy)|will]]" in European philosophy. With the steady rise of Darwinian and Freudian thinking, [[instinct]] also came to be seen as a primary source of motivation. According to [[drive theory]], the forces of instinct combine into a single source of energy which exerts a constant influence. Psychoanalysis, like biology, regarded these forces as physical demands made by the organism on the nervous system. However, they believed that these forces, especially the sexual instincts, could become entangled and transmuted within the psyche. Classical psychoanalysis conceives of a struggle between the [[pleasure principle]] and the [[reality principle]], roughly corresponding to id and ego. Later, in "[[Beyond the Pleasure Principle]]", Freud introduced the concept of the "[[death drive]]", a compulsion towards aggression, destruction, and [[Repetition compulsion|psychic repetition of traumatic events]]. Meanwhile, behaviorist researchers used simple dichotomous models (pleasure/pain, reward/punishment) and well-established principles such as the idea that a thirsty creature will take pleasure in drinking. [[Clark Hull]] formalized the latter idea with his [[Drive reduction theory (learning theory)|drive reduction]] model.
Hunger, thirst, fear, sexual desire, and thermoregulation all seem to constitute fundamental motivations for animals. Humans also seem to exhibit a more complex set of motivations—though theoretically these could be explained as resulting from primordial instincts—including desires for belonging, self-image, self-consistency, truth, love, and control.
Motivation can be modulated or manipulated in many different ways. Researchers have found that [[eating]], for example, depends not only on the organism's fundamental need for [[homeostasis]]—an important factor causing the experience of [[Hunger (motivational state)|hunger]]—but also on circadian rhythms, food availability, food palatability, and cost. Abstract motivations are also malleable, as evidenced by such phenomena as "goal contagion": the adoption of goals, sometimes unconsciously, based on inferences about the goals of others. Vohs and [[Roy Baumeister|Baumeister]] suggest that contrary to the need-desire-fulfilment cycle of animal instincts, human motivations sometimes obey a "getting begets wanting" rule: the more you get a reward such as self-esteem, love, drugs, or money, the more you want it. They suggest that this principle can even apply to food, drink, sex, and sleep.
Development.
[[File:Baby with book.jpg|thumb|upright|Developmental psychologists would engage a child with a book and then make observations based on how the child interacts with the object.]]
Mainly focusing on the development of the human mind through the life span, [[developmental psychology]] seeks to understand how people come to perceive, understand, and act within the world and how these processes change as they age. This may focus on cognitive, affective, [[moral development|moral]], social, or neural development. Researchers who study children use a number of unique research methods to make observations in natural settings or to engage them in experimental tasks. Such tasks often resemble specially designed games and activities that are both enjoyable for the child and scientifically useful, and researchers have even devised clever methods to study the mental processes of infants. In addition to studying children, developmental psychologists also study [[aging]] and processes throughout the life span, especially at other times of rapid change (such as [[adolescence]] and [[old age]]). Developmental psychologists draw on the full range of psychological theories to inform their research.
Applications.
Psychology encompasses many subfields and includes different approaches to the study of mental processes and behavior:
Mental testing.
[[Psychological testing]] has ancient origins, such as [[imperial examination|examinations for the Chinese civil service]] dating back to 2200 BC. Written exams began during the Han dynasty (202 BC.–AD. 200). By 1370, the Chinese system required a stratified series of tests, involving essay writing and knowledge of diverse topics. The system was ended in 1906. In Europe, mental assessment took a more physiological approach, with theories of [[physiognomy]]—judgment of character based on the face—described by Aristotle in 4th century BC Greece. Physiognomy remained current through the Enlightenment, and added the doctrine of [[phrenology]]: a study of mind and intelligence based on simple assessment of neuroanatomy.
When experimental psychology came to Britain, [[Francis Galton]] was a leading practitioner, and, with his procedures for measuring reaction time and sensation, is considered an inventor of modern mental testing (a.k.a. "[[psychometrics]]"). [[James McKeen Cattell]], a student of Wundt and Galton, brought the concept to the USA, and in fact coined the term "mental test". In 1901, Cattell's student [[Clark Wissler]] published discouraging results, suggesting that mental testing of Columbia and Barnard students failed to predict their academic performance. In response to 1904 orders from the [[Ministry of National Education (France)|Minister of Public Instruction]], French psychologists [[Alfred Binet]] and [[Théodore Simon]] elaborated a new test of intelligence in 1905–1911, using a range of questions diverse in their nature and difficulty. Binet and Simon introduced the concept of [[mental age]] and referred to the lowest scorers on their test as "[[idiot]]s". [[Henry H. Goddard]] put the Binet-Simon scale to work and introduced classifications of mental level such as "[[imbecile]]" and "[[feebleminded]]". In 1916 (after Binet's death), Stanford professor [[Lewis M. Terman]] modified the Binet-Simon scale (renamed the [[Stanford–Binet Intelligence Scales|Stanford-Binet scale]]) and introduced the [[intelligence quotient]] as a score report. From this test, Terman concluded that mental retardation "represents the level of intelligence which is very, very common among Spanish-Indians and Mexican families of the Southwest and also among negroes. Their dullness seems to be racial."
Following the [[Army Alpha]] and [[Army Beta]] tests for soldiers in World War I, mental testing became popular in the US, where it was soon applied to school children. The federally created National Intelligence Test was administered to 7 million children in the 1920s, and in 1926 the [[College Entrance Examination Board]] created the [[Scholastic Aptitude Test]] to standardize college admissions. The results of intelligence tests were used to argue for segregated schools and economic functions—i.e. the preferential training of [[Black Americans]] for manual labor. These practices were criticized by black intellectuals such a [[Horace Mann Bond]] and [[Allison Davis]]. Eugenicists used mental testing to justify and organize [[compulsory sterilization]] of individuals classified as [[mentally retarded]]. In the United States, tens of thousands of men and women were sterilized. Setting a precedent which has never been overturned, the U.S. Supreme Court affirmed the constitutionality of this practice in the 1907 case "[[Buck v. Bell]]".
Today mental testing is a routine phenomenon for people of all ages in Western societies. Modern testing aspires to criteria including standardization of procedure, [[reliability (psychometrics)|consistency of results]], output of an interpretable score, statistical norms describing population outcomes, and, ideally, [[test validity|effective prediction]] of behavior and life outcomes outside of testing situations.
Mental health care.
The provision of psychological health services is generally called "[[clinical psychology]]" in the U.S. The definitions of this term are various and may include [[school psychology]] and [[counseling psychology]]. Practitioners typically includes people who have graduated from doctoral programs in clinical psychology but may also include others. In Canada, the above groups usually fall within the larger category of "[[professional psychology]]". In Canada and the US, practitioners get bachelor's degrees and doctorates, then spend one year in an internship and one year in postdoctoral education. In Mexico and most other Latin American and European countries, psychologists do not get bachelor's and doctorate degrees; instead, they take a three-year professional course following high school. Clinical psychology is at present the largest specialization within psychology. It includes the study and application of psychology for the purpose of understanding, preventing, and relieving psychologically based distress, dysfunction or [[mental illness]] and to promote subjective [[Mental health|well-being]] and personal development. Central to its practice are psychological assessment and psychotherapy although clinical psychologists may also engage in research, teaching, consultation, forensic testimony, and program development and administration.
Credit for the first psychology clinic in the USA typically goes to [[Lightner Witmer]], who established his practice in Philadelphia in 1896. Another modern psychotherapist was [[Morton Prince]]. For the most part, in the first part of the twentieth century, most mental health care in the United States was performed by specialized medical doctors called psychiatrists. Psychology entered the field with its refinements of mental testing, which promised to improve diagnosis of mental problems. For their part, some psychiatrists became interested in using psychoanalysis and other forms of [[psychodynamic psychotherapy]] to understand and treat the mentally ill. In this type of treatment, a specially trained therapist develops a close relationship with the patient, who discusses wishes, dreams, social relationships, and other aspects of mental life. The therapist seeks to uncover repressed material and to understand why the patient creates defenses against certain thoughts and feelings. An important aspect of the therapeutic relationship is [[transference]], in which deep unconscious feelings in a patient reorient themselves and become manifest in relation to the therapist.
Psychiatric psychotherapy blurred the distinction between psychiatry and psychology, and this trend continued with the rise of [[Community mental health service|community mental health facilities]] and [[behavioral therapy]], a thoroughly non-psychodynamic model which used behaviorist learning theory to change the actions of patients. A key aspect of behavior therapy is empirical evaluation of the treatment's effectiveness. In the 1970s, [[cognitive-behavior therapy]] arose, using similar methods and now including the cognitive constructs which had gained popularity in theoretical psychology. A key practice in behavioral and cognitive-behavioral therapy is exposing patients to things they fear, based on the premise that their responses (fear, panic, anxiety) can be deconditioned.
Mental health care today involves psychologists and social workers in increasing numbers. In 1977, National Institute of Mental Health director [[Bertram Brown]] described this shift as a source of "intense competition and role confusion". Graduate programs issuing doctorates in psychology (PsyD) emerged in the 1950s and underwent rapid increase through the 1980s. This degree is intended to train practitioners who might conduct scientific research.
Some clinical psychologists may focus on the clinical management of patients with [[Brain damage|brain injury]]—this area is known as [[clinical neuropsychology]]. In many countries, clinical psychology is a regulated [[mental health profession]]. The emerging field of "disaster psychology" (see [[crisis intervention]]) involves professionals who respond to large-scale traumatic events.
The work performed by clinical psychologists tends to be influenced by various therapeutic approaches, all of which involve a formal relationship between professional and client (usually an individual, couple, family, or small group). Typically, these approaches encourage new ways of thinking, feeling, or behaving. Four major theoretical perspectives are [[psychodynamic psychotherapy|psychodynamic]], [[cognitive behavioral therapy|cognitive behavioral]], [[humanistic psychology|existential–humanistic]], and systems or [[family therapy]]. There has been a growing movement to integrate the various therapeutic approaches, especially with an increased understanding of issues regarding culture, gender, spirituality, and sexual orientation. With the advent of more robust research findings regarding psychotherapy, there is evidence that most of the major therapies have equal effectiveness, with the key common element being a strong [[therapeutic relationship|therapeutic alliance]]. Because of this, more training programs and psychologists are now adopting an [[Integrative Psychotherapy|eclectic therapeutic orientation]].
Diagnosis in clinical psychology usually follows the "Diagnostic and Statistical Manual of Mental Disorders" (DSM), a handbook first published by the American Psychiatric Association in 1952. New editions over time have increased in size and focused more on medical language. The study of mental illnesses is called [[abnormal psychology]].
Education.
[[File:Figural Relationships.svg|right|thumb|300px|An example of an item from a cognitive abilities test used in educational psychology.]]
[[Educational psychology]] is the study of how humans learn in [[education]]al settings, the effectiveness of educational interventions, the psychology of teaching, and the [[social psychology]] of [[school]]s as organizations. The work of child psychologists such as [[Lev Vygotsky]], [[Jean Piaget]], [[Bernard Luskin]], and [[Jerome Bruner]] has been influential in creating [[teaching]] methods and educational practices. Educational psychology is often included in teacher education programs in places such as North America, Australia, and New Zealand.
[[School psychology]] combines principles from [[educational psychology]] and [[clinical psychology]] to understand and treat students with learning disabilities; to foster the intellectual growth of [[intellectual giftedness|gifted]] students; to facilitate [[prosocial behavior]]s in adolescents; and otherwise to promote safe, supportive, and effective learning environments. School psychologists are trained in educational and behavioral assessment, intervention, prevention, and consultation, and many have extensive training in research.
Work.
Industrialists soon brought the nascent field of psychology to bear on the study of [[scientific management]] techniques for improving workplace efficiency. This field was at first called "economic psychology" or "business psychology"; later, "industrial psychology", "employment psychology", or "psychotechnology". An important early study examined workers at Western Electric's Hawthorne plant in Cicero, Illinois from 1924–1932. With funding from the Laura Spelman Rockefeller Fund and guidance from Australian psychologist [[Elton Mayo]], Western Electric experimented on thousands of factory workers to assess their responses to illumination, breaks, food, and wages. The researchers came to focus on workers' responses to observation itself, and the term [[Hawthorne effect]] is now used to describe the fact that people work harder when they think they're being watched.
The name [[industrial and organizational psychology]] (I–O) arose in the 1960s and became enshrined as the [[Society for Industrial and Organizational Psychology]], Division 14 of the American Psychological Association, in 1973. The goal is to optimize human potential in the workplace. Personnel psychology, a subfield of I–O psychology, applies the methods and principles of psychology in selecting and evaluating workers. I–O psychology's other subfield, [[organizational psychology]], examines the effects of work environments and management styles on worker motivation, [[job satisfaction]], and productivity. The majority of I–O psychologists work outside of academia, for private and public organizations and as consultants. A psychology consultant working in business today might expect to provide executives with information and ideas about their industry, their target markets, and the organization of their company.
Military and intelligence.
One role for psychologists in the military is to evaluate and counsel soldiers and other personnel. In the U.S., this function began during World War I, when [[Robert Yerkes]] established the School of Military Psychology at [[Fort Oglethorpe, Georgia|Fort Oglethorpe]] in Georgia, to provide psychological training for military staff military. Today, U.S Army psychology includes psychological screening, clinical psychotherapy, [[suicide prevention]], and treatment for post-traumatic stress, as well as other aspects of health and workplace psychology such as [[smoking cessation]].
Psychologists may also work on a diverse set of campaigns known broadly as [[psychological warfare]]. Psychologically warfare chiefly involves the use of [[propaganda]] to influence enemy soldiers and civilians. In the case of so-called [[black propaganda]] the propaganda is designed to seem like it originates from a different source. The [[CIA]]'s [[MKULTRA]] program involved more individualized efforts at [[mind control]], involving techniques such as hypnosis, torture, and covert involuntary administration of [[LSD]]. The U.S. military used the name [[Psychological Operations (United States)|Psychological Operations]] (PSYOP) until 2010, when these were reclassified as Military Information Support Operations (MISO), part of [[Information Operations (United States)|Information Operations]] (IO). Psychologists are sometimes involved in assisting the interrogation and torture of suspects, though this has sometimes been denied by those involved and sometimes opposed by others.
Health, well-being, and social change.
Medical facilities increasingly employ psychologists to perform various roles. A prominent aspect of [[health psychology]] is the [[psychoeducation]] of patients: instructing them in how to follow a medical regimen. Health psychologists can also educate doctors and conduct research on patient [[compliance (medicine)|compliance]].
Psychologists in the field of [[public health]] use a wide variety of interventions to influence human behavior. These range from public relations campaigns and outreach to governmental laws and policies. Psychologists study the composite influence of all these different tools in an effort to influence whole [[population]]s of people.
Black American psychologists [[Kenneth and Mamie Clark]] studied the psychological impact of segregation and testified with their findings in the desegregation case "[[Brown v. Board of Education]]" (1954).
[[Positive psychology]] is the study of factors which contribute to human [[happiness]] and well-being, focusing more on people who are currently health. In 2010 "Clinical Psychological Review" published a special issue devoted to positive psychological interventions, such as [[gratitude journal]]ing and the physical expression of [[gratitude]]. Positive psychological interventions have been limited in scope, but their effects are thought to be superior to that of [[placebo]]s, especially with regard to helping people with [[Body dysmorphic disorder|body image problems]].
Research methods.
[[Quantitative psychological research]] lends itself to the statistical testing of hypotheses. Although the field makes abundant use of randomized and controlled experiments in laboratory settings, such research can only assess a limited range of short-term phenomena. Thus, psychologists also rely on creative statistical methods to glean knowledge from clinical trials and population data. These include the [[Pearson product–moment correlation coefficient]], the [[analysis of variance]], [[multiple linear regression]], [[logistic regression]], [[structural equation modeling]], and [[hierarchical linear modeling]]. The measurement and [[operational definition|operationalization]] of important constructs is an essential part of these research designs.
Controlled experiments.
[[File:Flowchart of Phases of Parallel Randomized Trial - Modified from CONSORT 2010.png|thumb|250px|right|Flowchart of four phases (enrollment, intervention allocation, follow-up, and data analysis) of a parallel randomized trial of two groups, modified from the [[Consolidated Standards of Reporting Trials|CONSORT 2010 Statement]]]]
[[File:Milgram Experiment v2.png|right|thumb|The experimenter (E) orders the teacher (T), the subject of the experiment, to give what the latter believes are painful electric shocks to a learner (L), who is actually an actor and [[wikt:confederate|confederate]]. The subject believes that for each wrong answer, the learner was receiving actual electric shocks, though in reality there were no such punishments. Being separated from the subject, the confederate set up a tape recorder integrated with the electro-shock generator, which played pre-recorded sounds for each shock level etc.]]
A [[true experiment]] with [[randomized controlled trial|random]] allocation of subjects to conditions allows researchers to make strong inferences about causal relationships. In an experiment, the researcher alters parameters of influence, called [[independent variable]]s, and measures resulting changes of interest, called [[dependent variable]]s. Prototypical experimental research is conducted in a laboratory with a carefully controlled environment.
[[Repeated-measures experiment]]s are those which take place through intervention on multiple occasions. In research on the effectiveness of [[psychotherapy]], experimenters often compare a given treatment with [[placebo]] treatments, or compare different treatments against each other. Treatment type is the independent variable. The dependent variables are outcomes, ideally assessed in several ways by different professionals. Using [[crossover study|crossover design]], researchers can further increase the strength of their results by testing both of two treatments on two groups of subjects.
[[Quasi-experimental design]] refers especially to situations precluding random assignment to different conditions. Researchers can use common sense to consider how much the nonrandom assignment threatens the study's [[validity]]. For example, in research on the best way to affect reading achievement in the first three grades of school, school administrators may not permit educational psychologists to randomly assign children to phonics and whole language classrooms, in which case the psychologists must work with preexisting classroom assignments. Psychologists will compare the achievement of children attending phonics and whole language classes.
Experimental researchers typically use a [[statistical hypothesis testing]] model which involves making predictions before conducting the experiment, then assessing how well the data supports the predictions. (These predictions may originate from a more abstract scientific [[hypothesis]] about how the phenomenon under study actually works.) [[Analysis of variance]] (ANOVA) statistical techniques are used to distinguish unique results of the experiment from the [[null hypothesis]] that variations result from random fluctuations in data. In psychology, the widely usd standard ascribes [[statistical significance]] to results which have less than 5% [[p-value|probability of being explained by random variation]].
Other forms of statistical inference.
[[Statistical survey]]s are used in psychology for measuring attitudes and traits, monitoring changes in mood, checking the validity of experimental manipulations, and for other psychological topics. Most commonly, psychologists use paper-and-pencil surveys. However, surveys are also conducted over the phone or through e-mail. Web-based surveys are increasingly used to conveniently reach many subjects.
[[Neuropsychological tests]], such as the [[David Wechsler|Wechsler scales]] and [[Wisconsin Card Sorting Test]]), are mostly questionnaires or simple tasks used which assess a specific type of mental function in the respondent. These can be used in experiments, as in the case of [[lesion]] experiments evaluating the results of damage to a specific part of the brain.
[[Observational studies]] analyze uncontrolled data in search of correlations; [[multivariate statistics]] are typically used to interpret the more complex situation. [[Cross-sectional studies|Cross-sectional]] observational studies use data from a single point in time, whereas [[longitudinal studies|longitudinal]] studies are used to study trends across the life span. Longitudinal studies track the same people, and therefore detect more individual, rather than cultural, differences. However, they suffer from lack of controls and from confounding factors such as "selective attrition" (the bias introduced when a certain type of subject disproportionately leaves a study).
[[Exploratory data analysis]] refers to a variety of practices which researchers can use to visualize and analyze existing sets of data. In [[Charles Sanders Peirce#Modes of inference|Peirce's three modes of inference]], exploratory data anlysis corresponds to [[abduction (logic)|abduction]], or hypothesis formation. [[Meta-analysis]] is the technique of integrating the results from multiple studies and interpreting the statistical properties of the pooled dataset.
Technological assays.
[[File:MorrisWaterMaze.jpg|right|thumb|A rat undergoing a [[Morris water navigation test]] used in [[behavioral neuroscience]] to study the role of the [[hippocampus]] in [[spatial learning]] and memory.]]
A classic and popular tool used to relate mental and neural activity is the [[electroencephalogram]] (EEG), a technique using amplified electrodes on a person's scalp to measure voltage changes in different parts of the brain. [[Hans Berger]], the first researcher to use EEG on an unopened skull, quickly found that brains exhibit signature "[[neural oscillation|brain waves]]": electric oscillations which correspond to different states of consciousness. Researchers subsequently refined statistical methods for synthesizing the electrode data, and identified unique brain wave patterns such as the [[delta wave]] observed during non-REM sleep.
Newer [[functional neuroimaging]] techniques include [[functional magnetic resonance imaging]] and [[positron emission tomography]], both of which track the flow of blood through the brain. These technologies provide more localized information about activity in the brain and create representations of the brain with widespread appeal. They also provide insight which avoids the classic problems of subjective self-reporting. It remains challenging to draw hard conclusions about where in the brain specific thoughts originate—or even how usefully such localization corresponds with reality. However, neuroimaging has delivered unmistakable results showing the existence of correlations between mind and brain. Some of these draw on a systemic [[neural network]] model rather than a localized function model.
Psychiatric interventions such as [[transcranial magnetic stimulation]] and of course [[drug]]s also provide information about brain–mind interactions. [[Psychopharmacology]] is the study of drug-induced mental effects.
[[File:Multi-Layer Neural Network-Vector.svg|thumb|[[Artificial neural network]] with two layers, an interconnected group of nodes, akin to the vast network of neurons in the human brain.]]
Computer simulation.
[[Computer simulation|Computational modeling]] is a tool used in [[mathematical psychology]] and [[cognitive psychology]] to simulate behavior. This method has several advantages. Since modern computers process information quickly, simulations can be run in a short time, allowing for high statistical power. Modeling also allows psychologists to visualize hypotheses about the functional organization of mental events that couldn't be directly observed in a human. [[Connectionism]] uses [[neural network]]s to simulate the brain. Another method is symbolic modeling, which represents many mental objects using variables and rules. Other types of modeling include [[dynamic systems]] and [[stochastic process|stochastic]] modeling.
Animal studies.
[[File:Chimpanzee and stick.jpg|thumb|The common [[chimpanzee]] can use [[tool]]s. This chimpanzee is using a stick in order to get food.]]
Animal experiments aid in investigating many aspects of human psychology, including perception, emotion, learning, memory, and thought, to name a few. In the 1890s, Russian physiologist [[Ivan Pavlov]] famously used dogs to demonstrate [[classical conditioning]]. [[Animal testing on non-human primates|Non-human primates]], cats, dogs, pigeons, [[laboratory rat|rats]], and other [[Animal testing on rodents|rodents]] are often used in psychological experiments. Ideally, controlled experiments introduce only one [[independent variable]] at a time, in order to ascertain its unique effects upon dependent variables. These conditions are approximated best in laboratory settings. In contrast, human environments and genetic backgrounds vary so widely, and depend upon so many factors, that it is difficult to control important variables for human subjects. Of course, there are pitfalls in generalizing findings from animal studies to humans through animal models.
[[Comparative psychology]] refers to the scientific study of the behavior and mental processes of non-human animals, especially as these relate to the phylogenetic history, adaptive significance, and development of behavior. Research in this area explores the behavior of many species, from insects to primates. It is closely related to other disciplines that study animal behavior such as [[ethology]]. Research in comparative psychology sometimes appears to shed light on human behavior, but some attempts to connect the two have been quite controversial, for example the [[Sociobiology]] of [[E. O. Wilson]]. Animal models are often used to study neural processes related to human behavior, e.g. in [[cognitive neuroscience]].
Qualitative and descriptive research.
Research designed to answer questions about the current state of affairs such as the thoughts, feelings, and behaviors of individuals is known as "descriptive research". Descriptive research can be qualitative or quantitative in orientation. "Qualitative research" is descriptive research that is focused on observing and describing events as they occur, with the goal of capturing all of the richness of everyday behavior and with the hope of discovering and understanding phenomena that might have been missed if only more cursory examinations have been made.
[[Qualitative psychological research]] methods include [[interview]]s, first-hand observation, and [[participant observation]]. Creswell (2003) identifies five main possibilities for qualitative research, including narrative, [[Phenomenology (psychology)|phenomenology]], [[ethnography]], [[case study]], and [[grounded theory]]. Qualitative researchers sometimes aim to enrich [[hermeneutics|interpretations]] or [[critical theory|critiques]] of [[symbol]]s, [[subject (philosophy)|subjective]] experiences, or [[social structure]]s. Sometimes hermeneutic and critical aims can give rise to quantitative research, as in [[Erich Fromm]]'s study of [[Authoritarian personality|Nazi voting]] or [[Stanley Milgram]]'s [[Milgram experiment|studies]] of [[obedience to authority]].
[[File:Phineas gage - 1868 skull diagram.jpg|right|thumb|[[Phineas P. Gage]] survived an accident in which a large iron rod was driven completely through his head, destroying much of his brain's left frontal lobe, and is remembered for that injury's reported effects on his personality and behavior.]]
Just as [[Jane Goodall]] studied [[chimpanzee]] social and family life by careful observation of chimpanzee behavior in the field, psychologists conduct [[naturalistic observation]] of ongoing human social, professional, and family life. Sometimes the participants are aware they are being observed, and other times the participants do not know they are being observed. Strict ethical guidelines must be followed when covert observation is being carried out.
Contemporary issues in methodology and practice.
In 1959 statistician Theodore Sterling examined the results of psychological studies and discovered that 97% of them supported their initial hypotheses, implying a possible [[publication bias]]. Similarly, Fanelli (2010) found that 91.5% of psychiatry/psychology studies confirmed the effects they were looking for, and concluded that the odds of this happening (a positive result) was around five times higher than in fields such as [[space science|space]]- or [[geoscience]]s. Fanelli argues that this is because researchers in "softer" sciences have fewer constraints to their conscious and unconscious biases.
Some popular media outlets have in recent years spotlighted a [[replication crisis]] in psychology, arguing that many findings in the field cannot be reproduced. Repeats of some famous studies have not reached the same conclusions, and some researchers have been accused of outright fraud in their results. Focus on this issue has led to renewed efforts in the discipline to re-test important findings.
Some critics view [[statistical hypothesis testing#Criticism|statistical hypothesis testing]] as misplaced. Psychologist and statistician [[Jacob Cohen (statistician)|Jacob Cohen]] wrote in 1994 that psychologists routinely confuse [[statistical significance]] with [[effect size|practical importance]], enthusiastically reporting great certainty in unimportant facts. Some psychologists have responded with an increased use of [[effect size]] statistics, rather than sole reliance on the [[Ronald A. Fisher|Fisherian]] [[P value|"p" < .05]] [[statistical significance|significance]] criterion (whereby an observed difference is deemed "[[statistically significant]]" if an effect of that size or larger would occur with 5% -or less- [[frequency probability|probability]] in [[independence (probability theory)|independent]] [[replication (statistics)|replications]], assuming the truth of the [[null-hypothesis]] of no difference between the treatments).
In 2010, a group of researchers reported a systemic bias in psychology studies towards WEIRD ("western, educated, industrialized, rich and democratic") subjects. Although only 1/8 people worldwide fall into the WEIRD classification, the researchers claimed that 60–90% of psychology studies are performed on WEIRD subjects. The article gave examples of results that differ significantly between WEIRD subjects and tribal cultures, including the [[Müller-Lyer illusion]].
[[File:Psychology Wiki snap shot.jpg|thumbnail|Psychology Wiki snap shot]]
Some observers perceive a gap between scientific theory and its application—in particular, the application of unsupported or unsound clinical practices. Critics say there has been an increase in the number of mental health training programs that do not instill scientific competence. One skeptic asserts that practices, such as "[[facilitated communication]] for infantile autism"; memory-recovery techniques including [[Bodywork (alternative medicine)|body work]]; and other therapies, such as [[Rebirthing (breathwork)|rebirthing]] and [[reparenting]], may be dubious or even dangerous, despite their popularity. In 1984, Allen Neuringer made a similar point regarding the experimental analysis of behavior. Psychologists, sometimes divided along the lines of laboratory vs. clinic, continue to debate these issues.
Ethics.
Ethical standards in the discipline have changed over time. Some famous past studies are today considered unethical and in violation of established codes ([[Human subject research#APA Ethics Code|Ethics Code of the American Psychological Association]], the Canadian Code of Conduct for Research Involving Humans, and the [[Belmont Report]]).
The most important contemporary standards are informed and voluntary consent. After World War II, the [[Nuremberg Code]] was established because of Nazi abuses of experimental subjects. Later, most countries (and scientific journals) adopted the [[Declaration of Helsinki]]. In the U.S., the [[National Institutes of Health]] established the [[Institutional Review Board]] in 1966, and in 1974 adopted the [[National Research Act]] (HR 7724). All of these measures encouraged researchers to obtain informed consent from human participants in experimental studies. A number of influential studies led to the establishment of this rule; such studies included the [[MIT]] and Fernald School radioisotope studies, the [[Thalidomide scandal|Thalidomide tragedy]], the Willowbrook [[hepatitis]] study, and [[Stanley Milgram]]'s studies of obedience to authority.
Humans.
University psychology departments have ethics committees dedicated to the rights and well-being of research subjects. Researchers in psychology must gain approval of their research projects before conducting any experiment to protect the interests of human participants and laboratory animals.
The ethics code of the American Psychological Association originated in 1951 as "Ethical Stanards of Psychologists." This code has guided the formation of licensing laws in most American states. It has changed multiple times over the decades since its adoption. In 1989 the APA revised its policies on advertising and referral fees to negotiate the end of an investigation by the Federal Trade Commission. The 1992 incarnation was the first to distinguish between "aspirational" ethical standards and "enforceable" ones. Members of the public have a 5-year window to file ethics complaints about APA members with the APA ethics committee; members of the APA have a 3-year window.
Some of the ethical issues considered most important are the requirement to practice only within the area of competence, to maintain confidentiality with the patients, and to avoid sexual relations with them. Another important principle is [[informed consent]], the idea that a patient or research subject must understand and freely choose a procedure they are undergoing. Some of the most common complaints against clinical psychologists include sexual misconduct, and involvement in child custody evaluations.
Other animals.
Current ethical guidelines state that using non-human animals for scientific purposes is only acceptable when the harm (physical or psychological) done to animals is outweighed by the benefits of the research. Keeping this in mind, psychologists can use certain research techniques on animals that could not be used on humans.
External links.
[[Category:Psychology| ]]
[[Category:Behavioural sciences]]

</doc>
<doc id="22923" url="https://en.wikipedia.org/wiki?curid=22923" title="PhpWiki">
PhpWiki

PhpWiki is a web-based wiki software application.
It began as a clone of WikiWikiWeb and was the first wiki written in PHP.
PhpWiki has been used to edit and format paper books for publication.
History.
The first version, by Steve Wainstead, was in December 1999 and was the first Wiki written in PHP to be publicly released.
The first version ran under PHP 3.x and ran on DBM files only. 
It was a feature-for-feature reimplementation of the original WikiWikiWeb at c2.com.
In early 2000 Arno Hollosi contributed a second database library to run PhpWiki on MySQL.
From then on the features and contributions started to grow, including a templating system, color diffs, rewrites of the rendering engine and much more.
Arno was interested in running a wiki for the game Go.
Jeff Dairiki was the next major contributor, and soon headed the project for the next few years, then Reini Urban up to 1.4, and then Marc-Etienne Vargenau since 1.5.
Supports Wikicreole 1.0 including additions and MediaWiki markup syntax since Version 1.4.0. With Version 1.5.0 PHP 4 was deprecated.

</doc>
<doc id="22926" url="https://en.wikipedia.org/wiki?curid=22926" title="Poetry">
Poetry

Poetry is a form of literature that uses aesthetic and rhythmic qualities of language—such as phonaesthetics, sound symbolism, and metre—to evoke meanings in addition to, or in place of, the prosaïc ostensible meaning.
Poetry has a long history, dating back to the Sumerian "Epic of Gilgamesh". Early poems evolved from folk songs such as the Chinese "Shijing", or from a need to retell oral epics, as with the Sanskrit "Vedas", Zoroastrian "Gathas", and the Homeric epics, the "Iliad" and the "Odyssey". Ancient attempts to define poetry, such as Aristotle's "Poetics", focused on the uses of speech in rhetoric, drama, song and comedy. Later attempts concentrated on features such as repetition, verse form and rhyme, and emphasized the aesthetics which distinguish poetry from more objectively informative, prosaïc forms of writing. From the mid-20th century, poetry has sometimes been more generally regarded as a fundamental creative act employing language.
Poetry uses forms and conventions to suggest differential interpretation to words, or to evoke emotive responses. Devices such as assonance, alliteration, onomatopoeia and rhythm are sometimes used to achieve musical or incantatory effects. The use of ambiguity, symbolism, irony and other stylistic elements of poetic diction often leaves a poem open to multiple interpretations. Similarly figures of speech such as metaphor, simile and metonymy create a resonance between otherwise disparate images—a layering of meanings, forming connections previously not perceived. Kindred forms of resonance may exist, between individual verses, in their patterns of rhyme or rhythm.
Some poetry types are specific to particular cultures and genres and respond to characteristics of the language in which the poet writes. Readers accustomed to identifying poetry with Dante, Goethe, Mickiewicz and Rumi may think of it as written in lines based on rhyme and regular meter; there are, however, traditions, such as Biblical poetry, that use other means to create rhythm and euphony. Much modern poetry reflects a critique of poetic tradition, playing with and testing, among other things, the principle of euphony itself, sometimes altogether forgoing rhyme or set rhythm. In today's increasingly globalized world, poets often adapt forms, styles and techniques from diverse cultures and languages.
History.
Poetry as an art form may predate literacy. Epic poetry, from the Indian "Vedas" (1700–1200 BC) and Zoroaster's "Gathas" to the "Odyssey" (800–675 BC), appears to have been composed in poetic form to aid memorization and oral transmission, in prehistoric and ancient societies. Other forms of poetry developed directly from folk songs. The earliest entries in the ancient compilation "Shijing", were initially lyrics, preceding later entries intended to be read.
The oldest surviving epic poem is the "Epic of Gilgamesh", from the 3rd millennium BC in Sumer (in Mesopotamia, now Iraq), which was written in cuneiform script on clay tablets and, later, papyrus. The oldest love poem is only slightly younger sitting among Sumerian documents such as a court verdict from 2030 B.C. Other ancient epic poetry includes the Greek epics "Iliad" and "Odyssey", the Old Iranian books the "Gathic Avesta" and "Yasna", the Roman national epic, Virgil's "Aeneid", and the Indian epics "Ramayana" and "Mahabharata".
The efforts of ancient thinkers to determine what makes poetry distinctive as a form, and what distinguishes good poetry from bad, resulted in "poetics"—the study of the aesthetics of poetry. Some ancient poetic traditions; such as, contextually, Classical Chinese poetry in the case of the "Shijing" ("Classic of Poetry"), which records the development of poetic canons with ritual and aesthetic importance. More recently, thinkers have struggled to find a definition that could encompass formal differences as great as those between Chaucer's "Canterbury Tales" and Matsuo Bashō's "Oku no Hosomichi", as well as differences in context spanning Tanakh religious poetry, love poetry, and rap.
Western traditions.
Classical thinkers employed classification as a way to define and assess the quality of poetry. Notably, the existing fragments of Aristotle's "Poetics" describe three genres of poetry—the epic, the comic, and the tragic—and develop rules to distinguish the highest-quality poetry in each genre, based on the underlying purposes of the genre. Later aestheticians identified three major genres: epic poetry, lyric poetry, and dramatic poetry, treating comedy and tragedy as subgenres of dramatic poetry.
Aristotle's work was influential throughout the Middle East during the Islamic Golden Age, as well as in Europe during the Renaissance. Later poets and aestheticians often distinguished poetry from, and defined it in opposition to prose, which was generally understood as writing with a proclivity to logical explication and a linear narrative structure.
This does not imply that poetry is illogical or lacks narration, but rather that poetry is an attempt to render the beautiful or sublime without the burden of engaging the logical or narrative thought process. English Romantic poet John Keats termed this escape from logic "Negative Capability". This "romantic" approach views form as a key element of successful poetry because form is abstract and distinct from the underlying notional logic. This approach remained influential into the 20th century.
During this period, there was also substantially more interaction among the various poetic traditions, in part due to the spread of European colonialism and the attendant rise in global trade. In addition to a boom in translation, during the Romantic period numerous ancient works were rediscovered.
20th-century and 21st-century disputes.
Some 20th-century literary theorists, relying less on the opposition of prose and poetry, focused on the poet as simply one who creates using language, and poetry as what the poet creates. The underlying concept of the poet as creator is not uncommon, and some modernist poets essentially do not distinguish between the creation of a poem with words, and creative acts in other media. Yet other modernists challenge the very attempt to define poetry as misguided.
The rejection of traditional forms and structures for poetry that began in the first half of the 20th century coincided with a questioning of the purpose and meaning of traditional definitions of poetry and of distinctions between poetry and prose, particularly given examples of poetic prose and prosaïc poetry. Numerous modernist poets have written in non-traditional forms or in what traditionally would have been considered prose, although their writing was generally infused with poetic diction and often with rhythm and tone established by non-metrical means. While there was a substantial formalist reaction within the modernist schools to the breakdown of structure, this reaction focused as much on the development of new formal structures and syntheses as on the revival of older forms and structures.
Recently, postmodernism has come to convey more completely prose and poetry as distinct entities, and also among genres of poetry, as having meaning only as cultural artifacts. Postmodernism goes beyond modernism's emphasis on the creative role of the poet, to emphasize the role of the reader of a text (Hermeneutics), and to highlight the complex cultural web within which a poem is read. Today, throughout the world, poetry often incorporates poetic form and diction from other cultures and from the past, further confounding attempts at definition and classification that were once sensible within a tradition such as the Western canon.
The early 21st century poetic tradition appears to continue to strongly orient itself to earlier precursor poetic traditions such as those initiated by Whitman, Emerson, and Wordsworth. The literary critic Geoffrey Hartman has used the phrase "the anxiety of demand" to describe contemporary response to older poetic traditions as "being fearful that the fact no longer has a form", building on a trope introduced by Emerson. Emerson had maintained that in the debate concerning poetic structure where either "form" or "fact" could predominate, that one need simply "Ask the fact for the form." This has been challenged at various levels by other literary scholars such as Bloom who has stated in summary form concerning the early 21st century that: "The generation of poets who stand together now, mature and ready to write the major American verse of the twenty-first century, may yet be seen as what Stevens called 'a great shadow's last embellishment,' the shadow being Emerson's."
Elements.
Prosody.
Prosody is the study of the meter, rhythm, and intonation of a poem. Rhythm and meter are different, although closely related. Meter is the definitive pattern established for a verse (such as iambic pentameter), while rhythm is the actual sound that results from a line of poetry. Prosody also may be used more specifically to refer to the scanning of poetic lines to show meter.
Rhythm.
The methods for creating poetic rhythm vary across languages and between poetic traditions. Languages are often described as having timing set primarily by accents, syllables, or moras, depending on how rhythm is established, though a language can be influenced by multiple approaches. Japanese is a mora-timed language. Syllable-timed languages include Latin, Catalan, French, Leonese, Galician and Spanish. English, Russian and, generally, German are stress-timed languages. Varying intonation also affects how rhythm is perceived. Languages can rely on either pitch, such as in Vedic Sanskrit or Ancient Greek, or tone. Tonal languages include Chinese, Vietnamese and most Subsaharan languages.
Metrical rhythm generally involves precise arrangements of stresses or syllables into repeated patterns called feet within a line. In Modern English verse the pattern of stresses primarily differentiate feet, so rhythm based on meter in Modern English is most often founded on the pattern of stressed and unstressed syllables (alone or elided). In the classical languages, on the other hand, while the metrical units are similar, vowel length rather than stresses define the meter. Old English poetry used a metrical pattern involving varied numbers of syllables but a fixed number of strong stresses in each line.
The chief device of ancient Hebrew Biblical poetry, including many of the psalms, was "parallelism", a rhetorical structure in which successive lines reflected each other in grammatical structure, sound structure, notional content, or all three. Parallelism lent itself to antiphonal or call-and-response performance, which could also be reinforced by intonation. Thus, Biblical poetry relies much less on metrical feet to create rhythm, but instead creates rhythm based on much larger sound units of lines, phrases and sentences. Some classical poetry forms, such as Venpa of the Tamil language, had rigid grammars (to the point that they could be expressed as a context-free grammar) which ensured a rhythm. In Chinese poetry, tones as well as stresses create rhythm. Classical Chinese poetics identifies four tones: the level tone, rising tone, departing tone, and entering tone.
The formal patterns of meter used in Modern English verse to create rhythm no longer dominate contemporary English poetry. In the case of free verse, rhythm is often organized based on looser units of cadence rather than a regular meter. Robinson Jeffers, Marianne Moore, and William Carlos Williams are three notable poets who reject the idea that regular accentual meter is critical to English poetry. Jeffers experimented with sprung rhythm as an alternative to accentual rhythm.
Meter.
In the Western poetic tradition, meters are customarily grouped according to a characteristic metrical foot and the number of feet per line. The number of metrical feet in a line are described using Greek terminology: tetrameter for four feet and hexameter for six feet, for example. Thus, "iambic pentameter" is a meter comprising five feet per line, in which the predominant kind of foot is the "iamb". This metric system originated in ancient Greek poetry, and was used by poets such as Pindar and Sappho, and by the great tragedians of Athens. Similarly, "dactylic hexameter", comprises six feet per line, of which the dominant kind of foot is the "dactyl". Dactylic hexameter was the traditional meter of Greek epic poetry, the earliest extant examples of which are the works of Homer and Hesiod. Iambic pentameter and dactylic hexameter were later used by a number of poets, including William Shakespeare and Henry Wadsworth Longfellow, respectively. The most common metrical feet in English are:
There are a wide range of names for other types of feet, right up to a choriamb, a four syllable metric foot with a stressed syllable followed by two unstressed syllables and closing with a stressed syllable. The choriamb is derived from some ancient Greek and Latin poetry. Languages which utilize vowel length or intonation rather than or in addition to syllabic accents in determining meter, such as Ottoman Turkish or Vedic, often have concepts similar to the iamb and dactyl to describe common combinations of long and short sounds.
Each of these types of feet has a certain "feel," whether alone or in combination with other feet. The iamb, for example, is the most natural form of rhythm in the English language, and generally produces a subtle but stable verse. Scanning meter can often show the basic or fundamental pattern underlying a verse, but does not show the varying degrees of stress, as well as the differing pitches and lengths of syllables.
There is debate over how useful a multiplicity of different "feet" is in describing meter. For example, Robert Pinsky has argued that while dactyls are important in classical verse, English dactylic verse uses dactyls very irregularly and can be better described based on patterns of iambs and anapests, feet which he considers natural to the language. Actual rhythm is significantly more complex than the basic scanned meter described above, and many scholars have sought to develop systems that would scan such complexity. Vladimir Nabokov noted that overlaid on top of the regular pattern of stressed and unstressed syllables in a line of verse was a separate pattern of accents resulting from the natural pitch of the spoken words, and suggested that the term "scud" be used to distinguish an unaccented stress from an accented stress.
Metrical patterns.
Different traditions and genres of poetry tend to use different meters, ranging from the Shakespearean iambic pentameter and the Homeric dactylic hexameter to the anapestic tetrameter used in many nursery rhymes. However, a number of variations to the established meter are common, both to provide emphasis or attention to a given foot or line and to avoid boring repetition. For example, the stress in a foot may be inverted, a caesura (or pause) may be added (sometimes in place of a foot or stress), or the final foot in a line may be given a feminine ending to soften it or be replaced by a spondee to emphasize it and create a hard stop. Some patterns (such as iambic pentameter) tend to be fairly regular, while other patterns, such as dactylic hexameter, tend to be highly irregular. Regularity can vary between language. In addition, different patterns often develop distinctively in different languages, so that, for example, iambic tetrameter in Russian will generally reflect a regularity in the use of accents to reinforce the meter, which does not occur, or occurs to a much lesser extent, in English.
Some common metrical patterns, with notable examples of poets and poems who use them, include:
Rhyme, alliteration, assonance.
Rhyme, alliteration, assonance and consonance are ways of creating repetitive patterns of sound. They may be used as an independent structural element in a poem, to reinforce rhythmic patterns, or as an ornamental element. They can also carry a meaning separate from the repetitive sound patterns created. For example, Chaucer used heavy alliteration to mock Old English verse and to paint a character as archaic.
Rhyme consists of identical ("hard-rhyme") or similar ("soft-rhyme") sounds placed at the ends of lines or at predictable locations within lines ("internal rhyme"). Languages vary in the richness of their rhyming structures; Italian, for example, has a rich rhyming structure permitting maintenance of a limited set of rhymes throughout a lengthy poem. The richness results from word endings that follow regular forms. English, with its irregular word endings adopted from other languages, is less rich in rhyme. The degree of richness of a language's rhyming structures plays a substantial role in determining what poetic forms are commonly used in that language.
Alliteration is the repetition of letters or letter-sounds at the beginning of two or more words immediately succeeding each other, or at short intervals; or the recurrence of the same letter in accented parts of words. Alliteration and assonance played a key role in structuring early Germanic, Norse and Old English forms of poetry. The alliterative patterns of early Germanic poetry interweave meter and alliteration as a key part of their structure, so that the metrical pattern determines when the listener expects instances of alliteration to occur. This can be compared to an ornamental use of alliteration in most Modern European poetry, where alliterative patterns are not formal or carried through full stanzas. Alliteration is particularly useful in languages with less rich rhyming structures. 
Assonance, where the use of similar vowel sounds within a word rather than similar sounds at the beginning or end of a word, was widely used in skaldic poetry, but goes back to the Homeric epic. Because verbs carry much of the pitch in the English language, assonance can loosely evoke the tonal elements of Chinese poetry and so is useful in translating Chinese poetry. Consonance occurs where a consonant sound is repeated throughout a sentence without putting the sound only at the front of a word. Consonance provokes a more subtle effect than alliteration and so is less useful as a structural element.
Rhyming schemes.
In many languages, including modern European languages and Arabic, poets use rhyme in set patterns as a structural element for specific poetic forms, such as ballads, sonnets and rhyming couplets. However, the use of structural rhyme is not universal even within the European tradition. Much modern poetry avoids traditional rhyme schemes. Classical Greek and Latin poetry did not use rhyme. Rhyme entered European poetry in the High Middle Ages, in part under the influence of the Arabic language in Al Andalus (modern Spain). Arabic language poets used rhyme extensively from the first development of literary Arabic in the sixth century, as in their long, rhyming qasidas. Some rhyming schemes have become associated with a specific language, culture or period, while other rhyming schemes have achieved use across languages, cultures or time periods. Some forms of poetry carry a consistent and well-defined rhyming scheme, such as the chant royal or the rubaiyat, while other poetic forms have variable rhyme schemes.
Most rhyme schemes are described using letters that correspond to sets of rhymes, so if the first, second and fourth lines of a quatrain rhyme with each other and the third line does not rhyme, the quatrain is said to have an "a-a-b-a" rhyme scheme. This rhyme scheme is the one used, for example, in the rubaiyat form. Similarly, an "a-b-b-a" quatrain (what is known as "enclosed rhyme") is used in such forms as the Petrarchan sonnet. Some types of more complicated rhyming schemes have developed names of their own, separate from the "a-b-c" convention, such as the ottava rima and terza rima. The types and use of differing rhyming schemes is discussed further in the main article.
Form.
Poetic form is more flexible in modernist and post-modernist poetry, and continues to be less structured than in previous literary eras. Many modern poets eschew recognisable structures or forms, and write in free verse. But poetry remains distinguished from prose by its form; some regard for basic formal structures of poetry will be found in even the best free verse, however much such structures may appear to have been ignored. Similarly, in the best poetry written in classic styles there will be departures from strict form for emphasis or effect.
Among major structural elements used in poetry are the line, the stanza or verse paragraph, and larger combinations of stanzas or lines such as cantos. Also sometimes used are broader visual presentations of words and calligraphy. These basic units of poetic form are often combined into larger structures, called "poetic forms" or poetic modes (see following section), as in the sonnet or haiku.
Lines and stanzas.
Poetry is often separated into lines on a page. These lines may be based on the number of metrical feet, or may emphasize a rhyming pattern at the ends of lines. Lines may serve other functions, particularly where the poem is not written in a formal metrical pattern. Lines can separate, compare or contrast thoughts expressed in different units, or can highlight a change in tone. See the article on line breaks for information about the division between lines.
Lines of poems are often organized into stanzas, which are denominated by the number of lines included. Thus a collection of two lines is a couplet (or distich), three lines a triplet (or tercet), four lines a quatrain, and so on. These lines may or may not relate to each other by rhyme or rhythm. For example, a couplet may be two lines with identical meters which rhyme or two lines held together by a common meter alone.
Other poems may be organized into verse paragraphs, in which regular rhymes with established rhythms are not used, but the poetic tone is instead established by a collection of rhythms, alliterations, and rhymes established in paragraph form. Many medieval poems were written in verse paragraphs, even where regular rhymes and rhythms were used.
In many forms of poetry, stanzas are interlocking, so that the rhyming scheme or other structural elements of one stanza determine those of succeeding stanzas. Examples of such interlocking stanzas include, for example, the ghazal and the villanelle, where a refrain (or, in the case of the villanelle, refrains) is established in the first stanza which then repeats in subsequent stanzas. Related to the use of interlocking stanzas is their use to separate thematic parts of a poem. For example, the strophe, antistrophe and epode of the ode form are often separated into one or more stanzas.
In some cases, particularly lengthier formal poetry such as some forms of epic poetry, stanzas themselves are constructed according to strict rules and then combined. In skaldic poetry, the dróttkvætt stanza had eight lines, each having three "lifts" produced with alliteration or assonance. In addition to two or three alliterations, the odd numbered lines had partial rhyme of consonants with dissimilar vowels, not necessarily at the beginning of the word; the even lines contained internal rhyme in set syllables (not necessarily at the end of the word). Each half-line had exactly six syllables, and each line ended in a trochee. The arrangement of dróttkvætts followed far less rigid rules than the construction of the individual dróttkvætts.
Visual presentation.
Even before the advent of printing, the visual appearance of poetry often added meaning or depth. Acrostic poems conveyed meanings in the initial letters of lines or in letters at other specific places in a poem. In Arabic, Hebrew and Chinese poetry, the visual presentation of finely calligraphed poems has played an important part in the overall effect of many poems.
With the advent of printing, poets gained greater control over the mass-produced visual presentations of their work. Visual elements have become an important part of the poet's toolbox, and many poets have sought to use visual presentation for a wide range of purposes. Some Modernist poets have made the placement of individual lines or groups of lines on the page an integral part of the poem's composition. At times, this complements the poem's rhythm through visual caesuras of various lengths, or creates juxtapositions so as to accentuate meaning, ambiguity or irony, or simply to create an aesthetically pleasing form. In its most extreme form, this can lead to concrete poetry or asemic writing.
Diction.
Poetic diction treats the manner in which language is used, and refers not only to the sound but also to the underlying meaning and its interaction with sound and form. Many languages and poetic forms have very specific poetic dictions, to the point where distinct grammars and dialects are used specifically for poetry. Registers in poetry can range from strict employment of ordinary speech patterns, as favoured in much late-20th-century prosody, through to highly ornate uses of language, as in medieval and Renaissance poetry.
Poetic diction can include rhetorical devices such as simile and metaphor, as well as tones of voice, such as irony. Aristotle wrote in the "Poetics" that "the greatest thing by far is to be a master of metaphor." Since the rise of Modernism, some poets have opted for a poetic diction that de-emphasizes rhetorical devices, attempting instead the direct presentation of things and experiences and the exploration of tone. On the other hand, Surrealists have pushed rhetorical devices to their limits, making frequent use of catachresis.
Allegorical stories are central to the poetic diction of many cultures, and were prominent in the West during classical times, the late Middle Ages and the Renaissance. "Aesop's Fables", repeatedly rendered in both verse and prose since first being recorded about 500 B.C., are perhaps the richest single source of allegorical poetry through the ages. Other notables examples include the "Roman de la Rose", a 13th-century French poem, William Langland's "Piers Ploughman" in the 14th century, and Jean de la Fontaine's "Fables" (influenced by Aesop's) in the 17th century. Rather than being fully allegorical, however, a poem may contain symbols or allusions that deepen the meaning or effect of its words without constructing a full allegory.
Another element of poetic diction can be the use of vivid imagery for effect. The juxtaposition of unexpected or impossible images is, for example, a particularly strong element in surrealist poetry and haiku. Vivid images are often endowed with symbolism or metaphor. Many poetic dictions use repetitive phrases for effect, either a short phrase (such as Homer's "rosy-fingered dawn" or "the wine-dark sea") or a longer refrain. Such repetition can add a sombre tone to a poem, or can be laced with irony as the context of the words changes.
Forms.
Specific poetic forms have been developed by many cultures. In more developed, closed or "received" poetic forms, the rhyming scheme, meter and other elements of a poem are based on sets of rules, ranging from the relatively loose rules that govern the construction of an elegy to the highly formalized structure of the ghazal or villanelle. Described below are some common forms of poetry widely used across a number of languages. Additional forms of poetry may be found in the discussions of poetry of particular cultures or periods and in the glossary.
Sonnet.
Among the most common forms of poetry through the ages is the sonnet, which by the 13th century was a poem of fourteen lines following a set rhyme scheme and logical structure. By the 14th century, the form further crystallized under the pen of Petrarch, whose sonnets were later translated in the 16th century by Sir Thomas Wyatt, who is credited with introducing the sonnet form into English literature. A sonnet's first four lines typically introduce the topic, the second elaborates and the third posits a problem - the couplet usually, but not always, includes a twist, or an afterthought. A sonnet usually follows an a-b-a-b-c-d-c-d-e-f-e-f-gg rhyme pattern. The sonnet's conventions have changed over its history, and so there are several different sonnet forms. Traditionally, in sonnets English poets use iambic pentameter, the Spenserian and Shakespearean sonnets being especially notable. In the Romance languages, the hendecasyllable and Alexandrine are the most widely used meters, though the Petrarchan sonnet has been used in Italy since the 14th century.
Sonnets are particularly associated with love poetry, and often use a poetic diction heavily based on vivid imagery, but the twists and turns associated with the move from octave to sestet and to final couplet make them a useful and dynamic form for many subjects. Shakespeare's sonnets are among the most famous in English poetry, with 20 being included in the "Oxford Book of English Verse".
Shi.
"Shi" () Is the main type of Classical Chinese poetry. Within this form of poetry the most important variations are "folk song" styled verse ("yuefu"), "old style" verse ("gushi"), "modern style" verse ("jintishi"). In all cases, rhyming is obligatory. The Yuefu is a folk ballad or a poem written in the folk ballad style, and the number of lines and the length of the lines could be irregular. For the other variations of "shi" poetry, generally either a four line (quatrain, or "jueju") or else an eight line poem is normal; either way with the even numbered lines rhyming. The line length is scanned by according number of characters (according to the convention that one character equals one syllable), and are predominantly either five or seven characters long, with a caesura before the final three syllables. The lines are generally end-stopped, considered as a series of couplets, and exhibit verbal parallelism as a key poetic device. The "old style" verse ("gushi") is less formally strict than the "jintishi", or regulated verse, which, despite the name "new style" verse actually had its theoretical basis laid as far back to Shen Yue, in the 5th or 6th century, although not considered to have reached its full development until the time of Chen Zi'ang (661-702) A good example of a poet known for his "gushi" poems is Li Bai. Among its other rules, the jintishi rules regulate the tonal variations within a poem, including the use of set patterns of the four tones of Middle Chinese The basic form of jintishi (lushi) has eight lines in four couplets, with parallelism between the lines in the second and third couplets. The couplets with parallel lines contain contrasting content but an identical grammatical relationship between words. Jintishi often have a rich poetic diction, full of allusion, and can have a wide range of subject, including history and politics. One of the masters of the form was Du Fu, who wrote during the Tang Dynasty (8th century).
Villanelle.
The villanelle is a nineteen-line poem made up of five triplets with a closing quatrain; the poem is characterized by having two refrains, initially used in the first and third lines of the first stanza, and then alternately used at the close of each subsequent stanza until the final quatrain, which is concluded by the two refrains. The remaining lines of the poem have an a-b alternating rhyme. The villanelle has been used regularly in the English language since the late 19th century by such poets as Dylan Thomas, W. H. Auden, and Elizabeth Bishop.
Tanka.
Tanka is a form of unrhymed Japanese poetry, with five sections totalling 31 "onji" (phonological units identical to morae), structured in a 5-7-5-7-7 pattern. There is generally a shift in tone and subject matter between the upper 5-7-5 phrase and the lower 7-7 phrase. Tanka were written as early as the Asuka period by such poets as Kakinomoto no Hitomaro, at a time when Japan was emerging from a period where much of its poetry followed Chinese form. Tanka was originally the shorter form of Japanese formal poetry (which was generally referred to as "waka"), and was used more heavily to explore personal rather than public themes. By the tenth century, tanka had become the dominant form of Japanese poetry, to the point where the originally general term "waka" ("Japanese poetry") came to be used exclusively for tanka. Tanka are still widely written today.
Haiku.
Haiku is a popular form of unrhymed Japanese poetry, which evolved in the 17th century from the "hokku", or opening verse of a renku. Generally written in a single vertical line, the haiku contains three sections totalling 17 "onji", structured in a 5-7-5 pattern. Traditionally, haiku contain a kireji, or cutting word, usually placed at the end of one of the poem's three sections, and a kigo, or season-word. The most famous exponent of the haiku was Matsuo Bashō (1644–1694). An example of his writing:
Ode.
Odes were first developed by poets writing in ancient Greek, such as Pindar, and Latin, such as Horace. Forms of odes appear in many of the cultures that were influenced by the Greeks and Latins. The ode generally has three parts: a strophe, an antistrophe, and an epode. The antistrophes of the ode possess similar metrical structures and, depending on the tradition, similar rhyme structures. In contrast, the epode is written with a different scheme and structure. Odes have a formal poetic diction, and generally deal with a serious subject. The strophe and antistrophe look at the subject from different, often conflicting, perspectives, with the epode moving to a higher level to either view or resolve the underlying issues. Odes are often intended to be recited or sung by two choruses (or individuals), with the first reciting the strophe, the second the antistrophe, and both together the epode. Over time, differing forms for odes have developed with considerable variations in form and structure, but generally showing the original influence of the Pindaric or Horatian ode. One non-Western form which resembles the ode is the qasida in Persian poetry.
Ghazal.
The ghazal (also ghazel, gazel, gazal, or gozol) is a form of poetry common in Arabic, Persian, Turkish, Azerbaijani, Urdu and Bengali poetry. In classic form, the ghazal has from five to fifteen rhyming couplets that share a refrain at the end of the second line. This refrain may be of one or several syllables, and is preceded by a rhyme. Each line has an identical meter. The ghazal often reflects on a theme of unattainable love or divinity.
As with other forms with a long history in many languages, many variations have been developed, including forms with a quasi-musical poetic diction in Urdu. Ghazals have a classical affinity with Sufism, and a number of major Sufi religious works are written in ghazal form. The relatively steady meter and the use of the refrain produce an incantatory effect, which complements Sufi mystical themes well. Among the masters of the form is Rumi, a 13th-century Persian poet.
One of the most famous poet in this type of poetry is Hafez. Themes of his Ghazal is exposing hypocrisy. His life and poems have been the subject of much analysis, commentary and interpretation, influencing post-fourteenth century Persian writing more than any other author. West-östlicher Diwan of Johann Wolfgang von Goethe that is a collection of lyrical poems, has been inspired by the Persian poet Hafez.
Genres.
In addition to specific forms of poems, poetry is often thought of in terms of different genres and subgenres. A poetic genre is generally a tradition or classification of poetry based on the subject matter, style, or other broader literary characteristics. Some commentators view genres as natural forms of literature. Others view the study of genres as the study of how different works relate and refer to other works.
Narrative poetry.
Narrative poetry is a genre of poetry that tells a story. Broadly it subsumes epic poetry, but the term "narrative poetry" is often reserved for smaller works, generally with more appeal to human interest. Narrative poetry may be the oldest type of poetry. Many scholars of Homer have concluded that his "Iliad" and "Odyssey" were composed from compilations of shorter narrative poems that related individual episodes. Much narrative poetry—such as Scottish and English ballads, and Baltic and Slavic heroic poems—is performance poetry with roots in a preliterate oral tradition. It has been speculated that some features that distinguish poetry from prose, such as meter, alliteration and kennings, once served as memory aids for bards who recited traditional tales.
Notable narrative poets have included Ovid, Dante, Juan Ruiz, Chaucer, William Langland, Luís de Camões, Shakespeare, Alexander Pope, Robert Burns, Fernando de Rojas, Adam Mickiewicz, Alexander Pushkin, Edgar Allan Poe and Alfred Tennyson.
Epic poetry.
Epic poetry is a genre of poetry, and a major form of narrative literature. This genre is often defined as lengthy poems concerning events of a heroic or important nature to the culture of the time. It recounts, in a continuous narrative, the life and works of a heroic or mythological person or group of persons. Examples of epic poems are Homer's "Iliad" and "Odyssey", Virgil's Aeneid, the "Nibelungenlied", Luís de Camões' "Os Lusíadas", the "Cantar de Mio Cid", the "Epic of Gilgamesh", the "Mahabharata", Valmiki's "Ramayana", Ferdowsi's "Shahnama", Nizami (or Nezami)'s Khamse (Five Books), and the "Epic of King Gesar". While the composition of epic poetry, and of long poems generally, became less common in the west after the early 20th century, some notable epics have continued to be written. Derek Walcott won a Nobel prize to a great extent on the basis of his epic, "Omeros".
Dramatic poetry.
Dramatic poetry is drama written in verse to be spoken or sung, and appears in varying, sometimes related forms in many cultures. Greek tragedy in verse dates to the 6th century B.C., and may have been an influence on the development of Sanskrit drama, just as Indian drama in turn appears to have influenced the development of the "bianwen" verse dramas in China, forerunners of Chinese Opera. East Asian verse dramas also include Japanese Noh. Examples of dramatic poetry in Persian literature include Nizami's two famous dramatic works, "Layla and Majnun" and "Khosrow and Shirin", Ferdowsi's tragedies such as "Rostam and Sohrab", Rumi's "Masnavi", Gorgani's tragedy of "Vis and Ramin", and Vahshi's tragedy of "Farhad".
Satirical poetry.
Poetry can be a powerful vehicle for satire. The Romans had a strong tradition of satirical poetry, often written for political purposes. A notable example is the Roman poet Juvenal's satires.
The same is true of the English satirical tradition. John Dryden (a Tory), the first Poet Laureate, produced in 1682 "Mac Flecknoe", subtitled "A Satire on the True Blue Protestant Poet, T.S." (a reference to Thomas Shadwell). Another master of 17th-century English satirical poetry was John Wilmot, 2nd Earl of Rochester. Satirical poets outside England include Poland's Ignacy Krasicki, Azerbaijan's Sabir and Portugal's Manuel Maria Barbosa du Bocage.
Light poetry.
Light poetry, or light verse, is poetry that attempts to be humorous. Poems considered "light" are usually brief, and can be on a frivolous or serious subject, and often feature word play, including puns, adventurous rhyme and heavy alliteration. Although a few free verse poets have excelled at light verse outside the formal verse tradition, light verse in English is usually formal. Common forms include the limerick, the clerihew, and the double dactyl.
While light poetry is sometimes condemned as doggerel, or thought of as poetry composed casually, humor often makes a serious point in a subtle or subversive way. Many of the most renowned "serious" poets have also excelled at light verse. Notable writers of light poetry include Lewis Carroll, Ogden Nash, X. J. Kennedy, Willard R. Espy, and Wendy Cope.
Lyric poetry.
Lyric poetry is a genre that, unlike epic and dramatic poetry, does not attempt to tell a story but instead is of a more personal nature. Poems in this genre tend to be shorter, melodic, and contemplative. Rather than depicting characters and actions, it portrays the poet's own feelings, states of mind, and perceptions. Notable poets in this genre include John Donne, Gerard Manley Hopkins, and Antonio Machado.
Elegy.
An elegy is a mournful, melancholy or plaintive poem, especially a lament for the dead or a funeral song. The term "elegy," which originally denoted a type of poetic meter (elegiac meter), commonly describes a poem of mourning. An elegy may also reflect something that seems to the author to be strange or mysterious. The elegy, as a reflection on a death, on a sorrow more generally, or on something mysterious, may be classified as a form of lyric poetry.
Notable practitioners of elegiac poetry have included Propertius, Jorge Manrique, Jan Kochanowski, Chidiock Tichborne, Edmund Spenser, Ben Jonson, John Milton, Thomas Gray, Charlotte Turner Smith, William Cullen Bryant, Percy Bysshe Shelley, Johann Wolfgang von Goethe, Evgeny Baratynsky, Alfred Tennyson, Walt Whitman, Louis Gallet, Antonio Machado, Juan Ramón Jiménez, Giannina Braschi, William Butler Yeats, Rainer Maria Rilke, and Virginia Woolf.
Verse fable.
The fable is an ancient literary genre, often (though not invariably) set in verse. It is a succinct story that features anthropomorphized animals, plants, inanimate objects, or forces of nature that illustrate a moral lesson (a "moral"). Verse fables have used a variety of meter and rhyme patterns.
Notable verse fabulists have included Aesop, Vishnu Sarma, Phaedrus, Marie de France, Robert Henryson, Biernat of Lublin, Jean de La Fontaine, Ignacy Krasicki, Félix María de Samaniego, Tomás de Iriarte, Ivan Krylov and Ambrose Bierce.
Prose poetry.
Prose poetry is a hybrid genre that shows attributes of both prose and poetry. It may be indistinguishable from the micro-story ( the "short short story", "flash fiction"). While some examples of earlier prose strike modern readers as poetic, prose poetry is commonly regarded as having originated in 19th-century France, where its practitioners included Aloysius Bertrand, Charles Baudelaire, Arthur Rimbaud and Stéphane Mallarmé. Since the late 1980s especially, prose poetry has gained increasing popularity, with entire journals, such as "The Prose Poem: An International Journal", "Contemporary Haibun Online," and "Haibun Today" devoted to that genre and its hybrids. Latin American poets of the 20th century who wrote prose poems include Octavio Paz and Giannina Braschi
Speculative poetry.
Speculative poetry, also known as fantastic poetry, (of which weird or macabre poetry is a major subclassification), is a poetic genre which deals thematically with subjects which are 'beyond reality', whether via extrapolation as in science fiction or via weird and horrific themes as in horror fiction. Such poetry appears regularly in modern science fiction and horror fiction magazines. Edgar Allan Poe is sometimes seen as the "father of speculative poetry".

</doc>
<doc id="22934" url="https://en.wikipedia.org/wiki?curid=22934" title="Probability">
Probability

Probability is the measure of the likeliness that an event will occur. Probability is quantified as a number between 0 and 1 (where 0 indicates impossibility and 1 indicates certainty). The higher the probability of an event, the more certain we are that the event will occur. A simple example is the toss of a fair (unbiased) coin. Since the two outcomes are equally probable, the probability of "heads" equals the probability of "tails", so the probability is 1/2 (or 50%) chance of either "heads" or "tails".
These concepts have been given an axiomatic mathematical formalization in probability theory (see probability axioms), which is used widely in such areas of study as mathematics, statistics, finance, gambling, science (in particular physics), artificial intelligence/machine learning, computer science, game theory, and philosophy to, for example, draw inferences about the expected frequency of events. Probability theory is also used to describe the underlying mechanics and regularities of complex systems.
Interpretations.
When dealing with experiments that are random and well-defined in a purely theoretical setting (like tossing a fair coin), probabilities can be numerically described by the number of desired outcomes divided by the total number of all outcomes (tossing a fair coin twice will yield head-head with probability 1/4, because the four outcomes head-head, head-tails, tails-head and tails-tails are equally likely to occur). When it comes to practical application however, there are two major competing categories of probability interpretations, whose adherents possess different views about the fundamental nature of probability:
Etymology.
The word "probability" derives from the Latin "probabilitas", which can also mean "probity", a measure of the authority of a witness in a legal case in Europe, and often correlated with the witness's nobility. In a sense, this differs much from the modern meaning of "probability", which, in contrast, is a measure of the weight of empirical evidence, and is arrived at from inductive reasoning and statistical inference.
History.
The scientific study of probability is a modern development. Gambling shows that there has been an interest in quantifying the ideas of probability for millennia, but exact mathematical descriptions arose much later. There are reasons of course, for the slow development of the mathematics of probability. Whereas games of chance provided the impetus for the mathematical study of probability, are still obscured by the superstitions of gamblers.
According to Richard Jeffrey, "Before the middle of the seventeenth century, the term 'probable' (Latin "probabilis") meant "approvable", and was applied in that sense, univocally, to opinion and to action. A probable action or opinion was one such as sensible people would undertake or hold, in the circumstances." However, in legal contexts especially, 'probable' could also apply to propositions for which there was good evidence.
The sixteenth century Italian polymath Gerolamo Cardano demonstrated the efficacy of defining odds as the ratio of favourable to unfavourable outcomes (which implies that the probability of an event is given by the ratio of favourable outcomes to the total number of possible outcomes).
Aside from the elementary work by Cardano, the doctrine of probabilities dates to the correspondence of Pierre de Fermat and Blaise Pascal (1654). Christiaan Huygens (1657) gave the earliest known scientific treatment of the subject. Jakob Bernoulli's "Ars Conjectandi" (posthumous, 1713) and Abraham de Moivre's "Doctrine of Chances" (1718) treated the subject as a branch of mathematics. See Ian Hacking's "The Emergence of Probability" and James Franklin's "The Science of Conjecture" for histories of the early development of the very concept of mathematical probability.
The theory of errors may be traced back to Roger Cotes's "Opera Miscellanea" (posthumous, 1722), but a memoir prepared by Thomas Simpson in 1755 (printed 1756) first applied the theory to the discussion of errors of observation. The reprint (1757) of this memoir lays down the axioms that positive and negative errors are equally probable, and that certain assignable limits define the range of all errors. Simpson also discusses continuous errors and describes a probability curve.
The first two laws of error that were proposed both originated with Pierre-Simon Laplace. The first law was published in 1774 and stated that the frequency of an error could be expressed as an exponential function of the numerical magnitude of the error, disregarding sign. The second law of error was proposed in 1778 by Laplace and stated that the frequency of the error is an exponential function of the square of the error. The second law of error is called the normal distribution or the Gauss law. "It is difficult historically to attribute that law to Gauss, who in spite of his well-known precocity had probably not made this discovery before he was two years old."
Daniel Bernoulli (1778) introduced the principle of the maximum product of the probabilities of a system of concurrent errors.
Adrien-Marie Legendre (1805) developed the method of least squares, and introduced it in his "Nouvelles méthodes pour la détermination des orbites des comètes" ("New Methods for Determining the Orbits of Comets"). In ignorance of Legendre's contribution, an Irish-American writer, Robert Adrain, editor of "The Analyst" (1808), first deduced the law of facility of error,
where formula_2 is a constant depending on precision of observation, and formula_3 is a scale factor ensuring that the area under the curve equals 1. He gave two proofs, the second being essentially the same as John Herschel's (1850). Gauss gave the first proof that seems to have been known in Europe (the third after Adrain's) in 1809. Further proofs were given by Laplace (1810, 1812), Gauss (1823), James Ivory (1825, 1826), Hagen (1837), Friedrich Bessel (1838), W. F. Donkin (1844, 1856), and Morgan Crofton (1870). Other contributors were Ellis (1844), De Morgan (1864), Glaisher (1872), and Giovanni Schiaparelli (1875). Peters's (1856) formula for "r", the probable error of a single observation, is well known.
In the nineteenth century authors on the general theory included Laplace, Sylvestre Lacroix (1816), Littrow (1833), Adolphe Quetelet (1853), Richard Dedekind (1860), Helmert (1872), Hermann Laurent (1873), Liagre, Didion, and Karl Pearson. Augustus De Morgan and George Boole improved the exposition of the theory.
Andrey Markov introduced the notion of Markov chains (1906), which played an important role in stochastic processes theory and its applications. The modern theory of probability based on the measure theory was developed by Andrey Kolmogorov (1931).
On the geometric side (see integral geometry) contributors to "The Educational Times" were influential (Miller, Crofton, McColl, Wolstenholme, Watson, and Artemas Martin).
Theory.
Like other theories, the theory of probability is a representation of probabilistic concepts in formal terms—that is, in terms that can be considered separately from their meaning. These formal terms are manipulated by the rules of mathematics and logic, and any results are interpreted or translated back into the problem domain.
There have been at least two successful attempts to formalize probability, namely the Kolmogorov formulation and the Cox formulation. In Kolmogorov's formulation (see probability space), sets are interpreted as events and probability itself as a measure on a class of sets. In Cox's theorem, probability is taken as a primitive (that is, not further analyzed) and the emphasis is on constructing a consistent assignment of probability values to propositions. In both cases, the laws of probability are the same, except for technical details.
There are other methods for quantifying uncertainty, such as the Dempster–Shafer theory or possibility theory, but those are essentially different and not compatible with the laws of probability as usually understood.
Applications.
Probability theory is applied in everyday life in risk assessment and in trade on financial markets. Governments apply probabilistic methods in environmental regulation, where it is called pathway analysis.
A good example is the effect of the perceived probability of any widespread Middle East conflict on oil prices—which have ripple effects in the economy as a whole. An assessment by a commodity trader that a war is more likely vs. less likely sends prices up or down, and signals other traders of that opinion. Accordingly, the probabilities are neither assessed independently nor necessarily very rationally. The theory of behavioral finance emerged to describe the effect of such groupthink on pricing, on policy, and on peace and conflict.
In addition to financial assessment, probability can be used to analyze trends in biology (e.g. disease spread) as well as ecology (e.g. biological Punnett squares). As with finance, risk assessment can be used as a statistical tool to calculate the likelihood of undesirable events occurring and can assist with implementing protocols to avoid encountering such circumstances.
The discovery of rigorous methods to assess and combine probability assessments has changed society. It is important for most citizens to understand how probability assessments are made, and how they contribute to decisions.
Another significant application of probability theory in everyday life is reliability. Many consumer products, such as automobiles and consumer electronics, use reliability theory in product design to reduce the probability of failure. Failure probability may influence a manufacturer's decisions on a product's warranty.
The cache language model and other statistical language models that are used in natural language processing are also examples of applications of probability theory.
Mathematical treatment.
Consider an experiment that can produce a number of results. The collection of all results is called the sample space of the experiment. The power set of the sample space is formed by considering all different collections of possible results. For example, rolling a die can produce six possible results. One collection of possible results gives an odd number on the dice. Thus, the subset {1,3,5} is an element of the power set of the sample space of dice rolls. These collections are called "events." In this case, {1,3,5} is the event that the dice falls on some odd number. If the results that actually occur fall in a given event, the event is said to have occurred.
A probability is a way of assigning every event a value between zero and one, with the requirement that the event made up of all possible results (in our example, the event {1,2,3,4,5,6}) is assigned a value of one. To qualify as a probability, the assignment of values must satisfy the requirement that if you look at a collection of mutually exclusive events (events with no common results, e.g., the events {1,6}, {3}, and {2,4} are all mutually exclusive), the probability that at least one of the events will occur is given by the sum of the probabilities of all the individual events.
The probability of an event "A" is written as formula_4, formula_5, or formula_6. This mathematical definition of probability can extend to infinite sample spaces, and even uncountable sample spaces, using the concept of a measure.
The "opposite" or "complement" of an event "A" is the event [not "A"] (that is, the event of "A" not occurring), often denoted as formula_7, or formula_8; its probability is given by . As an example, the chance of not rolling a six on a six-sided die is formula_9. See Complementary event for a more complete treatment.
If two events "A" and "B" occur on a single performance of an experiment, this is called the intersection or joint probability of "A" and "B", denoted as formula_10.
Independent events.
If two events, "A" and "B" are independent then the joint probability is
for example, if two coins are flipped the chance of both being heads is formula_12.
Mutually exclusive events.
If either event "A" or event "B" occurs on a single performance of an experiment this is called the union of the events "A" and "B" denoted as formula_13.
If two events are mutually exclusive then the probability of either occurring is
For example, the chance of rolling a 1 or 2 on a six-sided is formula_15
Not mutually exclusive events.
If the events are not mutually exclusive then
For example, when drawing a single card at random from a regular deck of cards, the chance of getting a heart or a face card (J,Q,K) (or one that is both) is formula_17, because of the 52 cards of a deck 13 are hearts, 12 are face cards, and 3 are both: here the possibilities included in the "3 that are both" are included in each of the "13 hearts" and the "12 face cards" but should only be counted once.
Conditional probability.
"Conditional probability" is the probability of some event "A", given the occurrence of some other event "B".
Conditional probability is written formula_18, and is read "the probability of "A", given "B"". It is defined by
If formula_20 then formula_18 is formally undefined by this expression. However, it is possible to define a conditional probability for some zero-probability events using a σ-algebra of such events (such as those arising from a continuous random variable).
For example, in a bag of 2 red balls and 2 blue balls (4 balls in total), the probability of taking a red ball is formula_22; however, when taking a second ball, the probability of it being either a red ball or a blue ball depends on the ball previously taken, such as, if a red ball was taken, the probability of picking a red ball again would be formula_23 since only 1 red and 2 blue balls would have been remaining.
Inverse probability.
In probability theory and applications, Bayes' rule relates the odds of event formula_24 to event formula_25, before (prior to) and after (posterior to) conditioning on another event formula_26. The odds on formula_24 to event formula_25 is simply the ratio of the probabilities of the two events. When arbitrarily many events formula_29 are of interest, not just two, the rule can be rephrased as posterior is proportional to prior times likelihood, formula_30 where the proportionality symbol means that the left hand side is proportional to (i.e., equals a constant times) the right hand side as formula_29 varies, for fixed or given formula_26 (Lee, 2012; Bertsch McGrayne, 2012). In this form it goes back to Laplace (1774) and to Cournot (1843); see Fienberg (2005). See Inverse probability and Bayes' rule.
Relation to randomness.
In a deterministic universe, based on Newtonian concepts, there would be no probability if all conditions were known (Laplace's demon), (but there are situations in which sensitivity to initial conditions exceeds our ability to measure them, i.e. know them). In the case of a roulette wheel, if the force of the hand and the period of that force are known, the number on which the ball will stop would be a certainty (though as a practical matter, this would likely be true only of a roulette wheel that had not been exactly levelled — as Thomas A. Bass' Newtonian Casino revealed). Of course, this also assumes knowledge of inertia and friction of the wheel, weight, smoothness and roundness of the ball, variations in hand speed during the turning and so forth. A probabilistic description can thus be more useful than Newtonian mechanics for analyzing the pattern of outcomes of repeated rolls of a roulette wheel. Physicists face the same situation in kinetic theory of gases, where the system, while deterministic "in principle", is so complex (with the number of molecules typically the order of magnitude of Avogadro constant 6.02·1023) that only a statistical description of its properties is feasible.
Probability theory is required to describe quantum phenomena. A revolutionary discovery of early 20th century physics was the random character of all physical processes that occur at sub-atomic scales and are governed by the laws of quantum mechanics. The objective wave function evolves deterministically but, according to the Copenhagen interpretation, it deals with probabilities of observing, the outcome being explained by a wave function collapse when an observation is made. However, the loss of determinism for the sake of instrumentalism did not meet with universal approval. Albert Einstein famously in a letter to Max Born: "I am convinced that God does not play dice". Like Einstein, Erwin Schrödinger, who discovered the wave function, believed quantum mechanics is a statistical approximation of an underlying deterministic reality. In modern interpretations, quantum decoherence accounts for subjectively probabilistic behavior.

</doc>
<doc id="22936" url="https://en.wikipedia.org/wiki?curid=22936" title="Poland">
Poland

Poland ( ), officially the Republic of Poland (, ), is a country in Central Europe, bordered by Germany to the west; the Czech Republic and Slovakia to the south; Ukraine and Belarus to the east; and the Baltic Sea, Kaliningrad Oblast (a Russian exclave) and Lithuania to the north. The total area of Poland is , making it the 71st largest country in the world and the 9th largest in Europe. With a population of over 38.5 million people, Poland is the 34th most populous country in the world, the 8th most populous country in Europe and the sixth most populous member of the European Union, as well as the most populous post-communist member of the European Union. Poland is a unitary state divided into 16 administrative subdivisions.
The establishment of a Polish state can be traced back to 966, when Mieszko I, ruler of a territory roughly coextensive with that of present-day Poland, converted to Christianity. The Kingdom of Poland was founded in 1025, and in 1569 it cemented a longstanding political association with the Grand Duchy of Lithuania by signing the Union of Lublin. This union formed the Polish–Lithuanian Commonwealth, one of the largest and most populous countries of 16th and 17th-century Europe. The Commonwealth ceased to exist in the years 1772–1795, when its territory was partitioned among Prussia, the Russian Empire, and Austria. Poland regained its independence (as the Second Polish Republic) at the end of World War I, in 1918.
In September 1939, World War II started with the invasions of Poland by Nazi Germany and the Soviet Union (as part of the Molotov–Ribbentrop Pact). More than six million Polish citizens died in the war. In 1944, a Soviet-backed Polish provisional government was formed which, after a falsified referendum in 1947 took control of the country and Poland became a satellite state of the Soviet Union, as People's Republic of Poland. During the Revolutions of 1989 Poland's Communist government was overthrown and Poland adopted a new constitution establishing itself as a democracy.
Despite the vast casualties and destruction the country experienced during World War II, Poland managed to preserve much of its cultural wealth. There are 14 heritage sites inscribed on the UNESCO World Heritage and 54 Historical Monuments and many objects of cultural heritage in Poland. Since the end of the communist period, Poland has achieved a "very high" ranking in terms of human development, as well as gradually improving economic freedom. Poland is the sixth largest economy in the European Union and among the fastest rising economic states in the world. The country is the sole member nation of the European Union to have escaped a decline in GDP and in recent years was able to create probably the most varied GDP growth in its history. Furthermore, according to the Global Peace Index for 2014, Poland is one of the safest countries in the world to live in.
Etymology.
The source of the name Poland and the ethnonyms for the Poles include endonyms (the way Polish people refer to themselves and their country) and exonyms (the way other peoples refer to the Poles and their country). Endonyms and most exonyms for Poles and Poland derive from the name of the West Slavic tribe of the Polans ("Polanie").
The origin of the name "Polanie" itself is uncertain. It may derive from such Polish words as "pole" (field). The early tribal inhabitants denominated it from the nature of the country. Lowlands and low hills predominate throughout the vast region from the Baltic shores to the foothills of the Carpathian Mountains. "Between the Alps, Hungary, and the ocean, lies Poland, which is called in their native tongue Campania" () is the description by Gervase of Tilbury in his "Otia imperialia" ("Recreation for the Emperor") of 1211. In some languages, the exonyms for Poland derive from another tribal name, Lechites ("Lechici").
History.
Prehistory and protohistory of Poland.
Historians have postulated that throughout Late Antiquity, many distinct ethnic groups populated the regions of what is now Poland. The ethnicity and linguistic affiliation of these groups have been hotly debated; the time and route of the original settlement of Slavic peoples in these regions lacks written records and can only be defined as fragmented.
The most famous archaeological find from the prehistory and protohistory of Poland is the Biskupin fortified settlement (now reconstructed as an open-air museum), dating from the Lusatian culture of the early Iron Age, around 700 BC. The Slavic groups who would form Poland migrated to these areas in the second half of the 5th century AD. Up until the creation of Mieszko's state and his subsequent conversion to Christianity in 966 AD, the main religion of Slavic tribes that inhabited the geographical area of present-day Poland was Slavic paganism. After the Baptism of Poland the new religion accepted by the Polish ruler was Catholicism. The transition to Christianity was not a smooth and instantaneous process for the rest of the population as evident from the pagan reaction of the 1030s.
Piast dynasty.
Poland began to form into a recognizable unitary and territorial entity around the middle of the 10th century under the Piast dynasty. Poland's first historically documented ruler, Mieszko I, accepted Baptism in 966 and adopted Christianity as the new official religion of his subjects. The bulk of the population converted in the course of the next few centuries. In 1000, Boleslaw the Brave, continuing the policy of his father Mieszko, held a Congress of Gniezno and created the metropolis of Gniezno and the dioceses of Kraków, Kołobrzeg, and Wrocław. The pagan unrest however, led to the transfer of the capital to Kraków in 1038 by Casimir I the Restorer.
Prince Bolesław III Wrymouth defeated the King of Germany Henry V in the 1109 Battle of Hundsfeld, writes Gallus Anonymus in his 1118 chronicle. In 1138, Poland fragmented into several smaller duchies when Bolesław divided his lands among his sons. In 1226, Konrad I of Masovia, one of the regional Piast dukes, invited the Teutonic Knights to help him fight the Baltic Prussian pagans; a decision which led to centuries of warfare with the Knights. Elements of what is called now human rights may be found in early times of the Polish state. The Statute of Kalisz or the General Charter of Jewish Liberties (issued in 1264) introduced numerous right for the Jews in Poland, leading to a nearly autonomous "nation within a nation".<ref name="Dembkowski/Lublin"></ref>
In the middle of 13th-century the Silesian branch of the Piast dynasty (Henry I the Bearded and Henry II the Pious, ruled 1238–1241) almost succeeded in uniting the Polish lands, but the Mongols devastated the country and won the Battle of Legnica where Duke Henry II the Pious died (1241). In 1320, after a number of earlier unsuccessful attempts by regional rulers at uniting the Polish dukedoms, Władysław I consolidated his power, took the throne and became the first king of a reunified Poland. His son, Casimir III (reigned 1333–1370), has a reputation as one of the greatest Polish kings, and gained wide recognition for improving the country's infrastructure. Casimir also extended royal protection to Jews, and encouraged their immigration to Poland.
The education of Polish society was a goal of rulers as early as the 12th century, and Polish nobility became one of the most educated groups in Europe. The library catalogue of the Cathedral Chapter of Kraków dating back to 1110 shows that in the early 12th-century Polish intellectuals had access to European literature.
Casimir III realized that the nation needed a class of educated people, especially lawyers, who could codify the country's laws and administer the courts and offices. His efforts to found an institution of higher learning in Poland were finally rewarded when Pope Urban V granted him permission to open the University of Kraków.
The Golden Liberty of the nobles began to develop under Casimir's rule, when in return for their military support, the king made serious concessions to the aristocrats, finally establishing their status as superior to that of the townsmen, and aiding their rise to power. When Casimir died in 1370 he left no legitimate male heir and, considering his other male descendants either too young or unsuitable, was laid to rest as the last of the nation's Piast rulers.
Poland also became a magnet for migrants. Germans settled in the towns; the Jewish community began to settle and flourish in Poland during this era (see History of the Jews in Poland); the same applies in smaller number to Armenians. The Black Death which afflicted most parts of Europe from 1347 to 1351 affected Poland less severely.
Jagiellon dynasty.
The rule of the Jagiellon dynasty spanned the late Middle Ages and early Modern Era of Polish history. Beginning with the Lithuanian Grand Duke Jogaila (Władysław II Jagiełło), the Jagiellon dynasty (1386–1572) formed the Polish–Lithuanian union. The partnership brought vast Lithuania-controlled Rus' areas into Poland's sphere of influence and proved beneficial for the Poles and Lithuanians, who coexisted and cooperated in one of the largest political entities in Europe for the next four centuries. In the Baltic Sea region Poland's struggle with the Teutonic Knights continued and included the Battle of Grunwald (1410), where a Polish-Lithuanian army inflicted a decisive defeat on the Teutonic Knights, both countries' main adversary, allowing Poland's and Lithuania's territorial expansion into the far north region of Livonia. In 1466, after the Thirteen Years' War, King Casimir IV Jagiellon gave royal consent to the milestone Peace of Thorn, which created the future Duchy of Prussia, a Polish vassal. The Jagiellons at one point also established dynastic control over the kingdoms of Bohemia (1471 onwards) and Hungary. In the south Poland confronted the Ottoman Empire and the Crimean Tatars (by whom they were attacked on 75 separate occasions between 1474 and 1569), and in the east helped Lithuania fight the Grand Duchy of Moscow. Some historians estimate that Crimean Tatar slave-raiding cost Poland one million of its population from 1494 to 1694.
Poland was developing as a feudal state, with a predominantly agricultural economy and an increasingly powerful landed nobility. The "Nihil novi" act adopted by the Polish Sejm (parliament) in 1505, transferred most of the legislative power from the monarch to the Sejm, an event which marked the beginning of the period known as "Golden Liberty", when the state was ruled by the "free and equal" Polish nobility. Protestant Reformation movements made deep inroads into Polish Christianity, which resulted in the establishment of policies promoting religious tolerance, unique in Europe at that time. This tolerance allowed the country to avoid most the religious turmoil that spread over Europe during the late Middle Ages. The European Renaissance evoked in late Jagiellon Poland (kings Sigismund I the Old and Sigismund II Augustus) a sense of urgency in the need to promote a cultural awakening, and during this period Polish culture and the nation's economy flourished. In 1543 the Pole, Nicolaus Copernicus, an astronomer from Toruń, published his epochal works, "De revolutionibus orbium coelestium" ("On the Revolutions of the Celestial Spheres"), and thus became the first proponent of a predictive mathematical model confirming heliocentric theory which became the accepted basic model for the practice of modern astronomy. Another major figure associated with the era is classicist poet Jan Kochanowski.
Polish–Lithuanian Commonwealth.
The 1569 Union of Lublin established the Polish–Lithuanian Commonwealth, a more closely unified federal state with an elective monarchy, but which was governed largely by the nobility, through a system of local assemblies with a central parliament. The Warsaw Confederation (1573) confirmed the religious freedom of all residents of Poland, which was extremely important for the stability of the multiethnic Polish society of the time. Serfdom was banned in 1588. The establishment of the Commonwealth coincided with a period of stability and prosperity in Poland, with the union thereafter becoming a European power and a major cultural entity, occupying approximately one million square kilometers of Central and Eastern Europe, as well as an agent for the dissemination of 'Western culture' through Polonization in modern-day Ukraine, Belarus and Western Russia. Poland suffered from a number of dynastic crises during the reigns of the Vasa kings Sigismund III and Władysław IV and found itself engaged in major conflicts with Russia, Sweden and the Ottoman Empire, as well as a series of minor Cossack uprisings. In 1610 Hetman Stanisław Żółkiewski seized Moscow after winning the Battle of Klushino.
From the middle of the 17th century, the nobles' democracy, suffering from internal disorder, gradually declined, thus leaving the once powerful Commonwealth vulnerable to foreign intervention.
From 1648, the Cossack Khmelnytsky Uprising engulfed the south and east eventually leaving Ukraine divided, with the eastern part, lost by the Commonwealth, becoming a dependency of the Tsardom of Russia. This was followed by the 'Deluge', a Swedish invasion, which marched through the Polish heartlands and damaged Poland's population, culture and infrastructure. Around four million of Poland's eleven million population died in famines and epidemics in this period.
However, under John III Sobieski the Commonwealth's military prowess was re-established, and in 1683 Polish forces played a major part in relieving Vienna of a Turkish siege which was being conducted by Kara Mustafa.
Sobieski's reign marked the end of the nation's golden-era. Finding itself subjected to almost constant warfare and suffering enormous population losses as well as massive damage to its economy, the Commonwealth fell into decline. The government became ineffective as a result of large-scale internal conflicts (e.g. Lubomirski Rebellion against John II Casimir and rebellious confederations) and corrupted legislative processes. The nobility fell under the control of a handful of "magnats", and this, compounded with two relatively weak kings of the Saxon Wettin dynasty, Augustus II and Augustus III, as well as the rise of Russia and Prussia after the Great Northern War only served to worsen the Commonwealth's plight. Despite this The Commonwealth-Saxony personal union gave rise to the emergence of the Commonwealth's first reform movement, and laid the foundations for the Polish Enlightenment.
During the later part of the 18th century, the Commonwealth made attempts to implement fundamental internal reforms; with the second half of the century bringing a much improved economy, significant population growth and far-reaching progress in the areas of education, intellectual life, art, and especially toward the end of the period, evolution of the social and political system. The most populous capital city of Warsaw replaced Gdańsk (Danzig) as the leading centre of commerce, and the role of the more prosperous townsfolk increased.
The royal election of 1764 resulted in the elevation of Stanisław II August, a refined and worldly aristocrat connected to a major magnate faction, to the monarchy. However, a one-time lover of Empress Catherine II of Russia, the new king spent much of his reign torn between his desire to implement reforms necessary to save his nation, and his perceived necessity to remain in a relationship with his Russian sponsor. This led to the formation of the 1768 Bar Confederation, a "szlachta" rebellion directed against Russia and the Polish king that fought to preserve Poland's independence and the "szlachta"'s traditional privileges.
Attempts at reform provoked the union's neighbours, and in 1772 the First Partition of the Commonwealth by Russia, Austria and Prussia took place; an act which the "Partition Sejm", under considerable duress, eventually "ratified" "fait accompli". Disregarding this loss, in 1773 the king established the Commission of National Education, the first government education authority in Europe. Corporal punishment of children was officially prohibited in 1783 as first in the world at all schools.
The Great Sejm convened by Stanisław II August in 1788 successfully adopted the 3 May Constitution, the first set of modern supreme national laws in Europe. However, this document, accused by detractors of harbouring revolutionary sympathies, generated strong opposition from the Commonwealth's nobles and conservatives as well as from Catherine II, who, determined to prevent the rebirth of a strong Commonwealth set about planning the final dismemberment of the Polish-Lithuanian state. Russia was aided in achieving its goal when the Targowica Confederation, an organisation of Polish nobles, appealed to the Empress for help. In May 1792 Russian forces crossed the Commonwealth's frontier, thus beginning the Polish-Russian War.
The defensive war fought by the Poles ended prematurely when the King, convinced of the futility of resistance, capitulated and joined the Targowica Confederation. The Confederation then took over the government. Russia and Prussia, fearing the mere existence of a Polish state, arranged for, and in 1793 executed, the Second Partition of the Commonwealth, which left the country deprived of so much territory that it was practically incapable of independent existence. Eventually, in 1795, following the failed Kościuszko Uprising, the Commonwealth was partitioned one last time by all three of its more powerful neighbours, and with this, effectively ceased to exist.
The Age of Partitions.
Poles rebelled several times against the partitioners, particularly near the end of the 18th century and the beginning of the 19th century. An unsuccessful attempt at defending Poland's sovereignty took place in 1794 during the Kościuszko Uprising, where a popular and distinguished general Tadeusz Kosciuszko, who had served under Washington in America, led Polish insurgents against numerically superior Russian forces. Despite the victory at the Battle of Racławice, his ultimate defeat ended Poland's independent existence for 123 years. In 1807, Napoleon I of France temporarily recreated a Polish state as a satellite Duchy of Warsaw, but after the failed Napoleonic Wars, Poland was again split between the victorious Allies at the Congress of Vienna of 1815. The eastern part was ruled by the Russian tsar as a Congress Kingdom, which had a very liberal constitution. However, the tsars reduced Polish freedoms, and Russia annexed the country in virtually all but name. Thus in the latter half of the 19th century, only Austrian-ruled Galicia, and particularly the Free City of Kraków, created good environment for free Polish cultural life to flourish.
Throughout the period of the partitions, political and cultural repression of the Polish nation led to the organisation of a number of uprisings against the authorities of the occupying Russian, Prussian and Austrian governments. Notable among these are the November Uprising of 1830 and January Uprising of 1863, both of which were attempts to free Poland from the rule of tsarist Russia. The November uprising began on 29 November 1830 in Warsaw when, led by Lieutenant Piotr Wysocki, young non-commissioned officers at the Imperial Russian Army's military academy in that city revolted. They were joined by large segments of Polish society, and together forced Warsaw's Russian garrison to withdraw north of the city.
Over the course of the next seven months, Polish forces successfully defeated the Russian armies of Field Marshal Hans Karl von Diebitsch and a number of other Russian commanders; however, finding themselves in a position unsupported by any other foreign powers, save distant France and the newborn United States, and with Prussia and Austria refusing to allow the import of military supplies through their territories, the Poles accepted that the uprising was doomed to failure. Upon the surrender of Warsaw to General Ivan Paskievich, many Polish troops, feeling they could not go on, withdrew into Germany and there laid down their arms. Poles would have to wait another 32 years for another opportunity to free their homeland.
When in January 1863 a new Polish uprising against Russian rule began, it did so as a spontaneous protest by young Poles against conscription into the Imperial Russian Army. However, the insurrectionists, despite being joined by high-ranking Polish-Lithuanian officers and numerous politicians, were still severely outnumbered and lacking in foreign support. They were forced to resort to guerrilla warfare tactics and failed to win any major military victories. Afterwards no major uprising was witnessed in the Russian-controlled Congress Poland, and Poles resorted instead to fostering economic and cultural self-improvement.
Despite the political unrest experienced during the partitions, Poland did benefit from large-scale industrialisation and modernisation programs, instituted by the occupying powers, which helped it develop into a more economically coherent and viable entity. This was particularly true in the Greater Poland, Pomerania and Warmia annexed by Prussia (later becoming a part of the German Empire); an area which eventually, thanks largely to the Greater Poland Uprising, was reconstituted as a part of the Second Polish Republic and became one of its most productive regions.
Reconstitution of Poland.
During World War I, all the Allies agreed on the reconstitution of Poland that United States President Woodrow Wilson proclaimed in Point 13 of his Fourteen Points. A total of 2 million Polish troops fought with the armies of the three occupying powers, and 450,000 died. Shortly after the armistice with Germany in November 1918, Poland regained its independence as the Second Polish Republic ("II Rzeczpospolita Polska"). It reaffirmed its independence after a series of military conflicts, the most notable being the Polish–Soviet War (1919–1921) when Poland inflicted a crushing defeat on the Red Army at the Battle of Warsaw, an event which is considered to have halted the advance of Communism into Europe and forced Vladimir Lenin to rethink his objective of achieving global socialism. Nowadays the event is often referred to as the "Miracle at the Vistula".
During this period, Poland successfully managed to fuse the territories of the three former partitioning powers into a cohesive nation state. Railways were restructured to direct traffic towards Warsaw instead of the former imperial capitals, a new network of national roads was gradually built up and a major seaport was opened on the Baltic Coast, so as to allow Polish exports and imports to bypass the politically charged Free City of Danzig.
The inter-war period heralded in a new era of Polish politics. Whilst Polish political activists had faced heavy censorship in the decades up until the First World War, the country now found itself trying to establish a new political tradition. For this reason, many exiled Polish activists, such as Ignacy Paderewski (who would later become Prime Minister) returned home to help; a significant number of them then went on to take key positions in the newly formed political and governmental structures. Tragedy struck in 1922 when Gabriel Narutowicz, inaugural holder of the Presidency, was assassinated at the Zachęta Gallery in Warsaw by painter and right-wing nationalist Eligiusz Niewiadomski.
The 1926 May Coup of Józef Piłsudski turned rule of the Second Polish Republic over to the Sanacja movement. By the 1930s Poland had become increasingly authoritarian; a number of 'undesirable' political parties, such as the Polish Communists, had been banned and following Piłsudski's death, the regime, unable to appoint a new leader, began to show its inherent internal weaknesses and unwillingness to cooperate in any way with other political parties.
As result of the Munich Agreement of 1 October 1938, Poland invaded and occupied the Zaolzie Region of Czechoslovakia.
World War II.
The formal beginning of World War II was marked by the Nazi German invasion of Poland on 1 September 1939, followed by the Soviet invasion of Poland on 17 September in violation of the Soviet–Polish Non-Aggression Pact. On 28 September 1939 Warsaw capitulated. As agreed earlier in the Molotov–Ribbentrop Pact, Poland was split into two occupied zones, one subdivided by Nazi Germany, while the other, including all of eastern Kresy fell under the control of the Soviet Union. In 1939–1941, the Soviets had deported hundreds of thousands of Poles out to the most distant parts of the Soviet Union. The Soviet NKVD secretly executed thousands of Polish prisoners of war (inter alia Katyn massacre) ahead of the Operation Barbarossa.
All in all, Poland made the fourth-largest troop contribution to the Allied war effort, after the Soviets, the British, and the Americans. Polish troops fought under the command of both the Polish Government in Exile in the theatre of war west of Germany and under Soviet leadership in the theatre of war east of Germany. The Polish expeditionary corps, which was controlled by the exiled pre-war government based in London, played an important role in the Italian and North African Campaigns. They are particularly well remembered for their conduct at the Battle of Monte Cassino, a conflict which culminated in the raising of a Polish flag over the ruins of the mountain-top abbey by the 12th Podolian Uhlans. The Polish forces in the theatre of war east of Germany were commanded by Lieutenant General Władysław Anders who had received his command from Prime Minister of the exiled government Władysław Sikorski. On the east of Germany, the Soviet-backed Polish 1st Army distinguished itself in the battles for Berlin and Warsaw, although its actions in support of the latter have often been criticized.
Polish servicemen were also active in the theatres of naval and air warfare; during the Battle of Britain Polish squadrons such as the No. 303 "Kościuszko" fighter squadron achieved considerable success, and by the end of the war the exiled Polish Air Forces could claim 769 confirmed kills. Meanwhile, the Polish Navy was active in the protection of convoys in the North Sea and Atlantic Ocean.
In addition to the organised units of the 1st Army and the Forces in the Nazi-occupied Europe, the domestic underground resistance movement, the Armia Krajowa, or "Home Army", fought to free Poland from German occupation and establish an independent Polish state. The wartime resistance movement in Poland was one of the three largest resistance movements of the entire war, and encompassed an unusually broad range of clandestine activities, which essentially functioned as an underground state complete with degree-awarding universities and a court system. The resistance was, however, largely loyal to the exiled government and generally resented the idea of a communist Poland; for this reason, in the summer of 1944 they initiated Operation Tempest, of which the Warsaw Uprising that begun on 1 August 1944 was the best known operation. The objective of the uprising was to drive the German occupiers from the city and help with the larger fight against Germany and the Axis powers. However, secondary motives for the uprising sought to see Warsaw liberated before the Soviets could reach the capital, so as to underscore Polish sovereignty by empowering the Polish Underground State before the Soviet-backed Polish Committee of National Liberation could assume control. However, a lack of available allied military aid and Stalin's reluctance to allow the 1st Army to help their fellow countrymen take the city, led to the uprising's failure and subsequent planned destruction of the city.
During the war, German forces under direct order from Adolf Hitler set up six major extermination camps, all of which operated in the heart of Poland. They included the notorious Treblinka and Auschwitz killing grounds. This allowed the Germans to transport the condemned Jews away from public eye in the Third Reich or across occupied Europe and – under the guise of resettlement – murder them in the General Government and in brand new Warthegau among other annexed areas. The Nazi crimes against the Polish nation claimed the lives of 2.7 to 2.9 million Polish Jews,<ref name="Materski/Szarota-2">Wojciech Materski, Tomasz Szarota (2009), . "Quote:" Liczba Żydów i Polaków żydowskiego pochodzenia, obywateli II Rzeczypospolitej, zamordowanych przez Niemców sięga 2,7- 2,9 mln osób. "Translation:" The number of Jewish victims is estimated at 2,7–2,9 million. This was about 90% of the 3.3 million Jews living in prewar Poland. "Source:" IPN.</ref> and 2.77 million ethnic Poles,<ref name="Materski/Szarota">Wojciech Materski, Tomasz Szarota (2009), . Retrieved 27 October 2014. "Quote:" Łączne straty śmiertelne ludności polskiej pod okupacją niemiecką oblicza się obecnie na ok. 2 770 000. "Translation:" Current estimate is roughly 2,770,000 victims of German occupation. This was 11.3% of the 24.4 million ethnic Poles in prewar Poland.</ref> including Polish intelligentsia, doctors, lawyers, nobility, priests and numerous others. Since 3,5 million Jews lived in pre-war Poland, Jewish victims make up the largest percentage of all victims of the Nazis' extermination program. It is estimated that, of pre-war Poland's Jewry, approximately 90% were killed. Throughout the occupation, many members of the Armia Krajowa, supported by the Polish government in exile, and millions of ordinary Poles – at great risk to themselves and their families – engaged in rescuing Jews from the Nazi Germans. Grouped by nationality, Poles represent the largest number of people who rescued Jews during the Holocaust. To date, 6,394 Poles have been awarded the title of "Righteous Among the Nations" by the State of Israel–more than any other nation. Some estimates put the number of Poles involved in rescue efforts at up to 3 million, and credit Poles with sheltering up to 450,000 Jews.
At the war's conclusion in 1945, Poland's borders were shifted westwards, resulting in considerable territorial losses. Most of the Polish inhabitants of Kresy were expelled along the Curzon Line in accordance with Stalin's agreements. The western border was moved to the Oder-Neisse line. As a result, Poland's territory was reduced by 20%, or . The shift forced the migration of millions of other people, most of whom were Poles, Germans, Ukrainians, and Jews. Of all the countries involved in the war, Poland lost the highest percentage of its citizens: over 6 million perished – nearly one-fifth of Poland's population — half of them Polish Jews. Over 90% of deaths were non-military in nature. Population numbers did not recover until the 1970s.
Postwar communist Poland.
At the insistence of Joseph Stalin, the Yalta Conference sanctioned the formation of a new provisional pro-Communist coalition government in Moscow, which ignored the Polish government-in-exile based in London; a move which angered many Poles who considered it a betrayal by the Allies. In 1944, Stalin had made guarantees to Churchill and Roosevelt that he would maintain Poland's sovereignty and allow democratic elections to take place. However, upon achieving victory in 1945, the elections organized by the occupying Soviet authorities were falsified and were used to provide a veneer of 'legitimacy' for Soviet hegemony over Polish affairs. The Soviet Union instituted a new communist government in Poland, analogous to much of the rest of the Eastern Bloc. As elsewhere in Communist Europe the Soviet occupation of Poland met with armed resistance from the outset which continued into the fifties.
Despite widespread objections, the new Polish government accepted the Soviet annexation of the pre-war eastern regions of Poland (in particular the cities of Wilno and Lwów) and agreed to the permanent garrisoning of Red Army units on Poland's territory. Military alignment within the Warsaw Pact throughout the Cold War came about as a direct result of this change in Poland's political culture and in the European scene came to characterise the full-fledged integration of Poland into the brotherhood of communist nations.
The People's Republic of Poland ("Polska Rzeczpospolita Ludowa") was officially proclaimed in 1952. In 1956 after the death of Bolesław Bierut, the régime of Władysław Gomułka became temporarily more liberal, freeing many people from prison and expanding some personal freedoms. A similar situation repeated itself in the 1970s under Edward Gierek, but most of the time persecution of anti-communist opposition groups persisted. Despite this, Poland was at the time considered to be one of the least oppressive states of the Soviet Bloc.
Labour turmoil in 1980 led to the formation of the independent trade union "Solidarity" ("Solidarność"), which over time became a political force. Despite persecution and imposition of martial law in 1981, it eroded the dominance of the Polish United Workers' Party and by 1989 had triumphed in Poland's first partially free and democratic parliamentary elections since the end of the Second World War. Lech Wałęsa, a Solidarity candidate, eventually won the presidency in 1990. The Solidarity movement heralded the collapse of communist regimes and parties across Europe.
Present-day Poland.
A shock therapy programme, initiated by Leszek Balcerowicz in the early 1990s enabled the country to transform its socialist-style planned economy into a market economy. As with other post-communist countries, Poland suffered slumps in social and economic standards, but it became the first post-communist country to reach its pre-1989 GDP levels, which it achieved by 1995 largely thanks to its booming economy.
Most visibly, there were numerous improvements in human rights, such as the freedom of speech, internet freedom (no censorship), civil liberties (1st class) and political rights (1st class), according to Freedom House. In 1991, Poland became a member of the Visegrád Group and joined the North Atlantic Treaty Organization (NATO) alliance in 1999 along with the Czech Republic and Hungary. Poles then voted to join the European Union in a referendum in June 2003, with Poland becoming a full member on 1 May 2004. Poland joined the Schengen Area in 2007, as a result of which, the country's borders with other member states of the European Union have been dismantled, allowing for full freedom of movement within most of the EU. In contrast to this, a section of Poland's eastern border now comprises the external EU border with Belarus, Russia and Ukraine. That border has become increasingly well protected, and has led in part to the coining of the phrase 'Fortress Europe', in reference to the seeming 'impossibility' of gaining entry to the EU for citizens of the former Soviet Union.
Poland has been one of the most prominent voices of establishing a common European Armed Forces, with Poland's Premier along with Chancellor Angela Merkel and President Francois Hollande (collectively also part of Weimar Triangle) taking steps to negotiate such a deal, in hope of drastically reducing dependence on NATO and increasing readiness. Poland has already built several commands of a common battle group with Hungary, Czech Republic and Slovakia, with a total of 12,000 troops ready for deployment. Poland is seeking to build more battle groups with Lithuania and Ukraine. These battle groups have vowed to serve under the European Union, and not NATO. Eurosceptics criticize such moves as further unnecessary integration and a new major step towards a federalized European Union under one government. Military integration is judged to be the most significant step after a monetary union.
On 10 April 2010, the President of the Republic of Poland, Lech Kaczyński, along with 89 other high-ranking Polish officials died in a plane crash near Smolensk, Russia. The president's party were on their way to attend an annual service of commemoration for the victims of the Katyń massacre when the tragedy took place.
In 2011, the Presidency of the Council of the European Union responsible for the functioning of the Council was awarded to Poland. The same year parliamentary elections took place to both the Senate and the Sejm. They were won by the ruling Civic Platform. Poland joined European Space Agency in 2012, as well as organised the UEFA Euro 2012 (along with Ukraine). In 2013, Poland also became a member of the Development Assistance Committee. In 2014 the Prime Minister of Poland, Donald Tusk, was elected President of the European Council.
Geography.
Poland's territory extends across several geographical regions, between latitudes 49° and 55° N, and longitudes 14° and 25° E. In the north-west is the Baltic seacoast, which extends from the Bay of Pomerania to the Gulf of Gdańsk. This coast is marked by several spits, coastal lakes (former bays that have been cut off from the sea), and dunes. The largely straight coastline is indented by the Szczecin Lagoon, the Bay of Puck, and the Vistula Lagoon. The centre and parts of the north lie within the North European Plain.
Rising above these lowlands is a geographical region comprising the four hilly districts of moraines and moraine-dammed lakes formed during and after the Pleistocene ice age. These lake districts are the Pomeranian Lake District, the Greater Polish Lake District, the Kashubian Lake District, and the Masurian Lake District. The Masurian Lake District is the largest of the four and covers much of north-eastern Poland. The lake districts form part of the Baltic Ridge, a series of moraine belts along the southern shore of the Baltic Sea.
South of the Northern European Lowlands lie the regions of Lusatia, Silesia and Masovia, which are marked by broad ice-age river valleys. Farther south lies the Polish mountain region, including the Sudetes, the Kraków-Częstochowa Upland, the Świętokrzyskie Mountains, and the Carpathian Mountains, including the Beskids. The highest part of the Carpathians is the Tatra Mountains, along Poland's southern border. 
Geology.
The geological structure of Poland has been shaped by the continental collision of Europe and Africa over the past 60 million years and, more recently, by the Quaternary glaciations of northern Europe. Both processes shaped the Sudetes and the Carpathian Mountains. The moraine landscape of northern Poland contains soils made up mostly of sand or loam, while the ice age river valleys of the south often contain loess. The Kraków-Częstochowa Upland, the Pieniny, and the Western Tatras consist of limestone, while the High Tatras, the Beskids, and the Karkonosze are made up mainly of granite and basalts. The Polish Jura Chain is one of the oldest mountain ranges on earth.
Poland has 70 mountains over in elevation, all in the Tatras. The Polish Tatras, which consist of the High Tatras and the Western Tatras, is the highest mountain group of Poland and of the entire Carpathian range. In the High Tatras lies Poland's highest point, the north-western summit of Rysy, in elevation. At its foot lies the mountain lakes of Czarny Staw pod Rysami (Black Lake below Mount Rysy), and Morskie Oko (the Marine Eye).<ref name="CIA/World">The CIA World Factbook, Introduction: Poland. Geography. Retrieved 3 November 2014.</ref>
The second highest mountain group in Poland is the Beskids, whose highest peak is Babia Góra, at . The next highest mountain groups is the Karkonosze in the Sudetes, whose highest point is Śnieżka, at ; Śnieżnik Mountains whose highest point is Śnieżnik, at .
Tourists also frequent the Bieszczady Mountains in the far southeast of Poland, whose highest point in Poland is Tarnica, with an elevation of , Gorce Mountains in Gorce National Park, whose highest point is Turbacz, with elevations , and the Pieniny in Pieniny National Park, whose highest point is Wysokie Skałki (Wysoka), with elevations . The lowest point in Poland – at below sea level – is at Raczki Elbląskie, near Elbląg in the Vistula Delta.
The only desert located in Poland stretches over the Zagłębie Dąbrowskie (the Coal Fields of Dąbrowa) region. It is called the Błędów Desert, located in the Silesian Voivodeship in southern Poland. It has a total area of . It is one of only five natural deserts in Europe. But also, it is the warmest desert that appears at this latitude. Błędów Desert was created thousands of years ago by a melting glacier. The specific geological structure has been of big importance. The average thickness of the sand layer is about , with a maximum of , which made the fast and deep drainage very easy.
The Baltic Sea activity in Słowiński National Park created sand dunes which in the course of time separated the bay from the sea. As waves and wind carry sand inland the dunes slowly move, at a rate of meters per year. Some dunes are quite high – up to . The highest peak of the park – Rowokol ( above sea level) — is also an excellent observation point.
Waters.
The longest rivers are the Vistula (), long; the Oder () which forms part of Poland's western border, long; its tributary, the Warta, long; and the Bug, a tributary of the Vistula, long. The Vistula and the Oder flow into the Baltic Sea, as do numerous smaller rivers in Pomerania.
The Łyna and the Angrapa flow by way of the Pregolya to the Baltic, and the Czarna Hańcza flows into the Baltic through the Neman. While the great majority of Poland's rivers drain into the Baltic Sea, Poland's Beskids are the source of some of the upper tributaries of the Orava, which flows via the Váh and the Danube to the Black Sea. The eastern Beskids are also the source of some streams that drain through the Dniester to the Black Sea.
Poland's rivers have been used since early times for navigation. The Vikings, for example, traveled up the Vistula and the Oder in their longships. In the Middle Ages and in early modern times, when the Polish–Lithuanian Commonwealth was the breadbasket of Europe; the shipment of grain and other agricultural products down the Vistula toward Gdańsk and onward to other parts of Europe took on great importance.
With almost ten thousand closed bodies of water covering more than each, Poland has one of the highest numbers of lakes in the world. In Europe, only Finland has a greater density of lakes. The largest lakes, covering more than , are Lake Śniardwy and Lake Mamry in Masuria, and Lake Łebsko and Lake Drawsko in Pomerania.
In addition to the lake districts in the north (in Masuria, Pomerania, Kashubia, Lubuskie, and Greater Poland), there is also a large number of mountain lakes in the Tatras, of which the Morskie Oko is the largest in area. The lake with the greatest depth—of more than —is Lake Hańcza in the Wigry Lake District, east of Masuria in Podlaskie Voivodeship.
Among the first lakes whose shores were settled are those in the Greater Polish Lake District. The stilt house settlement of Biskupin, occupied by more than one thousand residents, was founded before the 7th century BC by people of the Lusatian culture.
Lakes have always played an important role in Polish history and continue to be of great importance to today's modern Polish society. The ancestors of today's Poles, the Polanie, built their first fortresses on islands in these lakes. The legendary Prince Popiel ruled from Kruszwica tower erected on the Lake Gopło. The first historically documented ruler of Poland, Duke Mieszko I, had his palace on an island in the Warta River in Poznań. Nowadays the Polish lakes provide a location for the pursuit of water sports such as yachting and wind-surfing.
The Polish Baltic coast is approximately long and extends from Świnoujście on the islands of Usedom and Wolin in the west to Krynica Morska on the Vistula Spit in the east. For the most part, Poland has a smooth coastline, which has been shaped by the continual movement of sand by currents and winds. This continual erosion and deposition has formed cliffs, dunes, and spits, many of which have migrated landwards to close off former lagoons, such as Łebsko Lake in Słowiński National Park.
Prior to the end of the Second World War and subsequent change in national borders, Poland had only a very small coastline; this was situated at the end of the 'Polish Corridor', the only internationally recognised Polish territory which afforded the country access to the sea. However, after World War II, the redrawing of Poland's borders and resulting 'shift' of the country's borders left it with an expanded coastline, thus allowing for far greater access to the sea than was ever previously possible. The significance of this event, and importance of it to Poland's future as a major industrialised nation, was alluded to by the 1945 Wedding to the Sea.
The largest spits are Hel Peninsula and the Vistula Spit. The largest Polish Baltic island is Wolin. The largest sea harbours are Szczecin, Świnoujście, Gdańsk, Gdynia, Police and Kołobrzeg. The main coastal resorts are Świnoujście, Międzyzdroje, Kołobrzeg, Łeba, Sopot, Władysławowo and the Hel Peninsula.
Land use.
Poland is the fourth most forested country in Europe. Forests cover about 30.5% of Poland's land area based on international standards. Its overall percentage is still increasing. Forests of Poland is managed by the national program of reforestation (KPZL), aiming at an increase of forest-cover to 33% in 2050. The richness of Polish forest (per SoEF 2011 statistics) is more than twice as high as European average (with Germany and France at the top), containing 2.304 billion cubic metres of trees. The largest forest complex in Poland is Lower Silesian Wilderness.
More than 1% of Poland's territory, , is protected within 23 Polish national parks. Three more national parks are projected for Masuria, the Kraków-Częstochowa Upland, and the eastern Beskids. In addition, wetlands along lakes and rivers in central Poland are legally protected, as are coastal areas in the north. There are over 120 areas designated as landscape parks, along with numerous nature reserves and other protected areas (e.g. Natura 2000).
Since Poland's accession to the European Union in 2004, Polish agriculture has performed extremely well and the country has over two million private farms. It is the leading producer in Europe of potatoes and rye (world's second largest in 1989) the world's largest producer of triticale, and one of the more important producers of barley, oats, sugar beets, flax, and fruits.It is the European Union's fourth largest supplier of pigmeat after Germany, Spain and France. The government continues debating further agricultural reform and pursuing the option of auctioning off large tracts of state-owned agricultural land.
Biodiversity.
Phytogeographically, Poland belongs to the Central European province of the Circumboreal Region within the Boreal Kingdom. According to the World Wide Fund for Nature, the territory of Poland belongs to three Palearctic Ecoregions of the continental forest spanning Central and Northern European temperate broadleaf and mixed forest ecoregions as well as the Carpathian montane conifer forest.
Many animals that have since died out in other parts of Europe still survive in Poland, such as the wisent in the ancient woodland of the Białowieża Forest and in Podlaskie. Other such species include the brown bear in Białowieża, in the Tatras, and in the Beskids, the gray wolf and the Eurasian lynx in various forests, the moose in northern Poland, and the beaver in Masuria, Pomerania, and Podlaskie.
In the forests, one also encounters game animals, such as red deer, roe deer and wild boars. In eastern Poland there are a number of ancient woodlands, like Białowieża forest, that have never been cleared or have been disturbed much by people. There are also large forested areas in the mountains, Masuria, Pomerania, Lubusz Land and Lower Silesia.
Poland is the most important breeding ground for a variety of European migratory birds. Out of all of the migratory birds who come to Europe for the summer, one quarter of the global population of white storks (40,000 breeding pairs) live in Poland, particularly in the lake districts and the wetlands along the Biebrza, the Narew, and the Warta, which are part of nature reserves or national parks.
Climate.
The climate is mostly temperate throughout the country. The climate is oceanic in the north and west and becomes gradually warmer and continental towards the south and east. Summers are generally warm, with average temperatures between depending on a region. Winters are rather cold, with average temperatures around in the northwest and in the northeast. Precipitation falls throughout the year, although, especially in the east; winter is drier than summer.
The warmest region in Poland is Lower Silesia located in south-western Poland where temperatures in the summer average between but can go as high as on some days in the warmest month of July and August. The warmest cities in Poland are Tarnów, which is situated in Lesser Poland and Wrocław, which is located in Lower Silesia. The average temperatures in Wrocław are in the summer and in the winter, but Tarnów has the longest summer in all of Poland, which lasts for 115 days, from mid-May to mid-September. The coldest region of Poland is in the northeast in the Podlaskie Voivodeship near the border of Belarus and Lithuania. Usually the coldest city is Suwałki. The climate is affected by cold fronts which come from Scandinavia and Siberia. The average temperature in the winter in Podlaskie ranges from .
Politics.
Poland is a democracy, with a president as a head of state, whose current constitution dates from 1997. Poland is a peaceful country. The government structure centers on the Council of Ministers, led by a prime minister. The president appoints the cabinet according to the proposals of the prime minister, typically from the majority coalition in the Sejm. The president is elected by popular vote every five years. The president is Andrzej Duda. The current prime minister is Ewa Kopacz.
Polish voters elect a bicameral parliament consisting of a 460-member lower house (Sejm) and a 100-member Senate (Senat). The Sejm is elected under proportional representation according to the d'Hondt method, a method similar to that used in many parliamentary political systems. The Senat, on the other hand, is elected under the First-past-the-post voting method, with one senator being returned from each of the 100 constituencies.
With the exception of ethnic minority parties, only candidates of political parties receiving at least 5% of the total national vote can enter the Sejm. When sitting in joint session, members of the Sejm and Senat form the National Assembly (the "Zgromadzenie Narodowe"). The National Assembly is formed on three occasions: when a new President takes the oath of office; when an indictment against the President of the Republic is brought to the State Tribunal ("Trybunał Stanu"); and when a president's permanent incapacity to exercise his duties due to the state of his health is declared. To date only the first instance has occurred.
The judicial branch plays an important role in decision-making. Its major institutions include the Supreme Court of the Republic of Poland ("Sąd Najwyższy"); the Supreme Administrative Court of the Republic of Poland ("Naczelny Sąd Administracyjny"); the Constitutional Tribunal of the Republic of Poland ("Trybunał Konstytucyjny"); and the State Tribunal of the Republic of Poland ("Trybunał Stanu"). On the approval of the Senat, the Sejm also appoints the ombudsman or the Commissioner for Civil Rights Protection ("Rzecznik Praw Obywatelskich") for a five-year term. The ombudsman has the duty of guarding the observance and implementation of the rights and liberties of Polish citizens and residents, of the law and of principles of community life and social justice.
Law.
The Constitution of Poland is the supreme law in contemporary Poland, and the Polish legal system is based on the principle of civil rights, governed by the code of Civil Law. Historically, the most famous Polish legal act is the Constitution of 3 May 1791. Historian Norman Davies describes it as the first of its kind in Europe. The Constitution was instituted as a Government Act () and then adopted on 3 May 1791 by the Sejm of the Polish–Lithuanian Commonwealth. Primarily, it was designed to redress long-standing political defects of the federative Polish–Lithuanian Commonwealth and its Golden Liberty. Previously only the Henrican articles signed by each of Poland's elected kings could perform the function of a set of basic laws.
The new Constitution introduced political equality between townspeople and the nobility ("szlachta"), and placed the peasants under the protection of the government. The Constitution abolished pernicious parliamentary institutions such as the "liberum veto", which at one time had placed the sejm at the mercy of any deputy who might choose, or be bribed by an interest or foreign power, to have rescinded all the legislation that had been passed by that sejm. The 3 May Constitution sought to supplant the existing anarchy fostered by some of the country's reactionary magnates, with a more egalitarian and democratic constitutional monarchy. The adoption of was treated as a threat by Poland's neighbours. In response Prussia, Austria and Russia formed an anti-Polish alliance and over the next decade collaborated with one another to partition their weaker neighbour and destroyed the Polish state. In the words of two of its co-authors, Ignacy Potocki and Hugo Kołłątaj, the constitution represented "the last will and testament of the expiring Fatherland." Despite this, its text influenced many later democratic movements across the globe. In Poland, freedom of expression is guaranteed by the Article 25 (section I. The Republic) and Article 54 (section II. The Freedoms, Rights and Obligations of Persons and Citizens) of the Constitution of Poland.
Feminism in Poland started in the 1800s in the age of the foreign Partitions. Poland's precursor of feminism, Narcyza Żmichowska, founded a group of Suffragettes in 1842. Prior to the last Partition in 1795, tax-paying females were allowed to take part in political life. Since 1918, following the return to independence, all women could vote. Poland was the 15th (12th sovereign) country to introduce universal women's suffrage. Nevertheless, there is a number of issues concerning women in modern-day Poland such as the abortion rights (formally allowed only in special circumstances) and the "glass ceiling". Homosexuality in Poland was confirmed as legal in 1932. Poland recognises gender change.
A 2010 article in "Rzeczpospolita" reported that in a 2008 study three-quarters of Poles were against gay marriage or the adoption of children by gay couples in accordance with the Catholic teachings. The same study revealed that 66% of respondents were opposed to Pride parade as the demonstration of a way of life, and 69% believed that gay people should not show their sexual orientation in public.<ref name="interia/Polska"></ref> Poland belongs to the group of 'Tier 1' countries in Trafficking in Persons Report. Trafficking women is 'illegal and rare' (top results worldwide).
Poland's current constitution was adopted by the National Assembly of Poland on 2 April 1997, approved by a national referendum on 25 May 1997, and came into effect on 17 October 1997. It guarantees a multi-party state, the freedoms of religion, speech and assembly, and specifically casts off many Communist ideals to create a 'free market economic system'. It requires public officials to pursue ecologically sound public policy and acknowledges the inviolability of the home, the right to form trade unions, and to strike, whilst at the same time prohibiting the practices of forced medical experimentation, torture and corporal punishment.
Foreign relations.
In recent years, Poland has extended its responsibilities and position in European and international affairs, supporting and establishing friendly relations with other European nations and a large number of 'developing' countries.
Poland is a member of the European Union, NATO, the UN, the World Trade Organization, the Organisation for Economic Co-operation and Development (OECD), European Economic Area, International Energy Agency, Council of Europe, Organization for Security and Co-operation in Europe, International Atomic Energy Agency, European Space Agency, G6, Council of the Baltic Sea States, Visegrád Group, Weimar Triangle and Schengen Agreement.
In 1994, Poland became an associate member of the European Union (EU) and its defensive arm, the Western European Union (WEU), having submitted preliminary documentation for full membership in 1996, it formally joined the European Union in May 2004, along with the other members of the Visegrád group. In 1996, Poland achieved full OECD membership, and at the 1997 Madrid Summit was invited to join the North Atlantic Treaty Organisation (NATO) in the first wave of policy enlargement finally becoming a full member of NATO in March 1999.
As changes since the fall of Communism in 1989 have redrawn the map of Europe, Poland has tried to forge strong and mutually beneficial relationships with its seven new neighbours, this has notably included signing 'friendship treaties' to replace links severed by the collapse of the Warsaw Pact. The Poles have forged special relationships with Lithuania and particularly Ukraine, with whom they co-hosted the UEFA Euro 2012 football tournament, in an effort to firmly anchor these countries within the Western world and provide them with an alternative to aligning themselves with the Russian Federation respectively. Despite many positive developments in the region, Poland has found itself in a position where it must seek to defend the rights of ethnic Poles living in the former Soviet Union; this is particularly true of Belarus, where in 2005 the Lukashenko regime launched a campaign against the Polish ethnic minority.
Poland is the sixth most populous member state of the European Union and, ever since joining in 2004, has pursued policies to increase its role in European affairs. Poland has a grand total of 51 representatives in the European Parliament. From 2009 to 2012, Jerzy Buzek, a former Prime Minister of Poland, was President of the European Parliament.
Administrative divisions.
Poland's current voivodeships (provinces) are largely based on the country's historic regions, whereas those of the past two decades (to 1998) had been centred on and named for individual cities. The new units range in area from less than for Opole Voivodeship to more than for Masovian Voivodeship. Administrative authority at voivodeship level is shared between a government-appointed voivode (governor), an elected regional assembly ("sejmik") and an executive elected by that assembly.
The voivodeships are subdivided into "powiats" (often referred to in English as counties), and these are further divided into "gminas" (also known as communes or municipalities). Major cities normally have the status of both "gmina" and "powiat". Poland has 16 voivodeships, 379 powiats (including 65 cities with "powiat" status), and 2,478 "gminas".
Military.
The Polish armed forces are composed of four branches: Land Forces ("Wojska Lądowe"), Navy ("Marynarka Wojenna"), Air Force ("Siły Powietrzne") and Special Forces ("Wojska Specjalne"). The military is subordinate to the Minister for National Defence. However, its sole commander-in-chief is the President of the Republic.
The Polish army consists of 65,000 active personnel, whilst the navy and air force respectively employ 14,300 and 26,126 servicemen and women. The Polish Navy is one of the larger navies on the Baltic Sea and is mostly involved in Baltic operations such as search and rescue provision for the section of the Baltic under Polish command, as well as hydrographic measurements and research; however, the Polish Navy played a more international role as part of the 2003 invasion of Iraq, providing logistical support for the United States Navy. The current position of the Polish Air Force is much the same; it has routinely taken part in Baltic Air Policing assignments, but otherwise, with the exception of a number of units serving in Afghanistan, has seen no active combat since the end of the Second World War. In 2003, the F-16C Block 52 was chosen as the new general multi-role fighter for the air force, the first deliveries taking place in November 2006; it is expected (2010) that the Polish Air Force will create three squadrons of F-16s, which will all be fully operational by 2012.
The most important mission of the armed forces is the defence of Polish territorial integrity and Polish interests abroad. Poland's national security goal is to further integrate with NATO and European defence, economic, and political institutions through the modernisation and reorganisation of its military. The armed forces is being re-organised according to NATO standards, and as of 1 January 2010, the transition to an entirely contract-based military has been completed. During the previous period, men were obliged to undertake compulsory military service. In the final stage of validity of this type of military service (since 2007 until the amendment of the law on conscription in 2008) the duration of compulsory service amounted nine months.
Polish military doctrine reflects the same defensive nature as that of its NATO partners. From 1953 to 2009 Poland was a large contributor to various United Nations peacekeeping missions. The Polish Armed Forces took part in the 2003 invasion of Iraq, deploying 2,500 soldiers in the south of that country and commanding the 17-nation Multinational force in Iraq.
The military was temporarily, but severely, affected by the loss of many of its top commanders in the wake the 2010 Polish Air Force Tu-154 crash near Smolensk, Russia, which killed all 96 passengers and crew, including, among others, the Chief of the Polish Army's General Staff Franciszek Gągor and Polish Air Force commanding general Andrzej Błasik. They were en route from Warsaw to attend an event to mark the 70th anniversary of the Katyn massacre, whose site is commemorated approximately west of Smolensk.
Law enforcement and emergency services.
Poland has a highly developed system of law enforcement with a long history of effective policing by the State Police Service. The structure of law enforcement agencies within Poland is a multi-tier one, with the State Police providing criminal-investigative services, Municipal Police serving to maintain public order and a number of other specialised agencies, such as the Polish Border Guard, acting to fulfil their assigned missions. In addition to these state services, private security companies are also common, although they possess no powers assigned to state agencies, such as, for example, the power to make an arrest or detain a suspect.
Emergency services in Poland consist of the emergency medical services, search and rescue units of the Polish Armed Forces and State Fire Service. Emergency medical services in Poland are, unlike other services, provided for by local and regional government.
Since joining the European Union all of Poland's emergency services have been undergoing major restructuring and have, in the process, acquired large amounts of new equipment and staff. All emergency services personnel are now uniformed and can be easily recognised thanks to a number of innovative design features, such as reflective paint and printing, present throughout their service dress and vehicle liveries. In addition to this, in an effort to comply with EU standards and safety regulations, the police and other agencies have been steadily replacing and modernising their fleets of vehicles; this has left them with thousands of new automobiles, as well as many new aircraft, boats and helicopters.
Economy.
Poland's high-income economy is considered to be one of the healthiest of the post-Communist countries and is one of the fastest growing within the EU. Having a strong domestic market, low private debt, flexible currency, and not being dependent on a single export sector, Poland is the only European economy to have avoided the late-2000s recession. Since the fall of the communist government, Poland has pursued a policy of liberalising the economy. It is an example of the transition from a centrally planned to a primarily market-based economy. In 2009 Poland had the highest GDP growth in the EU - 1.6%. The country's most successful exports include machinery, furniture, foods and meats, motor boats, light planes, hardwood products, casual clothing, shoes and cosmetics. Germany is by far the biggest importer of Poland's exports as of 2013.
The privatization of small and medium state-owned companies and a liberal law on establishing new firms have allowed the development of the private sector. As a consequence, consumer rights organizations have also appeared. Restructuring and privatisation of "sensitive sectors" such as coal, steel, rail transport and energy has been continuing since 1990. Between 2007 and 2010, the government plans to float twenty public companies on the Warsaw Stock Exchange, including parts of the coal industry. The biggest privatisations have been the sale of the national telecoms firm Telekomunikacja Polska to France Télécom in 2000, and an issue of 30% of the shares in Poland's largest bank, PKO Bank Polski, on the Polish stockmarket in 2004.
The Polish banking market is the largest in East Central and Eastern European region, with 32.3 branches per 100,000 adults.<ref name="datatopics/poland">World Bank, Financial Inclusion Data. Country Dashboard: Poland. The World Bank Group. Retrieved 6 November 2014.</ref> The banks are the largest and most developed sector of the country's financial markets. They are regulated by the Polish Financial Supervision Authority. During the transformation to a market-oriented economy, the government privatized some of them, recapitalized the rest, and introduced legal reforms that made the sector competitive. This has attracted a significant number of strategic foreign investors (ICFI). Poland's banking sector has approximately 5 national banks, a network of nearly 600 cooperative banks and 18 branches of foreign-owned banks. In addition, foreign investors have controlling stakes in nearly 40 commercial banks, which make up 68% of the banking capital.
Poland has a large number of private farms in its agricultural sector, with the potential to become a leading producer of food in the European Union. The biggest money-makers abroad include smoked and fresh fish, fine chocolate, and dairy products, meats and specialty breads, with the exchange rate conducive to export growth. Food exports amounted to 62 billion zloty in 2011, increasing by 17% from 2010. Structural reforms in health care, education, the pension system, and state administration have resulted in larger-than-expected fiscal pressures. Warsaw leads Central Europe in foreign investment. GDP growth had been strong and steady from 1993 to 2000 with only a short slowdown from 2001 to 2002.
The economy had growth of 3.7% annually in 2003, a rise from 1.4% annually in 2002. In 2004, GDP growth equaled 5.4%, in 2005 3.3% and in 2006 6.2%. According to Eurostat data, Polish PPS GDP per capita stood at 67% of the EU average in 2012.
In terms of the clarity, efficiency and neutrality of Poland's legal framework for multinational investors, a 2012 report by the World Economic Forum concluded that the ongoing foreign business disputes may "have damaged Poland's reputation as an attractive location for FDI" from other countries by creating the impression of "substandard reputation for maintaining an efficient and neutral framework to settle business disputes." Ernst and Young's 2010 European attractiveness survey reported that Poland saw a 52% decrease in FDI foreign job creation and a 42% decrease in number of FDI projects since 2008.
Average salaries in the enterprise sector in December 2010 were 3,848 PLN (1,012 euro or 1,374 US dollars) and growing sharply. Salaries vary between the regions: the median wage in the capital city Warsaw was 4,603 PLN (1,177 euro or 1,680 US dollars) while in Kielce it was 3,083 PLN (788 euro or 1125 US dollars). There is a wide distribution of salaries among the various districts of Poland. They range from 2,020 PLN (517 euro or 737 US dollars) in Kępno County, which is located in Greater Poland Voivodeship to 5,616 (1,436 euro or 2,050 US dollars) in Lubin County, which lies in Lower Silesian Voivodeship.
According to a Credit Suisse report, Poles are the second wealthiest (after Czechs) of the Central European peoples. Even though since World War II Poland is almost an ethnically homogeneous country, the number of foreign investors among immigrants is growing every year.
Since the opening of the labor market in the European Union, Poland experienced a mass emigration of over 2.3 million abroad, mainly due to higher wages offered abroad, and due to the raise in levels of unemployment following the global Great Recession of 2008. The out migration has increased the average wages for the workers who remained in Poland, in particular for those with intermediate level skills.
Commodities produced in Poland include: electronics, cars (Arrinera, Leopard), buses (Solaris, Solbus), helicopters (PZL Świdnik), transport equipment, locomotives, planes (PZL Mielec), ships, military engineering (including tanks, SPAAG systems), medicines (Polpharma, Polfa), food, clothes, glass, pottery (Bolesławiec), chemical products and others.
Corporations.
Poland is recognised as a regional economic power within East-Central Europe, with nearly 40 percent of the 500 biggest companies in the region (by revenues) as well as a high globalisation rate. Poland was the only member of the EU to avoid the recession of the late 2000s, a testament to the Polish economy's stability. The country's most competitive firms are components of the WIG30 which is traded on the Warsaw Stock Exchange.
Well known Polish brands include, among others, PKO BP, PKN Orlen, PGE, PZU, PGNiG, Tauron Group, Lotos Group, KGHM Polska Miedź, Asseco, Plus, Play, PLL LOT, Poczta Polska, PKP, Biedronka, and TVP.
Poland is recognised as having an economy with development potential, overtaking the Netherlands in mid-2010 to become Europe's sixth largest economy. Foreign Direct Investment in Poland has remained steady ever since the country's re-democratisation following the Round Table Agreement in 1989. However, problems still exist. It is believed that progress of privatization was uneven across sectors due to emergence of interest groups supporting government's push for the reforms based on "feasibility" rather than "efficiency", at the cost of Poland's remaining sectors in need of development and modernisation, such as the extractive industries.
The list includes the largest companies by turnover in 2011, but does not include major banks or insurance companies:
Tourism.
Poland experienced an increase in the number of tourists after joining the European Union. Tourism contributes significantly to Poland's overall economy and makes up a relatively large proportion of the country's service market.<ref name="unwto.org/en/press-release"></ref>
Kraków was the former capital and a relic of Poland's Golden Age of Renaissance. It contains the place of coronation of most Polish kings. It was named a European Capital of Culture by the European Union for the year 2000. The city of Wrocław, designated as a European Capital of Culture in 2016, is one of the oldest in Poland. During World War II, Wrocław was a fortress (Festung Breslau), and was heavily damaged in the nearly three months long Battle of Breslau. The city has been restored and attracts several million tourists every year. The Old Town of Poland's capital, Warsaw, was reconstructed after its wartime destruction and it offers a variety of attractions. Other cities attracting tourists include Gdańsk, Poznań, Szczecin, Lublin and Toruń. The historic site of the Nazi-German Auschwitz concentration camp is near Oświęcim.
Poland's main tourist offerings include outdoor activities such as skiing, sailing and mountain hiking, as well as agrotourism, sightseeing walks, countryside excursions and also holiday and business trips. Poland is the 17th most visited country in the world by foreign tourists, as ranked by World Tourism Organization (UNWTO) in 2012. Tourist destinations include the Baltic Sea coast in the north, the Masurian Lake District and Białowieża Forest in the east, the northern Karkonosze, the Table Mountains and the Tatra Mountains, where Rysy, the highest peak of Poland, and the famous Orla Perć long-distance path are located. The Pieniny and Bieszczady Mountains lie in the extreme south-east. There are over 100 castles in the country, many along the popular Trail of the Eagles' Nests.
Every year on the second weekend of June in Wrocław done Festival of Good Beer - one of Europe's largest international beer festivals.
Energy.
The electricity generation sector in Poland is largely fossil-fuel–based. Many power plants nationwide use Poland's position as a major European exporter of coal to their advantage by continuing to use coal as the primary raw material in production of their energy. In 2013 Poland scored 48 out of 129 states in the Energy Sustainability Index. The three largest Polish coal mining firms (Węglokoks, Kompania Węglowa and JSW) extract around 100 million tonnes of coal annually. All three of these companies are key constituents of the Warsaw Stock Exchange's lead economic indexes.
Renewable forms of energy account for a small proportion of Poland's full energy generation capacity. However, the national government has set targets for the development of renewable energy sources in Poland which should see the portion of power produced by renewable resources climb to 7.5% by 2010 and 15% by 2020. This is to be achieved mainly through the construction of wind farms and a number of hydroelectric stations.
Poland is thought to have around 164,800,000,000 m3 of proven natural gas reserves and around 96,380,000 barrels of proven oil reserves. These reserves are exploited by energy supply companies such as PKN Orlen ("the only Polish company listed in the Fortune Global 500"). However, the small amounts of fossil fuels naturally occurring in Poland is insufficient to satisfy the full energy consumption needs of the population. Therefore, the country is a net importer of oil and natural gas.
Transport.
Transport in Poland is provided by means of rail, road, marine shipping and air travel. Positioned in Central Europe with its eastern and part of its northeastern border constituting the longest land border of the Schengen Area with the rest of Northern and Central Europe, Poland has long been and remains a key country through which imports to the European Union and exports from it pass.
Since joining the EU in May 2004, Poland has invested large amounts of money into the modernisation of its transport networks. The country now has a developing expressway network composed of motorways such as the A1, A2, A4, A8, A18 and express roads such as the S1, S3, S5, S7, S8. In addition to these newly built roads, many local and regional roads are being rebuilt as part of a national programme to rebuild all roads in Poland.
In 2015, the nation had of railway track. Trains can operate up to on 7.5% of the track. Most trains operate between . Part of the system operates at .
Polish authorities maintain a program of improving operating speeds across the entire Polish rail network. Polish State Railways (PKP) are using new rolling stock such as Siemens Taurus ES64U4, which is in principle capable of speeds up to . In December 2014, Poland began to implement high–speed rail routes connecting major Polish cities. The Polish government has revealed that it intends to connect all major cities to a future high-speed rail network by 2020. The new PKP Pendolino ETR 610 test train set the record for the fastest train in the history of Poland, reaching on 24 November 2013. Previously, the speed record had been since 1985. Most intercity rail routes in Poland are operated by PKP Intercity, whilst regional trains are run by a number of operators, the largest of which is Przewozy Regionalne.
On 14 December 2014, Polish State Railways started passenger service using the PKP Pendolino ED250, operating at 200 km/h speed on 80 km of line between Olszamowice and Zawiercie (part of the Central Rail Line from Warsaw to Kraków). Currently it is the line with highest railway speed in Poland. Poland is the first country from the 2004 enlargement of the European Union which offers passenger rail services with scheduled speeds exceeding 160 km/h.
The air and maritime transport markets in Poland are largely well developed. Poland has a number of international airports, the largest of which is Warsaw Chopin Airport, the primary global hub for LOT Polish Airlines. LOT is the 28th largest European airline and the world's 12th oldest still in operation, established in 1929 from a merger of Aerolloyd (1922) and Aero (1925). Major airports with international connections exist in almost every region, for example John Paul II International Airport Kraków–Balice and Wrocław–Copernicus Airport.
Seaports exist all along Poland's Baltic coast, with most freight operations using Szczecin, Świnoujście, Gdynia and Gdańsk as well as Police, Kołobrzeg and Elbląg as their base. Passenger ferries link Poland with Scandinavia all year round; these services are provided from Gdańsk and Świnoujście by Polferries, Stena Line from Gdynia and Unity Line from the Port of Świnoujście.
Science and technology.
According to Frost & Sullivan's Country Industry Forecast the country is becoming an interesting location for research and development investments. Multinational companies such as: ABB, Delphi, GlaxoSmithKline, Google, Hewlett–Packard, IBM, Intel, LG Electronics, Microsoft, Motorola, Siemens and Samsung have set up research and development centres in Poland. Over 40 research and development centers and 4,500 researchers make Poland the biggest research and development hub in Central and Eastern Europe. Companies chose Poland because of the availability of highly qualified labour force, presence of universities, support of authorities, and the largest market in East-Central Europe.
Today Poland's tertiary education institutions; traditional universities (found in its major cities), as well as technical, medical, and economic institutions, employ around 61,000 researchers and members of staff. There are around 300 research and development institutes, with about 10,000 researchers. In total, there are around 91,000 scientists in Poland today. However, in the 19th and 20th centuries many Polish scientists worked abroad; one of the most important of these exiles was Maria Skłodowska-Curie, a physicist and chemist who lived much of her life in France. In the first half of the 20th century, Poland was a flourishing centre of mathematics. Outstanding Polish mathematicians formed the Lwów School of Mathematics (with Stefan Banach, Stanisław Mazur, Hugo Steinhaus, Stanisław Ulam) and Warsaw School of Mathematics (with Alfred Tarski, Kazimierz Kuratowski, Wacław Sierpiński). The events of World War II pushed many of them into exile. Such was the case of Benoît Mandelbrot, whose family left Poland when he was still a child. An alumnus of the Warsaw School of Mathematics was Antoni Zygmund, one of the shapers of 20th-century mathematical analysis.
According to a KPMG report 80% of Poland's current investors are content with their choice and willing to reinvest. In 2006, Intel decided to double the number of employees in its research and development centre in Gdańsk.
Communications.
The share of the telecom sector in the GDP is 4.4% (end of 2000 figure), compared to 2.5% in 1996. The coverage increased from 78 users per 1,000 inhabitants in 1989 to 282 in 2000. The value of the telecommunication market is zl 38.2bn (2006), and it grew by 12.4% in 2007 PMR. The coverage mobile cellular is over 1000 users per 1000 people (2007). Telephones—mobile cellular: 38.7 million (Onet.pl & GUS Report, 2007), telephones—main lines in use: 12.5 million (Telecom Team Report, 2005).
With regard to internet access, the most popular ADSL services for home users in Poland are Neostrada provided by TPSA, and Net24 provided by Netia. Business users as well as some home users use Internet DSL TP also offered by TPSA. According to Eurostat, OECD and others, Internet access in Poland is amidst the most expensive in Europe. This is mostly caused by the lack of competitiveness. New operators, such as Dialog and GTS Energis are making their own provider lines and offer more attractive and cheaper service. The Polish Office of Electronical Communication is forcing the TPSA to rent 51% of their ADSL lines to other ISPs for 60% lower prices. This move will affect the prices of DSL in Poland. In 2012, the process of converting to Digital terrestrial television started, to be compatible with the rest of Europe.
The public postal service in Poland is operated by "Poczta Polska" (the Polish Post). It was created on 18 October 1558, when King Sigismund II Augustus established a permanent postal route from Kraków to Venice. The service was dissolved during the foreign partitions. After regaining independence in 1918, Poland saw the rapid development of the postal system as new services were introduced including money transfers, payment of pensions, delivery of magazines, and air mail. During wars and national uprisings communication was provided mainly through the military authorities. Many important events in the history of Poland involved the postal service, like the heroic defence of the Polish Post Office in Gdańsk in 1939, and the participation of the Polish Scouts' Postal Service in the Warsaw Uprising. Nowadays the service is a modern state-owned company that provides a number of standard and express delivery as well as home-delivery services. Digital technologies are made available through the Internet platform "Envelo".
Demographics.
Poland, with 38,544,513 inhabitants, has the eighth-largest population in Europe and the sixth-largest in the European Union. It has a population density of 122 inhabitants per square kilometer (328 per square mile).
Poland historically contained many languages, cultures and religions on its soil. The country had a particularly large Jewish population prior to World War II, when the Nazi Germany's regime led to The Holocaust. There were an estimated 3 million Jews before the war; 300,000 after. The outcome of the war, particularly the shift of Poland's borders to the area between the Curzon Line and the Oder-Neisse line, coupled with post-war expulsion of minorities, significantly reduced the country's ethnic diversity. Over 7 million Germans fled or were expelled from the Polish side of the Oder-Neisse boundary.
According to the 2002 census, 36,983,700 people, or 96.74% of the population, consider themselves Polish, while 471,500 (1.23%) declared another nationality, and 774,900 (2.03%) did not declare any nationality. The largest minority nationalities and ethnic groups in Poland are Silesians (173,153 according to the census), Germans (152,897 according to the census, 92% of whom live in Opole Voivodeship and Silesian Voivodeship), Belarusians (c. 49,000), Ukrainians (c. 30,000), Lithuanians, Russians, Roma, Jews, Lemkos, Slovaks, Czechs, and Lipka Tatars. Among foreign citizens, the Vietnamese are the largest ethnic group, followed by Armenians. Greeks in Poland aren't a legal national minority, because they arrived only after WWII.
The Polish language, part of the West Slavic branch of the Slavic languages, functions as the official language of Poland. Until recent decades Russian was commonly learned as a second language but has been replaced by English as the most common second language studied and spoken. In 2015, more than 50% of Poles declared to speak English - Russian came second and German came third, whilst French, Italian and Spanish are less popular.
In recent years, Poland's population has decreased due to an increase in emigration and a sharp decline in the birth rate. Since Poland's accession to the European Union, a significant number of Poles have emigrated, primarily to the United Kingdom, Germany and Republic of Ireland in search of better work opportunities abroad.
Polish minorities are still present in the neighboring countries of Ukraine, Belarus, and Lithuania, as well as in other countries (see Poles for population numbers). Altogether, the number of ethnic Poles living abroad is estimated to be around 20 million. The largest number of Poles outside of Poland can be found in the United States.
The total fertility rate (TFR) in Poland was estimated in 2013 at 1.32 children born/woman, which is below the replacement rate of 2.1.
Languages.
Polish.
Polish ("język polski", "polszczyzna") is a Slavic language spoken primarily in Poland and the native language of the Poles. It belongs to the Lechitic subgroup of West Slavic languages. Polish is the official language of Poland, but it is also used throughout the world by Polish minorities in other countries. It is one of the official languages of the European Union. Its written standard is the Polish alphabet, which has 9 additions to the letters of the basic Latin script ("ą", "ć", "ę", "ł", "ń", "ó", "ś", "ź", "ż").
Sign language.
The deaf communities use Polish Sign Language belonging to the German family of Sign Languages.
Minority languages.
According to the Act of 6 January 2005 on national and ethnic minorities and on the regional languages, 16 other languages have officially recognized status of minority languages: 1 regional language, 10 languages of 9 national minorities (the minorities that have their own independent state elsewhere) and 5 languages of 4 ethnic minorities spoken by the members of minorities not having a separate state elsewhere). Jewish and Romani minorities each have 2 minority languages recognized.
Languages having the status of ethnic minority's language.
The official recognition gives to the representatives of the minority certain rights (under certain conditions prescribed by the laws): of education in their language, of having the language established as the secondary administrative language or help language in their municipalities, of financial support of the state to the promotion of their language and culture etc.
Religion.
From its beginnings, Poland has contributed substantially to the development of religious freedom. Since the country adopted Christianity in 966, it was also welcoming to other religions through a series of laws: Statute of Kalisz (1264), Warsaw Confederation (1573). The Polish king Władysław II Jagiełło, however, was pressed by the Catholic Church to issue the Edict of Wieluń (1424), outlawing early Protestant Hussitism. Polish theological thought includes theological movements, such as Calvinist Polish Brethren and a number of other Protestant groups, as well as atheists, such as ex-Jesuit philosopher Kazimierz Łyszczyński, one of the first atheist thinkers in Europe.
Until World War II Poland was a religiously diverse society, in which substantial Jewish, Christian Orthodox, Protestant and Roman Catholic groups coexisted. In the Second Polish Republic, Roman Catholic was the dominant religion, declared by about 65% of the Polish citizens, followed by other Christian denominations, and about 3% of Judaism believers. As a result of the Holocaust and the post–World War II flight and expulsion of German and Ukrainian populations, Poland has become overwhelmingly Roman Catholic. In 2007, 88.4% of the population belonged to the Catholic Church. Though rates of religious observance are lower, at 52% or 51% of the Polish Catholics, Poland remains one of the most devoutly religious countries in Europe.
From 16 October 1978 until his death on 2 April 2005 Karol Józef Wojtyła (later Pope John Paul II), a Polish native, reigned as Supreme Pontiff of the Roman Catholic Church. He has been the only Slavic and Polish Pope to date, and was the first non-Italian Pope since Dutch Pope Adrian VI in 1522. Additionally he is credited with having played a significant role in hastening the downfall of communism in Poland and throughout Central and Eastern Europe; he is famously quoted as having, at the height of communism in 1979, told Poles "not be afraid", later praying: "Let your Spirit descend and change the image of the land... this land".
Religious minorities include Polish Orthodox (about 506,800), various Protestants (about 150,000), Jehovah's Witnesses (126,827), Eastern Catholics, Mariavites, Polish Catholics, Jews, and Muslims (including the Tatars of Białystok). Members of Protestant churches include about 77,500 in the largest Evangelical-Augsburg Church, and a similar number in smaller Pentecostal and Evangelical churches. There are also a few thousand pagans some of whom are members of such officially registered churches as the Native Polish Church, (Rodzimy Kościół Polski).
Freedom of religion is now guaranteed by the 1989 statute of the Polish Constitution, enabling the emergence of additional denominations. The Concordat between the Holy See and Poland guarantees the teaching of religion in state schools. According to a 2007 survey, 72% of respondents were not opposed to religious instruction in public schools; alternative courses in ethics are available only in one percent of the entire public educational system.
Famous sites of Christian pilgrimage in Poland include the Monastery of Jasna Góra in the southern Polish city of Częstochowa, as well as the Family home of John Paul II in Wadowice just outside of Kraków.
Health.
Poland's healthcare system is based on an all-inclusive insurance system. State subsidised healthcare is available to all Polish citizens who are covered by this general health insurance program. However, it is not compulsory to be treated in a state-run hospital as a number of private medical complexes do exist nationwide.
All medical service providers and hospitals in Poland are subordinate to the Polish Ministry of Health, which provides oversight and scrutiny of general medical practice as well as being responsible for the day-to-day administration of the healthcare system. In addition to these roles, the ministry is also tasked with the maintenance of standards of hygiene and patient-care.
Hospitals in Poland are organised according to the regional administrative structure, resultantly most towns have their own hospital "(Szpital Miejski)". Larger and more specialised medical complexes tend only to be found in larger cities, with some even more specialised units located only in the capital, Warsaw. However, all voivodeships have their own general hospital (most have more than one), all of which are obliged to have a trauma centre; these types of hospital, which are able to deal with almost all medical problems are called 'regional hospitals' "(Szpital Wojewódzki)". The last category of hospital in Poland is that of specialised medical centres, an example of which would be the Skłodowska-Curie Institute of Oncology, Poland's leading, and most highly specialised centre for the research and treatment of cancer.
In 2012, the Polish health-care industry experienced a transformation. Hospitals were given priority for refurbishment where necessary. As a result of this process, many hospitals were updated with the latest medical equipment.
In 2013, the average life expectancy at birth was 76.45 years
(72.53 years infant male/80.62 years infant female).
Education.
The Commission of National Education ("Komisja Edukacji Narodowej") established in 1773, was the world's first state ministry of education. The education of Polish society was a goal of rulers as early as the 12th century. Poland became one of the most educated countries in Europe. The library catalogue of the Cathedral Chapter of Kraków dating back to 1110 shows that in the early 12th-century Polish intellectuals had access to European literature. The Jagiellonian University, founded in 1364 by King Casimir III in Kraków was blessed by Pope Urban V. It is the world's 19th oldest university.
The modern-day Programme for International Student Assessment, coordinated by the Organisation for Economic Co-operation and Development, ranks Poland's educational system in its PISA 2012 as the 10th best in the world, scoring higher than the OECD average.
Elementary and secondary.
Education in Poland starts at the age of five or six (with the particular age chosen by the parents) for the '0' class (Kindergarten) and six or seven years in the 1st class of primary school (Polish "szkoła podstawowa"). It is compulsory that children participate in one year of formal education before entering the 1st class at no later than 7 years of age. Corporal punishment of children in schools is officially prohibited since 1783 (before the partitions) and criminalised since 2010 (in schools as well as at home).
At the end of the 6th class when students are 13, students take a compulsory exam that will determine their acceptance and transition into a specific lower secondary school ("gimnazjum, pronounced gheem-nah-sium") (Middle School/Junior High). They will attend this school for three years during classes 7, 8, and 9. Students then take another compulsory exam to determine the upper secondary level school they will attend. There are several alternatives, the most common being the three years in a "liceum" or four years in a technikum. Both end with a maturity examination (matura, quite similar to French baccalauréat), and may be followed by several forms of upper education, leading to licencjat or inżynier (the Polish Bologna Process first cycle qualification), magister (second cycle qualification) and eventually doktor (third cycle qualification).
Higher education.
There are 500 university-level institutions for the pursuit of higher education in Poland, one of the largest number in Europe. The Jagiellonian University in Kraków, the first Polish university, was founded in 1364 by King Casimir III, as the 19th oldest university in the world, established in 1364.
There are 18 fully accredited traditional universities in Poland. There are twenty technical universities, nine independent medical universities, five universities for the study of economics, nine agricultural academies, three pedagogical universities, a theological academy and three maritime service universities.
There are a number of higher educational institutions dedicated to the teaching of the arts. Amongst these are the seven higher state academies of music. There are a number of private educational institutions and four national military academies (two for the army and one each for the other branches of service).
Culture.
The culture of Poland is closely connected with its intricate 1,000-year history Its unique character developed as a result of its geography at the confluence of European cultures. With origins in the culture of the Proto-Slavs, over time Polish culture has been profoundly influenced by its interweaving ties with the Germanic, Latinate and Byzantine worlds as well as in continual dialog with the many other ethnic groups and minorities living in Poland. The people of Poland have traditionally been seen as hospitable to artists from abroad and eager to follow cultural and artistic trends popular in other countries. In the 19th and 20th centuries the Polish focus on cultural advancement often took precedence over political and economic activity. These factors have contributed to the versatile nature of Polish art, with all its complex nuances.
Famous people.
The list of famous Poles begins in earnest with the polymath Mikołaj Kopernik, who studied at the Jagiellonian University founded in 1364 by Casimir the Great from proceeds of his Wieliczka Salt Mine. Poland is the birthplace of many distinguished personalities among whom are: Fryderyk Chopin, Maria Skłodowska Curie, Tadeusz Kościuszko, Kazimierz Pułaski, Józef Piłsudski, Lech Wałęsa and Pope John Paul II (Karol Wojtyła). Great Polish painter Jan Matejko devoted his monumental art to the most significant historical events on Polish lands, along with the playwright, painter and poet Stanisław Wyspiański. Stanisław Ignacy Witkiewicz (Witkacy) was an example of a Polish avant-garde philosopher and author of aesthetic theories. Polish Joseph Conrad was a notable author of works in English. Many world famous Polish movie directors include Academy Awards winners Roman Polański, Andrzej Wajda, Zbigniew Rybczyński, Janusz Kamiński, Krzysztof Kieślowski, and Agnieszka Holland. Actresses known outside of Poland, include Helena Modjeska and Pola Negri.
Society.
Poland has a long-standing tradition of tolerance towards minorities, as well as an absence of discrimination on the grounds of religion, nationality or race.
Prior to World War II, ethnic minorities made up a significant proportion of the Polish population. Poland has maintained a high level of gender equality, an established disability rights movement and promotes peaceful equality.
Poland was the first country in the world to prohibit corporal punishment in all its forms.Poland has, throughout most of its long history, experienced only very limited immigration from abroad; this trend can be largely attributed to Poland's rejection of slavery and to a lack of overseas colonies as well as occupation of its territories during much of the 19th and early 20th centuries. Despite this, the country has for a long time been regarded as having a very tolerant society, which affords equal rights to all people no matter what their ethnic background. This can be said to stem largely from the reign of King Casimir III the Great and his acceptance of Poland's Jewish community, in a time when most of Europe recessed into antisemitic moods and actions. The history of Jews in Poland exemplifies peaceful co-existence of a nation with a particular ethnic group.
Today, as many as 96.7% of Polish citizens declare to be Poles, and 97.8% declare that they speak Polish at home (Census 2002). The population of Poland became one of the most ethnically homogeneous in the world as a result of the radically altered borders after World War II and the subsequent migrations. This homogeneity is a result of post World War II deportations ordered by the Soviet authorities, who wished to remove the sizeable Polish minorities from Lithuania, Belarus and Ukraine and repatriation of Ukrainians from Poland to the Soviet Union (see territorial changes of Poland and historical demography of Poland for details). Unlike in many other countries, the ethnic minority rights in Poland are guaranteed directly by the Constitution of Poland (art. 35), and today there are, among others, sizeable German, Ukrainian and Belarusian minorities in the country.
In 2013, the Polish parliament rejected proposed legislation for civil partnerships, which the majority of Polish society is against, but for the first time it gave an asylum to a gay person from Uganda on the basis of the sexual orientation. In a 2013 opinion poll conducted by CBOS, 60% of Poles were against homosexual civil partnerships, 72% were against same-sex marriage, 88% were against adoption by same-sex couples, and 68% were against gays and lesbians publicly showing their way of life. Article 18 of the Constitution of Poland bans same-sex marriage.
The results of an Organization for Security and Co-operation in Europe (OSCE) survey from 2004 showed that Poles worked the second most hours per week of any nationality worldwide. Poland remains one of the most peaceful countries in the world.
Music.
Artists from Poland, including famous composers like Chopin or Penderecki and traditional, regionalized folk musicians, create a lively and diverse music scene, which even recognizes its own music genres, such as poezja śpiewana and disco polo. As of 2006, Poland is one of the few countries in Europe where rock and hip hop dominate over pop music, while all kinds of alternative music genres are encouraged.
The origins of Polish music can be traced as far back as the 13th century; manuscripts have been found in Stary Sącz, containing polyphonic compositions related to the Parisian Notre Dame School. Other early compositions, such as the melody of "Bogurodzica" and "Bóg się rodzi" (a coronation polonaise for Polish kings by an unknown composer), may also date back to this period, however, the first known notable composer, Mikołaj z Radomia, was born and lived in the 15th century. During the 16th century, two main musical groups – both based in Kraków and belonging to the King and Archbishop of the Wawel – led to the rapid development of Polish music. Composers writing during this period include Wacław z Szamotuł, Mikołaj Zieleński, and Mikołaj Gomółka. Diomedes Cato, a native-born Italian who lived in Kraków from about the age of five, became a renowned lutenist at the court of Sigismund III, and not only imported some of the musical styles from southern Europe, but blended them with native folk music.
At the end of the 18th century, Polish classical music evolved into national forms like the polonaise. In the 19th century the most popular composers were: Józef Elsner and his pupils Fryderyk Chopin and Ignacy Dobrzyński. Important opera composers of the era were Karol Kurpiński and Stanisław Moniuszko whilst the list of famous soloists and composers included Henryk Wieniawski, Juliusz Zarębski. At the turn of the 19th and 20th centuries the most prominent composers could said to have been Władysław Zeleński and Mieczysław Karłowicz, with Karol Szymanowski gaining prominence prior to World War II. Alexandre Tansman lived in Paris but had strong connections with Poland. Witold Lutosławski, Henryk Górecki, and Krzysztof Penderecki composed in Poland, Andrzej Panufnik emigrated.
Traditional Polish folk music has had a major effect on the works of many well-known Polish composers, and no more so than on Fryderyk Chopin, a widely recognised national hero of the arts. All of Chopin's works involve the piano and are technically demanding, emphasising nuance and expressive depth. As a great composer, Chopin invented the musical form known as the instrumental ballade and made major innovations to the piano sonata, mazurka, waltz, nocturne, polonaise, étude, impromptu and prélude, he was also the composer of a number of polonaises which borrowed heavily from traditional Polish folk music. It is largely thanks to him that the such pieces gained great popularity throughout Europe during the 19th century. Nowadays the most distinctive folk music can be heard in the towns and villages of the mountainous south, particularly in the region surrounding the winter resort town of Zakopane.
Today Poland has a very active music scene, with the jazz and metal genres being particularly popular among the contemporary populace. Polish jazz musicians such as Krzysztof Komeda, created a unique style, which was most famous in the 1960s and 1970s and continues to be popular to this day. Since the fall of Communism, Poland has become a major venue for large-scale music festivals, chief among which are the Open'er Festival, Opole Festival and Sopot Festival.
Visual arts.
Polish art has always reflected European trends while maintaining its unique character. The Kraków school of Historicist painting developed by Jan Matejko produced monumental portrayals of customs and significant events in Polish history. Stanisław Witkiewicz was an ardent supporter of realism in Polish art, its main representative being Jozef Chełmoński. The Młoda Polska (Young Poland) movement witnessed the birth of modern Polish art, and engaged in a great deal of formal experimentation led by Jacek Malczewski (Symbolism), Stanisław Wyspiański, Józef Mehoffer, and a group of Polish Impressionists. Artists of the twentieth-century Avant-Garde represented various schools and trends. The art of Tadeusz Makowski was influenced by Cubism; while Władysław Strzemiński and Henryk Stażewski worked within the Constructivist idiom. Distinguished contemporary artists include Roman Opałka, Leon Tarasewicz, Jerzy Nowosielski, Wojciech Siudmak, Mirosław Bałka, and Katarzyna Kozyra and Zbigniew Wąsiel in the younger generation. The most celebrated Polish sculptors include Xawery Dunikowski, Katarzyna Kobro, Alina Szapocznikow and Magdalena Abakanowicz. Since the inter-war years, Polish art and documentary photography has enjoyed worldwide recognition. In the sixties the Polish Poster School was formed, with Henryk Tomaszewski and Waldemar Świerzy at its head. Top fine Art schools in Poland are Jan Matejko Academy of Fine Arts, Cracow School of Art and Fashion Design, Academy of Fine Arts in Warsaw, Art Academy of Szczecin, University of Fine Arts in Poznań and Eugeniusz Geppert Academy of Fine Arts.
Architecture.
Polish cities and towns reflect the whole spectrum of European styles. Romanesque architecture is represented by St. Andrew's Church, Kraków, and St. Mary's Church, Gdańsk, is characteristic for the Brick Gothic style found in Poland. Richly decorated attics and arcade loggias are the common elements of the Polish Renaissance architecture, as evident in the City Hall in Poznań. For some time the late renaissance style known as mannerism, most notably in the Bishop's Palace in Kielce, coexisted with the early baroque style, typified in the Church of SS. Peter and Paul in Kraków.
History has not been kind to Poland's architectural monuments. Nonetheless, a number of ancient structures has survived: castles, churches, and stately homes, often unique in the regional or European context. Some of them have been painstakingly restored, like Wawel Castle, or completely reconstructed after being destroyed in the Second World War, including the Old Town and Royal Castle of Warsaw and the Old Town of Gdańsk.
The architecture of Gdańsk is mostly of the Hanseatic variety, a Gothic style common among the former trading cities along the Baltic sea and in the northern part of Central Europe. The architectural style of Wrocław is mainly representative of German architecture, since it was for centuries located within the German states. The centre of Kazimierz Dolny on the Vistula is a good example of a well-preserved medieval town. Poland's ancient capital, Kraków, ranks among the best-preserved Gothic and Renaissance urban complexes in Europe. Meanwhile, the legacy of the Kresy Marchlands of Poland's eastern regions, where Wilno and Lwów (now "Vilnius" and "Lviv") were recognised as two major centres for the arts, played a special role in the development of Polish architecture, with Catholic church architecture deserving special note.
The second half of the 17th century is marked by baroque architecture. Side towers, such as those of Branicki Palace in Białystok, are typical for the Polish baroque. The classical Silesian baroque is represented by the University in Wrocław. The profuse decorations of the Branicki Palace in Warsaw are characteristic of the rococo style. The centre of Polish classicism was Warsaw under the rule of the last Polish king Stanisław August Poniatowski. The Palace on the Water is the most notable example of Polish neoclassical architecture. Lublin Castle represents the Gothic Revival style in architecture, while the Izrael Poznański Palace in Łódź is an example of eclecticism.
Literature.
Polish literature dates back to the 12th century, and includes many renowned writers. Two Polish novelists have won the Nobel Prize in Literature: Henryk Sienkiewicz, and Władysław Reymont; along with two poets: Czesław Miłosz, and Wisława Szymborska. A prose poet of the highest order, Joseph Conrad (1857–1924), son of the Polish dramatist Apollo Korzeniowski, won world-wide fame with his English-language novels and stories that are informed with elements of the Polish national experience. Among the best known Polish Romantics are the "Three Bards" — the three national poets active in the age of Partitions: Adam Mickiewicz, Juliusz Słowacki, and Zygmunt Krasiński.
During the Middle Ages, most Polish writers and scholars (e.g., Jan Długosz) wrote only in Latin, the common language of European letters. This tradition was broken by Jan Kochanowski, who became one of the first Polish Renaissance authors to write most of his works in Polish, along with Mikołaj Rej. Especially notable 19th- and 20th-century Polish authors include Bolesław Prus, Kornel Makuszyński, Stanisław Lem, and Witold Gombrowicz among others.
Media.
Poland has instituted freedom of press since the fall of communism, a system under which the media was heavily politically controlled and censored. However, public TV and radio are still regulated by the government, this is exercised through an agency called "Krajowa Rada Radiofonii i Telewizji" ("The National Radio and Television Committee"), which is similar to television regulatory commissions in other developed nations.
Poland has a number of major media outlets, chief among which are the national television channels. TVP is Poland's public broadcasting corporation; about a third of its income comes from a broadcast receiver licence, while the rest is made through revenue from commercials and sponsorships. State television operates two mainstream channels, TVP 1 and TVP 2, as well as regional programs (TVP Info) for each of the country's 16 voivodeships. In addition to these general channels, TVP runs a number of genre-specific programmes such as TVP Sport, TVP Historia, TVP Kultura, TVP Seriale and TV Polonia, the latter is a state-run channel dedicated to the transmission of Polish language television for the Polish diaspora abroad.
Poland has a number of internationally broadcast and 24-hour news channels, chief among which are Polsat News, TVN 24. There are a number of major private television outlets such as Polsat and the TVN network.
Poland has a highly developed printed news industry, with daily newspapers like "Gazeta Wyborcza" ("Electoral Gazette"), "Rzeczpospolita" ("The Republic") and "Gazeta Polska Codziennie" ("Polish Daily Newspaper") providing more traditional, intellectually stimulating reporting and tabloids such as "Fakt" providing more sensationalist writing which is less current affairs orientated. "Rzeczpospolita" is one of the nation's oldest publications still in operation. Founded in 1920, it has become a stalwart bastion of Polish reporting and in 2006 won a prestigious award for being, along with the "Guardian" (a British daily), the best designed newspaper in the world. The most popular weeklies are Tygodnik Angora, Polityka, Wprost, Newsweek Polska, Gość Niedzielny, and Gazeta Polska.
Cuisine.
Polish cuisine has evolved over the centuries to become very eclectic due to Poland's history. Polish cuisine shares many similarities with other Central European cuisines, especially German and Austrian as well as Jewish, Belarusian, Ukrainian, Russian, French and Italian culinary traditions. It is rich in meat, especially pork, chicken and beef (depending on the region) and winter vegetables (cabbage in the dish "bigos"), and spices. It is also characteristic in its use of various kinds of noodles the most notable of which are kluski as well as cereals such as "kasha" (from the Polish word kasza). Polish cuisine is hearty and uses a lot of cream and eggs. Festive meals such as the meatless Christmas eve dinner ("Wigilia") or Easter breakfast could take days to prepare in their entirety.
The main course usually includes a serving of meat, such as roast, chicken, or "kotlet schabowy" (breaded pork cutlet), vegetables, side dishes and salads, including "surówka" – shredded root vegetables with lemon and sugar (carrot, celeriac, seared beetroot) or sauerkraut (, ). The side dishes are usually potatoes, rice or "kasza" (cereals). Meals conclude with a dessert such as "sernik", "makowiec" (a poppy seed pastry), or "drożdżówka" yeast pastry, and tea.
The Polish national dishes are "bigos" ; "pierogi" ; "kielbasa"; "kotlet schabowy" breaded cutlet; "gołąbki" cabbage rolls; "zrazy" roulade; "pieczeń" roast ; sour cucumber soup ("zupa ogórkowa", ); mushroom soup, ("zupa grzybowa", quite different from the North American cream of mushroom); "zupa pomidorowa" tomato soup ; "rosół" variety of meat broth; "żurek" sour rye soup; "flaki" tripe soup; "barszcz" and "chłodnik" among others.
Traditional alcoholic beverages include honey mead, widespread since the 13th century, beer, wine and vodka (old Polish names include "okowita" and "gorzałka"). The world's first written mention of vodka originates from Poland. The most popular alcoholic drinks at present are beer and wine which took over from vodka more popular in the years 1980-1998. Tea remains common in Polish society since the 19th century, whilst coffee is drunk widely since the 18th century. Other frequently consumed beverages include various mineral waters and juices, soft drinks popularized by the fast-food chains since the late 20th century, as well as buttermilk, soured milk and kefir.
Sports.
Football (soccer) is one of country's most popular sports, with a rich history of international competitions. Track and field, basketball, volleyball, handball, boxing, MMA, motorcycle speedway, ski jumping, cross-country skiing, ice hockey, tennis, fencing, swimming and weightlifting are other popular sports.
The golden era of football in Poland occurred throughout the 1970s and went on until the early 1980s when the Polish national football team achieved their best results in any FIFA World Cup competitions finishing 3rd place in the 1974 and the 1982 tournaments. The team won a gold medal in football at the 1972 Summer Olympics and two silver medals, in 1976 and in 1992. Poland, along with Ukraine, hosted the UEFA European Football Championship in 2012.
The Polish men's national volleyball team is ranked as 3rd in the world. Mariusz Pudzianowski is a highly successful strongman competitor and has won more World's Strongest Man titles than any other competitor in the world, winning the event in 2008 for the fifth time. The first Polish Formula One driver, Robert Kubica, has brought awareness of Formula One Racing to Poland.
Poland has made a distinctive mark in motorcycle speedway racing thanks to Tomasz Gollob, a highly successful Polish rider. The top Ekstraliga division has one of the highest average attendances for any sport in Poland. The national speedway team of Poland, one of the major teams in international speedway, has won the Speedway World Team Cup championships three times consequtively, in 2009, 2010, and 2011. No team has ever managed such feat.
Poles made significant achievements in mountaineering, in particular, in the Himalayas and the winter ascending of the eight-thousanders. The most famous Polish climbers are Jerzy Kukuczka, Krzysztof Wielicki, Piotr Pustelnik, Andrzej Zawada, Maciej Berbeka, Artur Hajzer, Andrzej Czok, Wojciech Kurtyka, and women Wanda Rutkiewicz, and Kinga Baranowska. Polish mountains are one of the tourist attractions of the country. Hiking, climbing, skiing and mountain biking and attract numerous tourists every year from all over the world. Water sports are the most popular summer recreation activities, with ample locations for fishing, canoeing, kayaking, sailing and windsurfing especially in the northern regions of the country.
International rankings.
The following are links to international rankings of Poland from selected research institutes and foundations including economic output and various composite indices.

</doc>
<doc id="22938" url="https://en.wikipedia.org/wiki?curid=22938" title="Performing arts">
Performing arts

Performing arts are art forms in which artists use their voices and/or the movements of their bodies, often in relation to other objects, to convey artistic expression—as opposed to, for example, purely visual arts, in which artists use paint/canvas or various materials to create physical or static art objects. Performing arts include a variety of disciplines but all are intended to be performed in front of a live audience.
Performers.
Artists who participate in performing arts in front of an audience are called performers. Example of this include actors, comedians, dancers, magicians, circus artists, musicians, and singers. Performing arts are also supported by workers in related fields, such as songwriting, choreography and stagecraft.
A performer who excels in acting, singing, and dancing is commonly referred to as a "triple threat". Well-known examples of historical triple threat artists include Gene Kelly, Fred Astaire, and Judy Garland.
Performers often adapt their appearance, such as with costumes and stage makeup, stage lighting, and sound.
Types.
Performing arts may include dance, music, opera, theatre and musical theatre, magic, illusion, mime, spoken word, puppetry, circus arts, performance art, recitation and public speaking.
There is also a specialized form of fine art, in which the artists "perform" their work live to an audience. This is called performance art. Most performance art also involves some form of plastic art, perhaps in the creation of props. Dance was often referred to as a "plastic art" during the Modern dance era.
Theatre.
Theatre is the branch of performing arts; concerned with acting out stories in front of an audience, using a combination of speech, gesture, music, dance, sound and spectacle. Any one or more of these elements is performing arts. In addition to the standard narrative dialogue style of plays. Theatre takes such forms as plays, musicals, opera, ballet, illusion, mime, classical Indian dance, kabuki, mummers' plays, improvisational theatre, stand-up comedy, pantomime, and non-conventional or contemporary forms like postmodern theatre, postdramatic theatre, or performance art .
Dance.
In the context of performing arts, dance generally refers to human movement, typically rhythmic and to music, used as a form of audience entertainment in a performance setting. Definitions of what constitutes dance are dependent on social, cultural, aesthetic artistic and moral constraints and range from functional movement (such as folk dance) to codified, virtuoso techniques such as ballet.
Dance is a powerful impulse, but the art of dance is that impulse channeled by skillful performers into something that becomes intensely expressive and that may delight spectators who feel no wish to dance themselves. These two concepts of the art of dance—dance as a powerful impulse and dance as a skillfully choreographed art practiced largely by a professional few—are the two most important connecting ideas running through any consideration of the subject. In dance, the connection between the two concepts is stronger than in some other arts, and neither can exist without the other.
Choreography is the art of making dances, and the person who practices this art is called a choreographer.
History.
History of Western performing arts.
Starting in the 6th century BC, the Classical period of performing art began in Greece, ushered in by the tragic poets such as Sophocles. These poets wrote plays which, in some cases, incorporated dance (see Euripides). The Hellenistic period began the widespread use of comedy.
However, by the 6th century AD, Western performing arts had been largely ended, as the Dark Ages began. Between the 9th century and 14th century, performing art in the West was limited to religious historical enactments and morality plays, organized by the Church in celebration of holy days and other important events.
Renaissance.
In the 15th century performing arts, along with the arts in general, saw a revival as the Renaissance began in Italy and spread throughout Europe plays, some of which incorporated dance, which were performed and Domenico da Piacenza credited with the first use of the term "ballo" (in "De Arte Saltandi et Choreas Ducendi") instead of "danza" (dance) for his "baletti" or "balli". The term eventually became "Ballet". The first Ballet "per se" is thought to be Balthasar de Beaujoyeulx's Ballet Comique de la Reine (1581).
By the mid-16th century Commedia Dell'arte became popular in Europe, introducing the use of improvisation. This period also introduced the Elizabethan masque, featuring music, dance and elaborate costumes as well as professional theatrical companies in England. William Shakespeare's plays in the late 16th century developed from this new class of professional performance.
In 1597, the first opera, Dafne was performed and throughout the 17th century, opera would rapidly become the entertainment of choice for the aristocracy in most of Europe, and eventually for large numbers of people living in cities and towns throughout Europe.
Modern era.
The introduction of the proscenium arch in Italy during the 17th century established the traditional theatre form that persists to this day. Meanwhile, in England, the Puritans forbade acting, bringing a halt to performing arts that lasted until 1660. After that, women began to appear in both French and English plays. The French introduced a formal dance instruction in the late 17th century.
It is also during this time that the first plays were performed in the American Colonies.
During the 18th century, the introduction of the popular opera buffa brought opera to the masses as an accessible form of performance. Mozart's "The Marriage of Figaro" and "Don Giovanni" are landmarks of the late 18th century opera.
At the turn of the 19th century, Beethoven and the Romantic movement ushered in a new era that led first to the spectacles of grand opera and then to the musical dramas of Giuseppe Verdi and the Gesamtkunstwerk (total work of art) of the operas of Richard Wagner leading directly to the music of the 20th century.
The 19th century was a period of growth for the performing arts for all social classes, technical advances such as the introduction of gaslight to theatres, burlesque, minstrel dancing, and variety theatre. In ballet, women make great progress in the previously male-dominated art.
Modern dance began in the late 19th century and early 20th century in response to the restrictions of traditional ballet.
Konstantin Stanislavski's "System" revolutionized acting in the early 20th century, and continues to have a major influence on actors of stage and screen to the current day. Both impressionism and modern realism were introduced to the stage during this period.
The arrival of Sergei Diaghilev's Ballets Russes (1909–1929) revolutionized ballet and the performing arts generally throughout the Western world, most importantly through Diaghilev's emphasis on collaboration, which brought choreographers, dancers, set designers/artists, composers and musicians together to revitalize and revolutionize ballet. It is extremely complex.
With the invention of the motion picture in the late 19th century by Thomas Edison and the growth of the motion picture industry in Hollywood in the early 20th century, film became a dominant performance medium throughout the 20th and 21st centuries.
Rhythm and blues, a cultural phenomenon of black America, became to prominence in the early 20th century; influencing a range of later popular music styles internationally.
In the 1930s Jean Rosenthal introduced what would become modern stage lighting, changing the nature of the stage as the Broadway musical became a phenomenon in the United States.
Post-War performance.
Post-World War II performing arts were highlighted by the resurgence of both ballet and opera in the Western world.
Postmodernism in performing arts dominated the 1960s to large extent.
History of Eastern performing arts.
Middle East.
The earliest recorded theatrical event dates back to 2000 BC with the passion plays of Ancient Egypt. This story of the god Osiris was performed annually at festivals throughout the civilization, marking the known beginning of a long relationship between theatre and religion.
The most popular forms of theater in the medieval Islamic world were puppet theatre (which included hand puppets, shadow plays and marionette productions) and live passion plays known as "ta'ziya", where actors re-enact episodes from Muslim history. In particular, Shia Islamic plays revolved around the "shaheed" (martyrdom) of Ali's sons Hasan ibn Ali and Husayn ibn Ali. Live secular plays were known as "akhraja", recorded in medieval "adab" literature, though they were less common than puppetry and "ta'ziya" theater.
Iran.
In Iran there are other forms of theatrical events such as "Naghali" (story telling), "ٰRu-Howzi", "Siah-Bazi", "Parde-Khani, ""Mareke giri".
India and Pakistan.
Folk theatre and dramatics can be traced to the religious ritualism of the Vedic peoples in the 2nd millennium BC. This folk theatre of the misty past was mixed with dance, food, ritualism, plus a depiction of events from daily life. The last element made it the origin of the classical theatre of later times. Many historians, notably D. D. Kosambi, Debiprasad Chattopadhyaya, Adya Rangacharaya, etc. have referred to the prevalence of ritualism amongst Indo-Aryan tribes in which some members of the tribe acted as if they were wild animals and some others were the hunters. Those who acted as mammals like goats, buffaloes, reindeer, monkeys, etc. were chased by those playing the role of hunters.
Bharata Muni (fl. 5th–2nd century BC) was an ancient Indian writer best known for writing the "Natya Shastra of Bharata", a theoretical treatise on Indian performing arts, including theatre, dance, acting, and music, which has been compared to Aristotle's "Poetics". Bharata is often known as the father of Indian theatrical arts. His "Natya Shastra" seems to be the first attempt to develop the technique or rather art, of drama in a systematic manner. The Natya Shastra tells us not only what is to be portrayed in a drama, but how the portrayal is to be done. Drama, as Bharata Muni says, is the imitation of men and their doings ("loka-vritti"). As men and their doings have to be respected on the stage, so drama in Sanskrit is also known by the term "roopaka," which means portrayal.
The "Ramayana" and "Mahabharata" can be considered the first recognized plays that originated in India. These epics provided the inspiration to the earliest Indian dramatists and they do it even today. Indian dramatists such as Bhāsa in the 2nd century BC wrote plays that were heavily inspired by the "Ramayana" and "Mahabharata".
Kālidāsa in the 1st century BC, is arguably considered to be ancient India's greatest dramatist. Three famous romantic plays written by Kālidāsa are the "Mālavikāgnimitram" ("Mālavikā and Agnimitra"), "Vikramōrvaśīyam" ("Pertaining to Vikrama and Urvashi"), and "Abhijñānaśākuntala" ("The Recognition of Shakuntala"). The last was inspired by a story in the "Mahabharata" and is the most famous. It was the first to be translated into English and German. In comparison to Bhāsa, who drew heavily from the epics, Kālidāsa can be considered an original playwright.
The next great Indian dramatist was Bhavabhuti (c. 7th century). He is said to have written the following three plays: "Malati-Madhava", "Mahaviracharita" and "Uttar Ramacharita". Among these three, the last two cover between them, the entire epic of "Ramayana". The powerful Indian emperor Harsha (606–648) is credited with having written three plays: the comedy "Ratnavali", "Priyadarsika", and the Buddhist drama "Nagananda". Many other dramatists followed during the Middle Ages.
There were many performing art forms in the southern part of India, Kerala is such a state with different such art forms like Koodiyattam, Nangyarkoothu, Kathakali, Chakyar koothu and there were many prominent artists like Painkulam Raman Chakyar and others.
China.
There are references to theatrical entertainments in China as early as 1500 BC during the Shang Dynasty; they often involved music, clowning and acrobatic displays.
The Tang dynasty is sometimes known as "The Age of 1000 Entertainments". During this era, Emperor Xuanzong formed an acting school known as the Children of the Pear Garden to produce a form of drama that was primarily musical.
During the Han Dynasty, shadow puppetry first emerged as a recognized form of theatre in China. There were two distinct forms of shadow puppetry, Cantonese southern and Pekingese northern. The two styles were differentiated by the method of making the puppets and the positioning of the rods on the puppets, as opposed to the type of play performed by the puppets. Both styles generally performed plays depicting great adventure and fantasy, rarely was this very stylized form of theatre used for political propaganda. Cantonese shadow puppets were the larger of the two. They were built using thick leather that created more substantial shadows. Symbolic color was also very prevalent; a black face represented honesty, a red one bravery. The rods used to control Cantonese puppets were attached perpendicular to the puppets' heads. Thus, they were not seen by the audience when the shadow was created. Pekingese puppets were more delicate and smaller. They were created out of thin, translucent leather usually taken from the belly of a donkey. They were painted with vibrant paints, thus they cast a very colorful shadow. The thin rods that controlled their movements were attached to a leather collar at the neck of the puppet. The rods ran parallel to the bodies of the puppet then turned at a ninety degree angle to connect to the neck. While these rods were visible when the shadow was cast, they laid outside the shadow of the puppet; thus they did not interfere with the appearance of the figure. The rods attached at the necks to facilitate the use of multiple heads with one body. When the heads were not being used, they were stored in a muslin book or fabric lined box. The heads were always removed at night. This was in keeping with the old superstition that if left intact, the puppets would come to life at night. Some puppeteers went so far as to store the heads in one book and the bodies in another, to further reduce the possibility of reanimating puppets. Shadow puppetry is said to have reached its highest point of artistic development in the 11th century before becoming a tool of the government.
In the Song dynasty, there were many popular plays involving acrobatics and music. These developed in the Yuan Dynasty into a more sophisticated form with a four- or five-act structure. Yuan drama spread across China and diversified into numerous regional forms, the best known of which is Beijing Opera, which is still popular today.
Thailand.
In Thailand, it has been a tradition from the Middle Ages to stage plays based on plots drawn from Indian epics. In particular, the theatrical version of Thailand's national epic "Ramakien", a version of the Indian "Ramayana", remains popular in Thailand even today.
Cambodia.
In Cambodia, at the ancient capital Angkor Wat, stories from the Indian epics "Ramayana" and "Mahabharata" have been carved on the walls of temples and palaces. Similar reliefs are found at Borobudur in Indonesia.
Japan.
During the 14th century, there were small companies of actors in Japan who performed short, sometimes vulgar comedies. A director of one of these companies, Kan'ami (1333–1384), had a son, Zeami Motokiyo (1363–1443) who was considered one of the finest child actors in Japan. When Kan'ami's company performed for Ashikaga Yoshimitsu (1358–1408), the Shogun of Japan, he implored Zeami to have a court education for his arts. After Zeami succeeded his father, he continued to perform and adapt his style into what is today Noh. A mixture of pantomime and vocal acrobatics, this style has fascinated the Japanese for hundreds of years.
Japan, after a long period of civil wars and political disarray, was unified and at peace primarily due to shogun Tokugawa Ieyasu (1600–1668). However, alarmed at increasing Christian growth, he cut off contact from Japan to Europe and China and outlawed Christianity. When peace did come, a flourish of cultural influence and growing merchant class demanded its own entertainment. The first form of theatre to flourish was Ningyō jōruri (commonly referred to as Bunraku). The founder of and main contributor to Ningyō jōruri, Chikamatsu Monzaemon (1653–1725), turned his form of theatre into a true art form. Ningyō jōruri is a highly stylized form of theatre using puppets, today about 1/3d the size of a human. The men who control the puppets train their entire lives to become master puppeteers, when they can then operate the puppet's head and right arm and choose to show their faces during the performance. The other puppeteers, controlling the less important limbs of the puppet, cover themselves and their faces in a black suit, to imply their invisibility. The dialogue is handled by a single person, who uses varied tones of voice and speaking manners to simulate different characters. Chikamatsu wrote thousands of plays during his lifetime, most of which are still used today.
Kabuki began shortly after Bunraku, legend has it by an actress named Okuni, who lived around the end of the 16th century. Most of Kabuki's material came from Nõ and Bunraku, and its erratic dance-type movements are also an effect of Bunraku. However, Kabuki is less formal and more distant than Nõ, yet very popular among the Japanese public. Actors are trained in many varied things including dancing, singing, pantomime, and even acrobatics. Kabuki was first performed by young girls, then by young boys, and by the end of the 16th century, Kabuki companies consisted of all men. The men who portrayed women on stage were specifically trained to elicit the essence of a woman in their subtle movements and gestures.

</doc>
<doc id="22939" url="https://en.wikipedia.org/wiki?curid=22939" title="Physics">
Physics

Physics (from , from "phúsis" "nature") is the natural science that involves the study of matter and its motion through space and time, along with related concepts such as energy and force. More broadly, it is "one" of the main analysis of nature, conducted in order to understand how the universe behaves.
Physics is one of the oldest academic disciplines, perhaps the oldest through its inclusion of astronomy. Over the last two millennia, physics was a part of natural philosophy along with chemistry, certain branches of mathematics, and biology, but during the scientific revolution in the 17th century, the natural sciences emerged as unique research programs in their own right. Physics intersects with many interdisciplinary areas of research, such as biophysics and quantum chemistry, and the boundaries of physics are not rigidly defined. New ideas in physics often explain the fundamental mechanisms of other sciences while opening new avenues of research in areas such as mathematics and philosophy.
Physics also makes significant contributions through advances in new technologies that arise from theoretical breakthroughs. For example, advances in the understanding of electromagnetism or nuclear physics led directly to the development of new products that have dramatically transformed modern-day society, such as television, computers, domestic appliances, and nuclear weapons; advances in thermodynamics led to the development of industrialization, and advances in mechanics inspired the development of calculus.
History.
Ancient astronomy.
Astronomy is the oldest of the natural sciences. The earliest civilizations dating back to beyond 3000 BCE, such as the Sumerians, ancient Egyptians, and the Indus Valley Civilization, all had a predictive knowledge and a basic understanding of the motions of the Sun, Moon, and stars. The stars and planets were often a target of worship, believed to represent their gods. While the explanations for these phenomena were often unscientific and lacking in evidence, these early observations laid the foundation for later astronomy.
According to Asger Aaboe, the origins of Western astronomy can be found in Mesopotamia, and all Western efforts in the exact sciences are descended from late Babylonian astronomy. Egyptian astronomers left monuments showing knowledge of the constellations and the motions of the celestial bodies, while Greek poet Homer wrote of various celestial objects in his "Iliad" and "Odyssey"; later Greek astronomers provided names, which are still used today, for most constellations visible from the northern hemisphere.
Natural philosophy.
Natural philosophy has its origins in Greece during the Archaic period, (650 BCE – 480 BCE), when Pre-Socratic philosophers like Thales rejected non-naturalistic explanations for natural phenomena and proclaimed that every event had a natural cause. They proposed ideas verified by reason and observation, and many of their hypotheses proved successful in experiment; for example, atomism was found to be correct approximately 2000 years after it was first proposed by Leucippus and his pupil Democritus.
Classical physics.
Physics became a separate science when early modern Europeans used experimental and quantitative methods to discover what are now considered to be the laws of physics.
Major developments in this period include the replacement of the geocentric model of the solar system with the helio-centric Copernican model, the laws governing the motion of planetary bodies determined by Johannes Kepler between 1609 and 1619, pioneering work on telescopes and observational astronomy by Galileo Galilei in the 16th and 17th Centuries, and Isaac Newton's discovery and unification of the laws of motion and universal gravitation that would come to bear his name. Newton also developed calculus, the mathematical study of change, which provided new mathematical methods for solving physical problems.
The discovery of new laws in thermodynamics, chemistry, and electromagnetics resulted from greater research efforts during the Industrial Revolution as energy needs increased. The laws comprising classical physics remain very widely used for objects on everyday scales travelling at non-relativistic speeds, since they provide a very close approximation in such situations, and theories such as quantum mechanics and the theory of relativity simplify to their classical equivalents at such scales. However, inaccuracies in classical mechanics for very small objects and very high velocities led to the development of modern physics in the 20th century.
Modern physics.
Modern physics began in the early 20th century with the work of Max Planck in quantum theory and Albert Einstein's theory of relativity. Both of these theories came about due to inaccuracies in classical mechanics in certain situations. Classical mechanics predicted a varying speed of light, which could not be resolved with the constant speed predicted by Maxwell's equations of electromagnetism; this discrepancy was corrected by Einstein's theory of special relativity, which replaced classical mechanics for fast-moving bodies and allowed for a constant speed of light. Black body radiation provided another problem for classical physics, which was corrected when Planck proposed that light comes in individual packets known as photons; this, along with the photoelectric effect and a complete theory predicting discrete energy levels of electron orbitals, led to the theory of quantum mechanics taking over from classical physics at very small scales.
Quantum mechanics would come to be pioneered by Werner Heisenberg, Erwin Schrödinger and Paul Dirac. From this early work, and work in related fields, the Standard Model of particle physics was derived. Following the discovery of a particle with properties consistent with the Higgs boson at CERN in 2012, all fundamental particles predicted by the standard model, and no others, appear to exist; however, physics beyond the Standard Model, with theories such as supersymmetry, is an active area of research. Areas of mathematics in general are important to this field, such as study of probabilities.
Philosophy.
In many ways, physics stems from ancient Greek philosophy. From Thales' first attempt to characterize matter, to Democritus' deduction that matter ought to reduce to an invariant state, the Ptolemaic astronomy of a crystalline firmament, and Aristotle's book "Physics" (an early book on physics, which attempted to analyze and define motion from a philosophical point of view), various Greek philosophers advanced their own theories of nature. Physics was known as natural philosophy until the late 18th century.
By the 19th century, physics was realized as a discipline distinct from philosophy and the other sciences. Physics, as with the rest of science, relies on philosophy of science and its "scientific method" to advance our knowledge of the physical world. The scientific method employs "a priori reasoning" as well as "a posteriori" reasoning and the use of Bayesian inference to measure the validity of a given theory.
The development of physics has answered many questions of early philosophers, but has also raised new questions. Study of the philosophical issues surrounding physics, the philosophy of physics, involves issues such as the nature of space and time, determinism, and metaphysical outlooks such as empiricism, naturalism and realism.
Many physicists have written about the philosophical implications of their work, for instance Laplace, who championed causal determinism, and Erwin Schrödinger, who wrote on quantum mechanics. The mathematical physicist Roger Penrose has been called a Platonist by Stephen Hawking, a view Penrose discusses in his book, "The Road to Reality". Hawking refers to himself as an "unashamed reductionist" and takes issue with Penrose's views.
Core theories.
Though physics deals with a wide variety of systems, certain theories are used by all physicists. Each of these theories were experimentally tested numerous times and found to be an adequate approximation of nature. For instance, the theory of classical mechanics accurately describes the motion of objects, provided they are much larger than atoms and moving at much less than the speed of light. These theories continue to be areas of active research today. Chaos theory, a remarkable aspect of classical mechanics was discovered in the 20th century, three centuries after the original formulation of classical mechanics by Isaac Newton (1642–1727).
These central theories are important tools for research into more specialised topics, and any physicist, regardless of their specialisation, is expected to be literate in them. These include classical mechanics, quantum mechanics, thermodynamics and statistical mechanics, electromagnetism, and special relativity.
Classical physics.
Classical physics includes the traditional branches and topics that were recognised and well-developed before the beginning of the 20th century—classical mechanics, acoustics, optics, thermodynamics, and electromagnetism. Classical mechanics is concerned with bodies acted on by forces and bodies in motion and may be divided into statics (study of the forces on a body or bodies not subject to an acceleration), kinematics (study of motion without regard to its causes), and dynamics (study of motion and the forces that affect it); mechanics may also be divided into solid mechanics and fluid mechanics (known together as continuum mechanics), the latter include such branches as hydrostatics, hydrodynamics, aerodynamics, and pneumatics. Acoustics is the study of how sound is produced, controlled, transmitted and received. Important modern branches of acoustics include ultrasonics, the study of sound waves of very high frequency beyond the range of human hearing; bioacoustics the physics of animal calls and hearing, and electroacoustics, the manipulation of audible sound waves using electronics. Optics, the study of light, is concerned not only with visible light but also with infrared and ultraviolet radiation, which exhibit all of the phenomena of visible light except visibility, e.g., reflection, refraction, interference, diffraction, dispersion, and polarization of light. Heat is a form of energy, the internal energy possessed by the particles of which a substance is composed; thermodynamics deals with the relationships between heat and other forms of energy. Electricity and magnetism have been studied as a single branch of physics since the intimate connection between them was discovered in the early 19th century; an electric current gives rise to a magnetic field, and a changing magnetic field induces an electric current. Electrostatics deals with electric charges at rest, electrodynamics with moving charges, and magnetostatics with magnetic poles at rest.
Modern physics.
Classical physics is generally concerned with matter and energy on the normal scale of observation, while much of modern physics is concerned with the behavior of matter and energy under extreme conditions or on a very large or very small scale. For example, atomic and nuclear physics studies matter on the smallest scale at which chemical elements can be identified. The physics of elementary particles is on an even smaller scale since it is concerned with the most basic units of matter; this branch of physics is also known as high-energy physics because of the extremely high energies necessary to produce many types of particles in particle accelerators. On this scale, ordinary, commonsense notions of space, time, matter, and energy are no longer valid.
The two chief theories of modern physics present a different picture of the concepts of space, time, and matter from that presented by classical physics. Classical mechanics approximates nature as continuous, while quantum theory is concerned with the discrete nature of many phenomena at the atomic and subatomic level and with the complementary aspects of particles and waves in the description of such phenomena. The theory of relativity is concerned with the description of phenomena that take place in a frame of reference that is in motion with respect to an observer; the special theory of relativity is concerned with relative uniform motion in a straight line and the general theory of relativity with accelerated motion and its connection with gravitation. Both quantum theory and the theory of relativity find applications in all areas of modern physics.
Difference between classical and modern physics.
While physics aims to discover universal laws, its theories lie in explicit domains of applicability. Loosely speaking, the laws of classical physics accurately describe systems whose important length scales are greater than the atomic scale and whose motions are much slower than the speed of light. Outside of this domain, observations do not match predictions provided by classical mechanics. Albert Einstein contributed the framework of special relativity, which replaced notions of absolute time and space with spacetime and allowed an accurate description of systems whose components have speeds approaching the speed of light. Max Planck, Erwin Schrödinger, and others introduced quantum mechanics, a probabilistic notion of particles and interactions that allowed an accurate description of atomic and subatomic scales. Later, quantum field theory unified quantum mechanics and special relativity. General relativity allowed for a dynamical, curved spacetime, with which highly massive systems and the large-scale structure of the universe can be well-described. General relativity has not yet been unified with the other fundamental descriptions; several candidate theories of quantum gravity are being developed.
Relation to other fields.
Prerequisites.
Mathematics provides a compact and exact language used to describe of the order in nature. This was noted and advocated by Pythagoras, Plato, Galileo, and Newton.
Physics uses mathematics to organize and formulate experimental results. From those results, precise or estimated solutions, quantitative results from which new predictions can be made and experimentally confirmed or negated. The results from physics experiments are numerical measurements. Technologies based on mathematics, like computation have made computational physics an active area of research.
Ontology is a prerequisite for physics, but not for mathematics. It means physics is ultimately concerned with descriptions of the real world, while mathematics is concerned with abstract patterns, even beyond the real world. Thus physics statements are synthetic, while mathematical statements are analytic. Mathematics contains hypotheses, while physics contains theories. Mathematics statements have to be only logically true, while predictions of physics statements must match observed and experimental data.
The distinction is clear-cut, but not always obvious. For example, mathematical physics is the application of mathematics in physics. Its methods are mathematical, but its subject is physical. The problems in this field start with a "mathematical model of a physical situation" (system) and a "mathematical description of a physical law" that will be applied to that system. Every mathematical statement used for solution has a hard-to-find physical meaning. The final mathematical solution has an easier-to-find meaning, because it is what the solver is looking for.
Physics is a branch of fundamental science, not practical science. Physics is also called "the fundamental science" because the subject of study of all branches of natural science like chemistry, astronomy, geology and biology are constrained by laws of physics, similar to how chemistry is often called the central science because of its role in linking the physical sciences. For example, chemistry studies properties, structures, and reactions of matter (chemistry's focus on the atomic scale distinguishes it from physics). Structures are formed because particles exert electrical forces on each other, properties include physical characteristics of given substances, and reactions are bound by laws of physics, like conservation of energy, mass and charge.
Physics is applied in industries like engineering and medicine. 
Application and influence.
Applied physics is a general term for physics research which is intended for a particular use. An applied physics curriculum usually contains a few classes in an applied discipline, like geology or electrical engineering. It usually differs from engineering in that an applied physicist may not be designing something in particular, but rather is using physics or conducting physics research with the aim of developing new technologies or solving a problem.
The approach is similar to that of applied mathematics. Applied physicists use physics in scientific research. For instance, people working on accelerator physics might seek to build better particle detectors for research in theoretical physics.
Physics is used heavily in engineering. For example, statics, a subfield of mechanics, is used in the building of bridges and other static structures. The understanding and use of acoustics results in sound control and better concert halls; similarly, the use of optics creates better optical devices. An understanding of physics makes for more realistic flight simulators, video games, and movies, and is often critical in forensic investigations.
With the standard consensus that the laws of physics are universal and do not change with time, physics can be used to study things that would ordinarily be mired in uncertainty. For example, in the study of the origin of the earth, one can reasonably model earth's mass, temperature, and rate of rotation, as a function of time allowing one to extrapolate forward or backward in time and so predict future or prior events. It also allows for simulations in engineering which drastically speed up the development of a new technology.
But there is also considerable interdisciplinarity in the physicist's methods, so many other important fields are influenced by physics (e.g., the fields of econophysics and sociophysics).
Research.
Scientific method.
Physicists use the scientific method to test the validity of a physical theory. By using a methodical approach to compare the implications of a theory with the conclusions drawn from its related experiments and observations, physicists are better able to test the validity of a theory in a logical, unbiased, and repeatable way. To that end, experiments are performed and observations are made in order to determine the validity or invalidity of the theory.
A scientific law is a concise verbal or mathematical statement of a relation which expresses a fundamental principle of some theory, such as Newton's law of universal gravitation.
Theory and experiment.
Theorists seek to develop mathematical models that both agree with existing experiments and successfully predict future experimental results, while experimentalists devise and perform experiments to test theoretical predictions and explore new phenomena. Although theory and experiment are developed separately, they are strongly dependent upon each other. Progress in physics frequently comes about when experimentalists make a discovery that existing theories cannot explain, or when new theories generate experimentally testable predictions, which inspire new experiments.
Physicists who work at the interplay of theory and experiment are called phenomenologists, who study complex phenomena observed in experiment and work to relate them to a fundamental theory.
Theoretical physics has historically taken inspiration from philosophy; electromagnetism was unified this way. Beyond the known universe, the field of theoretical physics also deals with hypothetical issues, such as parallel universes, a multiverse, and higher dimensions. Theorists invoke these ideas in hopes of solving particular problems with existing theories. They then explore the consequences of these ideas and work toward making testable predictions.
Experimental physics expands, and is expanded by, engineering and technology. Experimental physicists involved in basic research design and perform experiments with equipment such as particle accelerators and lasers, whereas those involved in applied research often work in industry developing technologies such as magnetic resonance imaging (MRI) and transistors. Feynman has noted that experimentalists may seek areas which are not well-explored by theorists.
Scope and aims.
Physics covers a wide range of phenomena, from elementary particles (such as quarks, neutrinos, and electrons) to the largest superclusters of galaxies. Included in these phenomena are the most basic objects composing all other things. Therefore, physics is sometimes called the "fundamental science". Physics aims to describe the various phenomena that occur in nature in terms of simpler phenomena. Thus, physics aims to both connect the things observable to humans to root causes, and then connect these causes together.
For example, the ancient Chinese observed that certain rocks (lodestone and magnetite) were attracted to one another by an invisible force. This effect was later called magnetism, which was first rigorously studied in the 17th century. But even before the Chinese discovered magnetism, the ancient Greeks knew of other objects such as amber, that when rubbed with fur would cause a similar invisible attraction between the two. This was also first studied rigorously in the 17th century, and came to be called electricity. Thus, physics had come to understand two observations of nature in terms of some root cause (electricity and magnetism). However, further work in the 19th century revealed that these two forces were just two different aspects of one force—electromagnetism. This process of "unifying" forces continues today, and electromagnetism and the weak nuclear force are now considered to be two aspects of the electroweak interaction. Physics hopes to find an ultimate reason (Theory of Everything) for why nature is as it is (see section "Current research" below for more information).
Research fields.
Contemporary research in physics can be broadly divided into particle physics; condensed matter physics; atomic, molecular, and optical physics; astrophysics; and applied physics. Some physics departments also support physics education research and physics outreach.
Since the 20th century, the individual fields of physics have become increasingly specialized, and today most physicists work in a single field for their entire careers. "Universalists" such as Albert Einstein (1879–1955) and Lev Landau (1908–1968), who worked in multiple fields of physics, are now very rare.
The major fields of physics, along with their subfields and the theories and concepts they employ, are shown in the following table.
Particle physics.
Particle physics is the study of the elementary constituents of matter and energy and the interactions between them. In addition, particle physicists design and develop the high energy accelerators, detectors, and computer programs necessary for this research. The field is also called "high-energy physics" because many elementary particles do not occur naturally but are created only during high-energy collisions of other particles.
Currently, the interactions of elementary particles and fields are described by the Standard Model. The model accounts for the 12 known particles of matter (quarks and leptons) that interact via the strong, weak, and electromagnetic fundamental forces. Dynamics are described in terms of matter particles exchanging gauge bosons (gluons, W and Z bosons, and photons, respectively). The Standard Model also predicts a particle known as the Higgs boson. In July 2012 CERN, the European laboratory for particle physics, announced the detection of a particle consistent with the Higgs boson, an integral part of a Higgs mechanism.
Nuclear physics is the field of physics that studies the constituents and interactions of atomic nuclei. The most commonly known applications of nuclear physics are nuclear power generation and nuclear weapons technology, but the research has provided application in many fields, including those in nuclear medicine and magnetic resonance imaging, ion implantation in materials engineering, and radiocarbon dating in geology and archaeology.
Atomic, molecular, and optical physics.
Atomic, molecular, and optical physics (AMO) is the study of matter–matter and light–matter interactions on the scale of single atoms and molecules. The three areas are grouped together because of their interrelationships, the similarity of methods used, and the commonality of their relevant energy scales. All three areas include both classical, semi-classical and quantum treatments; they can treat their subject from a microscopic view (in contrast to a macroscopic view).
Atomic physics studies the electron shells of atoms. Current research focuses on activities in quantum control, cooling and trapping of atoms and ions, low-temperature collision dynamics and the effects of electron correlation on structure and dynamics. Atomic physics is influenced by the nucleus (see, e.g., hyperfine splitting), but intra-nuclear phenomena such as fission and fusion are considered part of high-energy physics.
Molecular physics focuses on multi-atomic structures and their internal and external interactions with matter and light. Optical physics is distinct from optics in that it tends to focus not on the control of classical light fields by macroscopic objects but on the fundamental properties of optical fields and their interactions with matter in the microscopic realm.
Condensed matter physics.
Condensed matter physics is the field of physics that deals with the macroscopic physical properties of matter. In particular, it is concerned with the "condensed" phases that appear whenever the number of particles in a system is extremely large and the interactions between them are strong.
The most familiar examples of condensed phases are solids and liquids, which arise from the bonding by way of the electromagnetic force between atoms. More exotic condensed phases include the superfluid and the Bose–Einstein condensate found in certain atomic systems at very low temperature, the superconducting phase exhibited by conduction electrons in certain materials, and the ferromagnetic and antiferromagnetic phases of spins on atomic lattices.
Condensed matter physics is the largest field of contemporary physics. Historically, condensed matter physics grew out of solid-state physics, which is now considered one of its main subfields. The term "condensed matter physics" was apparently coined by Philip Anderson when he renamed his research group—previously "solid-state theory"—in 1967. In 1978, the Division of Solid State Physics of the American Physical Society was renamed as the Division of Condensed Matter Physics. Condensed matter physics has a large overlap with chemistry, materials science, nanotechnology and engineering.
Astrophysics.
Astrophysics and astronomy are the application of the theories and methods of physics to the study of stellar structure, stellar evolution, the origin of the solar system, and related problems of cosmology. Because astrophysics is a broad subject, astrophysicists typically apply many disciplines of physics, including mechanics, electromagnetism, statistical mechanics, thermodynamics, quantum mechanics, relativity, nuclear and particle physics, and atomic and molecular physics.
The discovery by Karl Jansky in 1931 that radio signals were emitted by celestial bodies initiated the science of radio astronomy. Most recently, the frontiers of astronomy have been expanded by space exploration. Perturbations and interference from the earth's atmosphere make space-based observations necessary for infrared, ultraviolet, gamma-ray, and X-ray astronomy.
Physical cosmology is the study of the formation and evolution of the universe on its largest scales. Albert Einstein's theory of relativity plays a central role in all modern cosmological theories. In the early 20th century, Hubble's discovery that the universe is expanding, as shown by the Hubble diagram, prompted rival explanations known as the steady state universe and the Big Bang.
The Big Bang was confirmed by the success of Big Bang nucleosynthesis and the discovery of the cosmic microwave background in 1964. The Big Bang model rests on two theoretical pillars: Albert Einstein's general relativity and the cosmological principle. Cosmologists have recently established the ΛCDM model of the evolution of the universe, which includes cosmic inflation, dark energy, and dark matter.
Numerous possibilities and discoveries are anticipated to emerge from new data from the Fermi Gamma-ray Space Telescope over the upcoming decade and vastly revise or clarify existing models of the universe. In particular, the potential for a tremendous discovery surrounding dark matter is possible over the next several years. Fermi will search for evidence that dark matter is composed of weakly interacting massive particles, complementing similar experiments with the Large Hadron Collider and other underground detectors.
IBEX is already yielding new astrophysical discoveries: "No one knows what is creating the ENA (energetic neutral atoms) ribbon" along the termination shock of the solar wind, "but everyone agrees that it means the textbook picture of the heliosphere—in which the solar system's enveloping pocket filled with the solar wind's charged particles is plowing through the onrushing 'galactic wind' of the interstellar medium in the shape of a comet—is wrong."
Current research.
Research in physics is continually progressing on a large number of fronts.
In condensed matter physics, an important unsolved theoretical problem is that of high-temperature superconductivity. Many condensed matter experiments are aiming to fabricate workable spintronics and quantum computers.
In particle physics, the first pieces of experimental evidence for physics beyond the Standard Model have begun to appear. Foremost among these are indications that neutrinos have non-zero mass. These experimental results appear to have solved the long-standing solar neutrino problem, and the physics of massive neutrinos remains an area of active theoretical and experimental research. Particle accelerators have begun probing energy scales in the TeV range, in which experimentalists are hoping to find evidence for the Higgs boson and supersymmetric particles.
Theoretical attempts to unify quantum mechanics and general relativity into a single theory of quantum gravity, a program ongoing for over half a century, have not yet been decisively resolved. The current leading candidates are M-theory, superstring theory and loop quantum gravity.
Many astronomical and cosmological phenomena have yet to be satisfactorily explained, including the existence of ultra-high energy cosmic rays, the baryon asymmetry, the acceleration of the universe and the anomalous rotation rates of galaxies.
Although much progress has been made in high-energy, quantum, and astronomical physics, many everyday phenomena involving complexity, chaos, or turbulence are still poorly understood. Complex problems that seem like they could be solved by a clever application of dynamics and mechanics remain unsolved; examples include the formation of sandpiles, nodes in trickling water, the shape of water droplets, mechanisms of surface tension catastrophes, and self-sorting in shaken heterogeneous collections.
These complex phenomena have received growing attention since the 1970s for several reasons, including the availability of modern mathematical methods and computers, which enabled complex systems to be modeled in new ways. Complex physics has become part of increasingly interdisciplinary research, as exemplified by the study of turbulence in aerodynamics and the observation of pattern formation in biological systems. In the 1932 "Annual Reviews in Fluid Mechanics", Horace Lamb said:
External links.
General
Organizations

</doc>
<doc id="22943" url="https://en.wikipedia.org/wiki?curid=22943" title="Papua New Guinea">
Papua New Guinea

Papua New Guinea (PNG; ; ; Hiri Motu: "Papua Niu Gini"), officially the Independent State of Papua New Guinea, is an Oceanian country that occupies the eastern half of the island of New Guinea and its offshore islands in Melanesia, a region of the southwestern Pacific Ocean north of Australia. Its capital, located along its southeastern coast, is Port Moresby. The western half of New Guinea forms the Indonesian provinces of Papua and West Papua.
Papua New Guinea is one of the most culturally diverse countries in the world; 848 languages are listed for the country, of which 12 have no known living speakers. Most of the population of over 7 million people live in customary communities, which are as diverse as the languages. It is also one of the most rural, as only 18 percent of its people live in urban centres. The country is one of the world's least explored, culturally and geographically, and many undiscovered species of plants and animals are thought to exist in the interior.
Strong growth in Papua New Guinea's mining and resource sector led to the country becoming the sixth fastest-growing economy in the world in 2011, although growth is expected to slow once major resource projects come on line in 2015. Mining remains a major economic factor, however, with talks of resuming mining operations in the previously closed-off Panguna mine ongoing with the local and national governments. Nearly 40 per cent of the population lives a self-sustainable natural lifestyle with no access to global capital.
At the local level, the majority of the population still live in strong customary societies and – while social life is overlaid with traditional religious cosmologies and modern practices, including conventional primary education – customary subsistence-based agriculture remains fundamental. These societies and clans are explicitly acknowledged within the nation's constitutional framework. The Papua New Guinea Constitution expresses the wish for "traditional villages and communities to remain as viable units of Papua New Guinean society" and for active steps to be taken in their continuing importance to local and national community life.
At the national level, after being ruled by three external powers since 1884, Papua New Guinea established its sovereignty in 1975 following almost 60 years of Australian administration. It became a separate Commonwealth realm with Queen Elizabeth II as its head of state and became a member of the Commonwealth of Nations in its own right.
History.
Archaeological evidence indicates that humans first arrived in Papua New Guinea around 42,000 to 45,000 years ago.
Agriculture was independently developed in the New Guinea highlands around 7000 BC, making it one of the few areas in the world where people independently domesticated plants. A major migration of Austronesian speaking peoples to coastal regions of New Guinea took place around 500 BC. This has been correlated with the introduction of pottery, pigs, and certain fishing techniques.
More recently, in the 18th century, the sweet potato was brought to New Guinea, having been introduced to the Moluccas by Portuguese traders, who obtained it from South America. The far higher crop yields from sweet potato gardens radically transformed traditional agriculture; sweet potato largely supplanted the previous staple, taro, and gave rise to a significant increase in population in the highlands.
Although headhunting and cannibalism have been practically eradicated, in the past they were practised in many parts of the country as part of rituals related to warfare and taking in enemy spirits or powers. For example, in 1901, on Goaribari Island in the Gulf of Papua, a missionary, Harry Dauncey, found 10,000 skulls in the island's Long Houses. According to the writer Marianna Torgovnick, "The most fully documented instances of cannibalism as a social institution come from New Guinea, where head-hunting and ritual cannibalism survived, in certain isolated areas, into the Fifties, Sixties, and Seventies, and still leave traces within certain social groups."
Little was known in Europe about the island until the 19th century, although Portuguese and Spanish explorers, such as Dom Jorge de Meneses and Yñigo Ortiz de Retez, had encountered it as early as the 16th century. Traders from Southeast Asia had visited New Guinea beginning 5,000 years ago to collect bird of paradise plumes. The country's dual name results from its complex administrative history before independence. The word "papua" is derived from an old local term of uncertain origin. "New Guinea" ("Nueva Guinea") was the name coined by the Spanish explorer Yñigo Ortiz de Retez. In 1545, he noted the resemblance of the people to those he had earlier seen along the Guinea coast of Africa. Guinea, in its turn, is etymologically derived from Portuguese word "Guiné".
In the nineteenth century, Germany ruled the northern half of the country as a colony for some decades, beginning in 1884, as German New Guinea. The southern half was colonised in the same year by the United Kingdom as British New Guinea. With the Papua Act 1905 it transferred this territory to the newly formed Commonwealth of Australia, which took on its administration. Additionally, from 1905, British New Guinea was renamed the Territory of Papua.
Early in World War I, German New Guinea was captured by Australian forces in a small military campaign, and after the war was given to Australia to administer as a League of Nations Mandate. Papua, by contrast, was deemed to be an External Territory of the Australian Commonwealth, though as a matter of law it remained a British possession. This was significant for the country's post-independence legal system. The difference in legal status meant that until 1949 Papua and New Guinea had entirely separate administrations, both controlled by Australia.
During World War II, the New Guinea campaign (1942–1945) was one of the major military campaigns. Approximately 216,000 Japanese, Australian, and US servicemen died. After World War II, the two territories were combined into the Territory of Papua and New Guinea, which later was simply referred to as "Papua New Guinea".
The natives of Papua appealed to the United Nations for oversight and independence. The nation established independence from Australia on 16 September 1975, and maintains close ties. (Australia continues as the largest aid donor to Papua New Guinea). Papua New Guinea was admitted to membership in the United Nations on 10 October 1975.
A secessionist revolt in 1975–76 on Bougainville Island resulted in an eleventh-hour modification of the draft Constitution of Papua New Guinea to allow for Bougainville and the other eighteen districts to have quasi-federal status as provinces. A renewed uprising started in 1988 and claimed 20,000 lives until it was resolved in 1997. Following the revolt, the autonomous Bougainville elected Joseph Kabui as president in 2005 and he served until 2008. He was succeeded by his deputy John Tabinaman, who continued to be re-elected as leader until the election of December 2008, which James Tanis won. As part of the current peace settlement, a referendum on independence is planned to be held sometime before mid-2020.
Anti-Chinese rioting involving tens of thousands of people broke out in May 2009. The initial spark was a fight between Chinese and Papua New Guinean workers at a nickel factory under construction by a Chinese company. Native resentment against Chinese ownership of numerous small businesses and their commercial success led to the rioting. The Chinese have traditionally been merchants in Papua New Guinea.
Politics.
Papua New Guinea is a Commonwealth realm; as such Queen Elizabeth II acts as its Sovereign and Head of State. It was expected by the constitutional convention, which prepared the draft constitution, and by Australia, the outgoing metropolitan power, that Papua New Guinea would choose not to retain its link with the monarchy. The founders, however, considered that imperial honours had a cachet that the newly independent state would not be able to confer with a purely indigenous honours system, so the monarchy was retained. The Queen is represented by the Governor-General of Papua New Guinea, currently Sir Michael Ogio. Papua New Guinea and the Solomon Islands are unusual among Commonwealth realms in that Governors-General are elected by the legislature rather than appointed by the executive branch.
Actual executive power lies with the Prime Minister, who heads the cabinet of 31 MPs from the ruling Coalition, which make up the government. The current Prime Minister is Peter O'Neill. The unicameral National Parliament has 111 seats, of which 22 are occupied by the governors of the 21 provinces (2 new ones were approved by Parliament in 2012) and the National Capital District (NCD). Candidates for members of parliament are voted upon when the prime minister asks the Governor-General to call a national election, a maximum of five years after the previous national election.
In the early years of independence, the instability of the party system led to frequent votes of no confidence in Parliament with resulting changes of the government of the day, but with referral to the electorate, through national elections only occurring every five years. In recent years, successive governments have passed legislation preventing such votes sooner than 18 months after a national election and within 12-month of the next election, and in December 2012 the first 2 (of 3) readings were passed to prevent votes of no confidence occurring within the first 30 months. This restriction on votes of no confidence has arguably resulted in greater stability, although perhaps at a cost of reducing the accountability of the executive branch of government.
Elections in PNG attract large numbers of candidates. After independence in 1975, members were elected by the first past the post system, with winners frequently gaining less than 15% of the vote. Electoral reforms in 2001 introduced the Limited Preferential Vote system (LPV), a version of the Alternative Vote. The 2007 general election was the first to be conducted using LPV.
In foreign policy, Papua New Guinea is a member of the Commonwealth of Nations, Pacific Islands Forum and the Melanesian Spearhead Group (MSG) of countries and was accorded Observer status within ASEAN in 1976, followed later by Special Observer status in 1981. It is also a member of APEC and an ACP country, associated with the European Union.
Since August 2011, there was a political crisis between the parliament-elect Prime Minister, Peter O'Neill (voted into office by a large majority of MPs) and Sir Michael Somare, who was deemed by the Supreme Court (in a December Opinion, 3:2) to retain office. The stand-off between Parliament and the Supreme Court continued until the July 2012 National Elections, with legislation passed effectively removing the Chief Justice and subjecting the Supreme Court members to greater control by the Legislature, as well as a series of other laws passed, for example limiting the age for a Prime Minister. The confrontation reached a peak, with the Deputy Prime Minister entering the Supreme Court, during a hearing, escorted by some police, ostensibly to 'arrest' the Chief Justice. There was strong pressure amongst some MPs to defer the National Elections for a further six months-1-year, although their powers to do that were highly questionable. The Parliament-elect 'Prime Minister' and other cooler-headed MPs carried the votes for the writs for the new Election to be issued, slightly late, but for the Election itself to occur on time, thereby avoiding a continuation of the constitutional crisis. The crisis was tense at times, but largely restricted to the political and legal fraternity, plus some police factions, but the public and public service (including most police and military) standing back. It was a period when, with increased telecommunication access and use of social media (notably Facebook and mobile phones) the public and students played some part in helping maintain restraint and demanding the leadership to adhere to constitutional processes and not to defer the elections and the people's say in who should be their legitimate representatives for the next five years.
Under an amendment of 2002, the leader of the party winning the largest number of seats in the Election is invited by the Governor-General to form the Government, if he can muster the necessary majority in Parliament. The process of forming such a coalition in PNG, where there is little ideologically binding parties together, involves considerable horsetrading right up until the last moment. Peter O'Neil emerged as Papua New Guinea's Prime Minister after the July 2012 Election, and formed a Government with the former Governor of East New Britain Province, Leon Dion as Deputy Prime Minister.
Law.
The unicameral Parliament enacts legislation in the same manner as in other jurisdictions that have "cabinet," "responsible government," or "parliamentary democracy": it is introduced by the executive government to the legislature, debated and, if passed, becomes law when it receives royal assent by the Governor-General. Most legislation is actually regulation implemented by the bureaucracy under enabling legislation previously passed by Parliament.
All ordinary statutes enacted by Parliament must be consistent with the Constitution. The courts have jurisdiction to rule on the constitutionality of statutes, both in disputes before them and on a reference where there is no dispute but only an abstract question of law. Unusual among developing countries, the judicial branch of government in Papua New Guinea has remained remarkably independent, and successive executive governments have continued to respect its authority.
The "underlying law" (Papua New Guinea's common law) consists of principles and rules of common law and equity in England common law as it stood on 16 September 1975 (the date of Independence), and thereafter the decisions of PNG's own courts. The courts are directed by the Constitution and, latterly, the "Underlying Law Act", to take note of the "custom" of traditional communities, with a view to determining which customs are common to the whole country and may be declared also to be part of the underlying law. In practice, this has proved extremely difficult and has been largely neglected. Statutes are largely adapted from overseas jurisdictions, primarily Australia and England. Advocacy in the courts follows the adversarial pattern of other common law countries.
This national court system used in towns and cities is supported by a village court system in the more remote areas. The law underpinning the village courts is 'customary law'.
Human rights.
Papua New Guinea is often labelled as potentially the worst place in the world for gender violence. A 2013 study in "The Lancet" found that 41% of men on Bougainville Island, Papua New Guinea, reported having raped a non-partner while 14.1% reported having committed gang rape. According to UNICEF, nearly half of reported rape victims are under 15 years of age and 13% are under 7 years of age, while a report by ChildFund Australia citing former Parliamentarian Dame Carol Kidu claimed 50% of those seeking medical help after rape are under 16, 25% are under 12 and 10% are under 8.
Administrative divisions.
Papua New Guinea is divided into four regions, which are not the primary administrative divisions but are quite significant in many aspects of government, commercial, sporting and other activities.
The nation has 22 province-level divisions: twenty provinces, the Autonomous Region of Bougainville and the National Capital District. Each province is divided into one or more districts, which in turn are divided into one or more Local Level Government areas.
Provinces are the primary administrative divisions of the country. Provincial governments are branches of the national government – Papua New Guinea is not a federation of provinces. The province-level divisions are as follows:
In 2009, Parliament approved the creation of two additional provinces: Hela Province, consisting of part of the existing Southern Highlands Province, and Jiwaka Province, formed by dividing Western Highlands Province. Jiwaka and Hela officially became separate provinces on 17 May 2012.
Geography.
At , Papua New Guinea is the world's fifty-fourth largest country. Including all its islands, it lies between latitudes 0° and 12°S, and longitudes 140° and 160°E.
The country's geography is diverse and, in places, extremely rugged. A spine of mountains, the New Guinea Highlands, runs the length of the island of New Guinea, forming a populous highlands region mostly covered with tropical rainforest, and the long Papuan Peninsula, known as the 'Bird's Tail'. Dense rainforests can be found in the lowland and coastal areas as well as very large wetland areas surrounding the Sepik and Fly rivers. This terrain has made it difficult for the country to develop transportation infrastructure. Some areas are accessible only on foot or by aeroplane. The highest peak is Mount Wilhelm at . Papua New Guinea is surrounded by coral reefs which are under close watch, in the interests of preservation.
The country is situated on the Pacific Ring of Fire, at the point of collision of several tectonic plates. There are a number of active volcanoes, and eruptions are frequent. Earthquakes are relatively common, sometimes accompanied by tsunamis.
The mainland of the country is the eastern half of New Guinea island, where the largest towns are also located, including Port Moresby (capital) and Lae; other major islands within Papua New Guinea include New Ireland, New Britain, Manus and Bougainville.
Papua New Guinea is one of the few regions close to the equator that experience snowfall, which occurs in the most elevated parts of the mainland.
Ecology.
Papua New Guinea is part of the Australasia ecozone, which also includes Australia, New Zealand, eastern Indonesia, and several Pacific island groups, including the Solomon Islands and Vanuatu.
Geologically, the island of New Guinea is a northern extension of the Indo-Australian tectonic plate, forming part of a single land mass which is Australia-New Guinea (also called "Sahul" or "Meganesia"). It is connected to the Australian segment by a shallow continental shelf across the Torres Strait, which in former ages had lain exposed as a land bridge, particularly during ice ages when sea levels were lower than at present.
Consequently, many species of birds and mammals found on New Guinea have close genetic links with corresponding species found in Australia. One notable feature in common for the two landmasses is the existence of several species of marsupial mammals, including some kangaroos and possums, which are not found elsewhere.
Many of the other islands within PNG territory, including New Britain, New Ireland, Bougainville, the Admiralty Islands, the Trobriand Islands, and the Louisiade Archipelago, were never linked to New Guinea by land bridges. As a consequence, they have their own flora and fauna; in particular, they lack many of the land mammals and flightless birds that are common to New Guinea and Australia.
Australia and New Guinea are portions of the ancient supercontinent of Gondwana, which started to break into smaller continents in the Cretaceous era, 66–130 million years ago. Australia finally broke free from Antarctica about 45 million years ago. All the Australasian lands are home to the Antarctic flora, descended from the flora of southern Gondwana, including the coniferous podocarps and "Araucaria" pines, and the broadleafed southern beech ("Nothofagus"). These plant families are still present in Papua New Guinea.
As the Indo-Australian Plate (which includes landmasses of India, Australia, and the Indian Ocean floor in between) drifts north, it collides with the Eurasian Plate. The collision of the two plates pushed up the Himalayas, the Indonesian islands, and New Guinea's Central Range. The Central Range is much younger and higher than the mountains of Australia, so high that it is home to rare equatorial glaciers. New Guinea is part of the humid tropics, and many Indomalayan rainforest plants spread across the narrow straits from Asia, mixing together with the old Australian and Antarctic floras.
PNG includes a number of terrestrial ecoregions:
At current rates of deforestation, more than half of the country's forests could be lost or seriously degraded by 2021, according to a new satellite study of the region. Nearly one-quarter of Papua New Guinea's rainforests were damaged or destroyed between 1972 and 2002.
Three new species of mammals were discovered in the forests of Papua New Guinea by an Australian lead expedition. A small wallaby, a large eared mouse and shrew like marsupial were discovered. The expedition was also successful in capturing photographs and video footage of some other rare animals such as the Tenkile tree kangaroo and the Weimang tree kangaroo.
Economy.
Papua New Guinea is richly endowed with natural resources, including mineral and renewable resources, such as forests, marine (including a large portion of the world's major tuna stocks), and in some parts agriculture. The rugged terrain — including high mountain ranges and valleys, swamps and islands — and high cost of developing infrastructure, combined with other factors (including serious law and order problems in some centres and the system of customary land title) makes it difficult for outside developers. Local developers are handicapped by years of deficient investment in education, health, ICT and access to finance. Agriculture, for subsistence and cash crops, provides a livelihood for 85% of the population and continues to provide some 30% of GDP. Mineral deposits, including gold, oil, and copper, account for 72% of export earnings. Oil palm production has grown steadily over recent years (largely from estates and with extensive outgrower output), with palm oil now the main agricultural export. In households participating, coffee remains the major export crop (produced largely in the Highlands provinces), followed by cocoa and coconut oil/copra from the coastal areas, each largely produced by smallholders and tea, produced on estates and rubber. The Iagifu/Hedinia Field was discovered in 1986 in the Papuan fold and thrust belt.
Former Prime Minister Sir Mekere Morauta tried to restore integrity to state institutions, stabilise the kina, restore stability to the national budget, privatise public enterprises where appropriate, and ensure ongoing peace on Bougainville following the 1997 agreement which ended Bougainville's secessionist unrest. The Morauta government had considerable success in attracting international support, specifically gaining the backing of the IMF and the World Bank in securing development assistance loans. Significant challenges face Prime Minister Sir Michael Somare, including gaining further investor confidence, continuing efforts to privatise government assets, and maintaining the support of members of Parliament.
In March 2006, the United Nations Development Programme Policy called for Papua New Guinea's designation of developing country to be downgraded to least-developed country because of protracted economic and social stagnation. However, an evaluation by the International Monetary Fund in late 2008 found that "a combination of prudent fiscal and monetary policies, and high global prices for mineral commodity exports, have underpinned Papua New Guinea's recent buoyant economic growth and macroeconomic stability. By 2012 PNG had enjoyed a decade of positive economic growth, at over 6% since 2007, even during the Global Financial Crisis years of 2008/9. PNG's Real GDP growth rate as at 2011 was 8.9%, and 9.2% for 2012, according to the Asian Development Bank. This economic growth has been primarily attributed to strong commodity prices, particularly mineral but also agricultural, with the high demand for mineral products largely sustained even during the crisis by the buoyant Asian markets a booming mining sector, and particularly since 2009 by a buoyant outlook and the construction phase for natural gas exploration, production, and exportation in liquefied form (Liquefied Natural Gas or "LNG") by LNG tankers (LNG carrier), all of which will require multibillion-dollar investments (exploration, production wells, pipelines, storage, liquefaction plants, port terminals, LNG tanker ships).
The first major gas project is the PNG LNG project of a consortium led by ExxonMobil, scheduled to commence production in late 2014, for export largely to China, Japan, South Korea and other Asian countries. This ExxonMobil-led consortium includes a PNG company named Oil Search, based in Port Moresby, which has a 29% share.
A second major project is based on initial rights held by the French oil and gas major Total S.A. and the US company InterOil Corp. (IOC), which have partly combined their assets after Total agreed in December 2013 to purchase 61.3% of IOC's Antelope and Elk gas fields rights, with the plan to develop them starting in 2016, including the construction of a liquefaction plant to allow export of LNG. Total S.A. has separately another joint operating agreement with the PNG company Oil Search.
The Anglo-Dutch major Royal Dutch Shell has indicated in 2011 that it is considering the possibility of investing in gas exploration and production in Papua New Guinea.
Further gas and mineral projects are proposed (including the large Wafi-Golpu copper-gold mine), with extensive exploration ongoing across the country.
Economic 'development' based on the extractive industries carries difficult consequences for local communities. There has been much contention around river tailings in the vast Fly River, submarine tailings from the new Ramu-Nickel-cobalt mine, commencing exports in late 2012 (after a delay from landowner-led court challenges), and from proposed submarine mining in the Bismarck Sea (by Nautilus Minerals). One major project conducted through the PNG Department for Community Development suggested that other pathways to sustainable development should be considered.
The PNG government's long-term Vision 2050 and shorter-term policy documents, including the 2013 Budget and the 2014 Responsible Sustainable Development Strategy, emphasise the need for a more diverse economy, based upon sustainable industries and avoiding the effects of Dutch Disease from major resource extraction projects undermining other industries, as has occurred in many countries experiencing oil or other mineral booms, notably in Western Africa, undermining much of their agriculture sector, manufacturing and tourism, and with them broad-based employment prospects. Measures have been taken to mitigate these effects, including through the establishment of a sovereign wealth fund, partly to stabilise revenue and expenditure flows, but much will depend upon the readiness to make real reforms to effective use of revenue, tackling rampant corruption and empowering households and businesses to access markets, services and develop a more buoyant economy, with lower costs, especially for small- to medium-size enterprises.
The Institute of National Affairs, a PNG independent policy think tank, provides a report on the business and investment environment of Papua New Guinea every five years, based upon a survey of large and small, local and overseas companies, highlighting law and order problems and corruption, as the worst impediments, followed by the poor state of transport, power and communications infrastructure.
Land tenure.
The PNG legislature has enacted laws in which a type of tenure called "customary land title" is recognised, meaning that the traditional lands of the indigenous peoples have some legal basis to inalienable tenure. This customary land notionally covers most of the usable land in the country (some 97% of total land area); alienated land is either held privately under state lease or is government land. Freehold title (also known as fee simple) can only be held by Papua New Guinean citizens.
Only some 3% of the land of Papua New Guinea is in private hands; it is privately held under 99-year state lease, or it is held by the State. There is virtually no freehold title; the few existing freeholds are automatically converted to state lease when they are transferred between vendor and purchaser. Unalienated land is owned under customary title by traditional landowners. The precise nature of the seisin varies from one culture to another. Many writers portray land as in the communal ownership of traditional clans; however, closer studies usually show that the smallest portions of land whose ownership cannot be further divided are held by the individual heads of extended families and their descendants or their descendants alone if they have recently died.
This is a matter of vital importance because a problem of economic development is identifying the membership of customary landowning groups and the owners. Disputes between mining and forestry companies and landowner groups often devolve on the issue of whether the companies entered into contractual relations for the use of land with the true owners. Customary property — usually land — cannot be devised by will. It can only be inherited according to the custom of the deceased's people. The Lands Act was amended in 2010 along with the Land Group Incorporation Act, intended to improve the management of state land, mechanisms for dispute resolution over land, and to enable customary landowners to be better able to access finance and possible partnerships over portions of their land, if they seek to develop it for urban or rural economic activities. The Land Group Incorporation Act requires more specific identification of the customary landowners than hitherto and their more specific authorisation before any land arrangements are determined; (a major issue in recent years has been a land grab, using, or rather misusing, the Lease-Leaseback provision under the Land Act, notably using 'Special Agricultural and Business Leases' (SABLs) to acquire vast tracts of customary land, purportedly for agricultural projects, but in an almost all cases as a back-door mechanism for securing tropical forest resources for logging — circumventing the more exacting requirements of the Forest Act, for securing Timber Permits (which must comply with sustainability requirements and be competitively secured, and with the customary landowners approval). Following a national outcry, these SABLs have been subject to a Commission of Inquiry, established in mid-2011, for which the report is still awaited for initial presentation to the Prime Minister and Parliament.
Demographics.
Papua New Guinea is one of the most heterogeneous nations in the world. There are hundreds of ethnic groups indigenous to Papua New Guinea, the majority being from the group known as Papuans, whose ancestors arrived in the New Guinea region tens of thousands of years ago. The other indigenous peoples are Austronesians, their ancestors having arrived in the region less than four thousand years ago.
There are also numerous people from other parts of the world now resident, including Chinese, Europeans, Australians, Filipinos, Polynesians, and Micronesians (the last three belonging to the Austronesian family). Around 40,000 expatriates, mostly from Australia and China, were living in Papua New Guinea in 1975.
Languages.
Papua New Guinea has more languages than any other country, with over 820 indigenous languages, representing 12% of the world's total, but most have fewer than 1,000 speakers. The most widely spoken indigenous language is Enga, with about 200,000 speakers, followed by Melpa and Huli. Indigenous languages are classified into two large groups, Austronesian languages and non-Austronesian, or Papuan, languages. There are four official languages for Papua New Guinea: English, "sign language" (which in practice means Papua New Guinean Sign Language), Tok Pisin and Hiri Motu.
English is the language of government and the education system, but it is not spoken widely.
The primary lingua franca of the country is Tok Pisin (commonly known in English as New Guinean Pidgin or Melanesian Pidgin), in which much of the debate in Parliament is conducted, many information campaigns and advertisements are presented, and until recently a national newspaper, "Wantok", was published. The only area where Tok Pisin is not prevalent is the southern region of Papua, where people often use the third official language, Hiri Motu.
Although it lies in the Papua region, Port Moresby has a highly diverse population which primarily uses Tok Pisin, and to a lesser extent English, with Motu spoken as the indigenous language in outlying villages. With an average of only 7,000 speakers per language, Papua New Guinea has a greater density of languages than any other nation on earth except Vanuatu.
Health.
Public expenditure was at 7.3% of all government expenditure in 2006, whereas private expenditure was at 0.6% of the GDP. There were five physicians per 100,000 people in the early 2000s. Malaria is the leading cause of illness and death in New Guinea. In 2003, the most recently reported year, 70,226 cases of laboratory confirmed malaria were reported, along with 537 deaths. A total of 1,729,697 cases were probable.
Papua New Guinea has the highest incidence of HIV and AIDS in the Pacific region and is the fourth country in the Asia Pacific region to fit the criteria for a generalised HIV/AIDS epidemic. Lack of HIV/AIDS awareness is a major problem, especially in rural areas.
In June 2011, the United Nations Population Fund released a report on "The State of the World's Midwifery". It contained new data on the midwifery workforce and policies relating to newborn and maternal mortality for 58 countries. The 2010 maternal mortality rate per 100,000 births for Papua New Guinea is 250. This is compared with 311.9 in 2008 and 476.3 in 1990. The under 5 mortality rate, per 1,000 births is 69 and the neonatal mortality as a percentage of under 5's mortality is 37. The aim of this report is to highlight ways in which the Millennium Development Goals can be achieved, particularly Goal 4 – Reduce child mortality and Goal 5 – Improve maternal health. In Papua New Guinea the number of midwives per 1,000 live births is 1 and the lifetime risk of death for pregnant women is 1 in 94.
Religion.
The courts and government practice uphold the constitutional right to freedom of speech, thought, and belief, and no legislation to curb those rights has been adopted. The 2000 census found that 96% of citizens identified themselves as members of a Christian church; however, many citizens combine their Christian faith with some traditional indigenous religious practices. The census percentages were as follows:
There are also approximately 4,000 Muslims in the country. The majority belong to the Sunni group, while a small number are Ahmadi. Non-traditional Christian churches and non-Christian religious groups are active throughout the country. The Papua New Guinea Council of Churches has stated that both Muslim and Confucian missionaries are active, and foreign missionary activity in general is high.
Traditional religions were often animist. Some also tended to have elements of Veneration of the dead, though generalisation is suspect given the extreme heterogeneity of Melanesian societies. Prevalent among traditional tribes is the belief in "masalai", or evil spirits, which are blamed for "poisoning" people, causing calamity and death, and the practice of puripuri (sorcery).
Culture.
It is estimated that more than a thousand cultural groups exist in Papua New Guinea. Because of this diversity, many styles of cultural expression have emerged; each group has created its own expressive forms in art, dance, weaponry, costumes, singing, music, architecture and much more.
Most of these cultural groups have their own language. People typically live in villages that rely on subsistence farming. In some areas people hunt and collect wild plants (such as yam roots) to supplement their diets. Those who become skilled at hunting, farming and fishing earn a great deal of respect.
On the Sepik river, there is a tradition of wood carving, often in the form of plants or animals, representing ancestor spirits.
Sea shells are no longer the currency of Papua New Guinea, as they were in some regions — sea shells were abolished as currency in 1933. However, this tradition is still present in local customs; in some cultures, to get a bride, a groom must bring a certain number of golden-edged clam shells as a bride price. In other regions, the bride price is paid in lengths of shell money, pigs, cassowaries or cash. Elsewhere, it is brides who traditionally pay a dowry.
People of the highlands engage in colourful local rituals that are called "sing sings". They paint themselves and dress up with feathers, pearls and animal skins to represent birds, trees or mountain spirits. Sometimes an important event, such as a legendary battle, is enacted at such a musical festival.
Sport.
Sport is an important part of Papua New Guinean culture and rugby league is by far the most popular sport. In a nation where communities are far apart and many people live at a minimal subsistence level, rugby league has been described as a replacement for tribal warfare as a way of explaining the local enthusiasm for the game (a matter of life and death). Many Papua New Guineans have become instant celebrities by representing their country or playing in an overseas professional league. Even Australian rugby league players who have played in the annual State of Origin series, which is celebrated feverishly every year in PNG, are among the most well known people throughout the nation.
State of Origin is a highlight of the year for most Papua New Guineans, although the support is so passionate that many people have died over the years in violent clashes supporting their team. The Papua New Guinea national rugby league team usually plays against the Australian Prime Minister's XIII (a selection of NRL players) each year, normally in Port Moresby.
Other major sports which have a part in the Papua New Guinea sporting landscape are Australian rules football, Association football, rugby union and, in eastern Papua, cricket.
The capital city, Port Moresby, hosted the Pacific Games in 2015.
Education.
A large proportion of the population is illiterate, with women predominating in this area. Much of the education in the country is provided by church institutions. This includes 500 schools of the Evangelical Lutheran Church of Papua New Guinea.
Papua New Guinea has six universities apart from other major tertiary institutions. The two founding universities are the University of Papua New Guinea based in the National Capital District, and the Papua New Guinea University of Technology based outside of Lae, in Morobe Province.
The four other universities which were once colleges were established recently after gaining government recognition. These are the University of Goroka in the Eastern Highlands province, Divine Word University (run by the Catholic Church's Divine Word Missionaries) in Madang Province, Vudal University in East New Britain Province and Pacific Adventist University (run by the Seventh-day Adventist Church) in the National Capital District.
Transport.
Transport in Papua New Guinea is heavily limited by the country's mountainous terrain. Port Moresby is not linked by road to any of the other major towns, and many remote villages can only be reached by light aircraft or on foot. As a result, air travel is the single most important form of transport for human and high value freight. In addition to two international airfields, Papua New Guinea has 578 airstrips, most of which are unpaved. Assets are not maintained to good operating standards and poor transport remains a major impediment to the development of ties of national unity.
Air travel.
Air travel is the single most important form of transport in Papua New Guinea, for the transport of humans and high density/value freight. Airplanes made it possible to open up the country during its early colonial period. Even today the two largest cities, Port Moresby and Lae, are only directly connected by planes.
Jacksons International Airport is the major international airport in Papua New Guinea, located from Port Moresby.
See also.
Lists
References.
External links.
Government
General information

</doc>
<doc id="22946" url="https://en.wikipedia.org/wiki?curid=22946" title="List of painters by name">
List of painters by name

The following list of painters by name includes over 3,100 painters from all ages and parts of the world.

</doc>
<doc id="22948" url="https://en.wikipedia.org/wiki?curid=22948" title="Poseidon">
Poseidon

Poseidon (; Greek: , ) is one of the twelve Olympian deities of the pantheon in Greek mythology. His main domain is the ocean, and he is called the "God of the Sea". Additionally, he is referred to as "Earth-Shaker" due to his role in causing earthquakes, and has been called the "tamer of horses". He is usually depicted as an older male with curly hair and beard.
The name of the sea-god Nethuns in Etruscan was adopted in Latin for Neptune in Roman mythology; both were sea gods analogous to Poseidon. Linear B tablets show that Poseidon was venerated at Pylos and Thebes in pre-Olympian Bronze Age Greece as a chief deity, but he was integrated into the Olympian gods as the brother of Zeus and Hades. According to some folklore, he was saved by his mother Rhea, who concealed him among a flock of lambs and pretended to have given birth to a colt, which was devoured by Cronos.
There is a Homeric hymn to Poseidon, who was the protector of many Hellenic cities, although he lost the contest for Athens to Athena. According to the references from Plato in his dialogues "Timaeus" and "Critias", the island of Atlantis was the chosen domain of Poseidon.
Etymology.
The earliest attested occurrence of the name, written in Linear B, is "Po-se-da-o" or "Po-se-da-wo-ne", which correspond to ("Poseidaōn") and ("Poseidawonos") in Mycenean Greek; in Homeric Greek it appears as ("Poseidaōn"); in Aeolic as ("Poteidaōn"); and in Doric as ("Poteidan"), ("Poteidaōn"), and ("Poteidas"). The form ("Poteidawn") appears in Corinth. A common epithet of Poseidon is "Enosichthon", "Earth-shaker," an epithet which is also identified in Linear B, as , "E-ne-si-da-o-ne", This recalls his later epithets "Ennosidas" and "Ennosigaios" indicating the chthonic nature of Poseidon.
The origins of the name "Poseidon" are unclear. One theory breaks it down into an element meaning "husband" or "lord" (Greek ("posis"), from PIE "*pótis") and another element meaning "earth" ( ("da"), Doric for ("gē")), producing something like lord or spouse of "Da", i.e. of the earth; this would link him with Demeter, "Earth-mother." Walter Burkert finds that "the second element "da-" remains hopelessly ambiguous" and finds a "husband of Earth" reading "quite impossible to prove."
Another theory interprets the second element as related to the word *δᾶϝον "dâwon", "water"; this would make *"Posei-dawōn" into the master of waters. There is also the possibility that the word has Pre-Greek origin. Plato in his dialogue Cratylus gives two alternative etymologies: either the sea restrained Poseidon when walking as a "foot-bond" (ποσίδεσμον), or he "knew many things" (πολλά εἰδότος or πολλά εἰδῶν).
Bronze Age Greece.
Linear B (Mycenean Greek) inscriptions.
If surviving Linear B clay tablets can be trusted, the name "po-se-da-wo-ne" ("Poseidon") occurs with greater frequency than does "di-u-ja" ("Zeus"). A feminine variant, "po-se-de-ia", is also found, indicating a lost consort goddess, in effect the precursor of Amphitrite.
Poseidon carries frequently the title "wa-na-ka" ( wanax) in Linear B inscriptions, as king of the underworld. The chthonic nature of Poseidon-Wanax is also indicated by his title "E-ne-si-da-o-ne" in Mycenean Knossos and Pylos, a powerful attribute (earthquakes had accompanied the collapse of the Minoan palace-culture). In the cave of Amnisos (Crete) "Enesidaon" is related with the cult of Eileithyia, the goddess of childbirth. She was related with the annual birth of the divine child. During the Bronze Age, a goddess of nature, dominated both in Minoan and Mycenean cult, and "Wanax" ("wa-na-ka") was her male companion (paredros) in Mycenean cult. Is possible that Demeter appears as "Da-ma-te" in a Linear B (Mycenean Greek) inscription (PN EN 609), however the interpretetion is still under dispute 
In Linear B inscriptions found at Pylos, "E-ne-si-da-o-ne" is related with Poseidon, and "Si-to Po-tini-ja" is probably related with Demeter. 
Tablets from Pylos record sacrificial goods destined for "the Two Queens and Poseidon" ("to the Two Queens and the King": "wa-na-soi", "wa-na-ka-te"). The "Two Queens" may be related with Demeter and Persephone, or their precursors, goddesses who were not associated with Poseidon in later periods. 
Arcadian myths.
The illuminating exception is the archaic and localised myth of the stallion Poseidon and mare Demeter at Phigalia in isolated and conservative Arcadia, noted by Pausanias (2nd century AD) as having fallen into desuetude; 
The stallion Poseidon pursues the mare-Demeter, and from the union she bears the horse Arion, and a daughter (Despoina), who obviously had the shape of a mare too. The violated Demeter was "Demeter Erinys" (furious) . In Arcadia, Demeter's mare-form was worshiped into historical times. Her "xoanon" of Phigaleia shows how the local cult interpreted her, as goddess of nature. A Medusa type with a horse's head with snaky hair, holding a dove and a dolphin, probably representing her power over air and water.
Origins.
It seems that the Arcadian myth is related with the first Greek speaking people who entered the region during the bronze age. (Linear B represents an archaic Greek dialect). Their religious beliefs were mixed with the beliefs of the indigenous population. It is possible that the Greeks didn’t bring with them other gods except the god Zeus and the Dioskouroi. The horse (numina) was related with the liguid element, and with the underworld. Poseidon appears as a beast (horse), which is the river spirit of the underworld , as it usually happens in northern-European folklore, and not unusually in Greece. Poseidon “Wanax” , is the male companion (paredros) of the goddess of nature. In the relative Minoan myth, Pasiphaë is mating with the white bull, and she bears the hybrid creature Minotaur. The Bull was the old pre-Olympian Poseidon. The goddess of nature and her paredros survived in the Eleusinian cult, where the following words were uttered : " Mighty Potnia bore a strong son"
In the heavily sea-dependent Mycenaean culture, there is not sufficient evidence that Poseidon was connected with the sea. We don’t know if "Posedeia" was a sea-goddess. Homer and Hesiod suggest that Poseidon became lord of the sea following the defeat of his father Kronos, when the world was divided by lot among his three sons; Zeus was given the sky, Hades the underworld, and Poseidon the sea, with the Earth and Mount Olympus belonging to all three.
Given Poseidon's connection with horses as well as the sea, and the landlocked situation of the likely Indo-European homeland, Nobuo Komita has proposed that Poseidon was originally an aristocratic Indo-European horse-god who was then assimilated to Near Eastern aquatic deities when the basis of the Greek livelihood shifted from the land to the sea, or a god of fresh waters who was assigned a secondary role as god of the sea, where he overwhelmed the original Aegean sea deities such as Proteus and Nereus. Conversely, Walter Burkert suggests that the Hellene cult worship of Poseidon as a horse god may be connected to the introduction of the horse and war-chariot from Anatolia to Greece around 1600 BC.
It is almost sure that once Poseidon was worshiped as a horse, and this is evident by his cult in Peloponnesos. However he was originally a god of the waters, and therefore he became the "earth-shaker", because the Greeks believed that the cause of the earthquakes was the erosion of the rocks by the waters, by the rivers who they saw to disappear into the earth and then to burst out again. This is what the natural philosophers Thales , Anaximenes and Aristotle believed , which couldn’t be diferrent from the folklore belief. Later, when the Myceneans travelled along the sea, he was assigned a role as god of the sea.
In any case, the early importance of Poseidon can still be glimpsed in Homer's Odyssey, where Poseidon rather than Zeus is the major mover of events. In Homer Poseidon is the master of the sea.
Worship of Poseidon.
Poseidon was a major civic god of several cities: in Athens, he was second only to Athena in importance, while in Corinth and many cities of Magna Graecia he was the chief god of the polis.
In his benign aspect, Poseidon was seen as creating new islands and offering calm seas. When offended or ignored, he supposedly struck the ground with his trident and caused chaotic springs, earthquakes, drownings and shipwrecks. Sailors prayed to Poseidon for a safe voyage, sometimes drowning horses as a sacrifice; in this way, according to a fragmentary papyrus, Alexander the Great paused at the Syrian seashore before the climactic battle of Issus, and resorted to prayers, "invoking Poseidon the sea-god, for whom he ordered a four-horse chariot to be cast into the waves."
According to Pausanias, Poseidon was one of the caretakers of the oracle at Delphi before Olympian Apollo took it over. Apollo and Poseidon worked closely in many realms: in colonization, for example, Delphic Apollo provided the authorization to go out and settle, while Poseidon watched over the colonists on their way, and provided the lustral water for the foundation-sacrifice. Xenophon's "Anabasis" describes a group of Spartan soldiers in 400–399 BC singing to Poseidon a paean—a kind of hymn normally sung for Apollo.
Like Dionysus, who inflamed the maenads, Poseidon also caused certain forms of mental disturbance. A Hippocratic text of ca 400 BC, "On the Sacred Disease" says that he was blamed for certain types of epilepsy.
Epithets.
Poseidon was known in various guises, denoted by epithets. In the town of Aegae in Euboea, he was known as "Poseidon Aegaeus" and had a magnificent temple upon a hill. Poseidon also had a close association with horses, known under the epithet "Poseidon Hippios", usually in Arcadia. He is more often regarded as the tamer of horses, but in some myths he is their father, either by spilling his seed upon a rock or by mating with a creature who then gave birth to the first horse. He was closely related with the springs, and with the strike of his trident, he created springs. Many springs like Hippocrene and Aganippe in Helikon are related with the word horse (hippos). 
(also Glukippe, Hyperippe). 
In the historical period, Poseidon was often referred to by the epithets "Enosichthon", "Seisichthon" and "Ennosigaios", and "Gaiēochos" all meaning "earth-shaker" and referring to his role in causing earthquakes.
Some other epithets of Poseidon are:
Poseidon in mythology.
Birth.
Poseidon was the second son of titans Cronus and Rhea. In most accounts he is swallowed by Cronus at birth but later saved, with his other brothers and sisters, by Zeus.
However, in some versions of the story, he, like his brother Zeus, did not share the fate of his other brother and sisters who were eaten by Cronus. He was saved by his mother Rhea, who concealed him among a flock of lambs and pretended to have given birth to a colt, which she gave to Cronus to devour.
According to John Tzetzes the "kourotrophos", or nurse of Poseidon was Arne, who denied knowing where he was, when Cronus came searching; according to Diodorus Siculus Poseidon was raised by the Telchines on Rhodes, just as Zeus was raised by the Korybantes on Crete.
According to a single reference in the "Iliad", when the world was divided by lot in three, Zeus received the sky, Hades the underworld and Poseidon the sea. In the "Odyssey" (v.398), Poseidon has a home in "Aegae".
The foundation of Athens.
Athena became the patron goddess of the city of Athens after a competition with Poseidon. Yet Poseidon remained a numinous presence on the Acropolis in the form of his surrogate, Erechtheus. At the dissolution festival at the end of the year in the Athenian calendar, the Skira, the priests of Athena and the priest of Poseidon would process under canopies to Eleusis. They agreed that each would give the Athenians one gift and the Athenians would choose whichever gift they preferred. Poseidon struck the ground with his trident and a spring sprang up; the water was salty and not very useful, whereas Athena offered them an olive tree.
The Athenians or their king, Cecrops, accepted the olive tree and along with it Athena as their patron, for the olive tree brought wood, oil and food. After the fight, infuriated at his loss, Poseidon sent a monstrous flood to the Attic Plain, to punish the Athenians for not choosing him. The depression made by Poseidon's trident and filled with salt water was surrounded by the northern hall of the Erechtheum, remaining open to the air. "In cult, Poseidon was identified with Erechtheus," Walter Burkert noted; "the myth turns this into a temporal-causal sequence: in his anger at losing, Poseidon led his son Eumolpus against Athens and killed Erectheus."
The contest of Athena and Poseidon was the subject of the reliefs on the western pediment of the Parthenon, the first sight that greeted the arriving visitor.
This myth is construed by Robert Graves and others as reflecting a clash between the inhabitants during Mycenaean times and newer immigrants.
It is interesting to note that Athens at its height was a significant sea power, at one point defeating the Persian fleet at Salamis Island in a sea battle.
The walls of Troy.
Poseidon and Apollo, having offended Zeus by their rebellion in Hera's scheme, were temporarily stripped of their divine authority and sent to serve King Laomedon of Troy. He had them build huge walls around the city and promised to reward them well, a promise he then refused to fulfill. In vengeance, before the Trojan War, Poseidon sent a sea monster to attack Troy. The monster was later killed by Heracles.
Consorts and children.
Poseidon was said to have had many lovers of both sexes (see expandable list below). His consort was Amphitrite, a nymph and ancient sea-goddess, daughter of Nereus and Doris.
Poseidon was the father of many heroes. He is thought to have fathered the famed Theseus.
A mortal woman named Tyro was married to Cretheus (with whom she had one son, Aeson) but loved Enipeus, a river god. She pursued Enipeus, who refused her advances. One day, Poseidon, filled with lust for Tyro, disguised himself as Enipeus, and from their union were born the heroes Pelias and Neleus, twin boys. Poseidon also had an affair with Alope, his granddaughter through Cercyon, his son and King of Eleusis, begetting the Attic hero Hippothoon. Cercyon had his daughter buried alive but Poseidon turned her into the spring, Alope, near Eleusis.
Poseidon rescued Amymone from a lecherous satyr and then fathered a child, Nauplius, by her.
After having raped Caeneus, Poseidon fulfilled her request and changed her into a male warrior.
A mortal woman named Cleito once lived on an isolated island; Poseidon fell in love with the human mortal and created a dwelling sanctuary at the top of a hill near the middle of the island and surrounded the dwelling with rings of water and land to protect her. She gave birth to five sets of twin boys(the firstborn who being named Atlas) became the first rulers of Atlantis.
Not all of Poseidon's children were human. In an archaic myth, Poseidon once pursued Demeter. She spurned his advances, turning herself into a mare so that she could hide in a herd of horses; he saw through the deception and became a stallion and captured her. Their child was a horse, Arion, which was capable of human speech. Poseidon also had sexual intercourse with Medusa on the floor of a temple to Athena.
Medusa was then changed into a monster by Athena. When she was later beheaded by the hero Perseus, Chrysaor and Pegasus emerged from her neck. There is also Triton (the merman), Polyphemus (the cyclops) and, finally, Alebion and Bergion and Otos and Ephialtae (the giants).
List of Poseidon's consorts and children.
Female lovers and offspring.
In Plato's myth of Atlantis, Poseidon consorted with Cleito, daughter of the autochthons Evenor and Leucippe, and had by her ten sons: Ampheres, Atlas, Autochthon, Azaes, Diaprepes, Elasippus, Euaemon, Eumelus (Gadeirus), Mestor, Mneseus.
Poseidon in literature and art.
In Greek art, Poseidon rides a chariot that was pulled by a hippocampus or by horses that could ride on the sea. He was associated with dolphins and three-pronged fish spears (tridents). He lived in a palace on the ocean floor, made of coral and gems.
In the "Iliad" Poseidon favors the Greeks, and on several occasion takes an active part in the battle against the Trojan forces. However, in Book XX he rescues Aeneas after the Trojan prince is laid low by Achilles.
In the "Odyssey", Poseidon is notable for his hatred of Odysseus who blinded the god's son, the cyclops Polyphemus. The enmity of Poseidon prevents Odysseus's return home to Ithaca for many years. Odysseus is even told, notwithstanding his ultimate safe return, that to placate the wrath of Poseidon will require one more voyage on his part.
In the "Aeneid", Neptune is still resentful of the wandering Trojans, but is not as vindictive as Juno, and in Book I he rescues the Trojan fleet from the goddess's attempts to wreck it, although his primary motivation for doing this is his annoyance at Juno's having intruded into his domain.
A hymn to Poseidon included among the Homeric Hymns is a brief invocation, a seven-line introduction that addresses the god as both "mover of the earth and barren sea, god of the deep who is also lord of Helicon and wide Aegae, and specificies his twofold nature as an Olympian: "a tamer of horses and a saviour of ships."
Poseidon appears in Percy Jackson and the Olympians as the father of Percy Jackson and Tyson the Cyclops.
Poseidon appears in the ABC television series "Once Upon a Time" as the guest star of the second half of season four played by Ernie Hudson. In this version, Poseidon is the father of the Sea Witch Ursula.

</doc>
<doc id="22949" url="https://en.wikipedia.org/wiki?curid=22949" title="Population">
Population

A population is a summation of all the organisms of the same group or species, which live in a particular geographical area, and have the capability of interbreeding.
In ecology, the population of a certain species in a certain area is estimated using the Lincoln Index. The area that is used to define a sexual population is defined as the area where inter-breeding is potentially possible between any pair within the area. The probability of interbreeding is greater than the probability of cross-breeding with individuals from other areas. Under normal conditions, breeding is substantially more common within the area than across the border.
In sociology, population refers to a collection of humans. Demography is a social science which entails the statistical study of human populations. This article refers mainly to human population.
Population genetics (ecology).
In population genetics a sexual population is a set of organisms in which any pair of members can breed together. This means that they can regularly exchange gametes to produce normally-fertile offspring, and such a breeding group is also known therefore as a "gamodeme". This also implies that all members belong to the same of species, such as humans.
If the gamodeme is very large (theoretically, approaching infinity), and all gene alleles are uniformly distributed by the gametes within it, the gamodeme is said to be panmictic. Under this state, allele (gamete) frequencies can be converted to genotype (zygote) frequencies by expanding an appropriate quadratic equation, as shown by Sir Ronald Fisher in his establishment of quantitative genetics.
This seldom occurs in nature : localisation of gamete exchange – through dispersal limitations, or preferential mating, or cataclysm, or other cause – may lead to small actual gamodemes which exchange gametes reasonably uniformly within themselves, but are virtually separated from their neighbouring gamodemes. However, there may be low frequencies of exchange with these neighbours. This may be viewed as the breaking up of a large sexual population(panmictic)into smaller overlapping sexual populations. This failure of panmixia leads to two important changes in overall population structure: (1).the component gamodemes vary (through gamete sampling) in their allele frequencies when compared with each other and with the theoretical panmictic original (this is known as "dispersion", and its details can be estimated using expansion of an appropriate binomial equation); and (2). the level of homozygosity rises in the entire collection of gamodemes. The overall rise in homozygosity is quantified by the "inbreeding coefficient" ("f" or "φ"). Note that "all homozygotes" are increased in frequency – both the deleterious and the desirable! The mean phenotype of the gamodemes collection is lower than that of the panmictic "original" – which is known as "inbreeding depression". It is most important to note, however, that some dispersion lines will be superior to the panmictic original, while some will be about the same, and some will be inferior. The probabilities of each can be estimated from those binomial equations. In plant and animal breeding, procedures have been developed which deliberately utilise the effects of dispersion (such as line breeding, pure-line breeding, back-crossing). It can be shown that "dispersion-assisted selection" leads to the greatest "genetic advance" ("ΔG" = change in the phenotypic mean), and is much more powerful than selection acting without attendant dispersion. This is so for both allogamous (random fertilization)
and autogamous (self-fertilization) gamodemes
World human population.
As of today's date, the world population is estimated by the United States Census Bureau to be billion/ million. The US Census Bureau estimates the 7 US billion/7000 million number was surpassed on 12 March 2012. According to a separate estimate by the United Nations, Earth’s population exceeded seven US billion in October 2011, a milestone that offers unprecedented challenges and opportunities to all of humanity, according to UNFPA, the United Nations Population Fund.
According to papers published by the United States Census Bureau,the world population hit 6.5 US billion/6500 million on 24 February 2006. The United Nations Population Fund designated 12 October 1999 as the approximate day on which world population reached 6 US billion/6000 million. This was about 12 years after world population reached 5 US billion/5000 million in 1987, and 6 years after world population reached 5.5 US billion/5500 million in 1993. The population of some countries, such as Nigeria, is not even known to the nearest million, so there is a considerable margin of error in such estimates.
Researcher Carl Haub calculated that a total of over 100 US billion/100 000 million people have probably been born in the last 2000 years.
Predicted growth and decline.
Population growth increased significantly as the Industrial Revolution gathered pace from 1700 onwards. The last 50 years have seen a yet more rapid increase in the rate of population growth due to medical advances and substantial increases in agricultural productivity, particularly beginning in the 1960s, made by the Green Revolution. In 2007 the United Nations Population Division projected that the world's population will likely surpass 10 billion in 2055.
In the future, the world's population is expected to peak, after which it will decline due to economic reasons, health concerns, land exhaustion and environmental hazards. According to one report, it is very likely that the world's population will stop growing before the end of the 21st century. Further, there is some likelihood that population will actually decline before 2100. Population has already declined in the last decade or two in Eastern Europe, the Baltics and in the Commonwealth of Independent States.
The population pattern of less-developed regions of the world in recent years has been marked by gradually declining birth rates. These followed an earlier sharp reduction in death rates. This transition from high birth and death rates to low birth and death rates is often referred to as the demographic transition.
Control.
Human population control is the practice of altering the rate of growth of a human population. Historically, human population control has been implemented with the goal of increasing the rate of population growth. In the period from the 1950s to the 1980s, concerns about global population growth and its effects on poverty, environmental degradation and political stability led to efforts to reduce population growth rates. While population control can involve measures that improve people's lives by giving them greater control of their reproduction, a few programmes, most notably the Chinese government's one-child per family policy, have resorted to coercive measures.
In the 1970s, tension grew between population control advocates and women's health activists who advanced women's reproductive rights as part of a human rights-based approach. Growing opposition to the narrow population control focus led to a significant change in population control policies in the early 1980s.

</doc>
<doc id="22951" url="https://en.wikipedia.org/wiki?curid=22951" title="Psychological egoism">
Psychological egoism

Psychological egoism is the view that humans are always motivated by self-interest, even in what seem to be acts of altruism. It claims that, when people choose to help others, they do so ultimately because of the personal benefits that they themselves expect to obtain, directly or indirectly, from doing so. This is a descriptive rather than normative view, since it only makes claims about how things are, not how they ought to be. It is, however, related to several other normative forms of egoism, such as ethical egoism and rational egoism.
A specific form of psychological egoism is psychological hedonism, the view that the ultimate motive for all voluntary human action is the desire to experience pleasure or to avoid pain. Many discussions of psychological egoism focus on this type, but the two are not the same: theorists have explained behavior motivated by self-interest without using pleasure and pain as the final causes of behavior. Psychological hedonism argues actions are caused by both a need for pleasure immediately and in the future. However, immediate gratification can be sacrificed for a chance of greater, future pleasure. Further, humans are not motivated to strictly avoid pain and only pursue pleasure, but, instead, humans will endure pain to achieve the greatest net pleasure. Accordingly, all actions are tools for increasing pleasure or decreasing pain, even those defined as altruistic and those that do not cause an immediate change in satisfaction levels.
Foundations.
Beginning with ancient philosophy, Epicureanism claims humans live to maximize pleasure. Epicurus argued the theory of human behavior being motivated by pleasure alone is evidenced from infancy to adulthood. Humanity performs altruistic, honorable, and virtuous acts not for the sake of another or because of a moral code but rather to increase the well being of the self.
In modern philosophy, Jeremy Bentham asserted, like Epicurus, that human behavior is governed by a need to increase pleasure and decrease pain. Bentham explicitly described what types and qualities of pain and pleasure exist, and how human motives are singularly explained using psychological hedonism. Bentham attempted to quantify psychological hedonism. Bentham endeavored to find the ideal human behavior based on hedonic calculus or the measurement of relative gains and losses in pain and pleasure to determine the most pleasurable action a human could choose in a situation.
From an evolutionary perspective, Herbert Spencer, a psychological egoist, argued that humans and animals primarily seek to survive and protect their lineage. Essentially, the need for the individual and for the individual's immediate family to live supersedes the others' need to live. All species attempt to maximize their own chances of survival and, therefore, well being. Spencer asserted the best adapted creatures will have their pleasure levels outweigh their pain levels in their environments. Thus, pleasure meant an animal or human was fulfilling its egoist goal of self survival, and pleasure would always be pursued because species constantly strive for survival.
Contributions to modern psychology.
Psychoanalysis.
Whether or not Sigmund Freud was a psychological egoist, his concept of the pleasure principle borrowed much from psychological egoism and psychological hedonism in particular. The pleasure principle rules the behavior of the Id which is an unconscious force driving humans to release tension from unfulfilled desires. When Freud introduced Thanatos and its opposing force, Eros, the pleasure principle emanating from psychological hedonism became aligned with the Eros, which drives a person to satiate sexual and reproductive desires. Alternatively, Thanatos seeks the cessation of pain through death and the end of the pursuit of pleasure: thus a hedonism rules Thanatos, but it centers on the complete avoidance of pain rather than psychological hedonist function which pursues pleasure and avoids pain. Therefore, Freud believed in qualitatively different hedonisms where the total avoidance of pain hedonism and the achievement of the greatest net pleasure hedonism are separate and associated with distinct functions and drives of the human psyche. Although Eros and Thanatos are ruled by qualitatively different types of hedonism, Eros remains under the rule of Jeremy Bentham's quantitative psychological hedonism because Eros seeks the greatest net pleasure.
Behaviorism.
Traditional behaviorism dictates all human behavior is explained by classical conditioning and operant conditioning. Operant conditioning works through reinforcement and punishment which adds or removes pleasure and pain to manipulate behavior. Using pleasure and pain to control behavior means behaviorists assumed the principles of psychological hedonism could be applied to predicting human behavior. For example, Thorndike's law of effect states that behaviors associated with pleasantness will be learned and those associated with pain will be extinguished. Often, behaviorist experiments using humans and animals are built around the assumption that subjects will pursue pleasure and avoid pain. Although psychological hedonism is incorporated into the fundamental principles and experimental designs of behaviorism, behaviorism itself explains and interprets only observable behavior and therefore does not theorize about the ultimate cause of human behavior. Thus, behaviorism uses but does not strictly support psychological hedonism over other understandings of the ultimate drive of human behavior.
The debate.
Psychological egoism is controversial. Proponents cite evidence from introspection: reflection on one's own actions may reveal their motives and intended results to be based on self-interest. Psychological egoists and hedonists have found through numerous observations of natural human behavior that behavior can be manipulated through reward and punishment both of which have direct effects of pain and pleasure. Also, the work of some social scientists has empirically supported this theory. Further, they claim psychological egoism posits a theory that is a more parsimonious explanation than competing theories.
Opponents have argued that psychological egoism is not more parsimonious than other theories. For example, a theory that claims altruism occurs for the sake of altruism explains altruism with less complexity than the egoistic approach. The psychological egoist asserts humans act altruistically for selfish reasons even when cost of the altruistic action is far outweighed by the reward of acting selfishly because altruism is performed to fulfill the desire of a person to act altruistically. Other critics argue that it is false either because it is an over-simplified interpretation of behavior or that there exists empirical evidence of altruistic behaviour. Recently, some have argued that evolutionary theory provides evidence against it.
Critics have stated that proponents of psychological egoism often confuse the satisfaction of their own desires with the satisfaction of their own "self-regarding" desires. Even though it is true that every human being seeks his own satisfaction, this sometimes may only be achieved via the well-being of his neighbor. An example of this situation could be phoning for an ambulance when a car accident has happened. In this case, the caller desires the well-being of the victim, even though the desire itself is the caller's own.
To counter this critique, psychological egoism asserts that all such desires for the well being of others are ultimately derived from self-interest. For example, German philosopher Friedrich Nietzsche was a psychological egoist for some of his career, though he is said to have repudiated that later in his campaign against morality. He argues in §133 of "The Dawn", that in such cases compassionate impulses arise out of the projection of our identity unto the object of our feeling. He gives some hypothetical examples as illustrations to his thesis: that of a person, feeling horrified after witnessing a personal feud, coughing blood, or that of the impulse felt to save a person who is drowning in the water. In such cases, according to Nietzsche, there comes into play unconscious fears regarding our own safety. The suffering of another person is felt as a threat to our own happiness and sense of safety, because it reveals our own vulnerability to misfortunes, and thus, by relieving it, one could also ameliorate those personal sentiments. Essentially, proponents argue that altruism is rooted in self-interest whereas opponents claim altruism occurs for altruism's sake or is caused by a non-selfish reason.
The problem of apparent altruism.
David Hume once wrote, "What interest can a fond mother have in view, who loses her health by assiduous attendance on her sick child, and afterwards languishes and dies of grief, when freed, by its death [the child's], from the slavery of that attendance?". It seems incorrect to describe such a mother's goal as self-interested.
Psychological egoists, however, respond that helping others in such ways is ultimately motivated by some form of self-interest, such as non-sensory satisfaction, the expectation of reciprocation, the desire to gain respect or reputation, or by the expectation of a reward in a putative afterlife. The helpful action is merely instrumental to these ultimately selfish goals.
In the ninth century, "Mohammed Ibn Al-Jahm Al-Barmaki محمد بن الجـَهْم البَرمَكي" has been quoted saying:
"No one deserves thanks from another about something he has done for him or goodness he has done, he is either willing to get a reward from God, therefore he wanted to serve himself, or he wanted to get a reward from people, therefore, he has done that to get profit for himself, or to be mentioned and praised by people, therefore, to it is also for himself, or due to his mercy and tenderheartedness, so he has simply done that goodness to pacify these feelings and treat himself."
This sort of explanation appears to be close to the view of La Rochefoucauld (and perhaps Hobbes).
According to psychological hedonism, the ultimate egoistic motive is to gain good feelings of pleasure and avoid bad feelings of pain. Other, less restricted forms of psychological egoism may allow the ultimate goal of a person to include such things as avoiding punishments from oneself or others (such as guilt or shame) and attaining rewards (such as pride, self-worth, power or reciprocal beneficial action).
Some psychologists explain empathy in terms of psychological hedonism. According to the "merge with others hypothesis," empathy increases the more an individual feels like they are one with another person, and decreases as the oneness decreases. Therefore, altruistic actions emanating from empathy and empathy itself are caused by making others' interests our own, and the satisfaction of their desires becomes our own, not just theirs. Both cognitive studies and neuropsychological experiments have provided evidence for this theory: as humans increase our oneness with others our empathy increases, and as empathy increases our inclination to act altruistically increases. Neuropsychological studies have linked mirror neurons to humans experiencing empathy. Mirror neurons are activated both when a human (or animal) performs an action and when they observe another human (or animal) performs the same action. Researchers have found that the more these mirror neurons fire the more human subjects report empathy. From a neurological perspective, scientists argue that when a human empathizes with another, the brain operates as if the human is actually participating in the actions of the other person. Thus, when performing altruistic actions motivated by empathy, humans experience someone else's pleasure of being helped. Therefore, in performing acts of altruism, people act in their own self interests even at a neurological level.
Criticisms.
Explanatory power.
Even accepting the theory of universal positivity, it is difficult to explain, for example, the actions of a soldier who sacrifices his life by jumping on a grenade in order to save his comrades. In this case, there is simply no time to experience positivity toward one's actions, although a psychological egoist may argue that the soldier experiences moral positivity in knowing that he is sacrificing his life to ensure the survival of his comrades, or that he is avoiding negativity associated with the thought of all his comrades dying. Psychological egoists argue that although some actions may not clearly cause physical nor social positivity, nor avoid negativity, one's current contemplation or reactionary mental expectation of these is the main factor of the decision. When a dog is first taught to sit, it is given a biscuit. This is repeated until, finally, the dog sits without requiring a biscuit. Psychological egoists could claim that such actions which do not 'directly' result in positivity, or reward, are not dissimilar from the actions of the dog. In this case, the action (sitting on command) will have become a force of habit, and breaking such a habit would result in mental discomfort. This basic theory of conditioning behavior, applied to other seemingly ineffective positive actions, can be used to explain moral responses that are instantaneous and instinctive such as the soldier jumping on the grenade.
Circularity.
Psychological egoism has been accused of being circular: "If a person willingly performs an act, that means he derives personal enjoyment from it; therefore, people only perform acts that give them personal enjoyment." In particular, seemingly altruistic acts must be performed because people derive enjoyment from them and are therefore, in reality, egoistic. This statement is circular because its conclusion is identical to its hypothesis: it assumes that people only perform acts that give them personal enjoyment, and concludes that people only perform acts that give them personal enjoyment. This objection was tendered by William Hazlitt and Thomas Macaulay in the 19th century, and has been restated many times since. An earlier version of the same objection was made by Joseph Butler in 1726.
Joel Feinberg, in his 1958 paper "Psychological Egoism", embraces a similar critique by drawing attention to the infinite regress of psychological egoism. He expounds it in the following cross-examination:

</doc>
<doc id="22954" url="https://en.wikipedia.org/wiki?curid=22954" title="Plato">
Plato

Plato (; Greek: "Plátōn" in Classical Attic; 428/427 or 424/423 – 348/347 BC) was a philosopher and mathematician in Classical Greece, and the founder of the Academy in Athens, the first institution of higher learning in the Western world. He is widely considered the most pivotal figure in the development of philosophy, especially the Western tradition. Unlike nearly all of his philosophical contemporaries, Plato's entire "œuvre" is believed to have survived intact for over 2,400 years.
Along with his teacher, Socrates, and his most famous student, Aristotle, Plato laid the very foundations of Western philosophy and science. Alfred North Whitehead once noted: "the safest general characterization of the European philosophical tradition is that it consists of a series of footnotes to Plato." In addition to being a foundational figure for Western science, philosophy, and mathematics, Plato has also often been cited as one of the founders of Western religion and spirituality, particularly Christianity, which Friedrich Nietzsche, amongst other scholars, called "Platonism for the people". Plato's influence on Christian thought is often thought to be mediated by his major influence on Saint Augustine of Hippo, one of the most important philosophers and theologians in the history of Christianity.
Plato was the innovator of the dialogue and dialectic forms in philosophy, which originate with him. Plato appears to have been the founder of Western political philosophy, with his "Republic", and "Laws" among other dialogues, providing some of the earliest extant treatments of political questions from a philosophical perspective. Plato's own most decisive philosophical influences are usually thought to have been Socrates, Parmenides, Heraclitus and Pythagoras, although few of his predecessors' works remain extant and much of what we know about these figures today derives from Plato himself. 
The Stanford Encyclopedia of Philosophy describes Plato as "...one of the most dazzling writers in the Western literary tradition and one of the most penetrating, wide-ranging, and influential authors in the history of philosophy. ... He was not the first thinker or writer to whom the word “philosopher” should be applied. But he was so self-conscious about how philosophy should be conceived, and what its scope and ambitions properly are, and he so transformed the intellectual currents with which he grappled, that the subject of philosophy, as it is often conceived—a rigorous and systematic examination of ethical, political, metaphysical, and epistemological issues, armed with a distinctive method—can be called his invention. Few other authors in the history of Western philosophy approximate him in depth and range: perhaps only Aristotle (who studied with him), Aquinas and Kant would be generally agreed to be of the same rank."
Biography.
Early life.
Little can be known about Plato's early life and education, due to a lack of surviving accounts. The philosopher came from one of the wealthiest and most politically active families in Athens. Ancient sources describe him as a bright though modest boy who excelled in his studies. His father contributed all which was necessary to give to his son a good education, and, therefore, Plato must have been instructed in grammar, music, gymnastics and philosophy by some of the most distinguished teachers of his era.
Birth and family.
The exact time and place of Plato's birth are not known, but it is certain that he belonged to an aristocratic and influential family. Based on ancient sources, most modern scholars believe that he was born in Athens or Aegina between 429 and 423 BCE. His father was Ariston. According to a disputed tradition, reported by Diogenes Laertius, Ariston traced his descent from the king of Athens, Codrus, and the king of Messenia, Melanthus. Plato's mother was Perictione, whose family boasted of a relationship with the famous Athenian lawmaker and lyric poet Solon. Perictione was sister of Charmides and niece of Critias, both prominent figures of the Thirty Tyrants, the brief oligarchic regime, which followed on the collapse of Athens at the end of the Peloponnesian War (404–403 BCE). Besides Plato himself, Ariston and Perictione had three other children; these were two sons, Adeimantus and Glaucon, and a daughter Potone, the mother of Speusippus (the nephew and successor of Plato as head of his philosophical Academy). The brothers Adeimantus and Glaucon are mentioned in the "Republic" as sons of Ariston, and presumably brothers of Plato, but some have argued they were uncles. But in a scenario in the Memorabilia, Xenophon confused the issue by presenting a Glaucon much younger than Plato.
The traditional date of Plato's birth (428/427) is based on a dubious interpretation of Diogenes Laertius, who says, "When [Socrates] was gone, [Plato] joined Cratylus the Heracleitean and Hermogenes, who philosophized in the manner of Parmenides. Then, at twenty-eight, Hermodorus says, [Plato] went to Euclides in Megara." As Debra Nails argues, "The text itself gives no reason to infer that Plato left immediately for Megara and implies the very opposite." In his Seventh Letter, Plato notes that his coming of age coincided with the taking of power by the Thirty, remarking, "But a youth under the age of twenty made himself a laughingstock if he attempted to enter the political arena." Thus, Nails dates Plato's birth to 424/423.
According to some accounts, Ariston tried to force his attentions on Perictione, but failed in his purpose; then the god Apollo appeared to him in a vision, and as a result, Ariston left Perictione unmolested. Another legend related that, when Plato was an infant, bees settled on his lips while he was sleeping: an augury of the sweetness of style in which he would discourse about philosophy.
Ariston appears to have died in Plato's childhood, although the precise dating of his death is difficult. Perictione then married Pyrilampes, her mother's brother, who had served many times as an ambassador to the Persian court and was a friend of Pericles, the leader of the democratic faction in Athens. Pyrilampes had a son from a previous marriage, Demus, who was famous for his beauty. Perictione gave birth to Pyrilampes' second son, Antiphon, the half-brother of Plato, who appears in "Parmenides".
In contrast to reticence about himself, Plato often introduced his distinguished relatives into his dialogues, or referred to them with some precision: Charmides has a dialogue named after him; Critias speaks in both "Charmides" and "Protagoras"; and Adeimantus and Glaucon take prominent parts in the "Republic". These and other references suggest a considerable amount of family pride and enable us to reconstruct Plato's family tree. According to Burnet, "the opening scene of the "Charmides" is a glorification of the whole [family] connection ... Plato's dialogues are not only a memorial to Socrates, but also the happier days of his own family."
Name.
According to Diogenes Laërtius, the philosopher was named "Aristocles" (Ἀριστοκλῆς) after his grandfather. It was common in Athenian society for boys to be named after grandfathers (or fathers). But there is only one inscriptional record of an Aristocles, an early Archon of Athens in 605/4 BCE. There is no record of a line from Aristocles to Plato's father, Ariston. However, if Plato was not named after an ancestor named Plato (there is no record of one), then the origin of his renaming as "Plato" becomes a conundrum.
The sources of Diogenes account for this fact by claiming that his wrestling coach, Ariston of Argos, dubbed him "Platon", meaning "broad," on account of his robust figure or that Plato derived his name from the breadth (πλατύτης, "platytēs") of his eloquence, or else because he was very wide (πλατύς, "platýs") across the forehead. Recently a scholar has argued that even the name Aristocles for Plato was a much later invention. Although "Platon" was a fairly common name (31 instances are known from Athens alone), the name does not occur in Plato's known family line. The fact that the philosopher in his maturity called himself "Platon" is indisputable, but the origin of this naming must remain moot unless the record is made to yield more information.
Education.
Apuleius informs us that Speusippus praised Plato's quickness of mind and modesty as a boy, and the "first fruits of his youth infused with hard work and love of study". Plato must have been instructed in grammar, music, and gymnastics by the most distinguished teachers of his time. Dicaearchus went so far as to say that Plato wrestled at the Isthmian games. Plato had also attended courses of philosophy; before meeting Socrates, he first became acquainted with Cratylus (a disciple of Heraclitus, a prominent pre-Socratic Greek philosopher) and the Heraclitean doctrines. W. A. Borody argues that an Athenian openness towards a wider range of sexuality may have contributed to the Athenian philosophers' openness towards a wider range of thought, a cultural situation Borody describes as "polymorphously discursive."
Plato and Pythagoras.
Although Socrates influenced Plato directly as related in the dialogues, the influence of Pythagoras upon Plato also appears to have significant discussion in the philosophical literature. Pythagoras, or in a broader sense, the Pythagoreans, allegedly exercised an important influence on the work of Plato. According to R. M. Hare, this influence consists of three points: (1) The platonic Republic might be related to the idea of "a tightly organized community of like-minded thinkers", like the one established by Pythagoras in Croton. (2) There is evidence that Plato possibly took from Pythagoras the idea that mathematics and, generally speaking, abstract thinking is a secure basis for philosophical thinking as well as "for substantial theses in science and morals". (3) Plato and Pythagoras shared a "mystical approach to the soul and its place in the material world". It is probable that both were influenced by Orphism.
Aristotle claimed that the philosophy of Plato closely followed the teachings of the Pythagoreans, and Cicero repeats this claim: "Platonem ferunt didicisse Pythagorea omnia" ("They say Plato learned all things Pythagorean"). Bertrand Russell, in his "A History of Western Philosophy", contended that the influence of Pythagoras on Plato and others was so great that he should be considered the most influential of all Western philosophers.
Plato and Socrates.
The precise relationship between Plato and Socrates remains an area of contention among scholars. Plato makes it clear in his "Apology of Socrates", that he was a devoted young follower of Socrates. In that dialogue, Socrates is presented as mentioning Plato by name as one of those youths close enough to him to have been corrupted, if he were in fact guilty of corrupting the youth, and questioning why their fathers and brothers did not step forward to testify against him if he was indeed guilty of such a crime (33d-34a). Later, Plato is mentioned along with Crito, Critobolus, and Apollodorus as offering to pay a fine of 30 minas on Socrates' behalf, in lieu of the death penalty proposed by Meletus (38b). In the "Phaedo", the title character lists those who were in attendance at the prison on Socrates' last day, explaining Plato's absence by saying, "Plato was ill." ("Phaedo" 59b)
Plato never speaks in his own voice in his dialogues. In the "Second Letter", it says, "no writing of Plato exists or ever will exist, but those now said to be his are those of a Socrates become beautiful and new" (341c); if the Letter is Plato's, the final qualification seems to call into question the dialogues' historical fidelity. In any case, Xenophon and Aristophanes seem to present a somewhat different portrait of Socrates from the one Plato paints. Some have called attention to the problem of taking Plato's Socrates to be his mouthpiece, given Socrates' reputation for irony and the dramatic nature of the dialogue form.
Aristotle attributes a different doctrine with respect to the Ideas to Plato and Socrates ("Metaphysics" 987b1–11). Putting it in a nutshell, Aristotle merely suggests that Socrates' idea of forms can be discovered through investigation of the natural world, unlike Plato's Forms that exist beyond and outside the ordinary range of human understanding.
Later life.
Plato may have traveled in Italy, Sicily, Egypt and Cyrene, Libya. Said to have returned to Athens at the age of forty, Plato founded one of the earliest known organized schools in Western Civilization on a plot of land in the Grove of Hecademus or Academus. The Academy was a large enclosure of ground about six stadia outside of Athens proper. One story is that the name of the Academy comes from the ancient hero, Academus. Another story is that the name came from a supposed a former owner, a citizen of Athens also named Academus. Yet another account is that it was named after a member of the army of Castor and Pollux, an Arcadian named Echedemus. The Academy operated until it was destroyed by Lucius Cornelius Sulla in 84 BCE. Neoplatonists revived the Academy in the early 5th century, and it operated until AD 529, when it was closed by Justinian I of Byzantium, who saw it as a threat to the propagation of Christianity. Many intellectuals were schooled in the Academy, the most prominent one being Aristotle.
Throughout his later life, Plato became entangled with the politics of the city of Syracuse. According to Diogenes Laertius, Plato initially visited Syracuse while it was under the rule of Dionysius. During this first trip Dionysius's brother-in-law, Dion of Syracuse, became one of Plato's disciples, but the tyrant himself turned against Plato. Plato almost faced death, but he was sold into slavery. Then Anniceris bought Plato's freedom for twenty minas, and sent him home. After Dionysius's death, according to Plato's "Seventh Letter", Dion requested Plato return to Syracuse to tutor Dionysius II and guide him to become a philosopher king. Dionysius II seemed to accept Plato's teachings, but he became suspicious of Dion, his uncle. Dionysius expelled Dion and kept Plato against his will. Eventually Plato left Syracuse. Dion would return to overthrow Dionysius and ruled Syracuse for a short time before being usurped by Calippus, a fellow disciple of Plato.
Death.
A variety of sources have given accounts of Plato's death. One story, based on a mutilated manuscript, suggests Plato died in his bed, whilst a young Thracian girl played the flute to him. Another tradition suggests Plato died at a wedding feast. The account is based on Diogenes Laertius's reference to an account by Hermippus, a third-century Alexandrian. According to Tertullian, Plato simply died in his sleep.
Philosophy.
Recurrent themes.
Plato often discusses the father-son relationship and the question of whether a father's interest in his sons has much to do with how well his sons turn out. In ancient Athens, a boy was socially located by his family identity, and Plato often refers to his characters in terms of their paternal and fraternal relationships. Socrates was not a family man, and saw himself as the son of his mother, who was apparently a midwife. A divine fatalist, Socrates mocks men who spent exorbitant fees on tutors and trainers for their sons, and repeatedly ventures the idea that good character is a gift from the gods. Crito reminds Socrates that orphans are at the mercy of chance, but Socrates is unconcerned. In the "Theaetetus", he is found recruiting as a disciple a young man whose inheritance has been squandered. Socrates twice compares the relationship of the older man and his boy lover to the father-son relationship ("Lysis" 213a, "Republic" 3.403b), and in the "Phaedo", Socrates' disciples, towards whom he displays more concern than his biological sons, say they will feel "fatherless" when he is gone.
In several of Plato's dialogues, Socrates promulgates the idea that knowledge is a matter of recollection, and not of learning, observation, or study. He maintains this view somewhat at his own expense, because in many dialogues, Socrates complains of his forgetfulness. Socrates is often found arguing that knowledge is not empirical, and that it comes from divine insight. In many middle period dialogues, such as the "Phaedo", "Republic" and "Phaedrus" Plato advocates a belief in the immortality of the soul, and several dialogues end with long speeches imagining the afterlife. More than one dialogue contrasts knowledge and opinion, perception and reality, nature and custom, and body and soul.
Several dialogues tackle questions about art: Socrates says that poetry is inspired by the muses, and is not rational. He speaks approvingly of this, and other forms of divine madness (drunkenness, eroticism, and dreaming) in the "Phaedrus "(265a–c), and yet in the 'Republic' wants to outlaw Homer's great poetry, and laughter as well. In "Ion", Socrates gives no hint of the disapproval of Homer that he expresses in the "Republic". The dialogue "Ion" suggests that Homer's "Iliad" functioned in the ancient Greek world as the Bible does today in the modern Christian world: as divinely inspired literature that can provide moral guidance, if only it can be properly interpreted.
Socrates and his company of disputants had something to say on many subjects, including politics and art, religion and science, justice and medicine, virtue and vice, crime and punishment, pleasure and pain, rhetoric and rhapsody, human nature and sexuality, as well as love and wisdom.
Metaphysics.
"Platonism" is a term coined by scholars to refer to the intellectual consequences of denying, as Plato's Socrates often does, the reality of the material world. In several dialogues, most notably the "Republic", Socrates inverts the common man's intuition about what is knowable and what is real. While most people take the objects of their senses to be real if anything is, Socrates is contemptuous of people who think that something has to be graspable in the hands to be real. In the "Theaetetus", he says such people are "eu amousoi" (εὖ ἄμουσοι), an expression that means literally, "happily without the muses" ("Theaetetus" 156a). In other words, such people live without the divine inspiration that gives him, and people like him, access to higher insights about reality.
Socrates's idea that reality is unavailable to those who use their senses is what puts him at odds with the common man, and with common sense. Socrates says that he who sees with his eyes is blind, and this idea is most famously captured in his allegory of the cave, and more explicitly in his description of the divided line. The allegory of the cave (begins "Republic" 7.514a) is a paradoxical analogy wherein Socrates argues that the invisible world is the most intelligible ("noeton") and that the visible world ("(h)oraton") is the least knowable, and the most obscure.
Socrates says in the "Republic" that people who take the sun-lit world of the senses to be good and real are living pitifully in a den of evil and ignorance. Socrates admits that few climb out of the den, or cave of ignorance, and those who do, not only have a terrible struggle to attain the heights, but when they go back down for a visit or to help other people up, they find themselves objects of scorn and ridicule.
According to Socrates, physical objects and physical events are "shadows" of their ideal or perfect forms, and exist only to the extent that they instantiate the perfect versions of themselves. Just as shadows are temporary, inconsequential epiphenomena produced by physical objects, physical objects are themselves fleeting phenomena caused by more substantial causes, the ideals of which they are mere instances. For example, Socrates thinks that perfect justice exists (although it is not clear where) and his own trial would be a cheap copy of it.
The allegory of the cave (often said by scholars to represent Plato's own epistemology and metaphysics) is intimately connected to his political ideology (often said to also be Plato's own), that only people who have climbed out of the cave and cast their eyes on a vision of goodness are fit to rule. Socrates claims that the enlightened men of society must be forced from their divine contemplations and be compelled to run the city according to their lofty insights. Thus is born the idea of the "philosopher-king", the wise person who accepts the power thrust upon him by the people who are wise enough to choose a good master. This is the main thesis of Socrates in the "Republic", that the most wisdom the masses can muster is the wise choice of a ruler.
Theory of Forms.
The theory of Forms (or theory of Ideas) typically refers to the belief that the material world as it seems to us is not the real world, but only an "image" or "copy" of the real world. In some of Plato's dialogues, this is expressed by Socrates, who spoke of forms in formulating a solution to the problem of universals. The forms, according to Socrates, are archetypes or abstract representations of the many types of things, and properties we feel and see around us, that can only be perceived by reason (). (That is, they are universals.) In other words, Socrates was able to recognize two worlds: the apparent world, which constantly changes, and an unchanging and unseen world of forms, which may be the cause of what is apparent.
Epistemology.
Many have interpreted Plato as stating—even having been the first to write—that knowledge is justified true belief, an influential view that informed future developments in epistemology. This interpretation is partly based on a reading of the "Theaetetus" wherein Plato argues that knowledge is distinguished from mere true belief by the knower having an "account" of the object of her or his true belief (). And this theory may again be seen in the "Meno", where it is suggested that true belief can be raised to the level of knowledge if it is bound with an account as to the question of "why" the object of the true belief is so (). Many years later, Edmund Gettier famously demonstrated the problems of the justified true belief account of knowledge. That the modern theory of justified true belief as knowledge which Gettier addresses is equivalent to Plato's is accepted by some scholars but rejected by others. Plato himself also identified problems with the "justified true belief" definition in the "Theaetetus", concluding that justification (or an "account") would require knowledge of "differentness", meaning that the definition of knowledge is circular ().
Later in the "Meno", Socrates uses a geometrical example to expound Plato's view that knowledge in this latter sense is acquired by recollection. Socrates elicits a fact concerning a geometrical construction from a slave boy, who could not have otherwise known the fact (due to the slave boy's lack of education). The knowledge must be present, Socrates concludes, in an eternal, non-experiential form.
In other dialogues, the "Sophist", "Statesman", "Republic", and the "Parmenides", Plato himself associates knowledge with the apprehension of unchanging Forms and their relationships to one another (which he calls "expertise" in Dialectic), including through the processes of "collection" and "division". More explicitly, Plato himself argues in the "Timaeus" that knowledge is always proportionate to the realm from which it is gained. In other words, if one derives one's account of something experientially, because the world of sense is in flux, the views therein attained will be mere opinions. And opinions are characterized by a lack of necessity and stability. On the other hand, if one derives one's account of something by way of the non-sensible forms, because these forms are unchanging, so too is the account derived from them. That apprehension of forms is required for knowledge may be taken to cohere with Plato's theory in the "Theaetetus" and "Meno". Indeed, the apprehension of Forms may be at the base of the "account" required for justification, in that it offers foundational knowledge which itself needs no account, thereby avoiding an infinite regression.
The state.
Plato's philosophical views had many societal implications, especially on the idea of an ideal state or government. There is some discrepancy between his early and later views. Some of the most famous doctrines are contained in the "Republic" during his middle period, as well as in the "Laws" and the "Statesman". However, because Plato wrote dialogues, it is assumed that Socrates is often speaking for Plato. This assumption may not be true in all cases.
Plato, through the words of Socrates, asserts that societies have a tripartite class structure corresponding to the appetite/spirit/reason structure of the individual soul. The appetite/spirit/reason are analogous to the castes of society.
In the Timaeus, Plato locates the parts of the soul within the human body: Reason is located in the head, spirit in the top third of the torso, and the appetite in the middle third of the torso, down to the navel.
According to this model, the principles of Athenian democracy (as it existed in his day) are rejected as only a few are fit to rule. Instead of rhetoric and persuasion, Plato says reason and wisdom should govern. As Plato puts it:
Plato describes these "philosopher kings" as "those who love the sight of truth" ("Republic" 475c) and supports the idea with the analogy of a captain and his ship or a doctor and his medicine. According to him, sailing and health are not things that everyone is qualified to practice by nature. A large part of the "Republic" then addresses how the educational system should be set up to produce these philosopher kings.
However, it must be taken into account that the ideal city outlined in the "Republic" is qualified by Socrates as the ideal "luxurious" city, examined to determine how it is that injustice and justice grow in a city ("Republic" 372e). According to Socrates, the "true" and "healthy" city is instead the one first outlined in book II of the "Republic", 369c–372d, containing farmers, craftsmen, merchants, and wage-earners, but lacking the guardian class of philosopher-kings as well as delicacies such as "perfumed oils, incense, prostitutes, and pastries", in addition to paintings, gold, ivory, couches, a multitude of occupations such as poets and hunters, and war.
In addition, the ideal city is used as an image to illuminate the state of one's soul, or the will, reason, and desires combined in the human body. Socrates is attempting to make an image of a rightly ordered human, and then later goes on to describe the different kinds of humans that can be observed, from tyrants to lovers of money in various kinds of cities. The ideal city is not promoted, but only used to magnify the different kinds of individual humans and the state of their soul. However, the philosopher king image was used by many after Plato to justify their personal political beliefs. The philosophic soul according to Socrates has reason, will, and desires united in virtuous harmony. A philosopher has the moderate love for wisdom and the courage to act according to wisdom. Wisdom is knowledge about the Good or the right relations between all that exists.
Wherein it concerns states and rulers, Plato has made interesting arguments. For instance he asks which is better—a bad democracy or a country reigned by a tyrant. He argues that it is better to be ruled by a bad tyrant, than be a bad democracy (since here all the people are now responsible for such actions, rather than one individual committing many bad deeds.) This is emphasised within the "Republic" as Plato describes the event of mutiny on board a ship. Plato suggests the ship's crew to be in line with the democratic rule of many and the captain, although inhibited through ailments, the tyrant. Plato's description of this event is parallel to that of democracy within the state and the inherent problems that arise.
According to Plato, a state made up of different kinds of souls will, overall, decline from an aristocracy (rule by the best) to a timocracy (rule by the honorable), then to an oligarchy (rule by the few), then to a democracy (rule by the people), and finally to tyranny (rule by one person, rule by a tyrant). Aristocracy is the form of government ("politeia") advocated in Plato's
"Republic". This regime is ruled by a philosopher king, and thus is grounded on wisdom and reason. The aristocratic state, and the man whose nature corresponds to it, are the objects of Plato's analyses throughout much of the "Republic", as opposed to the other four types of states/men, who are discussed later in his work. In Book VIII, Plato states in order the other four imperfect societies with a description of the state's structure and individual character. In timocracy the ruling class is made up primarily of those with a warrior-like character. In his description, Plato has Sparta in mind. Oligarchy is made up of a society in which wealth is the criterion of merit and the wealthy are in control. In democracy, the state bears resemblance to ancient Athens with traits such as equality of political opportunity and freedom for the individual to do as he likes. Democracy then degenerates into tyranny from the conflict of rich and poor. It is characterized by an undisciplined society existing in chaos, where the tyrant rises as popular champion leading to the formation of his private army and the growth of oppression.
Unwritten doctrines.
For a long time, Plato's unwritten doctrine had been controversial. Many modern books on Plato seem to diminish its importance; nevertheless, the first important witness who mentions its existence is Aristotle, who in his "Physics" (209 b) writes: "It is true, indeed, that the account he gives there [i.e. in "Timaeus"] of the participant is different from what he says in his so-called "unwritten teachings" (ἄγραφα δόγματα)." The term "ἄγραφα δόγματα" literally means "unwritten doctrines" and it stands for the most fundamental metaphysical teaching of Plato, which he disclosed only orally, and some say only to his most trusted fellows, and which he may have kept secret from the public. The importance of the unwritten doctrines does not seem to have been seriously questioned before the 19th century.
A reason for not revealing it to everyone is partially discussed in "Phaedrus" (276 c) where Plato criticizes the written transmission of knowledge as faulty, favoring instead the spoken logos: "he who has knowledge of the just and the good and beautiful ... will not, when in earnest, write them in ink, sowing them through a pen with words, which cannot defend themselves by argument and cannot teach the truth effectually." The same argument is repeated in Plato's "Seventh Letter" (344 c): "every serious man in dealing with really serious subjects carefully avoids writing." In the same letter he writes (341 c): "I can certainly declare concerning all these writers who claim to know the subjects that I seriously study ... there does not exist, nor will there ever exist, any treatise of mine dealing therewith." Such secrecy is necessary in order not "to expose them to unseemly and degrading treatment" (344 d).
It is, however, said that Plato once disclosed this knowledge to the public in his lecture "On the Good" (Περὶ τἀγαθοῦ), in which the Good (τὸ ἀγαθόν) is identified with the One (the Unity, τὸ ἕν), the fundamental ontological principle. The content of this lecture has been transmitted by several witnesses. Aristoxenus describes the event in the following words: "Each came expecting to learn something about the things that are generally considered good for men, such as wealth, good health, physical strength, and altogether a kind of wonderful happiness. But when the mathematical demonstrations came, including numbers, geometrical figures and astronomy, and finally the statement Good is One seemed to them, I imagine, utterly unexpected and strange; hence some belittled the matter, while others rejected it." Simplicius quotes Alexander of Aphrodisias, who states that "according to Plato, the first principles of everything, including the Forms themselves are One and Indefinite Duality (ἡ ἀόριστος δυάς), which he called Large and Small (τὸ μέγα καὶ τὸ μικρόν)", and Simplicius reports as well that "one might also learn this from Speusippus and Xenocrates and the others who were present at Plato's lecture on the Good".
Their account is in full agreement with Aristotle's description of Plato's metaphysical doctrine. In "Metaphysics" he writes: "Now since the Forms are the causes of everything else, he [i.e. Plato] supposed that their elements are the elements of all things. Accordingly the material principle is the Great and Small [i.e. the Dyad], and the essence is the One (τὸ ἕν), since the numbers are derived from the Great and Small by participation in the One" (987 b). "From this account it is clear that he only employed two causes: that of the essence, and the material cause; for the Forms are the cause of the essence in everything else, and the One is the cause of it in the Forms. He also tells us what the material substrate is of which the Forms are predicated in the case of sensible things, and the One in that of the Forms - that it is this the duality (the Dyad, ἡ δυάς), the Great and Small (τὸ μέγα καὶ τὸ μικρόν). Further, he assigned to these two elements respectively the causation of good and of evil" (988 a).
The most important aspect of this interpretation of Plato's metaphysics is the continuity between his teaching and the neoplatonic interpretation of Plotinus or Ficino which has been considered erroneous by many but may in fact have been directly influenced by oral transmission of Plato's doctrine. A modern scholar who recognized the importance of the unwritten doctrine of Plato was Heinrich Gomperz who described it in his speech during the 7th International Congress of Philosophy in 1930. All the sources related to the ἄγραφα δόγματα have been collected by Konrad Gaiser and published as "Testimonia Platonica". These sources have subsequently been interpreted by scholars from the German "Tübingen School of interpretation" such as Hans Joachim Krämer or Thomas A. Szlezák.
Dialectic.
The role of dialectic in Plato's thought is contested but there are two main interpretations: a type of reasoning and a method of intuition. Simon Blackburn adopts the first, saying that Plato's dialectic is "the process of eliciting the truth by means of questions aimed at opening out what is already implicitly known, or at exposing the contradictions and muddles of an opponent's position." A similar interpretation has been put forth by Louis Hartz, who suggests that elements of the dialectic are borrowed from Hegel. According to this view, opposing arguments improve upon each other, and prevailing opinion is shaped by the synthesis of many conflicting ideas over time. Each new idea exposes a flaw in the accepted model, and the epistemological substance of the debate continually approaches the truth. Hartz's is a teleological interpretation at the core, in which philosophers will ultimately exhaust the available body of knowledge and thus reach "the end of history." Karl Popper, on the other hand, claims that dialectic is the art of intuition for "visualising the divine originals, the Forms or Ideas, of unveiling the Great Mystery behind the common man's everyday world of appearances."
The dialogues.
Thirty-five dialogues and thirteen letters (the "Epistles") have traditionally been ascribed to Plato, though modern scholarship doubts the authenticity of at least some of these. Plato's writings have been published in several fashions; this has led to several conventions regarding the naming and referencing of Plato's texts.
The usual system for making unique references to sections of the text by Plato derives from a 16th-century edition of Plato's works by Henricus Stephanus. An overview of Plato's writings according to this system can be found in the Stephanus pagination article.
One tradition regarding the arrangement of Plato's texts is according to tetralogies. This scheme is ascribed by Diogenes Laertius to an ancient scholar and court astrologer to Tiberius named Thrasyllus.
The works are usually grouped into "Early", (sometimes by some into "Transitional"), "Middle", and "Late" period. This choice to group chronologically is thought worthy of criticism by some (Cooper "et al"), given that it's recognised that there is no absolute agreement as to the true chronologicity, since the facts of the temporal order of writing are not confidently ascertained.
Early : "Apology (of Socrates)", "Charmides", "Crito", "Euthyphro", "Gorgias", "(Lesser) Hippias (minor)", "(Greater) Hippias (major)", "Ion", "Laches", "Lysis", "Protagoras"
Middle/Transitional : "Cratylus", "Euthydemus", "Meno", "Parmenides", "Phaedo", "Phaedrus", "Republic", "Symposium",
Middle/Late : "Theaetetus"
Late : "Critias", "Sophist", "Statesman / Politicus", "Timaeus" , "Philebus", "Laws"
Chronologicity was not a consideration in ancient times, in that grouping of this nature are "virtually absent" (Tarrant) in the extant writings of ancient Platonists.
Writings of doubted authenticity.
Jowett mentions in his Appendix to Menexenus, that works which bore the character of a writer were attributed to that writer even when the actual author was unknown.
For below:
(*) if there is no consensus among scholars as to whether Plato is the author, and (‡) if most scholars agree that Plato is "not" the author of the work.
"First Alcibiades" (*), "Second Alcibiades" (‡), "Clitophon" (*), "Epinomis" (‡), "Epistles" (*), "Hipparchus" (‡), "Menexenus"(*), "Minos" (‡) "(Rival) Lovers" (‡), "Theages" (‡)
Spurious writings.
The following works were transmitted under Plato's name, most of them already considered spurious in antiquity, and so were not included by Thrasyllus in his tetralogical arrangement. These works are labelled as "Notheuomenoi" ("spurious") or "Apocrypha".
Composition of the dialogues.
No one knows the exact order Plato's dialogues were written in, nor the extent to which some might have been later revised and rewritten. A significant distinction of the early Plato and the later Plato has been offered by scholars such as E.R. Dodds and has been summarized by Harold Bloom in his book titled "Agon": "E.R. Dodds is the classical scholar whose writings most illuminated the Hellenic descent (in) "The Greeks and the Irrational" [...] In his chapter on Plato and the Irrational Soul [...] Dodds traces Plato's spiritual evolution from the pure rationalist of the "Protagoras" to the transcendental psychologist, influenced by the Pythagoreans and Orphics, of the later works culminating in the "Laws"."
Lewis Campbell was the first to make exhaustive use of stylometry to prove objectively that the "Critias", "Timaeus", "Laws", "Philebus", "Sophist", and "Statesman" were all clustered together as a group, while the "Parmenides", "Phaedrus", "Republic", and "Theaetetus" belong to a separate group, which must be earlier (given Aristotle's statement in his "Politics" that the "Laws" was written after the "Republic"; cf. Diogenes Laertius "Lives" 3.37). What is remarkable about Campbell's conclusions is that, in spite of all the stylometric studies that have been conducted since his time, perhaps the only chronological fact about Plato's works that can now be said to be "proven" by stylometry is the fact that "Critias", "Timaeus", "Laws", "Philebus", "Sophist", and "Statesman" are the latest of Plato's dialogues, the others earlier.
Increasingly in the most recent Plato scholarship, writers are skeptical of the notion that the order of Plato's writings can be established with any precision, though Plato's works are still often characterized as falling at least roughly into three groups. The following represents one relatively common such division. It should, however, be kept in mind that many of the positions in the ordering are still highly disputed, and also that the very notion that Plato's dialogues can or should be "ordered" is by no means universally accepted.
Among those who classify the dialogues into periods of composition, Socrates figures in all of the "early dialogues" and they are considered the most faithful representations of the historical Socrates. They include "The Apology of Socrates", "Charmides", "Crito", "Euthyphro", "Ion", "Laches", "Lesser Hippias", "Lysis", "Menexenus", and "Protagoras" (often considered one of the last of the "early dialogues"). Three dialogues are often considered "transitional" or "pre-middle": "Euthydemus", "Gorgias", and "Meno".
Whereas those classified as "early dialogues" often conclude in aporia, the so-called "middle dialogues" provide more clearly stated positive teachings that are often ascribed to Plato such as the theory of Forms. These dialogues include "Cratylus", "Phaedo", "Phaedrus", "Republic", "Symposium", "Parmenides", and "Theaetetus". Proponents of dividing the dialogues into periods often consider the "Parmenides" and "Theaetetus" to come late in this period and be transitional to the next, as they seem to treat the theory of Forms critically ("Parmenides") or only indirectly ("Theaetetus"). Ritter's stylometric analysis places "Phaedrus" as probably after "Theaetetus" and "Parmenides", although it does not relate to the theory of Forms in the same way. The first book of the "Republic" is often thought to have been written significantly earlier than the rest of the work, although possibly having undergone revisions when the later books were attached to it.
The remaining dialogues are classified as "late" and are generally agreed to be difficult and challenging pieces of philosophy. This grouping is the only one proven by stylometric analysis. While looked to for Plato's "mature" answers to the questions posed by his earlier works, those answers are difficult to discern. Some scholars indicate that the theory of Forms is absent from the late dialogues, its having been refuted in the "Parmenides", but there isn't total consensus that the "Parmenides" actually refutes the theory of Forms. The so-called "late dialogues" include "Critias", "Laws", "Philebus", "Sophist", "Statesman", and "Timaeus".
Narration of the dialogues.
Plato never presents himself as a participant in any of the dialogues, and with the exception of the "Apology", there is no suggestion that he heard any of the dialogues firsthand. Some dialogues have no narrator but have a pure "dramatic" form (examples: "Meno", "Gorgias", "Phaedrus", "Crito", "Euthyphro"), some dialogues are narrated by Socrates, wherein he speaks in first person (examples: "Lysis", "Charmides", "Republic"). One dialogue, "Protagoras", begins in dramatic form but quickly proceeds to Socrates' narration of a conversation he had previously with the sophist for whom the dialogue is named; this narration continues uninterrupted till the dialogue's end.
Two dialogues "Phaedo" and "Symposium" also begin in dramatic form but then proceed to virtually uninterrupted narration by followers of Socrates. "Phaedo", an account of Socrates' final conversation and hemlock drinking, is narrated by Phaedo to Echecrates in a foreign city not long after the execution took place. The "Symposium" is narrated by Apollodorus, a Socratic disciple, apparently to Glaucon. Apollodorus assures his listener that he is recounting the story, which took place when he himself was an infant, not from his own memory, but as remembered by Aristodemus, who told him the story years ago.
The "Theaetetus" is a peculiar case: a dialogue in dramatic form embedded within another dialogue in dramatic form. In the beginning of the "Theaetetus" (142c-143b), Euclides says that he compiled the conversation from notes he took based on what Socrates told him of his conversation with the title character. The rest of the "Theaetetus" is presented as a "book" written in dramatic form and read by one of Euclides' slaves (143c). Some scholars take this as an indication that Plato had by this date wearied of the narrated form. With the exception of the "Theaetetus", Plato gives no explicit indication as to how these orally transmitted conversations came to be written down.
Trial of Socrates.
The trial of Socrates is the central, unifying event of the great Platonic dialogues. Because of this, Plato's "Apology" is perhaps the most often read of the dialogues. In the "Apology", Socrates tries to dismiss rumors that he is a sophist and defends himself against charges of disbelief in the gods and corruption of the young. Socrates insists that long-standing slander will be the real cause of his demise, and says the legal charges are essentially false. Socrates famously denies being wise, and explains how his life as a philosopher was launched by the Oracle at Delphi. He says that his quest to resolve the riddle of the oracle put him at odds with his fellow man, and that this is the reason he has been mistaken for a menace to the city-state of Athens.
If Plato's important dialogues do not refer to Socrates' execution explicitly, they allude to it, or use characters or themes that play a part in it. Five dialogues foreshadow the trial: In the "Theaetetus" (210d) and the "Euthyphro" (2a–b) Socrates tells people that he is about to face corruption charges. In the "Meno" (94e–95a), one of the men who brings legal charges against Socrates, Anytus, warns him about the trouble he may get into if he does not stop criticizing important people. In the "Gorgias", Socrates says that his trial will be like a doctor prosecuted by a cook who asks a jury of children to choose between the doctor's bitter medicine and the cook's tasty treats (521e–522a). In the "Republic" (7.517e), Socrates explains why an enlightened man (presumably himself) will stumble in a courtroom situation. The "Apology" is Socrates' defense speech, and the "Crito" and "Phaedo" take place in prison after the conviction. In the "Protagoras", Socrates is a guest at the home of Callias, son of Hipponicus, a man whom Socrates disparages in the "Apology" as having wasted a great amount of money on sophists' fees.
Unity and diversity of the dialogues.
Two other important dialogues, the "Symposium" and the "Phaedrus", are linked to the main storyline by characters. In the "Apology" (19b, c), Socrates says Aristophanes slandered him in a comic play, and blames him for causing his bad reputation, and ultimately, his death. In the "Symposium", the two of them are drinking together with other friends. The character Phaedrus is linked to the main story line by character (Phaedrus is also a participant in the "Symposium" and the "Protagoras") and by theme (the philosopher as divine emissary, etc.) The "Protagoras" is also strongly linked to the "Symposium" by characters: all of the formal speakers at the "Symposium" (with the exception of Aristophanes) are present at the home of Callias in that dialogue. Charmides and his guardian Critias are present for the discussion in the "Protagoras". Examples of characters crossing between dialogues can be further multiplied. The "Protagoras" contains the largest gathering of Socratic associates.
In the dialogues Plato is most celebrated and admired for, Socrates is concerned with human and political virtue, has a distinctive personality, and friends and enemies who "travel" with him from dialogue to dialogue. This is not to say that Socrates is consistent: a man who is his friend in one dialogue may be an adversary or subject of his mockery in another. For example, Socrates praises the wisdom of Euthyphro many times in the "Cratylus", but makes him look like a fool in the "Euthyphro". He disparages sophists generally, and Prodicus specifically in the "Apology", whom he also slyly jabs in the "Cratylus" for charging the hefty fee of fifty drachmas for a course on language and grammar. However, Socrates tells Theaetetus in his namesake dialogue that he admires Prodicus and has directed many pupils to him. Socrates' ideas are also not consistent within or between or among dialogues.
Platonic scholarship.
Although their popularity has fluctuated over the years, the works of Plato have never been without readers since the time they were written. Plato's thought is often compared with that of his most famous student, Aristotle, whose reputation during the Western Middle Ages so completely eclipsed that of Plato that the Scholastic philosophers referred to Aristotle as "the Philosopher". However, in the Byzantine Empire, the study of Plato continued.
The only Platonic work known to western scholarship was Timaeus, until translations were made at a time post the fall of Constantinople, which occurred during 1453, George Gemistos Plethon brought Plato's original writings from Constantinople in the century of its fall. It is believed that Plethon passed a copy of the Dialogues to Cosimo de' Medici when in 1438 the Council of Ferrara, called to unify the Greek and Latin Churches, was adjourned to Florence, where Plethon then lectured on the relation and differences of Plato and Aristotle, and fired Cosimo with his enthusiasm; Cosimo would supply Marsilio Ficino with Plato's text for translation to Latin. During the early Islamic era, Persian and Arab scholars translated much of Plato into Arabic and wrote commentaries and interpretations on Plato's, Aristotle's and other Platonist philosophers' works (see Al-Farabi, Avicenna, Averroes, Hunayn ibn Ishaq). Many of these comments on Plato were translated from Arabic into Latin and as such influenced Medieval scholastic philosophers.
During the Renaissance, with the general resurgence of interest in classical civilization, knowledge of Plato's philosophy would become widespread again in the West. Many of the greatest early modern scientists and artists who broke with Scholasticism and fostered the flowering of the Renaissance, with the support of the Plato-inspired Lorenzo (grandson of Cosimo), saw Plato's philosophy as the basis for progress in the arts and sciences. His political views, too, were well-received: the vision of wise philosopher-kings of the "Republic" matched the views set out in works such as Machiavelli's "The Prince". More problematic was Plato's belief in metempsychosis, transmigration of the soul, as well as his ethical views (on polyamory and euthanasia in particular), which did not match those of Christianity. It was Plethon's student Bessarion who reconciled Plato with Christian theology, arguing that Plato's views were only ideals, unattainable due to the fall of man.
By the 19th century, Plato's reputation was restored, and at least on par with Aristotle's. Notable Western philosophers have continued to draw upon Plato's work since that time. Plato's influence has been especially strong in mathematics and the sciences. He helped to distinguish between pure and applied mathematics by widening the gap between "arithmetic", now called number theory and "logistic", now called arithmetic. He regarded "logistic" as appropriate for business men and men of war who "must learn the art of numbers or he will not know how to array his troops," while "arithmetic" was appropriate for philosophers "because he has to arise out of the sea of change and lay hold of true being." Plato's resurgence further inspired some of the greatest advances in logic since Aristotle, primarily through Gottlob Frege and his followers Kurt Gödel, Alonzo Church, and Alfred Tarski. Albert Einstein suggested that the scientist who takes philosophy seriously would have to avoid systematization and take on many different roles, and possibly appear as a Platonist or Pythagorean, in that such a one would have "the viewpoint of logical simplicity as an indispensable and effective tool of his research."
Many recent philosophers have diverged from what some would describe as the ontological models and moral ideals characteristic of traditional Platonism. A number of these postmodern philosophers have thus appeared to disparage Platonism from more or less informed perspectives. Friedrich Nietzsche notoriously attacked Plato's "idea of the good itself" along with many fundamentals of Christian morality, which he interpreted as "Platonism for the masses" in one of his most important works, "Beyond Good and Evil "(1886). Martin Heidegger argued against Plato's alleged obfuscation of "Being "in his incomplete tome, "Being and Time" (1927), and the philosopher of science Karl Popper argued in "The Open Society and Its Enemies" (1945) that Plato's alleged proposal for a utopian political regime in the "Republic" was prototypically totalitarian. The political philosopher and professor Leo Strauss is considered by some as the prime thinker involved in the recovery of Platonic thought in its more political, and less metaphysical, form. Strauss' political approach was in part inspired by the appropriation of Plato and Aristotle by medieval Jewish and Islamic political philosophers, especially Maimonides and Al-Farabi, as opposed to the Christian metaphysical tradition that developed from Neoplatonism. Deeply influenced by Nietzsche and Heidegger, Strauss nonetheless rejects their condemnation of Plato and looks to the dialogues for a solution to what all three latter day thinkers acknowledge as 'the crisis of the West.'
Textual sources and history.
Some 250 known manuscripts of Plato survive. The texts of Plato as received today apparently represent the complete written philosophical work of Plato and are generally good by the standards of textual criticism. No modern edition of Plato in the original Greek represents a single source, but rather it is reconstructed from multiple sources which are compared with each other. These sources are medieval manuscripts written on vellum (mainly from 9th-13th century AD Byzantium), papyri (mainly from late antiquity in Egypt), and from the independent "testimonia" of other authors who quote various segments of the works (which come from a variety of sources). The text as presented is usually not much different from what appears in the Byzantine manuscripts, and papyri and testimonia just confirm the manuscript tradition. In some editions however the readings in the papyri or testimonia are favoured in some places by the editing critic of the text. Reviewing editions of papyri for the "Republic" in 1987, Slings suggests that the use of papyri is hampered due to some poor editing practices.
In the first century AD, Thrasyllus of Mendes had compiled and published the works of Plato in the original Greek, both genuine and spurious. While it has not survived to the present day, all the extant medieval Greek manuscripts are based on his edition.
The oldest surviving complete manuscript for many of the dialogues is the Clarke Plato (Codex Oxoniensis Clarkianus 39, or Codex Boleianus MS E.D. Clarke 39), which was written in Constantinople in 895 and acquired by Oxford University in 1809. The Clarke is given the siglum "B" in modern editions. "B" contains the first six tetralogies and is described internally as being written by "John the Calligrapher" on behalf of Arethas of Caesarea. It appears to have undergone corrections by Arethas himself. For the last two tetralogies and the apocrypha, the oldest surviving complete manuscript is Codex Parisinus graecus 1807, designated "A", which was written nearly contemporaneously to "B", circa 900 AD. "A" must be a copy of the edition edited by the patriarch, Photios, teacher of Arethas."A" probably had an initial volume containing the first 7 tetralogies which is now lost, but of which a copy was made, Codex Venetus append. class. 4, 1, which has the siglum "T". The oldest manuscript for the seventh tetralogy is Codex Vindobonensis 54. suppl. phil. Gr. 7, with siglum "W", with a supposed date in the twelfth century. In total there are fifty-one such Byzantine manuscripts known, while others may yet be found.
To help establish the text, the older evidence of papyri and the independent evidence of the testimony of commentators and other authors (i.e., those who quote and refer to an old text of Plato which is no longer extant) are also used. Many papyri which contain fragments of Plato's texts are among the Oxyrhynchus Papyri. The 2003 Oxford Classical Texts edition by Slings even cites the Coptic translation of a fragment of the "Republic" in the Nag Hammadi library as evidence. Important authors for testimony include Olympiodorus the Younger, Plutarch, Proclus, Iamblichus, Eusebius, and Stobaeus.
During the early Renaissance, the Greek language and, along with it, Plato's texts were reintroduced to Western Europe by Byzantine scholars. In September or October of 1484 Filippo Valori and Francesco Berlinghieri printed 1025 copies of Ficino's translation, using the printing press at the Dominican convent S.Jacopo di Ripoli. Cosimo had been influenced toward studying Plato by the many Byzantine Platonists in Florence during his day, including George Gemistus Plethon. Henri Estienne's edition, including parallel Greek and Latin, was published in 1578. It was this edition which established Stephanus pagination, still in use today.
Modern editions.
The Oxford Classical Texts offers the current standard complete Greek text of Plato's complete works. In five volumes edited by John Burnet, its first edition was published 1900-1907, and it is still available from the publisher, having last been printed in 1993. The second edition is still in progress with only the first volume, printed in 1995, and the "Republic", printed in 2003, available. The "Cambridge Greek and Latin Texts" and "Cambridge Classical Texts and Commentaries" series includes Greek editions of the "Protagoras", "Symposium", "Phaedrus", "Alcibiades", and "Clitophon", with English philological, literary, and, to an extent, philosophical commentary. One distinguished edition of the Greek text is E. R. Dodds' of the "Gorgias", which includes extensive English commentary.
The modern standard complete English edition is the 1997 Hackett "Plato, Complete Works", edited by John M. Cooper. For many of these translations Hackett offers separate volumes which include more by way of commentary, notes, and introductory material. There is also the "Clarendon Plato Series" by Oxford University Press which offers English translations and thorough philosophical commentary by leading scholars on a few of Plato's works, including John McDowell's version of the "Theaetetus". Cornell University Press has also begun the "Agora" series of English translations of classical and medieval philosophical texts, including a few of Plato's.
Notes.
a. Plato is a nickname from the adjective "" "broad". Diogenes Laertius mentions three possible meanings of the nickname:
Seneca mentions the meaning of Plato's name in connection to a moral lesson:
b. The grammarian Apollodorus of Athens argues in his "Chronicles" that Plato was born in the first year of the eighty-eighth Olympiad (427 BCE), on the seventh day of the month Thargelion; according to this tradition the god Apollo was born this day. According to another biographer of him, Neanthes, Plato was eighty-four years of age at his death. If we accept Neanthes' version, Plato was younger than Isocrates by six years, and therefore he was born in the second year of the 87th Olympiad, the year Pericles died (429 BCE). According to the "Suda," Plato was born in Aegina in the 88th Olympiad amid the preliminaries of the Peloponnesian war, and he lived 82 years. Sir Thomas Browne also believes that Plato was born in the 88th Olympiad. Renaissance Platonists celebrated Plato's birth on November 7. Ulrich von Wilamowitz-Moellendorff estimates that Plato was born when Diotimos was archon eponymous, namely between July 29, 428 BCE and July 24, 427 BCE. Greek philologist Ioannis Kalitsounakis believes that the philosopher was born on May 26 or 27, 427 BCE, while Jonathan Barnes regards 428 BCE as year of Plato's birth. For her part, Debra Nails asserts that the philosopher was born in 424/423 BCE. According to Seneca Plato died at the age of 81 on the same day he was born.
c. Diogenes Laertius mentions that Plato "was born, according to some writers, in Aegina in the house of Phidiades the son of Thales". Diogenes mentions as one of his sources the "Universal History" of Favorinus. According to Favorinus, Ariston, Plato's family, and his family were sent by Athens to settle as cleruchs (colonists retaining their Athenian citizenship), on the island of Aegina, from which they were expelled by the Spartans after Plato's birth there. Nails points out, however, that there is no record of any Spartan expulsion of Athenians from Aegina between 431–411 BCE. On the other hand, at the Peace of Nicias, Aegina was silently left under Athens' control, and it was not until the summer of 411 that the Spartans overran the island. Therefore, Nails concludes that "perhaps Ariston was a cleruch, perhaps he went to Aegina in 431, and perhaps Plato was born on Aegina, but none of this enables a precise dating of Ariston's death (or Plato's birth). Aegina is regarded as Plato's place of birth by Suda as well.

</doc>
<doc id="22958" url="https://en.wikipedia.org/wiki?curid=22958" title="Sample space">
Sample space

In probability theory, the sample space of an experiment or random trial is the set of all possible outcomes or results of that experiment. A sample space is usually denoted using set notation, and the possible outcomes are listed as elements in the set. It is common to refer to a sample space by the labels "S", Ω, or "U" (for "universal set").
For example, if the experiment is tossing a coin, the sample space is typically the set {head, tail}. For tossing two coins, the corresponding sample space would be {(head,head), (head,tail), (tail,head), (tail,tail)}. For tossing a single six-sided die, the typical sample space is {1, 2, 3, 4, 5, 6} (in which the result of interest is the number of pips facing up).
A well-defined sample space is one of three basic elements in a probabilistic model (a probability space); the other two are a well-defined set of possible events (a sigma-algebra) and a probability assigned to each event (a probability measure function).
Multiple sample spaces.
For many experiments, there may be more than one plausible sample space available, depending on what result is of interest to the experimenter. For example, when drawing a card from a standard deck of fifty-two playing cards, one possibility for the sample space could be the various ranks (Ace through King), while another could be the suits (clubs, diamonds, hearts, or spades). A more complete description of outcomes, however, could specify both the denomination and the suit, and a sample space describing each individual card can be constructed as the Cartesian product of the two sample spaces noted above (this space would contain fifty-two equally likely outcomes). Still other sample spaces are possible, such as {right-side up, up-side down} if some cards have been flipped when shuffling.
Equally likely outcomes.
Some treatments of probability assume that the various outcomes of an experiment are always defined so as to be equally likely. However, there are experiments that are not easily described by a sample space of equally likely outcomes— for example, if one were to toss a thumb tack many times and observe whether it landed with its point upward or downward, there is no symmetry to suggest that the two outcomes should be equally likely.
Though most random phenomena do not have equally likely outcomes, it can be helpful to define a sample space in such a way that outcomes are at least approximately equally likely, since this condition significantly simplifies the computation of probabilities for events within the sample space. If each individual outcome occurs with the same probability, then the probability of any event becomes simply:
Simple random sample.
In statistics, inferences are made about characteristics of a population by studying a sample of that population's individuals. In order to arrive at a sample that presents an unbiased estimate of the true characteristics of the population, statisticians often seek to study a simple random sample— that is, a sample in which every individual in the population is equally likely to be included. The result of this is that every possible combination of individuals who could be chosen for the sample is also equally likely (that is, the space of simple random samples of a given size from a given population is composed of equally likely outcomes).
Infinitely large sample spaces.
In an elementary approach to probability, any subset of the sample space is usually called an event. However, this gives rise to problems when the sample space is infinite, so that a more precise definition of an event is necessary. Under this definition only measurable subsets of the sample space, constituting a σ-algebra over the sample space itself, are considered events.
However, this has essentially only theoretical significance, since in general the σ-algebra can always be defined to include all subsets of interest in applications.

</doc>
<doc id="22960" url="https://en.wikipedia.org/wiki?curid=22960" title="Elementary event">
Elementary event

In probability theory, an elementary event (also called an atomic event or simple event) is an event which contains only a single outcome in the sample space. Using set theory terminology, an elementary event is a singleton. Elementary events and their corresponding outcomes are often written interchangeably for simplicity, as such an event corresponds to precisely one outcome. 
The following are examples of elementary events:
Probability of an elementary event.
Elementary events may occur with probabilities that are between zero and one (inclusively). In a discrete probability distribution whose sample space is finite, each elementary event is assigned a particular probability. In contrast, in a continuous distribution, individual elementary events must all have a probability of zero because there are infinitely many of them— then non-zero probabilities can only be assigned to non-elementary events. 
Some "mixed" distributions contain both stretches of continuous elementary events and some discrete elementary events; the discrete elementary events in such distributions can be called atoms or atomic events and can have non-zero probabilities. 
Under the measure-theoretic definition of a probability space, the probability of an elementary event need not even be defined. In particular, the set of events on which probability is defined may be some σ-algebra on "S" and not necessarily the full power set.

</doc>
<doc id="22961" url="https://en.wikipedia.org/wiki?curid=22961" title="Event (probability theory)">
Event (probability theory)

In probability theory, an event is a set of outcomes of an experiment (a subset of the sample space) to which a probability is assigned. A single outcome may be an element of many different events, and different events in an experiment are usually not equally likely, since they may include very different groups of outcomes. An event defines a complementary event, namely the complementary set (the event "not" occurring), and together these define a Bernoulli trial: did the event occur or not?
Typically, when the sample space is finite, any subset of the sample space is an event ("i"."e". all elements of the power set of the sample space are defined as events). However, this approach does not work well in cases where the sample space is uncountably infinite, most notably when the outcome is a real number. So, when defining a probability space it is possible, and often necessary, to exclude certain subsets of the sample space from being events (see "Events in probability spaces", below).
A simple example.
If we assemble a deck of 52 playing cards with no jokers, and draw a single card from the deck, then the sample space is a 52-element set, as each card is a possible outcome. An event, however, is any subset of the sample space, including any singleton set (an elementary event), the empty set (an impossible event, with probability zero) and the sample space itself (a certain event, with probability one). Other events are proper subsets of the sample space that contain multiple elements. So, for example, potential events include: 
Since all events are sets, they are usually written as sets (e.g. {1, 2, 3}), and represented graphically using Venn diagrams. Given that each outcome in the sample space Ω is equally likely, the probability of an event "A" is the following : 
This rule can readily be applied to each of the example events above.
Events in probability spaces.
Defining all subsets of the sample space as events works well when there are only finitely many outcomes, but gives rise to problems when the sample space is infinite. For many standard probability distributions, such as the normal distribution, the sample space is the set of real numbers or some subset of the real numbers. Attempts to define probabilities for all subsets of the real numbers run into difficulties when one considers 'badly behaved' sets, such as those that are nonmeasurable. Hence, it is necessary to restrict attention to a more limited family of subsets. For the standard tools of probability theory, such as joint and conditional probabilities, to work, it is necessary to use a σ-algebra, that is, a family closed under complementation and countable unions of its members. The most natural choice is the Borel measurable set derived from unions and intersections of intervals. However, the larger class of Lebesgue measurable sets proves more useful in practice.
In the general measure-theoretic description of probability spaces, an event may be defined as an element of a selected σ-algebra of subsets of the sample space. Under this definition, any subset of the sample space that is not an element of the σ-algebra is not an event, and does not have a probability. With a reasonable specification of the probability space, however, all "events of interest" are elements of the σ-algebra.
A note on notation.
Even though events are subsets of some sample space Ω, they are often written as propositional formulas involving random variables. For example, if "X" is a real-valued random variable defined on the sample space Ω, the event
can be written more conveniently as, simply,
This is especially common in formulas for a probability, such as
The set "u" < "X" ≤ "v" is an example of an inverse image under the mapping "X" because formula_5 if and only if formula_6.

</doc>
<doc id="22973" url="https://en.wikipedia.org/wiki?curid=22973" title="Pig Latin">
Pig Latin

Pig Latin is a language game in which words in English are altered. The objective is to conceal the meaning of the words from others not familiar with the rules. The reference to Latin is a deliberate misnomer, as it is simply a form of jargon, used only for its English connotations as a strange and foreign-sounding language.
Origins.
The origins of Pig Latin are unknown. A youthful Thomas Jefferson wrote letters to friends in Pig Latin. One early mention of the name was in "Putnam's Magazine" in May 1869 "I had plenty of ammunition in reserve, to say nothing, Tom, of our pig Latin. 'Hoggibus, piggibus et shotam damnabile grunto,' and all that sort of thing," although the jargon cited is not modern Pig Latin, but rather what would be called today Dog Latin.
"The Atlantic" January 1895 also included a mention of the subject: "They all spoke a queer jargon which they themselves had invented. It was something like the well-known 'pig Latin' that all sorts of children like to play with."
Rules.
For words that begin with consonant sounds, all letters before the initial vowel are placed at the end of the word sequence. Then, "ay" (some people just add "a") is added, as in the following examples:
For words which begin with vowel sounds or silent letter, one just adds "yay" to the end. Examples are:
Another less common way some speakers may use a different ending for words starting with vowels is adding "way" (or "wa") to the end. Examples are:
This is to avoid having for speakers to disfavor pronouncing otherwise hard words which either sounds awkward, the human tongue cannot articulate, or both. As opposed to the last three examples above, the avoided words are:
Some people also follow this rule with words that begin with vowel sounds: only the first letter is moved to the end of the word, and then one just adds "way" after.
Examples:
Some people who speak Pig Latin follow an alternate second rule; this version of the rule dictates that if a word begins with a vowel (either a, e, i, o, or u) only the first letter is moved and the phrase added to the end is "i"; however, this form is fairly uncommon. Another form of Pig Latin is to add an "ag" in front of the vowel.. (i.e. pig latin will read as "pagig lagatagin") Found in Lancashire.
Examples:
In other languages.
In the German-speaking area, varieties of Pig Latin include Kedelkloppersprook, which originated around Hamburg harbour, and Mattenenglisch that was used in the "Matte", the traditional working-class neighborhood of Berne. Though Mattenenglisch has fallen out of use since the mid-20th century, it is still cultivated by voluntary associations. A characteristic of the Mattenenglisch Pig Latin is the complete substitution of the first vowel by "i", in addition to the usual moving of the initial consonant cluster and the adding of "ee".
The Swedish equivalent of Pig Latin is Fikonspråket ("Fig language" – see Language game § List of common language games).
French has the "loucherbem" (or "louchébem", or "largonji") coded language, which supposedly was originally used by butchers ("boucher" in French). In "loucherbem", the leading consonant cluster is moved to the end of the word (as in Pig Latin) and replaced by an "L", and then a suffix is added at the end of the word (-"oche", -"em", -"oque", etc., depending on the word). Example: "combien" (how much) = "lombienquès". Similar coded languages are "verlan" and "langue de feu". A few louchébem words have become usual French words: "fou" (crazy) = "loufoque", "portefeuille" (wallet) = "larfeuille", "en douce" (on the quiet) = "en loucedé".
Another equivalent of Pig Latin is used throughout the Slavic-speaking parts of the Balkans. It is called "Šatra" (/sha-tra/)or "Šatrovački" (/shatro-vachki/) and was used in crime-related and street language. For instance, marihuana (trava) turns to "vutra"; the Balkan slang name for cocaine (belo - meaning "white") turns to lobe, a pistol (pištolj) turns to štoljpi, bro (brate) turns to tebra. In the past few years it has become widely used between teenage immigrants in former Yugoslavian countries.

</doc>
<doc id="22975" url="https://en.wikipedia.org/wiki?curid=22975" title="Polish language">
Polish language

Polish ("język polski", "polszczyzna") is a Slavic language spoken primarily in Poland and the native language of the Poles. It belongs to the Lechitic subgroup of West Slavic languages. Polish is the official language of Poland, but it is also used throughout the world by Polish minorities in other countries. It is one of the official languages of the European Union. Its written standard is the Polish alphabet, which has 9 additions to the letters of the basic Latin script ("ą", "ć", "ę", "ł", "ń", "ó", "ś", "ź", "ż"). Polish is closely related to Kashubian, Lower Sorbian, Upper Sorbian, Czech and Slovak.
Although the Austrian, German and Russian administrations exerted much pressure on the Polish nation (during the 19th and early 20th centuries) following the Partitions of Poland, which resulted in attempts to suppress the Polish language, a rich literature has regardless developed over the centuries and the language currently has the largest number of speakers of the West Slavic group. It is also the second most widely spoken Slavic language, after Russian and just ahead of Ukrainian, which comes third.
In history, Polish is known to be an important language, both diplomatically and academically in Central and Eastern Europe. Today, Polish is spoken by over 38.5 million people as their first language in Poland. It is also spoken as a second language in western parts of Belarus, Lithuania and Ukraine, as well as northern parts of the Czech Republic and Slovakia. Because of the emigration from Poland during different time periods, most notably after World War II, millions of Polish speakers can be found in countries such as Australia, Brazil, Canada, the United Kingdom and the United States. There are 40 million Polish language speakers around the world.
History.
The originality of Polish culture is tied to its language and to its Slavonic roots. Linguistic studies indicate that 5000 to 4000 years ago early Balto-Slavic languages were part of the Aryan or the Eastern Indo-European languages. Over 3500 years ago, the languages of the Balto-Slavs separated from the Aryan languages; some 3000 years ago, the Baltic and Slavic languages separated from each other; and for the next 1500 years, the Slavic languages evolved parallel to the Greek, Latin, Celtic, Germanic, and other languages. The evolution of the Polish language occurred during the following 1500 years.
Polish began to emerge around the 10th century, the process largely triggered by the establishment and development of the Polish state. Mieszko I, ruler of the Polans tribe from Greater Poland region, united a few culturally and linguistically related tribes from the basins of the Vistula and Odra before eventually accepting baptism in 966. With Christianity, Poland also adopted the Latin alphabet, which made it possible to write down Polish, until then existing only as a spoken language.
The precursor to modern Polish is the Old Polish language. Ultimately, Polish is thought to descend from the unattested Proto-Slavic language.
Polish was a "lingua franca" from 1500-1700 in small parts of Central and large portions of Eastern Europe, because of the political, cultural, scientific and military influence of the Polish-Lithuanian Commonwealth.
Geographic distribution.
Poland is the most linguistically homogeneous European country; nearly 97% of Poland's citizens declare Polish as their native language. Elsewhere, ethnic Poles constitute large minorities in Lithuania, Belarus, and Ukraine. Polish is the most widely used minority language in Lithuania's Vilnius (Wilno) County (26% of the population, according to the 2001 census results, with Wilno (Vilnius) having been part of Poland until 1939) and is found elsewhere in southeastern Lithuania. In Ukraine it is most common in the western Lwów (Lviv) and Wołyń (Volyn) "oblast" (provinces), while in Western Belarus it is used by the significant Polish minority, especially in the Brest and Grodno regions and in areas along the Lithuanian border. There are significant numbers of Polish speakers among Polish emigrants and their descendants in many other countries.
In the United States, Polish Americans number more than 11 million (See also: Polish language in the United States) but most of them cannot speak Polish fluently. According to the United States 2000 Census, 667,414 Americans of age five years and over reported Polish as the language spoken at home, which is about 1.4% of people who speak languages other than English, 0.25% of the US population, and 6% of the Polish-American population. The largest concentrations of Polish speakers reported in the census (over 50%) were found in three states: Illinois (185,749), New York (111,740), and New Jersey (74,663). Enough people in these areas speak Polish that PNC Financial Services (which has a large number of branches and ATMs in all of these areas) offer ATM services available in Polish at all of their ATMs in addition to English and Spanish.
According to the 2011 census there are now over 500,000 people in England and Wales who consider Polish to be their "main" language. In Canada, there is a significant Polish Canadian population: There are 242,885 speakers of Polish according to the 2006 census, with a particular concentration in Toronto (91,810 speakers) and Montreal.
The geographical distribution of the Polish language was greatly affected by the border changes and population transfers that followed World War II. Poles settled in the "Recovered Territories" in the west and north, which had previously been mostly German-speaking. Some Poles remained in the previously Polish-ruled territories in the east that were annexed by the USSR, resulting in the present-day Polish-speaking minorities in Lithuania, Belarus, and Ukraine, although many Poles were expelled or emigrated from those areas to areas within Poland's new borders. Meanwhile, the flight and expulsion of Germans, as well as the expulsion of Ukrainians and resettlement of Ukrainians within Poland, contributed to the country's linguistic homogeneity.
Dialects.
The Polish language became far more homogeneous in the second half of the 20th century, in part due to the mass migration of several million Polish citizens from the eastern to the western part of the country after the Soviet annexation of the Kresy in 1939, and the acquisition of former German territory after World War II. This tendency toward a homogeneity also stems from the vertically integrated nature of the authoritarian Polish People's Republic.
The inhabitants of different regions of Poland speak "standard" Polish somewhat differently, although the differences between regional dialects appear slight. First-language speakers of Polish have no trouble understanding each other, and non-native speakers may have difficulty distinguishing regional variations.
Polish is normally described as consisting of four or five main dialects:
Kashubian, spoken in the Pomorze region west of Gdańsk on the Baltic Sea, is often considered a fifth dialect. It contains a number of features not found elsewhere in Poland, e.g. nine distinct oral vowels (vs. the five of standard Polish) and (in the northern dialects) phonemic word stress, an archaic feature preserved from Common Slavic times and not found anywhere else among the West Slavic languages. However, it "lacks most of the linguistic and social determinants of language-hood".
Many linguistic sources about the Slavic languages describe Silesian as a dialect of Polish. However, many Silesians consider themselves a separate ethnicity and have been advocating for the recognition of a Silesian language. According to the last official census in Poland in 2011, over half a million people declared Silesian as their native language. Many sociolinguistic sources (e.g. by Tomasz Kamusella, Agnieszka Pianka, Alfred F. Majewicz, Tomasz Wicherkiewicz) assume that extralinguistic criteria decide whether something is a language or a dialect of the language: users of speech or/and political decisions, and this is dynamic (i.e. change over time). Also, language organizations like as SIL International and resources for the academic field of linguistics like as Ethnologue, Linguist List and other, for example Ministry of Administration and Digitization recognized Silesian language. In July 2007, the Silesian language was recognized by an ISO, was attributed an ISO code of szl.
Some more characteristic but less widespread regional dialects include:
Phonology.
Polish has six oral vowels (all monophthongs) and two nasal vowels. The oral vowels are (spelled "i"), (spelled "y"), (spelled "e"), (spelled "a"), (spelled "o") and (spelled "u" or "ó"). The nasal vowels are (spelled "ę") and (spelled "ą").
The Polish consonant system shows more complexity: its characteristic features include the series of affricates and palatal consonants that resulted from four Proto-Slavic palatalizations and two further palatalizations that took place in Polish and Belarusian. The full set of consonants, together with their most common spellings, can be presented as follows (although other phonological analyses exist):
Neutralization occurs between voiced–voiceless consonant pairs in certain environments: at the end of words (where devoicing occurs), and in certain consonant clusters (where assimilation occurs). For details, see "Voicing and devoicing" in the article on Polish phonology.
Most Polish words are paroxytones (that is, the stress falls on the second-to-last syllable of a polysyllabic word), although there are exceptions.
Orthography.
The Polish alphabet derives from the Latin script, but includes certain additional letters formed using diacritics. The Polish alphabet was one of three major forms of Latin-based orthography developed for Slavic languages, the other being Czech orthography and Croatian orthography, the latter being a 19th-century invention trying to make a compromise between the first two. Kashubian uses a Polish-based system, Slovak uses a Czech-based system, and Slovene follows the Croatian one; the Sorbian languages blend the Polish and the Czech ones.
The diacritics used in the Polish alphabet are the "kreska" (graphically similar to the acute accent) in the letters "ć, ń, ó, ś, ź" and through the letter in "ł"; the "kropka" (superior dot) in the letter "ż", and the "ogonek" ("little tail") in the letters "ą, ę". The letters "q, v, x" are often not considered part of the Polish alphabet; they are used only in foreign words and names.
Polish orthography is largely phonemic—there is a consistent correspondence between letters (or digraphs and trigraphs) and phonemes (for exceptions see below). The letters of the alphabet and their normal phonemic values are listed in the following table.
The following digraphs and trigraphs are used:
Voiced consonant letters frequently come to represent voiceless sounds (as shown in the tables); this occurs at the end of words and in certain clusters, due to the neutralization mentioned in the "Phonology" section above. Occasionally also voiceless consonant letters can represent voiced sounds in clusters.
The spelling rule for the palatal sounds , , , and is as follows: before the vowel "i" the plain letters "s, z, c, dz, n" are used; before other vowels the combinations "si, zi, ci, dzi, ni" are used; when not followed by a vowel the diacritic forms "ś, ź, ć, dź, ń" are used. For example, the "s" in "siwy" ("grey-haired"), the "si" in "siarka" ("sulphur") and the "ś" in "święty" ("holy") all represent the sound . The exceptions to the above rule are certain loanwords from Latin, Italian, French, Russian or English—where "s" before "i" is pronounced as "s", e.g. "sinus", "sinologia", "do re mi fa sol la si do", "Saint-Simon i saint-simoniści", "Sierioża", "Siergiej", "Singapur", "singiel". In other loanwords the vowel "i" is changed to "y", e.g. "Syria", "Sybir", "synchronizacja", "Syrakuzy".
The following table shows the correspondence between the sounds and spelling:
digraphs and trigraphs are used:
Similar principles apply to , , and , except that these can only occur before vowels, so the spellings are "k, g, (c)h, l" before "i", and "ki, gi, (c)hi, li" otherwise. Most Polish speakers, however, do not consider palatalisation of "k, g, (c)h" or "l" as creating new sounds.
Except in the cases mentioned above, the letter "i" if followed by another vowel in the same word usually represents , yet a palatalisation of the previous consonant is always assumed.
The letters "ą" and "ę", when followed by plosives and affricates, represent an oral vowel followed by a nasal consonant, rather than a nasal vowel. For example, "ą" in "dąb" ("oak") is pronounced , and "ę" in "tęcza" ("rainbow") is pronounced (the nasal assimilates with the following consonant). When followed by "l" or "ł" (for example "przyjęli", "przyjęły"), "ę" is pronounced as just "e". When "ę" is at the end of the word it is often pronounced as just .
Note that, depending on the word, the phoneme can be spelt "h" or "ch", the phoneme can be spelt "ż" or "rz", and can be spelt "u" or "ó". In several cases it determines the meaning, for example: "może" ("maybe") and "morze" ("sea").
In occasional words, letters that normally form a digraph are pronounced separately. For example, "rz" represents , not , in words like "zamarzać" ("freeze") and in the name "Tarzan".
Notice that doubled letters represent separate occurrences of the sound in question; for example "Anna" is pronounced in Polish (the double "n" is often pronounced as a lengthened single "n").
There are certain clusters where a written consonant would not be pronounced. For example, the "ł" in the words "mógł" ("could") and "jabłko" ("apple") might be omitted in ordinary speech, leading to the pronunciations "muk" and "japko" or "jabko".
Grammar.
Polish is a highly inflected language, with relatively free word order, although the dominant arrangement is subject–verb–object (SVO). There are no articles, and subject pronouns are often dropped.
Nouns may belong to three genders: masculine, feminine and neuter. A distinction is also made between animate and inanimate masculine nouns in the singular, and between masculine personal and non-personal nouns in the plural. There are seven cases: nominative, genitive, dative, accusative, instrumental, locative and vocative.
Adjectives agree with nouns in terms of gender, case and number. Attributive adjectives most commonly precede the noun, although in certain cases, especially in fixed phrases (like "język polski", "Polish (language)"), the noun may come first. Most short adjectives and their derived adverbs form comparatives and superlatives by inflection (the superlative is formed by prefixing "naj-" to the comparative).
Verbs are of imperfective or perfective aspect, often occurring in pairs. Imperfective verbs have a present tense, past tense, compound future tense (except for "być" "to be", which has a simple future "będę" etc., this in turn being used to form the compound future of other verbs), subjunctive/conditional (formed with the detachable particle "by"), imperatives, an infinitive, present participle, present gerund and past participle. Perfective verbs have a simple future tense (formed like the present tense of imperfective verbs), past tense, subjunctive/conditional, imperatives, infinitive, present gerund and past participle. Conjugated verb forms agree with their subject in terms of person, number, and (in the case of past tense and subjunctive/conditional forms) gender.
Passive-type constructions can be made using the auxiliary "być" or "zostać" ("become") with the passive participle. There is also an impersonal construction where the active verb is used (in third person singular) with no subject, but with the reflexive pronoun "się" present to indicate a general, unspecified subject (as in "pije się wódkę" "vodka is drunk"—note that "wódka" appears in the accusative). A similar sentence type in the past tense uses the passive participle with the ending "-o", as in "widziano ludzi" ("people were seen"). As in other Slavic languages, there are also subjectless sentences formed using such words as "można" ("it is possible") together with an infinitive.
Yes-no questions (both direct and indirect) are formed by placing the word "czy" at the start. Negation uses the word "nie", before the verb or other item being negated; "nie" is still added before the verb even if the sentence also contains other negatives such as "nigdy" ("never") or "nic" ("nothing"), effectively creating a double negative.
Cardinal numbers have a complex system of inflection and agreement. Numbers higher than five (except for those ending with the digit 2, 3 or 4) govern the genitive case rather than the nominative or accusative. Special forms of numbers (collective numerals) are used with certain classes of noun, which include "dziecko" ("child") and exclusively plural nouns such as "drzwi" ("door").
Borrowed words.
Polish has, over the centuries, borrowed a number of words from other languages. When borrowing, pronunciation was adapted to Polish phonemes and spelling was altered to match Polish orthography. In addition, word endings are liberally applied to almost any word to produce verbs, nouns, adjectives, as well as adding the appropriate endings for cases of nouns, adjectives, diminutives, augmentatives, etc.
Depending on the historical period, borrowing has proceeded from various languages. Notable influences have been Latin (9th–18th centuries), Czech (10th and 14th–15th centuries), Italian (15th–16th centuries), French (18th–19th centuries), German (13–15th and 18th–20th centuries), Hungarian (14th–16th centuries) and Turkish (17th century). Currently, English words are the most common imports to Polish.
The Latin language, for a very long time the only official language of the Polish state, has had a great influence on Polish. Many Polish words ("rzeczpospolita" from "res publica", "zdanie" for both "opinion" and "sentence", from "sententia") were direct borrowings from Latin. Latin was known to a larger or smaller degree by most of the numerous szlachta in the 16th to 18th centuries (and it continued to be extensively taught at secondary schools until World War II). Apart from dozens of loanwords, its influence can also be seen in a number of verbatim Latin phrases in Polish literature (especially from the 19th century and earlier).
During the 12th and 13th centuries, Mongolian words were brought to the Polish language during wars with the armies of Genghis Khan and his descendants, e.g. "dzida" (spear) and "szereg" (a line or row).
Words from Czech, an important influence during the 10th and 14th–15th centuries include "sejm", "hańba" and "brama".
In 1518, the Polish king Sigismund the Old married Bona Sforza, the niece of the Holy Roman emperor Maximilian, who introduced Italian cuisine to Poland, especially vegetables. Hence, words from Italian include "pomidor" from "pomodoro" (tomato), "kalafior" from "cavolfiore" (cauliflower), and "pomarańcza", a portmanteau from Italian "pomo" (pome) plus "arancio" (orange). A later word of Italian origin is "autostrada" (from Italian "autostrada", highway).
In the 18th century, with the rising prominence of France in Europe, French supplanted Latin as an important source of words. Some French borrowings also date from the Napoleonic era, when the Poles were enthusiastic supporters of Napoleon. Examples include "ekran" (from French "écran", screen), "abażur" ("abat-jour", lamp shade), "rekin" ("requin", shark), "meble" ("meuble", furniture), "bagaż" ("bagage", luggage), "walizka" ("valise", suitcase), "fotel" ("fauteuil", armchair), "plaża" ("plage", beach) and "koszmar" ("cauchemar", nightmare). Some place names have also been adapted from French, such as the Warsaw borough of Żoliborz ("joli bord" = beautiful riverside), as well as the town of Żyrardów (from the name Girard, with the Polish suffix -ów attached to refer to the founder of the town).
Many words were borrowed from the German language from the sizable German population in Polish cities during medieval times. German words found in the Polish language are often connected with trade, the building industry, civic rights and city life. Some words were assimilated verbatim, for example "handel" (trade) and "dach" (roof); others are pronounced the same, but differ in writing "schnur"—"sznur" (cord). As a result of being neighbours with Germany, Polish has many German expressions which have become literally translated (calques). Interestingly, the regional dialects of Upper Silesia and Masuria (Modern Polish East Prussia) have noticeably more German loanwords than other dialects.
The contacts with Ottoman Turkey in the 17th century brought many new words, some of them still in use, such as: "jar" (deep valley), "szaszłyk" (shish kebab), "filiżanka" (cup), "arbuz" (watermelon), "dywan" (carpet), etc.
From the founding of the Kingdom of Poland in 1025 through the early years of the Polish-Lithuanian Commonwealth created in 1569, Poland was the most tolerant country of Jews in Europe. Known as paradisus Iudaeorum (Latin for "paradise for the Jews"), it became a shelter for persecuted and expelled European Jewish communities and the home to the world's largest Jewish community of the time. As a result, many Polish words come from Yiddish, spoken by the large Polish Jewish population that existed until the Holocaust. Borrowed Yiddish words include "bachor" (an unruly boy or child), "bajzel" (slang for mess), "belfer" (slang for teacher), "ciuchy" (slang for clothing), "cymes" (slang for very tasty food), "geszeft" (slang for business), "kitel" (slang for apron), "machlojka" (slang for scam), "mamona" (money), "menele" (slang for oddments and also for homeless people), "myszygine" (slang for lunatic), "pinda" (slang for girl, pejoratively), "plajta" (slang for bankruptcy), "rejwach" (noise), "szmal" (slang for money), and "trefny" (dodgy).
The mountain dialects of the Górale in southern Poland, have quite a number of words borrowed from Hungarian (e.g. "baca", "gazda", "juhas", "hejnał") and Romanian as a result of historical contacts with Hungarian-dominated Slovakia and Wallachian herders who travelled north along the Carpathians.
Thieves' slang includes such words as "kimać" (to sleep) or "majcher" (knife) of Greek origin, considered then unknown to the outside world.
Direct borrowings from Russian are extremely rare, in spite of long periods of dependence on Tsarist Russia and the Soviet Union, and are limited to a few internationalisms, such as "sputnik" and "pierestrojka" . Russian personal names are transcribed into Polish likewise; thus Tchaikovsky's name is spelled "Piotr Iljicz Czajkowski".
Recent loanwords come primarily from the English language, mainly those that have Latin or Greek roots, for example "komputer" (computer), "korupcja" (from 'corruption', but sense restricted to 'bribery'), etc. Slang sometimes borrows and alters common English words, e.g. "luknąć" (to look). Concatenation of parts of words (e.g. "auto-moto"), which is not native to Polish but common in English, for example, is also sometimes used. When borrowing English words, Polish often changes their spelling. For example, Latin suffix '-tio' corresponds to "-cja". To make the word plural, "-cja" becomes "-cje". Examples of this include "inauguracja" (inauguration), "dewastacja" (devastation), "recepcja" (reception), "konurbacja" (conurbation) and "konotacje" (connotations). Also, the digraph "qu" becomes "kw" ("kwadrant" = quadrant; "kworum" = quorum).
Loanwords from Polish.
The Polish language has influenced others. Particular influences appear in other Slavic languages and in German — due to their proximity and shared borders. Examples of loanwords include German "Grenze" (border), Dutch and Afrikaans "grens" from Polish "granica"; German "Peitzker" from Polish "piskorz" (weatherfish); German "Zobel", French "zibeline", Swedish "sabel", and English "sable" from Polish "soból"; and "ogonek" ("little tail") — the word describing a diacritic hook-sign added below some letters in various alphabets. "," a Polish-Ruthenian word for "mop" or "rag" became part of Yiddish.
Quite a few culinary loanwords exist in German and in other languages, some of which describe distinctive features of Polish cuisine. These include German and English "Quark" from "twaróg" (a kind of fresh cheese; see: quark (dairy product)) and German "Gurke", English "gherkin" from "ogórek" (cucumber). The word "pierogi" (Polish dumplings) has spread internationally, as well as "pączki" (Polish donuts) and kiełbasa (sausage) (see e.g. "kolbaso" in Esperanto). As far as "pierogi" concerned, the original Polish word is already in plural (sing. "pieróg", plural "pierogi"; stem "pierog-", plural ending "-i"; NB. "o" becomes "ó" in a closed syllable, like here in singular), yet it is commonly used with the English plural ending "-s" in Canada and United States of America, "pierogis", thus making it a "double plural". (A similar situation happened in the opposite direction to the Polish loanword from English "czipsy" ("potato chips")—from English "chips" being already plural in the original ("chip" + "-s"), yet it has obtained the Polish plural ending "-y".)
The word "spruce" entered the English language from the Polish name of Prusy (a historical region, today part of Poland). It became "spruce" because in Polish, "z Prus", sounded like "spruce" in English (transl. "from Prussia") and was a generic term for commodities brought to England by Hanseatic merchants and because the tree was believed to have come from Polish Ducal Prussia.

</doc>
<doc id="22977" url="https://en.wikipedia.org/wiki?curid=22977" title="Pulp magazine">
Pulp magazine

Pulp magazines (often referred to as "the pulps") are inexpensive fiction magazines that were published from 1896 through the 1950s. The term "pulp" derives from the cheap wood pulp paper on which the magazines were printed; in contrast, magazines printed on higher quality paper were called "glossies" or "slicks". The typical pulp magazine had 128 pages; it was wide by high, and thick, with ragged, untrimmed edges.
The pulps gave rise the term pulp fiction in reference to run-of-the-mill low quality literature.
In their first decades, pulps were most often priced at ten cents per magazine, while competing slicks cost 25 cents a piece. Pulps were the successors to the penny dreadfuls, dime novels, and short fiction magazines of the 19th century. Although many respected writers wrote for pulps, the magazines were best known for their lurid and exploitative stories and sensational cover art. Modern superhero comic books are sometimes considered descendants of "hero pulps"; pulp magazines often featured illustrated novel-length stories of heroic characters, such as The Shadow, Doc Savage, and The Phantom Detective.
Origins.
The first "pulp" was Frank Munsey's revamped "Argosy Magazine" of 1896, with about 135,000 words (192 pages) per issue, on pulp paper with untrimmed edges, and no illustrations, even on the cover. The steam-powered printing press had been in widespread use for some time, enabling the boom in dime novels; prior to Munsey, however, no one had combined cheap printing, cheap paper and cheap authors in a package that provided affordable entertainment to young working-class people. In six years "Argosy" went from a few thousand copies per month to over half a million.
Street & Smith, a dime novel and boys' weekly publisher, was next on the market. Seeing "Argosy"'s success, they launched "The Popular Magazine" in 1903, which they billed as the "biggest magazine in the world" by virtue of its being two pages (the interior sides of the front and back cover) longer than "Argosy". Due to differences in page layout however, the magazine had substantially less text than "Argosy". "The Popular Magazine" did introduce color covers to pulp publishing, and the magazine began to take off when the publishers in 1905 acquired the rights to serialize "Ayesha", by H. Rider Haggard, a sequel to his popular novel "She". Haggard's Lost World genre influenced several key pulp writers, including Edgar Rice Burroughs, Robert E. Howard, Talbot Mundy and Abraham Merritt. In 1907, the cover price rose to 15 cents and 30 pages were added to each issue; along with establishing a stable of authors for each magazine, this change proved successful and circulation began to approach that of "Argosy". Street and Smith's next innovation was the introduction of specialized genre pulps, with each magazine focusing on a particular genre, such as detective stories, romance, etc.
Popularity.
At their peak of popularity in the 1920s and 1930s, the most successful pulps could sell up to one million copies per issue. In 1934, Frank Gruber (writer) says there were some 150 pulp titles. The most successful pulp magazines were "Argosy", "Adventure", "Blue Book" and "Short Stories", collectively described by some pulp historians as "The Big Four". Among the best-known other titles of this period were "Amazing Stories", "Black Mask", "Dime Detective", "Flying Aces", "Horror Stories", "Love Story Magazine", "Marvel Tales", "Oriental Stories", "Planet Stories", "Spicy Detective", "Startling Stories", "Thrilling Wonder Stories", "Unknown", "Weird Tales" and "Western Story Magazine".
Although pulp magazines were primarily an American phenomenon, there were also a number of British pulp magazines published between the Edwardian era and World War II. Notable UK pulps included "Pall Mall Magazine", "The Novel Magazine", "Cassell's Magazine", "The Story-Teller", "The Sovereign Magazine", "Hutchinson's Adventure-Story" and "Hutchinson's Mystery-Story". The German fantasy magazine "Der Orchideengarten" had a similar format to American pulp magazines, in that it was printed on rough pulp paper and heavily illustrated.
World War II and market decline.
The Second World War paper shortages had a serious impact on pulp production, starting a steady rise in costs and the decline of the pulps. Beginning with "Ellery Queen's Mystery Magazine" in 1941, pulp magazines began to switch to digest size; smaller, thicker magazines. In 1949, Street & Smith closed most of their pulp magazines in order to move upmarket and produce slicks.
The pulp format declined from rising expenses, but even more due to the heavy competition from comic books, television, and the paperback novel. In a more affluent post-war America, the price gap compared to slick magazines was far less significant. In the 1950s, men's adventure magazines began to replace the pulp.
The 1957 liquidation of the American News Company, then the primary distributor of pulp magazines, has sometimes been taken as marking the end of the "pulp era"; by that date, many of the famous pulps of the previous generation, including "Black Mask," "The Shadow," "Doc Savage," and "Weird Tales," were defunct. Almost all of the few remaining pulp magazines are science fiction or mystery magazines now in formats similar to "digest size", such as "Analog Science Fiction and Fact" and "Ellery Queen's Mystery Magazine". The format is still in use for some lengthy serials, like the German science fiction weekly "Perry Rhodan" (over 2,650 issues as of 2012).
Over the course of their evolution, there were a huge number of pulp magazine titles; Harry Steeger of Popular Publications claimed that his company alone had published over 300, and at their peak they were publishing 42 titles per month. Many titles of course survived only briefly. While the most popular titles were monthly, many were bimonthly and some were quarterly.
The collapse of the pulp industry changed the landscape of publishing because pulps were the single largest sales outlet for short stories. Combined with the decrease in slick magazine fiction markets, writers attempting to support themselves by creating fiction switched to novels and book-length anthologies of shorter pieces.
Genres.
Pulp magazines often contained a wide variety of genre fiction, including, but not limited to,
The American Old West was a mainstay genre of early turn of the 20th century novels as well as later pulp magazines, and lasted longest of all the traditional pulps. In many ways, the later men's adventure ("the sweats") was the replacement of pulps.
Many classic science fiction and crime novels were originally serialized in pulp magazines such as "Weird Tales", "Amazing Stories", and "Black Mask".
Notable original characters.
While the majority of pulp magazines were anthology titles featuring many different authors, characters and settings, some of the most enduringly popular magazines were those that featured a single recurring character. These were often referred to as "hero pulps" because the recurring character was almost always a larger-than-life hero in the mold of Doc Savage or The Shadow.
Popular pulp characters that headlined in their own magazines:
Popular pulp characters who appeared in anthology titles such as "All-Story" or "Weird Tales":
Illustrators.
Pulp covers were printed in color on higher-quality (slick) paper. They were famous for their half-dressed damsels in distress, usually awaiting a rescuing hero. Cover art played a major part in the marketing of pulp magazines. The early pulp magazines could boast covers by some distinguished American artists; "The Popular Magazine" had covers by N.C. Wyeth, and Edgar Franklin Wittmack contributed cover art to "Argosy" and "Short Stories". Later, many artists specialized in creating covers mainly for the pulps; a number of the most successful cover artists became as popular as the authors featured on the interior pages. Among the most famous pulp artists were Walter Baumhofer, Earle K. Bergey, Margaret Brundage, Edd Cartier, Virgil Finlay, Frank R. Paul, Norman Saunders, Nick Eggenhofer, (who specialized in Western illustrations), Hugh J. Ward, George Rozen, and Rudolph Belarski. Covers were important enough to sales that sometimes they would be designed first; authors would then be shown the cover art and asked to write a story to match.
Later pulps began to feature interior illustrations, depicting elements of the stories. The drawings were printed in black ink on the same cream-colored paper used for the text, and had to use specific techniques to avoid blotting on the coarse texture of the cheap pulp. Thus, fine lines and heavy detail were usually not an option. Shading was by crosshatching or pointillism, and even that had to be limited and coarse. Usually the art was black lines on the paper's background, but Finlay and a few others did some work that was primarily white lines against large dark areas.
Authors and editors.
Another way pulps kept costs down was by paying authors less than other markets; thus many eminent authors started out in the pulps before they were successful enough to sell to better-paying markets, and similarly, well-known authors whose careers were slumping or who wanted a few quick dollars could bolster their income with sales to pulps. Additionally, some of the earlier pulps solicited stories from amateurs who were quite happy to see their words in print and could thus be paid token amounts.
There were also career pulp writers, capable of turning out huge amounts of prose on a steady basis, often with the aid of dictation to stenographers, machines or typists. Before he became a novelist, Upton Sinclair was turning out at least 8,000 words per day seven days a week for the pulps, keeping two stenographers fully employed. Pulps would often have their authors use multiple pen names so that they could use multiple stories by the same person in one issue, or use a given author's stories in three or more successive issues, while still appearing to have varied content. One advantage pulps provided to authors was that they paid "upon acceptance" for material instead of on publication; since a story might be accepted months or even years before publication, to a working writer this was a crucial difference in cash flow.
Some pulp editors became known for cultivating good fiction and interesting features in their magazines. Preeminent pulp magazine editors included Arthur Sullivant Hoffman ("Adventure)", Robert H. Davis ("All-Story Weekly"), Harry E. Maule ("Short Stories"), Donald Kennicott ("Blue Book"), Joseph T. Shaw ("Black Mask"), Farnsworth Wright ("Weird Tales", "Oriental Stories"), John W. Campbell ("Astounding Science Fiction", "Unknown") and Daisy Bacon ("Love Story Magazine", "Detective Story Magazine").
Authors featured.
Well-known authors who wrote for pulps include:
Sinclair Lewis, first American winner of the Nobel Prize in Literature, worked as an editor for "Adventure", writing filler paragraphs (brief facts or amusing anecdotes designed to fill small gaps in page layout), advertising copy and a few stories.
Legacy.
The term "pulp fiction" can also refer to mass market paperbacks since the 1950s. The Brown Popular Culture Library News noted:
In 1992, Rich W. Harvey came out with a magazine called "Pulp Adventures" reprinting old classics. It came out regularly until 2001, and then started up again in 2014.
In 1994, Quentin Tarantino directed the film "Pulp Fiction". The working title of the film was "Black Mask", in homage to the pulp magazine of that name, and it embodied the seedy, violent, often crime-related spirit found in pulp magazines.
After the year 2000, several small independent publishers released magazines which published short fiction, either short stories or novel-length presentations, in the tradition of the pulp magazines of the early 20th century. These included "Blood 'N Thunder", "High Adventure" and a short-lived magazine which revived the title "Argosy". These specialist publications, printed in limited press runs, were pointedly not printed on the brittle, high-acid wood pulp paper of the old publications and were not mass market publications targeted at a wide audience. In 2004, Lost Continent Library published "Secret of the Amazon Queen" by E.A. Guest, their first contribution to a "New Pulp Era", featuring the hallmarks of pulp fiction for contemporary mature readers: violence, horror and sex. E.A. Guest was likened to a blend of pulp era icon Talbot Mundy and Stephen King by real-life explorer David Hatcher Childress. 
In 2002, the tenth issue of "McSweeney's Quarterly" was guest edited by Michael Chabon. Published as "McSweeney's Mammoth Treasury of Thrilling Tales", it is a collection of "pulp fiction" stories written by such current well-known authors as Stephen King, Nick Hornby, Aimee Bender and Dave Eggers. Explaining his vision for the project, Chabon wrote in the introduction, "I think that we have forgotten how much fun reading a short story can be, and I hope that if nothing else, this treasury goes some small distance toward reminding us of that lost but fundamental truth."
The Scottish publisher DC Thomson publishes "My Weekly Compact Novel" every week. It is literally a pulp novel, though it does not fall into the hard-edged genre most associated with pulp fiction.
In 2010, Pro Se Press released three new pulp magazines "Fantasy & Fear", "Masked Gun Mystery" and "Peculiar Adventures". In 2011, they amalgamated the three titles into one magazine "Pro Se Presents" which came out regularly until Winter/Spring 2014.

</doc>
<doc id="22980" url="https://en.wikipedia.org/wiki?curid=22980" title="Phoneme">
Phoneme

A phoneme is one of the units of sound that distinguish one word from another in a particular language. The difference in meaning between the English words "kill" and "kiss" is a result of the exchange of the phoneme for the phoneme . Two words that differ in meaning through a contrast of a single phoneme form a minimal pair.
In linguistics, phonemes (established by the use of minimal pairs, such as "kill" vs "kiss" or "pat" vs "bat") are written between slashes like this: , whereas when it is desired to show the more exact pronunciation of any sound, linguists use square brackets, for example (indicating an aspirated p).
Within linguistics there are differing views as to exactly what phonemes are and how a given language should be analyzed in "phonemic" (or "phonematic") terms. However, a phoneme is generally regarded as an abstraction of a set (or equivalence class) of speech sounds ("phones") which are perceived as equivalent to each other in a given language. For example, in English, the "k" sounds in the words "kit" and "skill" are not identical (as described below), but they are distributional variants of a single phoneme . Different speech sounds that are realizations of the same phoneme are known as allophones. Allophonic variation may be conditioned, in which case a certain phoneme is realized as a certain allophone in particular phonological environments, or it may be free in which case it may vary randomly. In this way, phonemes are often considered to constitute an abstract underlying representation for segments of words, while speech sounds make up the corresponding phonetic realization, or surface form.
Notation.
Phonemes are conventionally placed between slashes in transcription, whereas speech sounds (phones) are placed between square brackets. Thus represents a sequence of three phonemes , , (the word "push" in standard English), while represents the phonetic sequence of sounds (aspirated "p"), , (the usual pronunciation of "push"). (Another similar convention is the use of angle brackets to enclose the units of orthography, namely graphemes; for example, <f> represents the written letter (grapheme) "f".)
The symbols used for particular phonemes are often taken from the International Phonetic Alphabet (IPA), the same set of symbols that are most commonly used for phones. (For computer typing purposes, systems such as X-SAMPA and Kirshenbaum exist to represent IPA symbols in plain text.) However, descriptions of particular languages may use different conventional symbols to represent the phonemes of those languages. For languages whose writing systems employ the phonemic principle, ordinary letters may be used to denote phonemes, although this approach is often hampered by the complexity of the relationship between orthography and pronunciation (see Correspondence between letters and phonemes below).
Assignment of speech sounds to phonemes.
A phoneme is a sound or a group of different sounds perceived to have the same function by speakers of the language or dialect in question. An example is the English phoneme , which occurs in words such as cat", kit", "scat", "skit". Although most native speakers do not notice this, in most English dialects the "c/k" sounds in these words are not identical: in cat" and kit" (U.S. pronunciations: and ) the sound is aspirated, while in "scat" and "skit" it is unaspirated. The words therefore contain different "speech sounds", or "phones", transcribed for the aspirated form, for the unaspirated one. These different sounds are nonetheless considered to belong to the same phoneme, because if a speaker used one instead of the other, the meaning of the word would not change: using the aspirated form in "skill" might sound odd, but the word would still be recognized. By contrast, some other sounds would cause a change in meaning if substituted: for example, substitution of the sound would produce the different word "still", and that sound must therefore be considered to represent a different phoneme (the phoneme ).
The above shows that in English, and are allophones of a single phoneme . In some languages, however, and are perceived by native speakers as different sounds, and substituting one for the other can change the meaning of a word; this means that in those languages, the two sounds represent different phonemes. For example, in Icelandic, is the first sound of "kátur" meaning "cheerful", while is the first sound of "gátur" meaning "riddles". Icelandic therefore has two separate phonemes and .
Minimal pairs.
A pair of words like "kátur" and "gátur" (above) that differ only in one phone is called a minimal pair for the two alternative phones in question (in this case, and ). The existence of minimal pairs is a common test to decide whether two phones represent different phonemes or are allophones of the same phoneme. To take another example, the minimal pair tip" and dip" illustrates that in English, and belong to separate phonemes, and ; since these two words have different meanings, English speakers must be conscious of the distinction between the two sounds. In other languages, though, including Korean, even though both sounds and occur, no such minimal pair exists. The lack of minimal pairs distinguishing and in Korean provides evidence that in this language they are allophones of a single phoneme . The word is pronounced , for example. That is, when they hear this word, Korean speakers perceive the same sound in both the beginning and middle of the word, whereas an English speaker would perceive different sounds in these two locations.
However, the absence of minimal pairs for a given pair of phones does not always mean that they belong to the same phoneme: they may be too dissimilar phonetically for it to be likely that speakers perceive them as the same sound. For example, English has no minimal pair for the sounds (as in hat") and (as in "bang), and the fact that they can be shown to be in complementary distribution could be used to argue for them being allophones of the same phoneme. However, they are so dissimilar phonetically that they are considered separate phonemes.
Phonologists have sometimes had recourse to "near minimal pairs" to show that speakers of the language perceive two sounds as significantly different even if no exact minimal pair exists in the lexicon. It is virtually impossible to find a minimal pair to distinguish English from , yet it seems uncontroversial to claim that the two consonants are distinct phonemes. The two words 'pressure' and 'pleasure' can serve as a near minimal pair.
Other features with phonemic status.
While phonemes are normally conceived of as abstractions of discrete segmental speech sounds (vowels and consonants), there are other features of pronunciation – principally tone and stress – which in some languages can change the meaning of words in the way that phoneme contrasts do, and are consequently called "phonemic" features of those languages.
"Phonemic stress" is encountered in languages such as English. For example, the word "invite" stressed on the second syllable is a verb, but when stressed on the first syllable (without changing any of the individual sounds) it becomes a noun. The position of the stress in the word affects the meaning, and therefore a full phonemic specification (providing enough detail to enable the word to be pronounced unambiguously) would include indication of the position of the stress: for the verb, for the noun. In other languages, such as French, word stress cannot have this function (its position is generally predictable) and is therefore not phonemic (and is not usually indicated in dictionaries).
"Phonemic tones" are found in languages such as Mandarin Chinese, in which a given syllable can have five different tonal pronunciations. For example, the character 妈 (pronounced "mā", high level pitch) means "mom", 麻 ("má", rising pitch) means "hemp", 马 ("mǎ", falling then rising) means "horse", 骂 ("mà", falling) means "scold", and 吗 ("ma", neutral tone) is an interrogative particle. The tone "phonemes" in such languages are sometimes called "tonemes". Languages such as English do not have phonemic tone, although they use intonation for functions such as emphasis and attitude.
Distribution of allophones.
When a phoneme has more than one allophone, the one actually heard at a given occurrence of that phoneme may be dependent on the phonetic environment (surrounding sounds) – allophones which normally cannot appear in the same environment are said to be in complementary distribution. In other cases the choice of allophone may be dependent on the individual speaker or other unpredictable factors – such allophones are said to be in free variation.
Background and related ideas.
The term "phonème" (from Ancient Greek φώνημα "phōnēma", "sound made, utterance") was reportedly first used by A. Dufriche-Desgenettes in 1873, but it referred only to a speech sound. The term "phoneme" as an abstraction was developed by the Polish linguist Jan Niecisław Baudouin de Courtenay and his student Mikołaj Kruszewski during 1875–1895. The term used by these two was "fonema", the basic unit of what they called "psychophonetics". The concept of the phoneme was then elaborated in the works of Nikolai Trubetzkoi and others of the Prague School (during the years 1926–1935), and in those of structuralists like Ferdinand de Saussure, Edward Sapir, and Leonard Bloomfield. Some structuralists (though not Sapir) rejected the idea of a cognitive or psycholinguistic function for the phoneme
Later, it was used and redefined in generative linguistics, most famously by Noam Chomsky and Morris Halle, and remains central to many accounts of the development of modern phonology. As a theoretical concept or model, though, it has been supplemented and even replaced by others.
Some linguists (such as Roman Jakobson and Morris Halle) proposed that phonemes may be further decomposable into features, such features being the true minimal constituents of language. Features overlap each other in time, as do suprasegmental phonemes in oral language and many phonemes in sign languages. Features could be characterized in different ways: Jakobson and colleagues defined them in acoustic terms, Chomsky and Halle used a predominantly articulatory basis, though retaining some acoustic features, while Ladefoged's system is a purely articulatory system apart from the use of the acoustic term 'sibilant'.
In the description of some languages, the term chroneme has been used to indicate contrastive length or "duration" of phonemes. In languages in which tones are phonemic, the tone phonemes may be called tonemes. Not all scholars working on such languages use these terms, which may be considered obsolete.
By analogy with the phoneme, linguists have proposed other sorts of underlying objects, giving them names with the suffix "-eme", such as "morpheme" and "grapheme". These are sometimes called emic units. The latter term was first used by Kenneth Pike, who also generalized the concepts of emic and etic description (from "phonemic" and "phonetic" respectively) to applications outside linguistics.
Restrictions on occurrence.
Languages do not generally allow words or syllables to be built of any arbitrary sequences of phonemes; there are phonotactic restrictions on which sequences of phonemes are possible and in which environments certain phonemes can occur. Phonemes that are significantly limited by such restrictions may be called "restricted phonemes". Examples of such restrictions in English include:
Some phonotactic restrictions can alternatively be analyzed as cases of neutralization. See Neutralization and archiphonemes below, particularly the example of the occurrence of the three English nasals before stops.
Biuniqueness.
Biuniqueness is a requirement of classic structuralist phonemics. It means that a given phone, wherever it occurs, must unambiguously be assigned to one and only one phoneme. In other words, the mapping between phones and phonemes is required to be many-to-one rather than many-to-many. The notion of biuniqueness was controversial among some pre-generative linguists and was prominently challenged by Morris Halle and Noam Chomsky in the late 1950s and early 1960s.
An example of the problems arising from the biuniqueness requirement is provided by the phenomenon of flapping in North American English. This may cause either or (in the appropriate environments) to be realized with the phone (an alveolar flap). For example, the same flap sound may be heard in the words "hitting" and "bidding", although it is clearly intended to realize the phoneme in the first word and in the second. This appears to contradict biuniqueness.
For further discussion of such cases, see the next section.
Neutralization and archiphonemes.
Phonemes that are contrastive in certain environments may not be contrastive in all environments. In the environments where they do not contrast, the contrast is said to be neutralized. In these positions it may become less clear which phoneme a given phone represents. Some phonologists prefer not to specify a unique phoneme in such cases, since to do so would mean providing redundant or even arbitrary information – instead they use the technique of underspecification. An archiphoneme is an object sometimes used to represent an underspecified phoneme.
An example of neutralization is provided by the Russian vowels and . These phonemes are contrasting in stressed syllables, but in unstressed syllables the contrast is lost, since both are reduced to the same sound, usually (for details, see Vowel reduction in Russian). In order to assign such an instance of to one of the phonemes and , it is necessary to consider morphological factors (such as which of the vowels occurs in other forms of the words, or which inflectional pattern is followed). In some cases even this may not provide an unambiguous answer. A description using the approach of underspecification would not attempt to assign to a specific phoneme in some or all of these cases, although it might be assigned to an archiphoneme, written something like |A|, which reflects the two neutralized phonemes in this position.
A somewhat different example is found in English, with the three nasal phonemes . In word-final position these all contrast, as shown by the minimal triplet "sum" , "sun" , "sung" . However, before a stop such as (provided there is no morpheme boundary between them), only one of the nasals is possible in any given position: before , before or , and before , as in "limp, lint, link" ( , , ). The nasals are therefore not contrastive in these environments, and according to some theorists this makes it inappropriate to assign the nasal phones heard here to any one of the phonemes (even though, in this case, the phonetic evidence is unambiguous). Instead they may analyze these phones as belonging to a single archiphoneme, written something like |N|, and state the underlying representations of "limp, lint, link" to be .
This latter type of analysis is often associated with Nikolai Trubetzkoy of the Prague school. Archiphonemes are often notated with a capital letter within pipes, as with the examples |A| and |N| given above. Other ways the second of these might be notated include , }, or |n*|.
Another example from English, but this time involving complete phonetic convergence as in the Russian example, is the flapping of and in some American English (described above under Biuniqueness). Here the words "betting" and "bedding" might both be pronounced , and if a speaker applies such flapping consistently, it would be necessary to look for morphological evidence (the pronunciation of the related forms "bet" and "bed", for example) in order to determine which phoneme the flap represents. As in the previous examples, some theorists would prefer not to make such a determination, and simply assign the flap in both cases to a single archiphoneme, written (for example) |D|.
For a special kind of neutralization proposed in generative phonology, see absolute neutralization.
Morphophonemes.
A morphophoneme is a theoretical unit at a deeper level of abstraction than traditional phonemes, and is taken to be a unit from which morphemes are built up. A morphophoneme within a morpheme can be expressed in different ways in different allomorphs of that morpheme (according to morphophonological rules). For example, the English plural morpheme "-s" appearing in words such as "cats" and "dogs" can be considered to consist of a single morphophoneme, which might be written (for example) //z// or |z|, and which is pronounced as [s] after most voiceless consonants (as in "cats) and [z] in most other cases (as in "dogs).
Numbers of phonemes in different languages.
A given language will use only a small subset of the many possible sounds that the human speech organs can produce, and (because of allophony) the number of distinct phonemes will generally be smaller than the number of identifiably different sounds. Different languages vary considerably in the number of phonemes they have in their systems (although apparent variation may sometimes result from the different approaches taken by the linguists doing the analysis). The total phonemic inventory in languages varies from as few as 11 in Rotokas and Pirahã to as many as 141 in !Xũ.
The number of phonemically distinct vowels can be as low as two, as in Ubykh and Arrernte. At the other extreme, the Bantu language Ngwe has 14 vowel qualities, 12 of which may occur long or short, making 26 oral vowels, plus 6 nasalized vowels, long and short, making a total of 38 vowels; while !Xóõ achieves 31 pure vowels, not counting its additional variation by vowel length, by varying the phonation. As regards consonant phonemes, Puinave has just seven, and Rotokas has only six. !Xóõ, on the other hand, has somewhere around 77, and Ubykh 81. The English language uses a rather large set of 13 to 21 vowel phonemes, including diphthongs, although its 22 to 26 consonants are close to average.
Some languages, such as French, have no phonemic tone or stress, while several of the Kam–Sui languages have nine tones, and one of the Kru languages, Wobe, has been claimed to have 14, though this is disputed.
The most common vowel system consists of the five vowels . The most common consonants are . Relatively few languages lack any of these consonants, although it does happen: for example, Arabic lacks , standard Hawaiian lacks , Mohawk and Tlingit lack and , Hupa lacks both and a simple , colloquial Samoan lacks and , while Rotokas and Quileute lack and .
Correspondence between letters and phonemes.
Phonemes are considered to be the basis for alphabetic writing systems. In such systems the written symbols (graphemes) represent, in principle, the phonemes of the language being written. This is most obviously the case when the alphabet was invented with a particular language in mind; for example, the Latin alphabet was devised for Classical Latin, and therefore the Latin of that period enjoyed a near one-to-one correspondence between phonemes and graphemes in most cases, though the devisers of the alphabet chose not to represent the phonemic effect of vowel length. However, because changes in the spoken language are often not accompanied by changes in the established orthography (as well as other reasons, including dialect differences, the effects of morphophonology on orthography, and the use of foreign spellings for some loanwords), the correspondence between spelling and pronunciation in a given language may be highly distorted; this is the case with English, for example.
The correspondence between symbols and phonemes in alphabetic writing systems is not necessarily a one-to-one correspondence. A phoneme might be represented by a combination of two or more letters (digraph, trigraph, etc.), like <sh> in English or <sch> in German (both representing phonemes ). Also a single letter may represent two phonemes, as in English <x> representing /gz/ or /ks/. There may also exist spelling/pronunciation rules (such as those for the pronunciation of <c> in Italian) that further complicate the correspondence of letters to phonemes, although they need not affect the ability to predict the pronunciation from the spelling and vice versa, provided the rules are known.
Phonemes in sign languages.
In sign languages, the basic elements of gesture and location were formerly called "cheremes" or "cheiremes" but they are now generally referred to as phonemes, as with oral languages.
Sign language phonemes are combinations of articulation bundles in ASL. These bundles may be classified as "tab" (elements of location, from Latin "tabula"), "dez" (the hand shape, from "designator"), "sig" (the motion, from "signation"), and with some researchers, "ori" (orientation). Facial expression and mouthing are also considered articulation bundles. Just as with spoken languages, when these bundles are combined, they create phonemes.
Stokoe notation is no longer used by researchers to denote the phonemes of sign languages; his research, while still considered seminal, has been found to not describe American Sign Language and cannot be used interchangeably with other signed languages. Originally developed for American Sign Language, it has also been applied to British Sign Language by Kyle and Woll, and to Australian Aboriginal sign languages by Adam Kendon. Other sign notations, such as the Hamburg Notation System and SignWriting, are phonetic scripts capable of writing any sign language. Stokoe's work has been succeeded and improved upon by researcher Scott Liddell in his book "Grammar, Gesture, and Meaning in American Sign Language", and both Stokoe and Liddell's work have been included in the Linguistics of American Sign Language, 5th Edition.

</doc>
<doc id="22981" url="https://en.wikipedia.org/wiki?curid=22981" title="Phone (phonetics)">
Phone (phonetics)

In phonetics and linguistics, the word phone may refer to any speech sound or gesture considered as a physical event without regard to its place in the phonology of a language. In contrast, a phoneme is a set of phones or a set of sound features that are thought of as the same element within the phonology of a particular language. .
In the context of spoken languages, a phone is an unanalyzed sound of a language . A phone is a speech segment that possesses distinct physical or perceptual properties, and serves as the basic unit of phonetic speech analysis. Phones are generally either vowels or consonants.
A phonetic transcription (based on phones) is enclosed within square brackets ([ ]), rather than the slashes (/ /) of a phonemic transcription (based on phonemes). Phones (and often phonemes also) are commonly represented using symbols of the International Phonetic Alphabet (IPA).
For example, the English word "spin" consists of four phones, [s], [p], [ɪ] and [n], and thus has the phonetic representation [spɪn]. The word "pin" has three phones; in this case the initial sound is aspirated, and so can be represented as [pʰ]; the word's phonetic representation will then be [pʰɪn]. (Precisely which features are shown in a phonetic representation will depend on whether a narrow or broad transcription is being used, and to which features the writer wishes to draw attention in the context.)
When phones are considered to be realizations of the same phoneme, they are called allophones of that phoneme (more information on the methods of making such assignments can be found under Phoneme). In English, for example, [p] and [pʰ] are considered allophones of a single phoneme, written as /p/. The phonemic transcriptions of the above two words will consequently be /spɪn/ and /pɪn/, aspiration no longer being shown, since it is not distinctive.

</doc>
<doc id="22984" url="https://en.wikipedia.org/wiki?curid=22984" title="Primate">
Primate

A primate ( ) is a mammal of the order Primates ( ; Latin: "prime, first rank"). In taxonomy, primates include two distinct lineages, strepsirrhines and haplorhines. Primates arose from ancestors that lived in the trees of tropical forests; many primate characteristics represent adaptations to life in this challenging three-dimensional environment. Most primate species remain at least partly arboreal.
With the exception of humans, who inhabit every continent, most primates live in tropical or subtropical regions of the Americas, Africa and Asia. They range in size from Madame Berthe's mouse lemur, which weighs only , to the eastern gorilla, weighing over . Based on fossil evidence, the earliest known true primates, represented by the genus "Teilhardina", date to 55.8 million years old. An early close primate relative known from abundant remains is the Late Paleocene "Plesiadapis", c. 55–58 million years old. Molecular clock studies suggest that the primate branch may be even older, originating near the Cretaceous–Paleogene boundary or around 63-74 mya.
The order Primates was traditionally divided into two main groupings: prosimians and anthropoids (simians). Prosimians have characteristics more like those of the earliest primates, and include the lemurs of Madagascar, lorisoids, and tarsiers. Simians include monkeys, apes and hominins. More recently, taxonomists have preferred to split primates into the suborder Strepsirrhini, or wet-nosed primates, consisting of non-tarsier prosimians, and the suborder Haplorhini, or dry-nosed primates, consisting of tarsiers and the simians.
Simians are divided into two groups: catarrhine (narrow-nosed) monkeys and apes of Africa and southeastern Asia and platyrrhine ("flat-nosed") or New World monkeys of South and Central America. Catarrhines consist of Old World monkeys (such as baboons and macaques), gibbons and great apes; New World monkeys include the capuchin, howler and squirrel monkeys. Humans are the only extant catarrhines to have spread successfully outside of Africa, South Asia, and East Asia, although fossil evidence shows many other species were formerly present in Europe. New primate species are still being discovered. More than 25 species were taxonomically described in the decade of the 2000s and eleven have been described since 2010.
Considered generalist mammals, primates exhibit a wide range of characteristics. Some primates (including some great apes and baboons) are primarily terrestrial rather than arboreal, but all species possess adaptations for climbing trees. Locomotion techniques used include leaping from tree to tree, walking on two or four limbs, knuckle-walking, and swinging between branches of trees (brachiation).
Primates are characterized by large brains relative to other mammals, as well as an increased reliance on stereoscopic vision at the expense of smell, the dominant sensory system in most mammals. These features are more developed in monkeys and apes and noticeably less so in lorises and lemurs. Three-color vision has developed in some primates. Most also have opposable thumbs and some have prehensile tails. Many species are sexually dimorphic; differences include body mass, canine tooth size, and coloration. Primates have slower rates of development than other similarly sized mammals and reach maturity later, but have longer lifespans. Depending on the species, adults may live in solitude, in mated pairs, or in groups of up to hundreds of members.
Historical and modern terminology.
The relationships among the different groups of primates were not clearly understood until relatively recently, so the commonly used terms are somewhat confused. For example, "ape" has been used either as an alternative for "monkey" or for any tailless, relatively humanlike primate.
Sir Wilfrid Le Gros Clark was one of the primatologists who developed the idea of trends in primate evolution and the methodology of arranging the living members of an order into an "ascending series" leading to humans. Commonly used names for groups of primates such as "prosimians", "monkeys", "lesser apes", and "great apes" reflect this methodology. According to our current understanding of the evolutionary history of the primates, several of these groups are paraphyletic: a paraphyletic group is one which does "not" include all the descendants of the group's common ancestor.
In contrast with Clark's methodology, modern classifications typically identify (or name) only those groupings that are monophyletic; that is, such a named group includes "all" the descendants of the group's common ancestor.
The cladogram below shows one possible classification sequence of the living primates, with groups that use common (traditional) names are shown on the right.
All groups with scientific names are monophyletic (that is, they are clades), and the sequence of scientific classification reflects the evolutionary history of the related lineages. Traditionally named groups are shown on the right; they form an "ascending series" (per Clark, see above), and several groups are paraphyletic:
Thus, the members of the two sets of groups, and hence names, do not match, which causes problems in relating scientific names to common (usually traditional) names. Consider the superfamily Hominoidea: In terms of the common names on the right, this group consists of apes and humans and there is no single common name for all the members of the group. One remedy is to create a new common name, in this case "hominoids". Another possibility is to expand the use of one of the traditional names. For example, in his 2005 book, the vertebrate palaeontologist Benton wrote, "The apes, Hominoidea, today include the gibbons and orang-utan ... the gorilla and chimpanzee ... and humans"; thereby Benton was using "apes" to mean "hominoids". In that case, the group heretofore called "apes" must now be identified as the "non-human apes".
, there is no consensus as to which methodology will rule, whether to accept traditional (that is, common), but paraphyletic, names or to use monophyletic names only; or to use 'new' common names or adaptations of old ones. Both competing approaches will be found in biological sources, often in the same work, and sometimes by the same author. Thus, Benton defines "apes" to include humans, then he repeatedly uses "ape-like" to mean "like an ape rather than a human"; and when discussing the reaction of others to a new fossil he writes of "claims that "Orrorin" ... was an ape rather than a human".
Classification of living primates.
A list of the families of the living primates is given below, together with one possible classification into ranks between order and family. Other classifications are also used. For example, an alternative classification of the living Strepsirrhini divides them into two infraorders, Lemuriformes and Lorisiformes.
Order Primates was established by Carl Linnaeus in 1758, in the tenth edition of his book "Systema Naturae", for the genera "Homo" (humans), "Simia" (other apes and monkeys), "Lemur" (prosimians) and "Vespertilio" (bats). In the first edition of the same book (1735), he had used the name Anthropomorpha for "Homo", "Simia" and "Bradypus" (sloths). In 1839, Henri Marie Ducrotay de Blainville, following Linnaeus and imitating his nomenclature, established the orders Secundates (including the suborders Chiroptera, Insectivora and Carnivora), Tertiates (or Glires) and Quaternates (including Gravigrada, Pachydermata and Ruminantia), but these new taxa were not accepted.
Before Anderson and Jones introduced the classification of Strepsirrhini and Haplorhini in 1984, (followed by McKenna and Bell's 1997 work "Classification of Mammals: Above the species level"), the Primates were divided into two superfamilies: Prosimii and Anthropoidea. Prosimii included all of the prosimians: Strepsirrhini plus the tarsiers. Anthropoidea contained all of the simians.
Evolutionary history.
Order Primates is part of the clade Euarchontoglires, which is nested within the clade Eutheria of Class Mammalia. Recent molecular genetic research on primates, colugos, and treeshrews has shown that the two species of colugos are more closely related to primates than to treeshrews, even though treeshrews were at one time considered primates. These three orders make up the clade Euarchonta. The combination of this clade with the clade Glires (composed of Rodentia and Lagomorpha) forms the clade Euarchontoglires. Variously, both Euarchonta and Euarchontoglires are ranked as superorders. Some scientists consider Dermoptera to be a suborder of Primates and use the suborder Euprimates for the "true" primates.
Evolution.
The primate lineage is thought to go back at least 65 million years ago (mya), even though the oldest known primates from the fossil record date to the Late Paleocene of Africa ("Altiatlasius") or the Paleocene-Eocene transition in the northern continents, c. 55 mya ("Cantius", "Donrussellia", "Altanius", and "Teilhardina"). Other studies, including molecular clock studies, have estimated the origin of the primate branch to have been in the mid-Cretaceous period, around 85 mya.
By modern cladistic reckoning, the order Primates is monophyletic. The suborder Strepsirrhini, the "wet-nosed" primates, is generally thought to have split off from the primitive primate line about 63 mya, although earlier dates are also supported. The seven strepsirrhine families are the five related lemur families and the two remaining families that include the lorisids and the galagos. Older classification schemes wrap Lepilemuridae into Lemuridae and Galagidae into Lorisidae, yielding a four-one family distribution instead of five-two as presented here. During the Eocene, most of the northern continents were dominated by two groups, the adapiforms and the omomyids. The former are considered members of Strepsirrhini, but did not have a toothcomb like modern lemurs; recent analysis has demonstrated that "Darwinius masillae" fits into this grouping. The latter was closely related to tarsiers, monkeys, and apes. How these two groups relate to extant primates is unclear. Omomyids perished about 30 mya, while adapiforms survived until about 10 mya.
According to genetic studies, the lemurs of Madagascar diverged from the lorisoids approximately 75 mya. These studies, as well as chromosomal and molecular evidence, also show that lemurs are more closely related to each other than to other strepsirrhine primates. However, Madagascar split from Africa 160 mya and from India 90 mya. To account for these facts, a founding lemur population of a few individuals is thought to have reached Madagascar from Africa via a single rafting event between 50 and 80 mya. Other colonization options have been examined, such as multiple colonizations from Africa and India, but none are supported by the genetic and molecular evidence.
Until recently, the aye-aye has been difficult to place within Strepsirrhini. Theories had been proposed that its family, Daubentoniidae, was either a lemuriform primate (meaning its ancestors split from the lemur line more recently than lemurs and lorises split) or a sister group to all the other strepsirrhines. In 2008, the aye-aye family was confirmed to be most closely related to the other Malagasy lemurs, likely having descended from the same ancestral population that colonized the island.
Suborder Haplorhini, the simple-nosed or "dry-nosed" primates, is composed of two sister clades. Prosimian tarsiers in the family Tarsiidae (monotypic in its own infraorder Tarsiiformes), represent the most basal division, originating about 58 mya. The earliest known haplorhine skeleton, that of 55 MA old tarsier-like "Archicebus", was found in central China, supporting an already suspected Asian origin for the group. The infraorder Simiiformes (simian primates, consisting of monkeys and apes) emerged about 40 mya, possibly also in Asia; if so, they dispersed across the Tethys Sea from Asia to Africa soon afterwards. There are two simian clades, both parvorders: Catarrhini, which developed in Africa, consisting of Old World monkeys, humans and the other apes, and Platyrrhini, which developed in South America, consisting of New World monkeys. A third clade, which included the eosimiids, developed in Asia, but went extinct millions of years ago.
As in the case of lemurs, the origin of New World monkeys is unclear. Molecular studies of concatenated nuclear sequences have yielded a widely varying estimated date of divergence between platyrrhines and catarrhines, ranging from 33 to 70 mya, while studies based on mitochondrial sequences produce a narrower range of 35 to 43 mya. The anthropoid primates possibly traversed the Atlantic Ocean from Africa to South America during the Eocene by island hopping, facilitated by Atlantic Ocean ridges and a lowered sea level. Alternatively, a single rafting event may explain this transoceanic colonization. Due to continental drift, the Atlantic Ocean was not nearly as wide at the time as it is today. Research suggests that a small primate could have survived 13 days on a raft of vegetation. Given estimated current and wind speeds, this would have provided enough time to make the voyage between the continents.
Apes and monkeys spread from Africa into Europe and Asia starting in the Miocene. Soon after, the lorises and tarsiers made the same journey. The first hominin fossils were discovered in northern Africa and date back 5–8 mya. Old World monkeys disappeared from Europe about 1.8 mya. Molecular and fossil studies generally show that modern humans originated in Africa 100,000–200,000 years ago.
Although primates are well studied in comparison to other animal groups, several new species have been discovered recently, and genetic tests have revealed previously unrecognised species in known populations. "Primate Taxonomy" listed about 350 species of primates in 2001; the author, Colin Groves, increased that number to 376 for his contribution to the third edition of "Mammal Species of the World" (MSW3). However, publications since the taxonomy in MSW3 was compiled in 2003 have pushed the number to 424 species, or 658 including subspecies.
Hybrids.
Primate hybrids usually arise in captivity, but there have also been examples in the wild. Hybridization occurs where two species' range overlap to form hybrid zones; hybrids may be created by humans when animals are placed in zoos or due to environmental pressures such as predation. Intergeneric hybridizations, hybrids of different genera, have also been found in the wild. Although they belong to genera that have been distinct for several million years, interbreeding still occurs between the gelada and the hamadryas baboon.
Anatomy, physiology, and morphology.
Primates have forward-facing eyes on the front of the skull; binocular vision allows accurate distance perception, useful for the brachiating ancestors of all great apes. A bony ridge above the eye sockets reinforces weaker bones in the face, which are put under strain during chewing. Strepsirrhines have a postorbital bar, a bone around the eye socket, to protect their eyes; in contrast, the higher primates, haplorhines, have evolved fully enclosed sockets.
The primate skull has a large, domed cranium, which is particularly prominent in anthropoids. The cranium protects the large brain, a distinguishing characteristic of this group. The endocranial volume (the volume within the skull) is three times greater in humans than in the greatest nonhuman primate, reflecting a larger brain size. The mean endocranial volume is 1,201 cubic centimeters in humans, 469 cm3 in gorillas, 400 cm3 in chimpanzees and 397 cm3 in orangutans. The primary evolutionary trend of primates has been the elaboration of the brain, in particular the neocortex (a part of the cerebral cortex), which is involved with sensory perception, generation of motor commands, spatial reasoning, conscious thought and, in humans, language. While other mammals rely heavily on their sense of smell, the arboreal life of primates has led to a tactile, visually dominant sensory system, a reduction in the olfactory region of the brain and increasingly complex social behavior.
Primates generally have five digits on each limb (pentadactyly), with keratin nails on the end of each finger and toe. The bottom sides of the hands and feet have sensitive pads on the fingertips. Most have opposable thumbs, a characteristic primate feature, though not limited to this order, (opossums, for example, also have them). Thumbs allow some species to use tools. In primates, the combination of opposing thumbs, short fingernails (rather than claws) and long, inward-closing fingers is a relict of the ancestral practice of gripping branches, and has, in part, allowed some species to develop brachiation (swinging by the arms from tree limb to tree limb) as a significant means of locomotion. Prosimians have clawlike nails on the second toe of each foot, called toilet-claws, which they use for grooming.
The primate collar bone is retained as prominent element of the pectoral girdle; this allows the shoulder joint broad mobility. Apes have more mobile shoulder joints and arms due to the dorsal position of the scapula, broad ribcages that are flatter front-to-back, and a shorter, less mobile spine compared to Old World monkeys (with lower vertebrae greatly reduced, resulting in tail loss in some species). Old World monkeys are unlike apes in that most have tails. New World atelids, including the howler, spider, woolly spider and woolly monkeys, and New World capuchins have prehensile tails. Male primates typically have a pendulous penis and scrotal testes.
Primates show an evolutionary trend towards a reduced snout. Technically, Old World monkeys are distinguished from New World monkeys by the structure of the nose, and from apes by the arrangement of their teeth. In New World monkeys, the nostrils face sideways; in Old World monkeys, they face downwards. Dental pattern in primates vary considerably; although some have lost most of their incisors, all retain at least one lower incisor. In most strepsirrhines, the lower incisors and canines form a toothcomb, which is used in grooming and sometimes foraging, and the first lower premolar is shaped like a canine. Old World monkeys have eight premolars, compared with 12 in New World monkeys. The Old World species are divided into apes and monkeys depending on the number of cusps on their molars; apes have five, Old World monkeys have four, although humans may have four or five. The main hominid molar cusp (hypocone) evolved in early primate history, while the cusp of the corresponding primitive lower molar (paraconid) was lost. Prosimians are distinguished by their immobilized upper lips, the moist tip of their noses and forward-facing lower front teeth.
The evolution of color vision in primates is unique among most eutherian mammals. While the remote vertebrate ancestors of the primates possessed three color vision (trichromaticism), the nocturnal, warm-blooded, mammalian ancestors lost one of three cones in the retina during the Mesozoic era. Fish, reptiles and birds are therefore trichromatic or tetrachromatic, while all mammals, with the exception of some primates and marsupials, are dichromats or monochromats (totally color blind). Nocturnal primates, such as the night monkeys and bush babies, are often monochromatic. Catarrhines are routinely trichromatic due to a gene duplication of the red-green opsin gene at the base of their lineage, 30 to 40 million years ago. Platyrrhines, on the other hand, are trichromatic in a few cases only. Specifically, individual females must be heterozygous for two alleles of the opsin gene (red and green) located on the same locus of the X chromosome. Males, therefore, can only be dichromatic, while females can be either dichromatic or trichromatic. Color vision in strepsirrhines is not as well understood; however, research indicates a range of color vision similar to that found in platyrrhines.
Like catarrhines, howler monkeys (a family of platyrrhines) show routine trichromatism that has been traced to an evolutionarily recent gene duplication. Howler monkeys are one of the most specialized leaf-eaters of the New World monkeys; fruits are not a major part of their diets, and the type of leaves they prefer to consume (young, nutritive, and digestible) are detectable only by a red-green signal. Field work exploring the dietary preferences of howler monkeys suggests that routine trichromaticism was selected by environment.
Sexual dimorphism.
Sexual dimorphism is often exhibited in simians, though to a greater degree in Old World species (apes and some monkeys) than New World species. Recent studies involve comparing DNA to examine both the variation in the expression of the dimorphism among primates and the fundamental causes of sexual dimorphism. Primates usually have dimorphism in body mass and canine tooth size along with pelage and skin color. The dimorphism can be attributed to and affected by different factors, including mating system, size, habitat and diet.
Comparative analyses have generated a more complete understanding of the relationship between sexual selection, natural selection, and mating systems in primates. Studies have shown that dimorphism is the product of changes in both male and female traits. Ontogenetic scaling, where relative extension of a common growth trajectory occurs, may give some insight into the relationship between sexual dimorphism and growth patterns. Some evidence from the fossil record suggests that there was convergent evolution of dimorphism, and some extinct hominids probably had greater dimorphism than any living primate.
Locomotion.
Primate species move by brachiation, bipedalism, leaping, arboreal and terrestrial quadrupedalism, climbing, knuckle-walking or by a combination of these methods. Several prosimians are primarily vertical clingers and leapers. These include many bushbabies, all indriids (i.e., sifakas, avahis and indris), sportive lemurs, and all tarsiers. Other prosimians are arboreal quadrupeds and climbers. Some are also terrestrial quadrupeds, while some are leapers. Most monkeys are both arboreal and terrestrial quadrupeds and climbers. Gibbons, muriquis and spider monkeys all brachiate extensively, with gibbons sometimes doing so in remarkably acrobatic fashion. Woolly monkeys also brachiate at times. Orangutans use a similar form of locomotion called quadramanous climbing, in which they use their arms and legs to carry their heavy bodies through the trees. Chimpanzees and gorillas knuckle walk, and can move bipedally for short distances. Although numerous species, such as australopithecines and early hominids, have exhibited fully bipedal locomotion, humans are the only extant species with this trait.
Behavior.
Social systems.
Primates are among the most social of animals, forming pairs or family groups, uni-male harems, and multi-male/multi-female groups. Richard Wrangham stated that social systems of non-human primates are best classified by the amount of movement by females occurring between groups. He proposed four categories:
Other systems are known to occur as well. For example, with howler monkeys both the males and females typically transfer from their natal group on reaching sexual maturity, resulting in groups in which neither the males nor females are typically related. Some prosimians, colobine monkeys and callitrichid monkeys use this system.
The transfer of females and/or males from their native group is likely an adaptation for avoiding inbreeding. An analysis of breeding records of captive primate colonies representing numerous different species indicates that the infant mortality of inbred young is generally higher than that of non-inbred young. This effect of inbreeding on infant mortality is probably largely a result of increased expression of deleterious recessive alleles (see Inbreeding depression).
Primatologist Jane Goodall, who studied in the Gombe Stream National Park, noted fission-fusion societies in chimpanzees. There is "fission" when the main group splits up to forage during the day, then "fusion" when the group returns at night to sleep as a group. This social structure can also be observed in the hamadryas baboon, spider monkeys and the bonobo. The gelada has a similar social structure in which many smaller groups come together to form temporary herds of up to 600 monkeys.
These social systems are affected by three main ecological factors: distribution of resources, group size, and predation. Within a social group there is a balance between cooperation and competition. Cooperative behaviors include social grooming (removing skin parasites and cleaning wounds), food sharing, and collective defense against predators or of a territory. Aggressive behaviors often signal competition for food, sleeping sites or mates. Aggression is also used in establishing dominance hierarchies.
Interspecific associations.
Several species of primates are known to associate in the wild. Some of these associations have been extensively studied. In the Tai Forest of Africa several species coordinate anti-predator behavior. These include the Diana monkey, Campbell's mona monkey, lesser spot-nosed monkey, western red colobus, king colobus and sooty mangabey, which coordinate anti-predator alarm calls. Among the predators of these monkeys is the common chimpanzee.
The red-tailed monkey associates with several species, including the western red colobus, blue monkey, Wolf's mona monkey, mantled guereza, black crested mangabey and Allen's swamp monkey. Several of these species are preyed upon by the common chimpanzee.
In South America, squirrel monkeys associate with capuchin monkeys. This may have more to do with foraging benefits to the squirrel monkeys than anti-predation benefits.
Cognition and communication.
Primates have advanced cognitive abilities: some make tools and use them to acquire food and for social displays; some have sophisticated hunting strategies requiring cooperation, influence and rank; they are status conscious, manipulative and capable of deception; they can recognise kin and conspecifics; and they can learn to use symbols and understand aspects of human language including some relational syntax and concepts of number and numerical sequence. Research in primate cognition explores problem solving, memory, social interaction, a theory of mind, and numerical, spatial, and abstract concepts. Comparative studies show a trend towards higher intelligence going from prosimians to New World monkeys to Old World monkeys, and significantly higher average cognitive abilities in the great apes. However, there is a great deal of variation in each group (e.g., among New World monkeys, both spider and capuchin monkeys have scored highly by some measures), as well as in the results of different studies.
Lemurs, lorises, tarsiers, and New World monkeys rely on olfactory signals for many aspects of social and reproductive behavior. Specialized glands are used to mark territories with pheromones, which are detected by the vomeronasal organ; this process forms a large part of the communication behavior of these primates. In Old World monkeys and apes this ability is mostly vestigial, having regressed as trichromatic eyes evolved to become the main sensory organ. Primates also use vocalizations, gestures, and facial expressions to convey psychological state. The Philippine tarsier, has a high-frequency limit of auditory sensitivity of approximately 91 kHz with a dominant frequency of 70 kHz. Such values are among the highest recorded for any terrestrial mammal, and a relatively extreme example of ultrasonic communication. For Philippine tarsiers, ultrasonic vocalizations might represent a private channel of communication that subverts detection by predators, prey and competitors, enhances energetic efficiency, or improves detection against low-frequency background noise.
Life history.
Primates have slower rates of development than other mammals. All primate infants are breastfed by their mothers (with the exception of some human cultures and various zoo raised primates which are fed formula) and rely on them for grooming and transportation. In some species, infants are protected and transported by males in the group, particularly males who may be their fathers. Other relatives of the infant, such as siblings and aunts, may participate in its care as well. Most primate mothers cease ovulation while breastfeeding an infant; once the infant is weaned the mother can reproduce again. This often leads to weaning conflict with infants who attempt to continue breastfeeding.
Infanticide is common in polygynous species such as gray langurs and gorillas. Adult males may kill dependent offspring that are not theirs so the female will return to estrus and thus they can sire offspring of their own. Social monogamy in some species may have evolved to combat this behavior. Promiscuity may also lessen the risk of infanticide since paternity becomes uncertain.
Primates have a longer juvenile period between weaning and sexual maturity than other mammals of similar size. Some primates such as galagos and new world monkeys use tree-holes for nesting, and park juveniles in leafy patches while foraging. Other primates follow a strategy of "riding", i,e. carrying individuals on the body while feeding. Adults may construct and/or use nesting sites, sometimes accompanied by juveniles, for the purpose of resting, a behavior which has developed secondarily in the great apes. 
During the juvenile period, primates are more susceptible than adults to predation and starvation; they gain experience in feeding and avoiding predators during this time. They learn social and fighting skills, often through playing. Primates, especially females, have longer lifespans than other similarly sized mammals, this may be partially due to their slower metabolisms. Late in life, female catarrhine primates appear to undergo a cessation of reproductive function known as menopause; other groups are less studied.
Diet, feeding and hunting.
Primates exploit a variety of food sources. It has been said that many characteristics of modern primates, including humans, derive from an early ancestor's practice of taking most of its food from the tropical canopy. Most primates include fruit in their diets to obtain easily digested carbohydrates and lipids for energy. However, they require other foods, such as leaves or insects, for amino acids, vitamins and minerals. Primates in the suborder Strepsirrhini (non-tarsier prosimians) are able to synthesize vitamin C, like most other mammals, while primates of the suborder Haplorrhini (tarsiers, monkeys and apes) have lost this ability, and require the vitamin in their diet.
Many primates have anatomical specializations that enable them to exploit particular foods, such as fruit, leaves, gum or insects. For example, leaf eaters such as howler monkeys, black-and-white colobuses and sportive lemurs have extended digestive tracts which enable them to absorb nutrients from leaves that can be difficult to digest. Marmosets, which are gum eaters, have strong incisor teeth, enabling them to open tree bark to get to the gum, and claws rather than nails, enabling them to cling to trees while feeding. The aye-aye combines rodent-like teeth with a long, thin middle finger to fill the same ecological niche as a woodpecker. It taps on trees to find insect larvae, then gnaws holes in the wood and inserts its elongated middle finger to pull the larvae out. Some species have additional specializations. For example, the grey-cheeked mangabey has thick enamel on its teeth, enabling it to open hard fruits and seeds that other monkeys cannot. The gelada is the only primate species that feeds primarily on grass.
Hunting.
Tarsiers are the only extant obligate carnivorous primates, exclusively eating insects, crustaceans, small vertebrates and snakes (including venomous species). Capuchin monkeys can exploit many different types of plant matter, including fruit, leaves, flowers, buds, nectar and seeds, but also eat insects and other invertebrates, bird eggs, and small vertebrates such as birds, lizards, squirrels and bats.
The common chimpanzee has a varied diet that includes predation on other primate species, such as the western red colobus monkey. This sometimes involves tool use. Common chimpanzees sharpen sticks to use as weapons when hunting mammals. This is considered the first evidence of systematic use of weapons in a species other than humans. Researchers documented 22 occasions where wild chimpanzees fashioned sticks into "spears" to hunt lesser bush babies ("Galago senegalensis"). In each case, a chimpanzee modified a branch by breaking off one or both ends and, frequently using its teeth, sharpened the stick. The tools, on average, were about 60 cm (24 in) long and 1.1 cm (0.4 in) in circumference. The chimpanzees then jabbed their spears into hollows in tree trunks where bush babies slept. There was a single case in which a chimpanzee successfully extracted a bush baby with the tool. The bonobo is an omnivorous frugivore - the majority of its diet is fruit, but it supplements this with leaves, meat from small vertebrates, such as anomalures, flying squirrels and duikers, and invertebrates. In some instances, bonobos have been shown to consume lower-order primates.
As prey.
Predators of primates include various species of carnivorans, birds of prey, reptiles and other primates. Even gorillas have been recorded as prey. Predators of primates have diverse hunting strategies and as such, primates have evolved several different antipredator adaptations including crypsis, alarm calls and mobbing. Several species have separate alarm calls for different predators such as air-borne or ground-dwelling predators. Predation may have shaped group size in primates as species exposed to higher predation pressures appear to live in larger groups. With their technology and increased intelligence, modern humans are nearly free of threats from predators and are themselves apex predators.
Tool use and manufacture.
Tool use.
There are many reports of non-human primates using tools, both in the wild or when captive. The use of tools by primates is varied and includes hunting (mammals, invertebrates, fish), collecting honey, processing food (nuts, fruits, vegetables and seeds), collecting water, weapons and shelter.
In 1960, Jane Goodall observed a chimpanzee poking pieces of grass into a termite mound and then raising the grass to his mouth. After he left, Goodall approached the mound and repeated the behaviour because she was unsure what the chimpanzee was doing. She found that the termites bit onto the grass with their jaws. The chimpanzee had been using the grass as a tool to “fish” or "dip" for termites. There are more limited reports of the closely related bonobo using tools in the wild; it has been claimed they rarely use tools in the wild although they use tools as readily as chimpanzees when in captivity, It has been reported that both female chimpanzees and bonobos use tools more avidly than males. Orangutans in Borneo scoop catfish out of small ponds. Anthropologist Anne Russon saw several animals on these forested islands learn on their own to jab at catfish with sticks, so that the panicked prey would flop out of ponds and into the orangutan's waiting hands There are few reports of gorillas using tools in the wild. An adult female western lowland gorilla used a branch as a walking stick apparently to test water depth and to aid her in crossing a pool of water. Another adult female used a detached trunk from a small shrub as a stabilizer during food gathering, and another used a log as a bridge.
The black-striped capuchin was the first non-ape primate for which tool use was documented in the wild; individuals were observed cracking nuts by placing them on a stone anvil and hitting them with another large stone. In Thailand and Myanmar, crab-eating macaques use stone tools to open nuts, oysters and other bivalves, and various types of sea snails. Chacma baboons use stones as weapons; stoning by these baboons is done from the rocky walls of the canyon where they sleep and retreat to when they are threatened. Stones are lifted with one hand and dropped over the side whereupon they tumble down the side of the cliff or fall directly to the canyon floor.
Although they have not been observed to use tools in the wild, lemurs in controlled settings have been shown to be capable of understanding the functional properties of the objects they had been trained to use as tools, performing as well as tool-using haplorhines.
Tool manufacture.
Tool manufacture is much rarer than simple tool use and probably represents higher cognitive functioning. Soon after her initial discovery of tool use, Goodall observed other chimpanzees picking up leafy twigs, stripping off the leaves and using the stems to fish for insects. This change of a leafy twig into a tool was a major discovery. Prior to this, scientists thought that only humans manufactured and used tools, and that this ability was what separated humans from other animals. Both bonobos and chimpanzees have also been observed making "sponges" out of leaves and moss that suck up water and are used as grooming tools. Sumatran orangutans have been observed making and using tools. They will break off a tree branch that is about 30 cm long, snap off the twigs, fray one end and then use the stick to dig in tree holes for termites. In the wild, mandrills have been observed to clean their ears with modified tools. Scientists filmed a large male mandrill at Chester Zoo (UK) stripping down a twig, apparently to make it narrower, and then using the modified stick to scrape dirt from underneath its toenails. Captive gorillas have made a variety of tools.
Habitat and distribution.
Primates evolved from arboreal animals, and many species live most of their lives in trees. Most primate species live in tropical rain forests. The number of primate species within tropical areas has been shown to be positively correlated to the amount of rainfall and the amount of rain forest area. Accounting for 25% to 40% of the fruit-eating animals (by weight) within tropical rainforests, primates play an important ecological role by dispersing seeds of many tree species.
Some species are partially terrestrial, such as baboons and patas monkeys, and a few species are fully terrestrial, such as geladas and humans. Non-human primates live in a diverse number of forested habitats in the tropical latitudes of Africa, India, Southeast Asia, and South America, including rainforests, mangrove forests, and montane forests. There are some examples of non-human primates that live outside of the tropics; the mountain-dwelling Japanese macaque lives in the north of Honshū where there is snow-cover eight months of the year; the Barbary macaque lives in the Atlas Mountains of Algeria and Morocco. Primate habitats span a range of altitudes: the black snub-nosed monkey has been found living in the Hengduan Mountains at altitudes of 4,700 meters (15,400 ft), the mountain gorilla can be found at 4,200 meters (13,200 ft) crossing the Virunga Mountains, and the gelada has been found at elevations of up to in the Ethiopian Highlands. Although most species are generally shy of water, a few are good swimmers and are comfortable in swamps and watery areas, including the proboscis monkey, De Brazza's monkey and Allen's swamp monkey, which has developed small webbing between its fingers. Some primates, such as the rhesus macaque and gray langurs, can exploit human-modified environments and even live in cities.
Interactions between humans and other primates.
Close interactions between humans and non-human primates (NHPs) can create pathways for the transmission of zoonotic diseases. Viruses such as "Herpesviridae" (most notably Herpes B Virus), "Poxviridae", measles, ebola, rabies, the Marburg virus and viral hepatitis can be transmitted to humans; in some cases the viruses produce potentially fatal diseases in both humans and non-human primates.
Legal and social status.
Only humans are recognized as persons and protected in law by the United Nations Universal Declaration of Human Rights. The legal status of NHPs, on the other hand, is the subject of much debate, with organizations such as the Great Ape Project (GAP) campaigning to award at least some of them legal rights. In June 2008, Spain became the first country in the world to recognize the rights of some NHPs, when its parliament's cross-party environmental committee urged the country to comply with GAP's recommendations, which are that chimpanzees, bonobos, orangutans, and gorillas are not be used for animal experiments.
Many species of NHP are kept as pets by humans, the Allied Effort to Save Other Primates (AESOP) estimates that around 15,000 NHPs live as exotic pets in the United States. The expanding Chinese middle class has increased demand for NHPs as exotic pets in recent years. Although NHP import for the pet trade was banned in the U.S. in 1975, smuggling still occurs along the United States – Mexico border, with prices ranging from US$3000 for monkeys to $30,000 for apes.
Primates are used as model organisms in laboratories and have been used in space missions. They serve as service animals for disabled humans. Capuchin monkeys can be trained to assist quadriplegic humans; their intelligence, memory, and manual dexterity make them ideal helpers.
NHPs are kept in zoos around the globe. Historically, zoos were primarily a form of entertainment, but more recently have shifted their focus towards conservation, education and research. GAP does not insist that all NHPs should be released from zoos, primarily because captive-born primates lack the knowledge and experience to survive in the wild if released.
Role in scientific research.
Thousands of non-human primates are used around the world in research because of their psychological and physiological similarity to humans. In particular, the brains and eyes of NHPs more closely parallel human anatomy than those of any other animals. NHPs are commonly used in preclinical trials, neuroscience, ophthalmology studies, and toxicity studies. Rhesus macaques are often used, as are other macaques, African green monkeys, chimpanzees, baboons, squirrel monkeys, and marmosets, both wild-caught and purpose-bred. In 2005, GAP reported that 1,280 of the 3,100 NHPs living in captivity in the United States were used for experiments. In 2004, the European Union used around 10,000 NHPs in such experiments; in 2005 in Great Britain, 4,652 experiments were conducted on 3,115 NHPs. Governments of many nations have strict care requirements of NHPs kept in captivity. In the US, federal guidelines extensively regulate aspects of NHP housing, feeding, enrichment, and breeding. European groups such as the European Coalition to End Animal Experiments are seeking a ban on all NHP use in experiments as part of the European Union's review of animal testing legislation.
Conservation.
The International Union for Conservation of Nature (IUCN) lists more than a third of primates as critically endangered or vulnerable. Trade is regulated, as all species are listed by CITES in Appendix II, except 50 species and subspecies listed in Appendix I, which gain full protection from trade. Common threats to primate species include deforestation, forest fragmentation, monkey drives (resulting from primate crop raiding), and primate hunting for use in medicines, as pets, and for food. Large-scale tropical forest clearing is widely regarded as the process that most threatens primates. More than 90% of primate species occur in tropical forests. The main cause of forest loss is clearing for agriculture, although commercial logging, subsistence harvesting of timber, mining, and dam construction also contribute to tropical forest destruction. In Indonesia large areas of lowland forest have been cleared to increase palm oil production, and one analysis of satellite imagery concluded that during 1998 and 1999 there was a loss of 1,000 Sumatran orangutans per year in the Leuser Ecosystem alone.
Primates with a large body size (over 5 kg) are at increased extinction risk due to their greater profitability to poachers compared to smaller primates. They reach sexual maturity later and have a longer period between births. Populations therefore recover more slowly after being depleted by poaching or the pet trade. Data for some African cities show that half of all protein consumed in urban areas comes from the bushmeat trade. Endangered primates such as guenons and the drill are hunted at levels that far exceed sustainable levels. This is due to their large body size, ease of transport and profitability per animal. As farming encroaches on forest habitats, primates feed on the crops, causing the farmers large economic losses. Primate crop raiding gives locals a negative impression of primates, hindering conservation efforts.
Madagascar, home to five endemic primate families, has experienced the greatest extinction of the recent past; since human settlement 1,500 years ago, at least eight classes and fifteen of the larger species have become extinct due to hunting and habitat destruction. Among the primates wiped out were "Archaeoindris" (a lemur larger than a silverback gorilla) and the families Palaeopropithecidae and Archaeolemuridae.
In Asia, Hinduism, Buddhism, and Islam prohibit eating primate meat; however, primates are still hunted for food. Some smaller traditional religions allow the consumption of primate meat. The pet trade and traditional medicine also increase demand for illegal hunting. The rhesus macaque, a model organism, was protected after excessive trapping threatened its numbers in the 1960s; the program was so effective that they are now viewed as a pest throughout their range.
In Central and South America forest fragmentation and hunting are the two main problems for primates. Large tracts of forest are now rare in Central America. This increases the amount of forest vulnerable to edge effects such as farmland encroachment, lower levels of humidity and a change in plant life. Movement restriction results in a greater amount of inbreeding, which can cause deleterious effects leading to a population bottleneck, whereby a significant percentage of the population is lost.
There are 21 critically endangered primates, 7 of which have remained on the IUCN's "The World's 25 Most Endangered Primates" list since the year 2000: the silky sifaka, Delacour's langur, the white-headed langur, the gray-shanked douc, the Tonkin snub-nosed monkey, the Cross River gorilla and the Sumatran orangutan. Miss Waldron's red colobus was recently declared extinct when no trace of the subspecies could be found from 1993 to 1999. A few hunters have found and killed individuals since then, but the subspecies' prospects remain bleak.

</doc>
<doc id="22986" url="https://en.wikipedia.org/wiki?curid=22986" title="Politics">
Politics

Politics (from , definition "of, for, or relating to citizens") is the practice and theory of influencing other people. Politics involves the making of a common decision for a group of people, that is, a uniform decision applying in the same way to all members of the group. It also involves the use of power by one person to affect the behavior of another person. More narrowly, it refers to achieving and exercising positions of governance — organized control over a human community, particularly a state. Furthermore, politics is the study or practice of the distribution of power and resources within a given community (a usually hierarchically organized population) as well as the interrelationship(s) between communities.
A variety of methods are employed in politics, which include promoting or forcing one's own political views among people, negotiation with other political subjects, making laws, and exercising force, including warfare against adversaries. Politics is exercised on a wide range of social levels, from clans and tribes of traditional societies, through modern local governments, companies and institutions up to sovereign states, to the international level.
It is very often said that politics is about power. A political system is a framework which defines acceptable political methods within a given society. History of political thought can be traced back to early antiquity, with seminal works such as Plato's "Republic", Aristotle's "Politics" and the works of Confucius.
Formal Politics refers to the operation of a constitutional system of government and publicly defined institutions and procedures. Political parties, public policy or discussions about war and foreign affairs would fall under the category of Formal Politics. Many people view formal politics as something outside of themselves, but that can still affect their daily lives.
Informal Politics is understood as forming alliances, exercising power and protecting and advancing particular ideas or goals. Generally, this includes anything affecting one's daily life, such as the way an office or household is managed, or how one person or group exercises influence over another. Informal Politics is typically understood as everyday politics, hence the idea that "politics is everywhere".
Etymology.
The word comes from the Greek word from which the title of Aristotle's books Politics ("politika") derives: "affairs of the cities", a dissertation on governing and governments, which was rendered in English in the mid-15th century as Latinized "Polettiques". Thus it became "politics" in Middle English . The singular "politic" first attested in English 1430 and comes from Middle French "politique", in turn from Latin "politicus", which is the Latinization of the Greek πολιτικός ("politikos"), meaning amongst others "of, for, or relating to citizens", "civil", "civic", "belonging to the state", in turn from πολίτης ("polites"), "citizen" and that from πόλις ("polis"), "city".
History of state politics.
The history of politics is reflected in the origin, development, and economics of the institutions of government.
The state.
The origin of the state is to be found in the development of the art of warfare. Historically speaking, all political communities of the modern type owe their existence to successful warfare.
Kings, emperors and other types of monarchs in many countries including China and Japan, were considered divine. Of the institutions that ruled states, that of kingship stood at the forefront until the French Revolution put an end to the "divine right of kings". Nevertheless, the monarchy is among the longest-lasting political institutions, dating as early as 2100 BC in Sumeria to the 21st century AD British Monarchy. Kingship becomes an institution through heredity.
The king often, even in absolute monarchies, ruled his kingdom with the aid of an elite group of advisors, a council without which he could not maintain power. As these advisors and others outside the monarchy negotiated for power, constitutional monarchies emerged, which may be considered the germ of constitutional government. Long before the council became a bulwark of democracy, it rendered invaluable aid to the institution of kingship by:
The greatest of the king's subordinates, the earls and dukes in England and Scotland, the dukes and counts in the Continent, always sat as a right on the council. A conqueror wages war upon the vanquished for vengeance or for plunder but an established kingdom exacts tribute. One of the functions of the council is to keep the coffers of the king full. Another is the satisfaction of military service and the establishment of lordships by the king to satisfy the task of collecting taxes and soldiers.
The state and property.
Property is the right vested on the individual or a group of people to enjoy the benefits of an object, be it material or intellectual. A right is a power enforced by public trust. Sometimes it happens that the exercise of a right is opposed to public trust. Nevertheless, a right is really an institution brought around by public trust, past, present or future. The growth of knowledge is the key to the history of property as an institution. The more man becomes knowledgeable of an object, be it physical or intellectual, the more it is appropriated. The appearance of the State brought about the final stage in the evolution of property from wildlife to husbandry. In the presence of the State, man can hold landed property. The State began granting lordships and ended up conferring property and with it came inheritance. With landed property came rent and in the exchange of goods, profit, so that in modern times, the "lord of the land" of long ago becomes the landlord. If it is, wrongly, assumed that the value of land is always the same, then there is no evolution of property whatsoever. However, the price of land goes up with every increase in something benefiting the landlord. The landlordism of large land owners has been the most rewarded of all political services. In industry, the position of the landlord is less important but in towns which have grown out of an industry, the fortunate landlord has reaped an enormous profit. Towards the latter part of the Middle Ages in Europe, both the State - the State would use the instrument of confiscation for the first time to satisfy a debt - and the Church - the Church succeeded in acquiring immense quantities of land - were allied against the village community to displace the small landlord and they were successful to the extent that today, the village has become the ideal of the individualist, a place in which every man "does what he wills with his own." The State has been the most important factor in the evolution of the institution of property be it public or private.
The state and the justice system.
As a primarily military institution, the State is concerned with the allegiance of its subjects, viewing disloyalty and espionage as well as other sorts of conspiracies as detrimental to its national security. Thus arises the law of treason. Criminal acts in general, breaking the peace and treason make up the whole, or at least part of criminal law enforced by the State as distinguished from the law enforced by private individuals or by the state on behalf of private individuals. State justice has taken the place of clan, feudal, merchant and ecclesiastical justice due to its strength, skill and simplicity. One very striking evidence of the superiority of the royal courts over the feudal and popular courts in the matter of official skill is the fact that, until comparatively late in history, the royal courts alone kept written records of their proceedings. The trial by jury was adopted by the Royal Courts, securing its popularity and making it a bulwark of liberty. By the time of the Protestant Reformation, with the separation of Church and State, in the most progressive countries, the State succeeded in dealing with the business of administering justice. Federalism shared power between states and federal government constituting a balance of powers between the Legislative, Executive, and Judicial branches.
The state and legislation.
The making of laws was unknown to primitive societies.
That most persistent of all patriarchal societies, the Jewish, retains to a certain extent its tribal law in the Gentile cities of the West. This tribal law is the rudimentary idea of law as it presented itself to people in the patriarchal stage of society; it was custom or observance sanctioned by the approval and practice of ancestors.
The state of affairs which existed in the 10th century, when every town had its own laws and nations like France, Germany, Spain and other countries had no national law until the end of the 18th century, was brought to an end by three great agencies that helped to create the modern system of law and legislation:
Finally there is the enactment of laws or legislation. When progress and development is rapid, the faster method of political representation is adopted. This method does not originate in primitive society but in the State's need for money and its use of an assembly to raise the same. From the town assembly, a national assembly and the progress of commerce sprang parliaments all over Europe around the end of the 12th century, but not entirely representative or homogeneous for the nobility and the clergy. The clergy had amassed a fortune in land, about one-fifth of all Christendom but at the time, in the 12th and 13th centuries, the Church was following a policy of isolation; they adopted the rule of celibacy and cut themselves from domestic life; they refused to plead in a secular court; they refused to pay taxes to the State on the grounds that they had already paid it to the Pope. Since the main object of the king in holding a national assembly was to collect money, the Church could not be left out and so they came to Parliament. The Church did not like it but in most cases they had to come.
The medieval Parliament was complete when it represented all the states in the realm: nobles, clergy, peasants and craftsmen but it was not a popular institution mainly because it meant taxation. Only by the strongest pressure of the Crown were Parliaments maintained during the first century of their existence and the best proof of this assertion lies in the fact that in those countries where the Crown was weak, Parliament ceased to exist. The notion that parliaments were the result of a democratic movement cannot be supported by historical facts. Originally, the representative side of Parliament was solely concerned with money; representation in Parliament was a liability rather than a privilege. It is not uncommon that an institution created for one purpose begins to serve another. People who were asked to contribute with large sums of money began to petition. Pretty soon, sessions in Parliament would turn into bargaining tables, the king granting petitions in exchange for money. However, there were two kinds of petitions, one private and the other public and it was from this last that laws were adopted or legislation originated. The king as head of State could give orders to preserve territorial integrity but not until these royal enactments were combined with public petition that successful legislation ever took place. Even to the present day, this has always been the basis of all successful legislation: public custom is adopted and enforced by the State.
In the early days of political representation, the majority did not necessarily carry the day and there was very little need for contested elections but by the beginning of the 15th century, a seat in Parliament was something to be cherished. Historically speaking, the dogma of the equality of man is the result of the adoption of the purely practical machinery of the majority, but the adoption of the majority principle is also responsible for another institution of modern times: the party system. The party system is an elaborate piece of machinery that pits at least two political candidates against each other for the vote of an electorate; its advantage being equal representation interesting a large number of people in politics; it provides effective criticism of the government in power and it affords an outlet for the ambition of a large number of wealthy and educated people guaranteeing a consistent policy in a state.
These three institutions: political representation, majority rule and the party system are the basic components of modern political machinery; they are applicable to both central and local governments and are becoming by their adaptability ends in themselves rather than machinery to achieve some purpose.
The state and the executive system.
The administration is one of the most difficult aspects of government. In the enactment and enforcement of laws, the victory of the State is complete but not so in regards to administration – the reason being that it is easy to see the advantage of the enactment and enforcement of laws but not the administration of domestic, religious and business affairs which should be kept to a minimum by government.
Originally, the state was a military institution. For many years, it was just a territory ruled by a king who was surrounded by a small elite group of warriors and court officials and it was basically rule by force over a larger mass of people. Slowly, however, the people gained political representation for none can really be said to be a member of the State without the right of having a voice in the direction of policy making. One of the basic functions of the State in regards to administration is maintaining peace and internal order; it has no other excuse for interfering in the lives of its citizens. To maintain law and order the State develops means of communication. Historically, the "king's highway" was laid down and maintained for the convenience of the royal armies not as an incentive to commerce. In almost all countries, the State maintains the control of the means of communication and special freedoms such as those delineated in the First Amendment to the United States Constitution are rather limited. The State's original function of maintaining law and order within its borders gave rise to police administration which is a branch of the dispensation of Justice but on its preventive side, police jurisdiction has a special character of its own, which distinguishes it from ordinary judicial work. In the curfew, the State shows early in history the importance of preventing disorder. In early days, next to maintaining law and order, the State was concerned with the raising of revenue. It was then useful to the State to establish a standard of weights and measures so that value could be generally accepted and finally the State acquired a monopoly of coinage. The regulation of labor by the State as one of its functions dates from the 15th century, when the Black Plague killed around half of the European population.
The invariable policy of the State has always been to break down all intermediate authorities and to deal directly with the individual. This was the policy until Adam Smith's "The Wealth of Nations" was published promoting a strong public reaction against State interference. By its own action, the State raised the issue of the poor or the State relief of the indigent. The State, of course, did not create poverty but by destroying the chief agencies which dealt with it such as the village, the church and the guilds, it practically assumed full responsibility for the poor without exercising any power over it. The Great Poor Law Report of 1834 showed that communism was widespread in the rural areas of England. In newly developed countries such as the colonies of the British Empire, the State has refused to take responsibility for the poor and the relief of poverty, although the poor classes lean heavily towards State socialism.
Taking into account the arguably significant powers of the State, it is only natural that in times of great crisis such as an overwhelming calamity the people should invoke general State aid.
Political representation has helped to shape State administration. When the voice of the individual can be heard, the danger of arbitrary interference by the State is greatly reduced. To that extent is the increase of State activity popular. There are no hard and fast rules to limit State administration but it is a fallacy to believe that the State is the nation and what the State does is necessarily for the good of the nation. In the first place, even in modern times, the State and the nation are never identical. Even where "universal suffrage" prevails, the fact remains that an extension of State administration means an increased interference of some by others, limiting freedom of action. Even if it is admitted that State and nation are one and the same, it is sometimes difficult to admit that State administration is necessarily good. Finally, the modern indiscriminate advocacy of State administration conceals the fallacy that State officials must necessarily prove more effective in their action than private enterprise. Herein lies the basic difference between public and business administration; the first deals with the public weal while the second deals basically in profit, but both require a great deal of education and ethical conduct to avoid the mishaps inherent in the relationship not only relating to business and labour but also the State and the people administrating its government.
Themes.
Forms of political organization.
There are many forms of political organization, including states, non-government organizations (NGOs) and international organizations such as the United Nations. States are perhaps the predominant institutional form of political governance, where a state is understood as an institution and a government is understood as the regime in power.
According to Aristotle, states are classified into monarchies, aristocracies, timocracies, democracies, oligarchies, and tyrannies. Due to changes across the history of politics, this classification has been abandoned. Generally speaking, no form of government could be considered the absolute best, as it would have to be the perfect form under all circumstances, for all people and in all ways. As an institution created by human nature to govern society, it is vulnerable to abuse by people for their own gain, no matter what form of government a state utilizes, thus suggesting there is no 'best' form of government.
All states are varieties of a single organizational form, the sovereign state. All the great powers of the modern world rule on the principle of sovereignty. Sovereign power may be vested on an individual as in an autocratic government or it may be vested on a group as in a constitutional government. Constitutions are written documents that specify and limit the powers of the different branches of government. Although a constitution is a written document, there is also an unwritten constitution. The unwritten constitution is continually being written by the legislative branch of government; this is just one of those cases in which the nature of the circumstances determines the form of government that is most appropriate. England did set the fashion of written constitutions during the Civil War but after the Restoration abandoned them to be taken up later by the American Colonies after their emancipation and then France after the Revolution and the rest of Europe including the European colonies.
There are many forms of government. One form is a strong central government as in France and China. Another form is local government, such as the ancient divisions in England that are comparatively weaker but less bureaucratic. These two forms helped to shape the practice of federal government, first in Switzerland, then in the United States in 1776, in Canada in 1867 and in Germany in 1870 and in the 20th century, Australia. Federal states introduced the new principle of agreement or contract. Compared to a federation, a confederation has a more dispersed system of judicial power. In the American Civil War, the contention of the Confederate States that a State could secede from the Union was untenable because of the power enjoyed by the Federal government in the executive, legislative and judiciary branches.
According to professor A. V. Dicey in "An Introduction to the Study of the Law of the Constitution", the essential features of a federal constitution are: a) A written supreme constitution in order to prevent disputes between the jurisdictions of the Federal and State authorities; b) A distribution of power between the Federal and State governments and c) A Supreme Court vested with the power to interpret the Constitution and enforce the law of the land remaining independent of both the executive and legislative branches.
Global politics.
Global politics include different practices of political globalization in relation to questions of social power: from global patterns of governance to issues of globalizing conflict. The 20th century witnessed the outcome of two world wars and not only the rise and fall of the Third Reich but also the rise and fall of communism. The development of the atomic bomb gave the United States a more rapid end to its conflict in Japan in World War II. Later, the development of the hydrogen bomb became the ultimate weapon of mass destruction.
Global politics also concerns the rise of global and international organizations. The United Nations has served as a forum for peace in a world threatened by nuclear war, "The invention of nuclear and space weapons has made war unacceptable as an instrument for achieving political ends." Although an all-out final nuclear holocaust is out of the question for man, "nuclear blackmail" comes into question not only on the issue of world peace but also on the issue of national sovereignty. On a Sunday in 1962, the world stood still at the brink of nuclear war during the October Cuban Missile Crisis from the implementation of U.S. vs U.S.S.R. nuclear blackmail policy.
According to political science professor Paul James, global politics is affected by "values": norms of human rights, ideas of human development, and beliefs such as cosmopolitanism about how we should relate to each:
Political corruption.
William Pitt the Elder, speaking before the British House of Lords, 9 January 1770, observed: "Unlimited power is apt to corrupt the minds of those who possess it." This was echoed more famously by John Dalberg-Acton over a century later: "Power tends to corrupt, and absolute power corrupts absolutely."
Political corruption is the use of legislated powers by government officials for illegitimate private gain. Misuse of government power for other purposes, such as repression of political opponents and general police brutality, is not considered political corruption. Neither are illegal acts by private persons or corporations not directly involved with the government. An illegal act by an officeholder constitutes political corruption only if the act is directly related to their official duties and/or power.
Forms of corruption vary, but include corruption, extortion, cronyism, nepotism, patronage, graft, and embezzlement. While corruption may facilitate criminal enterprise such as drug trafficking, money laundering, and trafficking, it is not restricted to these activities. The activities that constitute illegal corruption differ depending on the country or jurisdiction. For instance, certain political funding practices that are legal in one place may be illegal in another. In some cases, government officials have broad or poorly defined powers, which make it difficult to distinguish between legal and illegal actions. Worldwide, bribery alone is estimated to involve over 1 trillion US dollars annually. A state of unrestrained political corruption is known as a kleptocracy, literally meaning "rule by thieves".
Political parties.
A political party is a political organization that typically seeks to attain and maintain political power within government, usually by participating in electoral campaigns, educational outreach or protest actions. Parties often espouse an expressed ideology or vision bolstered by a written platform with specific goals, forming a coalition among disparate interests.
Politics as an academic discipline.
Political science, the study of politics, examines the acquisition and application of power. Political scientist Harold Lasswell defined politics as "who gets what, when, and how". Related areas of study include political philosophy, which seeks a rationale for politics and an ethic of public behaviour, political economy, which attempts to develop understandings of the relationships between politics and the economy and the governance of the two, and public administration, which examines the practices of governance. The philosopher Charles Blattberg, who has defined politics as "responding to conflict with dialogue," offers an account which distinguishes political philosophies from political ideologies.
The first academic chair devoted to politics in the United States was the chair of history and political science at Columbia University, first occupied by Prussian émigré Francis Lieber in 1857.
Political values.
Several different political spectrums have been proposed.
Left–right politics.
Political analysts and politicians divide politics into left wing and right wing politics, often also using the idea of center politics as a middle path of policy between the right and left. This classification is comparatively recent (it was not used by Aristotle or Hobbes, for instance), and dates from the French Revolution era, when those members of the National Assembly who supported the republic, the common people and a secular society sat on the left and supporters of the monarchy, aristocratic privilege and the Church sat on the right.
The meanings behind the labels have become more complicated over the years. A particularly influential event was the publication of the Communist Manifesto by Karl Marx and Frederick Engels in 1848. The "Manifesto" suggested a course of action for a proletarian revolution to overthrow the bourgeois society and abolish private property, in the belief that this would lead to a classless and stateless society.
The meaning of left-wing and right-wing varies considerably between different countries and at different times, but generally speaking, it can be said that the right wing often values tradition and social stratification while the left wing often values reform and egalitarianism, with the center seeking a balance between the two such as with social democracy or regulated capitalism.
According to Norberto Bobbio, one of the major exponents of this distinction, the Left believes in attempting to eradicate social inequality, while the Right regards most social inequality as the result of ineradicable natural inequalities, and sees attempts to enforce social equality as utopian or authoritarian.
Some ideologies, notably Christian Democracy, claim to combine left and right wing politics; according to Geoffrey K. Roberts and Patricia Hogwood, "In terms of ideology, Christian Democracy has incorporated many of the views held by liberals, conservatives and socialists within a wider framework of moral and Christian principles." Movements which claim or formerly claimed to be above the left-right divide include Fascist Terza Posizione economic politics in Italy, Gaullism in France, Peronism in Argentina, and National Action Party in Mexico.
Authoritarian–libertarian politics.
Authoritarianism and libertarianism refer to the amount of individual freedom each person possesses in that society relative to the state. One author describes authoritarian political systems as those where "individual rights and goals are subjugated to group goals, expectations and conformities", while libertarians generally oppose the state and hold the individual as sovereign. In their purest form, libertarians are anarchists, who argue for the total abolition of the state, of political parties and of other political entities, while the purest authoritarians are, theoretically, totalitarians who support state control over all aspects of society.
For instance, classical liberalism (also known as "laissez-faire liberalism", ) is a doctrine stressing individual freedom and limited government. This includes the importance of human rationality, individual property rights, free markets, natural rights, the protection of civil liberties, constitutional limitation of government, and individual freedom from restraint as exemplified in the writings of John Locke, Adam Smith, David Hume, David Ricardo, Voltaire, Montesquieu and others. According to the libertarian Institute for Humane Studies, "the libertarian, or 'classical liberal,' perspective is that individual well-being, prosperity, and social harmony are fostered by 'as much liberty as possible' and 'as little government as necessary.'"
For anarchist political philosopher L. Susan Brown "Liberalism and anarchism are two political philosophies that are fundamentally concerned with individual freedom yet differ from one another in very distinct ways. Anarchism shares with liberalism a radical commitment to individual freedom while rejecting liberalism's competitive property relations."

</doc>
<doc id="22989" url="https://en.wikipedia.org/wiki?curid=22989" title="Paris">
Paris

Paris ( ; ; ) is the capital and most populous city of France. Situated on the Seine River, in the north of the country, it is in the centre of the Île-de-France region, also known as the "région parisienne", "Paris Region". The City of Paris has an area of 105 km² (41 mi²) and a population of 2,240,621 (Jan. 2012 census) within its administrative borders essentially unchanged since 1860. Since the 19th century, the built-up area of Paris has grown largely beyond its administrative borders: together with its suburbs and exurbs, the Paris metropolitan area has a population of 12,341,418 (Jan. 2012 census), or 18.9% of the population of France. The administrative Paris Region covers 12,012 km² (4,638 mi²), and has its own regional council and president. It had a population of 12,005,077 as of January 2014 estimates.
Paris was founded in the 3rd century BC by a Celtic people called the Parisii, who gave the city its name. By the 12th century, Paris was the largest city in the western world, a prosperous trading centre, and the home of the University of Paris, one of the first in Europe. In the 18th century, it was the centre stage for the French Revolution, and became an important centre of finance, commerce, fashion, science, and the arts, a position it still retains today.
The Paris Region had a GDP of €624 billion (US $687 billion) in 2012, accounting for 30.0 percent of the GDP of France, and ranking it as one of the wealthiest five regions in Europe; it is the banking and financial centre of France, and contains the headquarters of 29 of the 31 companies in France ranked in the 2015 Fortune Global 500.
Paris is the home of the most visited art museum in the world, the Louvre, as well as the Musée d'Orsay, noted for its collection of French Impressionist art, and the Musée National d'Art Moderne, a museum of modern and contemporary art. The notable architectural landmarks of Paris include Notre Dame Cathedral (12th century); the Sainte-Chapelle (13th century); the Eiffel Tower (1889); and the Basilica of Sacré-Cœur on Montmartre (1914). In 2014 Paris received 22.4 million visitors, making it one of the world's top tourist destinations. Paris is also known for its fashion, particularly the twice-yearly Paris Fashion Week, and for its "haute cuisine", and three-star restaurants. Most of France's major universities and "grandes écoles" are located in Paris, as are France's major newspapers, including "Le Monde", "Le Figaro", and "Libération".
Paris is home to the association football club Paris Saint-Germain and the rugby union club Stade Français. The 80,000-seat Stade de France, built for the 1998 FIFA World Cup, is located just north of Paris in the commune of Saint-Denis. Paris hosts the annual French Open Grand Slam tennis tournament on the red clay of Roland Garros. Paris played host to the 1900 and 1924 Summer Olympics, the 1938 and 1998 FIFA World Cups, and the 2007 Rugby World Cup.
The city is a major rail, highway, and air-transport hub, served by the two international airports Paris-Charles de Gaulle and Paris-Orly. Opened in 1900, the city's subway system, the Paris Métro, serves 4.5 million passengers daily. Paris is the hub of the national road network, and is surrounded by three orbital roads: the Périphérique, the A86 motorway, and the Francilienne motorway in the outer suburbs.
History.
Etymology.
The name "Paris" is derived from its early inhabitants, the Celtic Parisii tribe.
Paris is often referred to as "The City of Light" ("La Ville Lumière"), both because of its leading role during the Age of Enlightenment, and more literally because Paris was one of the first European cities to adopt gas street lighting. In the 1860s, the boulevards and streets of Paris were illuminated by 56,000 gas lamps. Since the late 19th century, Paris is also known as "Panam(e)" () in French slang.
Inhabitants are known in English as "Parisians" and in French as "Parisiens" (), pejoratively also called "Parigots" ().
Origins.
The "Parisii", a sub-tribe of the Celtic Senones, inhabited the Paris area from around the middle of the 3rd century BC. One of the area's major north-south trade routes crossed the Seine on the île de la Cité; this meeting place of land and water trade routes gradually became a town and an important trading centre. The Parisii traded with many river towns as far away as the Iberian Peninsula, and minted their own coins for that purpose.
The Romans conquered the Paris basin in 52 BC and, after making the island a garrison camp, began extending their settlement in a more permanent way to Paris's Left Bank. The Gallo-Roman town was originally called Lutetia (more fully, "Lutetia Parisiorum", "Lutetia of the Parisii"). It became a prosperous city with a forum, baths, temples, theatres, and an amphitheatre.
By the end of the Western Roman Empire, the town was known simply as "Parisius" in Latin and "Paris" in French. Christianity was introduced in the middle of the 3rd century AD. According to tradition, it was brought by Saint Denis, the first Bishop of Paris. When he refused to renounce his faith, he was beheaded on the hill which became known as the "Mountain of Martyrs" ("Mons Martyrum"), eventually "Montmartre". His burial place became an important religious shrine; the Basilica of Saint-Denis was built there and became the burial place of the French Kings.
Clovis the Frank, the first king of the Merovingian dynasty, made the city his capital from 508.
Fortification of the Île-de-France failed to prevent sacking by Vikings in 845 but Paris's strategic importance—with its bridges preventing ships from passing—was established by successful defence in the Siege of Paris (885–86). In 987 Hugh Capet, Count of Paris ("comte de Paris"), Duke of the Franks ("duc des Francs") was elected King of the Franks ("roi des Franks"). Under the rule of the Capetian kings, Paris gradually became the largest and most prosperous city in France.
Middle Ages to Louis XIV.
By the end of the 12th century, Paris had become the political, economic, religious, and cultural capital of France. The "Île de la Cité" was the site of the royal palace. In 1163, during the reign of Louis VII, Maurice de Sully, bishop of Paris, undertook the construction of the Notre Dame Cathedral at its eastern extremity. The Left Bank was the site of the University of Paris, a corporation of students and teachers formed in the mid-12th century to train scholars first in theology, and later in canon law, medicine and the arts. The Right Bank became the centre of commerce and finance. The merchants who controlled the trade on the river formed a league and quickly became a powerful force. Between 1190 and 1202, Philip Augustus built the massive fortress of the Louvre, continued the construction of Notre Dame, rebuilt the two bridges, began paving Paris's main thoroughfares, and the construction of a fortified wall around the city.
During the Hundred Years' War, the army of the Duke of Burgundy and a force of about two hundred English soldiers occupied Paris from May 1420 until 1436. They repelled an attempt by Joan of Arc to liberate the city in 1429. A century later, during the French Wars of Religion, Paris was a stronghold of the Catholic League. On 24 August 1572, Paris was the site of the St. Bartholomew's Day massacre, when thousands of French Protestants were killed. The last of these wars, the eighth one, ended in 1594, after Henri IV had converted to Catholicism and was finally able to enter Paris as he supposedly declared "Paris vaut bien une messe" ("Paris is well worth a Mass"). The city had been neglected for decades; by the time of his assassination in 1610, Henry IV had rebuilt the "Pont Neuf", the first Paris bridge with sidewalks and not lined with buildings, linked with a new wing the Louvre to the Tuileries Palace, and created the first Paris residential square, the "Place Royale", now Place des Vosges.
In the 17th century, Cardinal Richelieu, chief minister of Louis XIII, was determined to make Paris the most beautiful city in Europe. He built five new bridges, a new chapel for the College of Sorbonne, and a palace for himself, the "Palais Cardinal", which he bequeathed to Louis XIII, and which became, after his own death in 1642, the Palais-Royal.
Louis XIV distrusted the Parisians and moved his court to Versailles in 1682, but his reign also saw an unprecedented flourishing of the arts and sciences in Paris. The Comédie-Française, the Academy of Painting, and the French Academy of Sciences were founded and made their headquarters in the city. To show that the city was safe against attack, he had the city walls demolished, replacing them with "Grands Boulevards". To leave monuments to his reign, he built the "Collège des Quatre-Nations", "Place Vendôme", "Place des Victoires", and began "Les Invalides".
The 18th and 19th century.
Between 1640 and 1789, Paris grew in population from 400,000 to 600,000. A new boulevard, the Champs-Élysées, extended the city west to "Étoile", while the working-class neighbourhood of the "Faubourg Saint-Antoine" on the eastern site of the city grew more and more crowded with poor migrants from other regions of France.
Paris was the centre of an explosion of philosophic and scientific activity known as the Age of Enlightenment. Diderot and d'Alembert published their "Encyclopédie" in 1751-52, and the Montgolfier Brothers launched the first manned flight in a hot-air balloon on 21 November 1783, from the gardens of the Château de la Muette. Paris was the financial capital of continental Europe, the primary European centre of book publishing, fashion, and the manufacture of fine furniture and luxury goods.
In the summer of 1789, Paris became the centre stage of the French Revolution. On 14 July, a mob seized the arsenal at the Invalides, acquiring thousands of guns, and stormed the Bastille, a symbol of royal authority. The first independent Paris Commune, or city council, met in the "Hôtel de Ville" and, on 15 July, elected a Mayor, the astronomer Jean Sylvain Bailly.
Louis XVI and the royal family were brought to Paris and made virtual prisoners within the Tuileries Palace. In 1793, as the revolution turned more and more radical, the king, queen, and the mayor were guillotined, along with more than 16,000 others (throughout France), during the Reign of Terror. The property of the aristocracy and the church was nationalised, and the city's churches were closed, sold or demolished. A succession of revolutionary factions ruled Paris until 9 November 1799 ("coup d'état du 18 brumaire"), when Napoléon Bonaparte seized power as First Consul.
The population of Paris had dropped by 100,000 during the Revolution, but between 1799 and 1815, it surged with 160,000 new residents, reaching 660,000. Bonaparte replaced the elected government of Paris with a prefect reporting only to him. He began erecting monuments to military glory, including the "Arc de Triomphe", and improved the neglected infrastructure of the city with new fountains, the Canal de l'Ourcq, Père Lachaise Cemetery and the city's first metal bridge, the "Pont des Arts".
During the Restoration, the bridges and squares of Paris were returned to their pre-Revolution names, but the July Revolution of 1830 in Paris, (commemorated by the July Column on Place de la Bastille), brought a constitutional monarch, Louis Philippe I, to power. The first railway line to Paris opened in 1837, beginning a new period of massive migration from the provinces to the city.
Louis-Philippe was overthrown by a popular uprising in the streets of Paris in 1848. His successor, Napoleon III, and the newly appointed prefect of the Seine, Georges-Eugène Haussmann, launched a gigantic public works project to build wide new boulevards, a new opera house, a central market, new aqueducts, sewers, and parks, including the Bois de Boulogne and Bois de Vincennes. In 1860, Napoleon III also annexed the surrounding towns and created eight new arrondissements, expanding Paris to its current limits.
During the Franco-Prussian War (1870–1871), Paris was besieged by the Prussian army. After months of blockade, hunger, and then bombardment by the Prussians, the city was forced to surrender on 28 January 1871. On 28 March, a revolutionary government called the Paris Commune seized power in Paris. The Commune held power for two months, until it was harshly suppressed by the French army during the "Bloody Week" at the end of May 1871.
Late in the 19th century, Paris hosted two major international expositions: the 1889 Universal Exposition, was held to mark the centennial of the French Revolution and featured the new Eiffel Tower; and the 1900 Universal Exposition, which gave Paris the "Pont Alexandre III", the "Grand Palais", the "Petit Palais" and the first Paris Métro line. Paris became the laboratory of Naturalism (Émile Zola) and Symbolism (Charles Baudelaire and Paul Verlaine), and of Impressionism in art (Courbet, Manet, Monet, Renoir.)
20th and 21st century.
By 1901, the population of Paris had grown to 2,715,000. At the beginning of the century, artists from around the world, including Picasso, Modigliani and Matisse made Paris their home; it was the birthplace of Fauvism, Cubism and abstract art, and authors such as Marcel Proust were exploring new approaches to literature.
During the First World War, Paris sometimes found itself on the front line; 600 to 1,000 Paris taxis played a small but highly important symbolic role in transporting 6,000 soldiers to the front line at the First Battle of the Marne. The city was also bombed by Zeppelins and shelled by German long-range guns. In the years after the war, known as "Les Années Folles", Paris continued to be a mecca for writers, musicians and artists from around the world, including Ernest Hemingway, Igor Stravinsky, James Joyce, Josephine Baker, Sidney Bechet and the surrealist Salvador Dalí.
In the years after the peace conference, the city was also home to growing numbers of students and activists from French colonies and other Asian and African countries, who later became leaders of their countries, such as Ho Chi Minh, Zhou Enlai and Léopold Sédar Senghor.
On 14 June 1940, the German army marched into Paris, which had been declared an "open city". On 16–17 July 1942, following German orders, the French police and gendarmes arrested 12,884 Jews, including 4,115 children, and confined them during five days at the "Vel d'Hiv" ("Vélodrome d'Hiver"), from which they were transported by train to the extermination camp at Auschwitz. None of the children came back. On 25 August 1944, the city was liberated by the French 2nd Armoured Division and the 4th Infantry Division of the United States Army. General Charles de Gaulle led a huge and emotional crowd down the Champs Élysées towards Notre Dame de Paris, and made a rousing speech from the Hôtel de Ville.
In the 1950s and the 1960s, Paris became one front of the Algerian War for independence; in August 1961, the pro-independence FLN targeted and killed 11 Paris policemen, leading to the imposition of a curfew on Muslims of Algeria (who, at that time, were French citizens). On 17 October 1961, an unauthorised but peaceful protest demonstration of Algerians against the curfew led to violent confrontations between the police and demonstrators, in which at least 40 people were killed, including some thrown into the Seine. The anti-independence "Organisation de l'armée secrète" (OAS), for their part, carried out a series of bombings in Paris throughout 1961 and 1962.
In May 1968, protesting students occupied the Sorbonne and put up barricades in the Latin Quarter. Thousands of Parisian blue-collar workers joined the students, and the movement grew into a two-week general strike. Supporters of the government won the June elections by a large majority. The May 1968 events in France resulted in the breakup of the University of Paris into 13 independent campuses.
In 1975, the National Assembly changed the status of Paris to that of other French cities and, on 25 March 1977, Jacques Chirac became the first elected mayor of Paris since 1793. The Tour Maine Montparnasse, the tallest building in the city at 57 storeys and 210 metres high, was built between 1969 and 1973. It was highly controversial, and it remains the only building in the centre of the city over 32 storeys high.
The population of Paris dropped from 2,850,000 in 1954 to 2,152,000 in 1990, as middle-class families moved to the suburbs. A suburban railway network, the RER ("Réseau Express Régional"), was built to complement the "Métro," and the "Périphérique" expressway encircling the city, was completed in 1973.
Most of the postwar's presidents of the Fifth Republic wanted to leave their own monuments in Paris; President Georges Pompidou started the Centre Georges Pompidou (1977), Valéry Giscard d'Estaing began the Musée d'Orsay (1986); President François Mitterrand, in power for 14 years, built the Opéra Bastille (1985-1989), the Bibliothèque nationale de France (1996), the Arche de la Défense (1985-1989), and the Louvre Pyramid with its underground courtyard (1983-1989); Jacques Chirac (2006), the Musée du quai Branly.
In the early 21st century, the population of Paris began to increase slowly again, as more young people moved into the city. It reached 2.25 million in 2011. In March 2001, Bertrand Delanoë became the first socialist mayor of Paris. In 2007, in an effort to reduce car traffic in the city, he introduced the Vélib', a system which rents bicycles for the use of local residents and visitors. Bertrand Delanoë also transformed a section of the highway along the left bank of the Seine into an urban promenade and park, the "Promenade des Berges de la Seine", which he inaugurated in June 2013.
In 2007, President Nicolas Sarkozy launched the "Grand Paris" project, to integrate Paris more closely with the towns in the region around it. After many modifications, the new area, named the Metropolis of Grand Paris, with a population of 6.7 million, is scheduled for creation on 1 January 2016.
In 2011, the City of Paris and the national government approved the plans for the Grand Paris Express, totaling 205 kilometres of automated metro lines to connect Paris, the innermost three departments around Paris, airports and high-speed rail (TGV) stations, at an estimated cost of €35 billion. The system is scheduled to be completed by 2030.
On 5 April 2014, Anne Hidalgo, a socialist, was elected the first female mayor of Paris.
On 7 January 2015, two French Muslim extremists attacked the Paris headquarters of "Charlie Hebdo" and killed thirteen people, and on 9 January, a third terrorist killed four hostages during an attack at a Jewish grocery store at "Porte de Vincennes". On 11 January an estimated 1.5 million people marched in Paris–along with international political leaders–to show solidarity against terrorism and in defence of freedom of speech.
Ten months later, 13 November 2015, came a series of coordinated terrorist attacks in Paris and Saint-Denis claimed by the 'Islamic state' organisation ISIL ('Daesh', ISIS); 130 people were killed by gunfire and bombs, and more than 350 were injured. Seven of the attackers killed themselves and others by setting off their explosive vests. On the morning of 18 November three suspected terrorists, including alleged planner of the attacks Abdelhamid Abaaoud, were killed in a shootout with police in the Paris suburb of Saint-Denis. President Hollande declared France to be in a three-month state of emergency,
Geography.
Paris is located in northern central France. By road it is south-east of London, south of Calais, south-west of Brussels, north of Marseille, north-east of Nantes, and south-east of Rouen. Paris is located in the north-bending arc of the river Seine and includes two islands, the "Île Saint-Louis" and the larger "Île de la Cité", which form the oldest part of the city. The river's mouth on the English Channel ("La Manche") is about downstream of the city, established around 7600 BC. The city is spread widely on both banks of the river. Overall, the city is relatively flat, and the lowest point is above sea level. Paris has several prominent hills, the highest of which is Montmartre at . Montmartre gained its name from the martyrdom of Saint Denis, first bishop of Paris, atop the "Mons Martyrum", "Martyr's mound", in 250.
Excluding the outlying parks of "Bois de Boulogne" and "Bois de Vincennes", Paris covers an oval measuring about in area, enclosed by the ring road, the Boulevard Périphérique. The city's last major annexation of outlying territories in 1860 not only gave it its modern form but also created the 20 clockwise-spiralling arrondissements (municipal boroughs). From the 1860 area of , the city limits were expanded marginally to in the 1920s. In 1929, the "Bois de Boulogne" and "Bois de Vincennes" forest parks were officially annexed to the city, bringing its area to about . The metropolitan area of the city is .
Climate.
Paris has a typical Western European oceanic climate (Köppen climate classification: "Cfb ") which is affected by the North Atlantic Current. The overall climate throughout the year is mild and moderately wet. Summer days are usually warm and pleasant with average temperatures hovering between , and a fair amount of sunshine. Each year, however, there are a few days where the temperature rises above . Some years have even witnessed long periods of harsh summer weather, such as the heat wave of 2003 when temperatures exceeded for weeks, surged up to on some days and seldom cooled down at night. More recently, the average temperature for July 2011 was , with an average minimum temperature of and an average maximum temperature of .
Spring and autumn have, on average, mild days and fresh nights but are changing and unstable. Surprisingly warm or cool weather occurs frequently in both seasons. In winter, sunshine is scarce; days are cold but generally above freezing with temperatures around . Light night frosts are however quite common, but the temperature will dip below for only a few days a year. Snow falls every year, but rarely stays on the ground. The city sometimes sees light snow or flurries with or without accumulation.
Paris has an average annual precipitation of , and experiences light rainfall distributed evenly throughout the year. However the city is known for intermittent abrupt heavy showers. The highest recorded temperature is on 28 July 1948, and the lowest is a on 10 December 1879.
Administration.
City government.
For almost all of its long history, except for a few brief periods, Paris was governed directly by representatives of the king, emperor, or president of France. The city was not granted municipal autonomy by the National Assembly until 1974. The first modern elected mayor of Paris was Jacques Chirac, elected 20 March 1977, becoming the city's first mayor since 1793. The current mayor is Anne Hidalgo, a socialist, elected 5 April 2014.
The mayor of Paris is not elected directly by Paris voters; the voters of each arrondissement elect the "Conseil de Paris" (Council of Paris), composed of 163 members. Each arrondissement has a number of members depending upon its population, from 10 members for each of the least-populated arrondissements (1st through 9th) to 36 members for the most populated (the 15th). The elected council members select the mayor. Sometimes the candidate who receives the most votes city-wide is not selected if the other candidate has won the support of the majority of council members. Mayor Bertrand Delanoë (2001-2014) was elected by only a minority of city voters, but a majority of council members. Once elected, the council plays a largely passive role in the city government; it meets only once a month. The current council is divided between a coalition of the left of 91 members, including the socialists, communists, greens, and extreme left; and 71 members for the centre right, plus a few members from smaller parties.
Each of Paris's 20 arrondissements has its own town hall and a directly elected council ("conseil d'arrondissement"), which, in turn, elects an arrondissement mayor. The council of each arrondissement is composed of members of the "Conseil de Paris" and also members who serve only on the council of the arrondissement. The number of deputy mayors in each arrondissement varies depending upon its population. There are a total of 20 arrondissement mayors and 120 deputy mayors.
The budget of the city for 2013 was €7.6 billion, of which 5.4 billion went for city administration, while €2.2 billion went for investment. The largest part of the budget (38 percent) went for public housing and urbanism projects; 15 percent for roads and transport; 8 percent for schools (which are mostly financed by the state budget); 5 percent for parks and gardens; and 4 percent for culture. The main source of income for the city is direct taxes (35 percent), supplemented by a 13-percent real estate tax; 19 percent of the budget comes in a transfer from the national government.
The number of city employees, or agents, grew from 40,000 in 2000 to 73,000 in 2013. The city debt grew from €1.6 billion in 2000 to 3.1 billion in 2012, with a debt of €3.65 billion expected for 2014. As a result of the growing debt, the bond rating of the city was lowered from AAA to AA+ in both 2012 and 2013. In September 2014, Mayor Hidalgo announced that the city would have budget shortfall of €400 million, largely because of a cut in support from the national government.
Metropolitan government.
In 2007, President Sarkozy proposed the creation of a "Grand Paris", a new metropolitan authority composed of the City of Paris and the communes in the suburbs surrounding it. After much discussion and modification, in 2014 and 2015 laws were passed in Parliament to create the "Métropole du Grand Paris", or Greater Paris Metropolis, which will formally come into existence on January 1, 2016.
The Greater Paris Metropolis will encompass the City (commune) of Paris and 130 suburban communes surrounding it. It will cover a territory of housing nearly 7 million inhabitants. The Metropolis will comprise a metropolitan council ("conseil de la métropole du Grand Paris") representing the 131 communes, and an executive head, the president of the metropolitan council ("président du conseil de la métropole du Grand Paris"). The first president of the metropolitan council will be elected on January 22, 2016.
Regional government.
The Region of Île de France, including Paris and its surrounding communities, is governed by the Regional Council, which has its headquarters in the 7th arrondissement of Paris. It is composed of 209 members representing the different communes within the region, with a majority belonging to the socialists and their allies. The current president of the council is Jean-Paul Huchon, a socialist. The next elections for the Regional council will take place 6 and 13 December 2015.
National government.
As the capital of France, Paris is the seat of France's national government. For the executive, the two chief officers each have their own official residences, which also serve as their offices. The President of the French Republic resides at the Élysée Palace in the 8th arrondissement, while the Prime Minister's seat is at the Hôtel Matignon in the 7th arrondissement. Government ministries are located in various parts of the city; many are located in the 7th arrondissement, near the Matignon.
The two houses of the French Parliament are located on the Left Bank. The upper house, the Senate, meets in the Palais du Luxembourg in the 6th arrondissement, while the more important lower house, the Assemblée Nationale, meets in the Palais Bourbon in the 7th arrondissement. The President of the Senate, the second-highest public official in France (the President of the Republic being the sole superior), resides in the "Petit Luxembourg", a smaller palace annex to the Palais du Luxembourg.
France's highest courts are located in Paris. The Court of Cassation, the highest court in the judicial order, which reviews criminal and civil cases, is located in the Palais de Justice on the "Île de la Cité", while the Conseil d'État, which provides legal advice to the executive and acts as the highest court in the administrative order, judging litigation against public bodies, is located in the Palais-Royal in the 1st arrondissement. The Constitutional Council, an advisory body with ultimate authority on the constitutionality of laws and government decrees, also meets in the Montpensier wing of the Palais Royal.
Paris and its region host the headquarters of several international organisations including UNESCO, the Organisation for Economic Co-operation and Development, the International Chamber of Commerce, the Paris Club, the European Space Agency, the International Energy Agency, the "Organisation internationale de la Francophonie", the European Union Institute for Security Studies, the International Bureau of Weights and Measures, the International Exhibition Bureau and the International Federation for Human Rights.
Following the motto "Only Paris is worthy of Rome; only Rome is worthy of Paris"; the only sister city of Paris is Rome, although Paris has partnership agreements with many other cities around the world.
Police force.
The security of Paris is mainly the responsibility of the Prefecture of Police of Paris, a subdivision of the Ministry of the Interior of France. It supervises the units of the National Police who patrol the city and the three neighbouring departments. It is also responsible for providing emergency services, including the Paris Fire Brigade. Its headquarters is on "Place Louis Lépine" on the "Île de la Cité". There are 30,200 officers under the prefecture, and a fleet of more than 6,000 vehicles, including police cars, motorcycles, fire trucks, boats and helicopters. In addition to traditional police duties, the local police monitors the number of discount sales held by large stores (no more than two a year are allowed) and verify that, during summer holidays, at least one bakery is open in every neighbourhood. The national police has its own special unit for riot control and crowd control and security of public buildings, called the "Compagnies Républicaines de Sécurité" ("CRS"), a unit formed in 1944 right after the liberation of France. Vans of CRS agents are frequently seen in the centre of the city when there are demonstrations and public events.
The police are supported by the National Gendarmerie, a branch of the French Armed Forces, though their police operations now are supervised by the Ministry of the Interior. The traditional kepis of the "gendarmes" were replaced in 2002 with caps, and the force modernised, though they still wear kepis for ceremonial occasions.
Crime in Paris is similar to that in most large cities. Violent crime is relatively rare in the city centre. Political violence is uncommon, though very large demonstrations may occur in Paris and other French cities simultaneously. These demonstrations, usually managed by a strong police presence, can turn confrontational and escalate into violence.
Cityscape.
Urbanism and architecture.
Most French rulers since the Middle Ages made a point of leaving their mark on a city that, contrary to many other of the world's capitals, has never been destroyed by catastrophe or war. In modernising its infrastructure through the centuries, Paris has preserved even its earliest history in its street map. At its origin, before the Middle Ages, the city was composed around several islands and sandbanks in a bend of the Seine; of those, two remain today: the île Saint-Louis, the île de la Cité; a third one is the 1827 artificially created île aux Cygnes. Modern Paris owes much to its late 19th century Second Empire remodelling by the Baron Haussmann: many of modern Paris's busiest streets, avenues and boulevards today are a result of that city renovation. Paris also owes its style to its aligned street-fronts, distinctive cream-grey "Paris stone" building ornamentation, aligned top-floor balconies, and tree-lined boulevards. The high residential population of its city centre makes it much different from most other western global cities.
Paris's urbanism laws have been under strict control since the early 17th century, particularly where street-front alignment, building height and building distribution is concerned. In recent developments, a 1974-2010 building height limitation of was raised to in central areas and in some of Paris's peripheral quarters, yet for some of the city's more central quarters, even older building-height laws still remain in effect. The Montparnasse tower was both Paris and France's tallest building until 1973, but this record has been held by the La Défense quarter Tour First tower in Courbevoie since its 2011 construction. A new project for La Defense, called Hermitage Plaza, launched in 2009, proposes to build two towers, 85 and 86 stories or 320 metres high, which would be the tallest buildings in the European Union, just slightly shorter than the Eiffel Tower. They were scheduled for completion in 2019 or 2020, but as of January 2015 construction had not yet begun, and there were questions in the press about the future of the project.
Parisian examples of European architecture date back more than a millennium; including the Romanesque church of the Abbey of Saint-Germain-des-Prés (1014-1163); the early Gothic Architecture of the Basilica of Saint-Denis (1144), the Notre Dame Cathedral (1163-1345), the Flamboyant Gothic of Saint Chapelle (1239-1248), the Baroque churches of Saint-Paul-Saint-Louis (1627-1641) and Les Invalides (1670-1708). The 19th century produced the neoclassical church of La Madeleine (1808-1842); the Palais Garnier Opera House (1875); the neo-Byzantine Basilica of Sacré-Cœur (1875-1919), and the exuberant Belle Époque modernism of the Eiffel Tower (1889). Striking examples of 20th century architecture include the Centre Georges Pompidou by Richard Rogers and Renzo Piano (1977), and the Louvre Pyramid by I.M. Pei (1989). Contemporary architecture includes the Musée du Quai Branly by Jean Nouvel (2006) and the new contemporary art museum of the Louis Vuitton Foundation by Frank Gehry (2014).
Housing.
Paris is the fifth most expensive city in the world for luxury housing: in 2014. According to a 2012 study for the La Tribune newspaper, the most expensive street is the quai des Orfèvres in the 1st arrondissement, with an average price of , against for rue Pajol in the 18th arrondissement.
The total number of residences in the city of Paris in 2011 was , up from a former high of in 2006. Among these, (85.9 percent) were main residences, (6.8 percent) were secondary residences, and the remaining 7.3 percent were empty (down from 9.2 percent in 2006).
Paris urban tissue began to fill and overflow its 1860 limits from around the 1920s, and because of its density, it has seen few modern constructions since then. Sixty-two percent of its buildings date from 1949 and before, 20 percent were built between 1949 and 1974, and only 18 percent of the buildings remaining were built after that date.
Two-thirds of the city's 1.3 million residences are studio and two-room apartments. Paris averages 1.9 people per residence, a number that has remained constant since the 1980s, but it is much less than Île-de-France's 2.33 person-per-residence average. Only 33 percent of principal-residence Parisians own their habitation (against 47 percent for the entire Île-de-France): the major part of the city's population is a rent-paying one.
Social housing represents a little more than 17 percent of the city's total residences, but these are rather unevenly distributed throughout the capital: the vast majority of these are concentrated in a crescent formed by Paris's south-western to northern periphery arrondissements.
In 2012 the Paris agglomeration (urban area) counted 28,800 people without a fixed residence, an increase of 84 percent since 2001; it represents 43 percent of the homeless in all of France. Forty-one percent were women, and 29 percent were accompanied by children. Fifty-six percent of the homeless were born outside of France, the largest number coming from Africa and Eastern Europe. The city of Paris has sixty homeless shelters, called "Centres d'hébergement et de réinsertion sociale" or CHRS, which are funded by the city and operated by private charities and associations.
Paris and its suburbs.
Aside from the 20th century addition of the "Bois de Boulogne", "Bois de Vincennes" and Paris heliport, Paris's administrative limits have remained unchanged since 1860. The "Seine département" had been governing Paris and its suburbs since its creation in 1790, but the rising suburban population had made it difficult to govern as a unique entity. This problem was 'resolved' when its parent "District de la région parisienne" (Paris region) was reorganised into several new departments from 1968: Paris became a department in itself, and the administration of its suburbs was divided between the three departments surrounding it. The Paris region was renamed "Île-de-France" in 1977, but the "Paris region" name is still commonly used today. Paris will be reunited with its suburbs on January 1, 2016 when the "Métropole du Grand Paris" comes into existence.
Paris's disconnect with its suburbs, its lack of suburban transportation in particular, became all too apparent with the Paris agglomeration's growth. Paul Delouvrier promised to resolve the Paris-suburbs "mésentente" when he became head of the Paris region in 1961: two of his most ambitious projects for the Region were the construction of five suburban "villes nouvelles" ("new cities") and the RER commuter train network. Many other suburban residential districts ("grands ensembles") were built between the 1960s and 1970s to provide a low-cost solution for a rapidly expanding population: these districts were socially mixed at first, but few residents actually owned their homes (the growing economy made these accessible to the middle classes only from the 1970s). Their poor construction quality and their haphazard insertion into existing urban growth contributed to their desertion by those able to move elsewhere and their repopulation by those with more limited possibilities.
These areas, "quartiers sensibles" ("sensitive quarters"), are in northern and eastern Paris, namely around its Goutte d'Or and Belleville neighbourhoods. To the north of the city they are grouped mainly in the Seine-Saint-Denis department, and to a lesser extreme to the east in the Val-d'Oise department. Other difficult areas are located in the Seine valley, in Évry et Corbeil-Essonnes (Essonne), in Mureaux, Mantes-la-Jolie (Yvelines), and scattered among social housing districts created by Delouvrier's 1961 "ville nouvelle" political initiative.
The Paris agglomeration's urban sociology is basically that of 19th century Paris: its fortuned classes are situated in its west and south-west, and its middle-to-lower classes are in its north and east. The remaining areas are mostly middle-class citizenry dotted with islands of fortuned populations located there due to reasons of historical importance, namely Saint-Maur-des-Fossés to the east and Enghien-les-Bains to the north of Paris.
Demographics.
The population of Paris in its administrative city limits was 2,241,346 in January 2014. This makes Paris the fifth largest municipality in the European Union, following London, Berlin, Madrid and Rome. Eurostat, the statistical agency of the EU, places Paris (6.5 million people) second behind London (8 million) and ahead of Berlin (3.5 million), based on the 2012 populations of what Eurostat calls "urban audit core cities". The Paris Urban Area, or "unité urbaine", is a statistical area created by the French statistical agency INSEE to measure the population of built-up areas around the city. It is slightly smaller than the Paris Region. According to INSEE, the Paris Urban Area had a population of 10,550,350 at the January 2012 census, the most populous in the European Union, and third most populous in Europe, behind Istanbul and Moscow. The Paris Metropolitan Area is the second most populous in the European Union after London with a population of 12,341,418 at the Jan. 2012 census.
The population of Paris today is lower than its historical peak of 2.9 million in 1921. The principal reasons were a significant decline in household size, and a dramatic migration of residents to the suburbs between 1962 and 1975. Factors in the migration included de-industrialisation, high rent, the gentrification of many inner quarters, the transformation of living space into offices, and greater affluence among working families. The city's population loss came to an end in the 21st century; the population estimate of July 2004 showed a population increase for the first time since 1954, and the population reached 2,234,000 by 2009.
According to Eurostat, the EU statistical agency, in 2012 the Commune of Paris was the most densely populated city in the European Union, with 21,616 people per square kilometre within the city limits (the NUTS-3 statistical area), ahead of Inner London West, which had 10,374 people per square kilometre. According to the same census, three departments bordering Paris, Hauts-de-Seine, Seine-Saint-Denis and Val-de-Marne, had population densities of over ten thousand people per square kilometre, ranking among the ten most densely populated areas of the EU.
Migration.
According to the 2012 French census, 586,163 residents of the City of Paris, or 26.2 percent, and 2,782,834 residents of the Paris Region (Île-de-France), or 23.4 percent, were born outside of Metropolitan France (the last figure up from 22.4% at the 2007 census).
26,700 of these in the City of Paris and 210,159 in the Paris Region were people born in Overseas France (more than two-thirds of whom in the French West Indies) and are therefore not counted as immigrants since there are legally French citizens at birth.
A further 103,648 in the City of Paris and in 412,114 in the Paris Region were born in foreign countries with French citizenship at birth. This concerns in particular the many Christians and Jews from North Africa who moved to France and Paris after the times of independence and are not counted as immigrants due to their being born French citizens.
The remaining group, people born in foreign countries with no French citizenship at birth, are those defined as immigrants under French law. According to the 2012 census, 135,853 residents of the city of Paris were immigrants from Europe, 112,369 were immigrants from the Maghreb, 70,852 from sub-Saharan Africa and Egypt, 5,059 from Turkey, 91,297 from Asia (outside Turkey), 38,858 from the Americas, and 1,365 from the South Pacific. Note that the immigrants from the Americas and the South Pacific in Paris are vastly outnumbered by migrants from French overseas regions and territories located in these regions of the world.
In the Paris Region, 590,504 residents were immigrants from Europe, 627,078 were immigrants from the Maghreb, 435,339 from sub-Saharan Africa and Egypt, 69,338 from Turkey, 322,330 from Asia (outside Turkey), 113,363 from the Americas, and 2,261 from the South Pacific. These last two groups of immigrants are again vastly outnumbered by migrants from French overseas regions and territories located in the Americas and the South Pacific.
In 2012, there were 8,810 British citizens and 10,019 US citizens living in the City of Paris (Ville de Paris), and 20,466 British citizens and 16,408 US citizens living in the entire Paris Region (Île-de-France).
Religion.
According to a 2011 survey by IFOP, a French public opinion research organization, 47 percent of residents of the Paris Region (Île-de-France) identified themselves as Roman Catholic, though just 15 percent said they were practicing Catholics, while 46 percent were non-practicing. In the same survey, 7 percent of residents identified themselves as Muslims, 4 percent as Protestants, two percent as Jewish, and 25 percent as without religion.
According to INSEE, the French government statistical office, between 4 and 5 million French residents were born or had at least one parent born in a predominately Muslim country, particularly Algeria, Morocco and Tunisia. An IFOP survey in 2008 reported that, of immigrants from these predominantly Muslim countries, 25 percent went to the mosque regularly; 41 percent practiced the religion, and 34 percent were believers but did not practice the religion.
In 2012, Dalil Boubakeur, the Rector of the Grand Mosque of Paris and former President of the French Council of the Muslim Faith, estimated that there were 500,000 Muslims in the city of Paris, 1.5 million Muslims in the Ile-de-France region, and 4 to 5 million Muslims in France.
The Jewish population of the Paris Region was estimated in 2014 to be 282,000, the largest concentration of Jews in the world outside of Israel and the United States.
Economy.
The economy of the City of Paris is today is based largely on services and commerce; of the 390,480 enterprises in the city, 80.6 percent are engaged in commerce, transportation, and diverse services, 6.5 percent in construction, and just 3.8 percent in industry. The story is similar in the Paris Region, or Île-de-France. 76.7 percent of enterprises are engaged in commerce and services, and 3.4 percent in industry.
At the 2012 census, 59.5% of jobs in the Paris Region were in market services (12.0% in wholesale and retail trade, 9.7% in professional, scientific, and technical services, 6.5% in information and communication, 6.5% in transportation and warehousing, 5.9% in finance and insurance, 5.8% in administrative and support services, 4.6% in accommodation and food services, and 8.5% in various other market services), 26.9% in non-market services (10.4% in human health and social work activities, 9.6% in public administration and defence, and 6.9% in education), 8.2% in manufacturing and utilities (6.6% in manufacturing and 1.5% in utilities), 5.2% in construction, and 0.2% in agriculture.
The top ten French companies listed in the Fortune Global 500 for 2015 all have their headquarters in the Paris Region; five in the City of Paris; and three in the Hauts-de-Seine Department, in the business district of La Défense, and one in the suburb of Montrouge. The fourth-largest company, Société Générale, has headquarters in both Paris and La Défense.
The Paris Region is France's leading region for economic activity, with a 2012 GDP of €624 billion (US$687 billion). In 2011, its GDP ranked second among the regions of Europe and its per-capita GDP was the 4th highest in Europe. While the Paris region's population accounted for 18.8 percent of metropolitan France in 2011, the Paris region's GDP accounted for 30 percent of metropolitan France's GDP. In 2015 it hosts the world headquarters of 29 of the 31 Fortune Global 500 companies located in France.
The Paris Region economy has gradually shifted from industry to high-value-added service industries (finance, IT services, etc.) and high-tech manufacturing (electronics, optics, aerospace, etc.). The Paris region's most intense economic activity through the central Hauts-de-Seine department and suburban La Défense business district places Paris's economic centre to the west of the city, in a triangle between the "Opéra Garnier", "La Défense" and the "Val de Seine". While the Paris economy is dominated by services, and employment in manufacturing sector has declined sharply, the region remains an important manufacturing centre, particularly for aeronautics, automobiles, and "eco" industries.
In a 2015 worldwide cost of living survey by the Economist Intelligence Unit, Paris ranked as the world's second most expensive city. In the survey, it is joined among the most expensive European cities by Oslo, Zurich, Geneva and Copenhagen. The ranking compares more than 400 individual prices across 160 products and services, and is designed to calculate cost-of-living allowances and build compensation packages for expatriates and business travellers.
Employment.
According to 2012 INSEE figures, 68 percent of employees in the City of Paris work in commerce, transportation, and services; 24.4 percent in public administration, health and social services; 4.4 percent in industry, and .1 percent in agriculture.
The majority of Paris's salaried employees fill 370,000 businesses services jobs, concentrated in the north-western 8th, 16th and 17th arrondissements. Paris's financial service companies are concentrated in the central-western 8th and 9th arrondissement banking and insurance district. Paris's department store district in the 1st, 6th, 8th and 9th arrondissements employ 10 percent of mostly female Paris workers, with 100,000 of these registered in the retail trade. Fourteen percent of Parisians work in hotels and restaurants and other services to individuals. Nineteen percent of Paris employees work for the State in either in administration or education. The majority of Paris's healthcare and social workers work at the hospitals and social housing concentrated in the peripheral 13th, 14th, 18th, 19th and 20th arrondissements. Outside Paris, the western Hauts-de-Seine department La Défense district specialising in finance, insurance and scientific research district, employs 144,600, and the north-eastern Seine-Saint-Denis audiovisual sector has 200 media firms and 10 major film studios.
Paris's manufacturing is mostly focused in its suburbs, and the city itself has only around 75,000 manufacturing workers, most of which are in the textile, clothing, leather goods and shoe trades. Paris region manufacturing specialises in transportation, mainly automobiles, aircraft and trains, but this is in a sharp decline: Paris proper manufacturing jobs dropped by 64 percent between 1990 and 2010, and the Paris region lost 48 percent during the same period. Most of this is due to companies relocating outside the Paris region. The Paris region's 800 aerospace companies employed 100,000. Four hundred automobile industry companies employ another 100,000 workers: many of these are centred in the Yvelines department around the Renault and PSA-Citroen plants (this department alone employs 33,000), but the industry as a whole suffered a major loss with the 2014 closing of a major Aulnay-sous-Bois Citroen assembly plant.
The southern Essonne department specialises in science and technology, and the south-eastern Val-de-Marne, with its wholesale Rungis food market, specialises in food processing and beverages. The Paris region's manufacturing decline is quickly being replaced by eco-industries: these employ about 100,000 workers. In 2011, while only 56,927 construction workers worked in Paris itself, its metropolitan area employed 246,639, in an activity centred largely around the Seine-Saint-Denis (41,378) and Hauts-de-Seine (37,303) departments and the new business-park centres appearing there.
Incomes.
The average net household income (after social, pension and health insurance contributions) in Paris was €36,085 for 2011. It ranged from €22,095 in the 19th arrondissement to €82,449 in the 7th arrondissement. The median taxable income for 2011 was around €25,000 in Paris and €22,200 for "Île-de-France". Generally speaking, incomes are higher in the Western part of the city and in the western suburbs than in the northern and eastern parts of the urban area. Unemployment was estimated at 8.2 percent in the city of Paris and 8.8 percent in the Île-de-France region in the first trimester of 2015. It ranged from 7.6 percent in the wealthy Essonne department to 13.1 percent in the Seine-Saint-Denis department, where many recent immigrants live.
While Paris has some of the richest neighbourhoods in France, it also has some of the poorest, mostly on the eastern side of the city. In 2012, 14 percent of households in the city earned less than €977 per month, the official poverty line. Twenty-five percent of residents in the 19th arrondissement lived below the poverty line; 24 percent in the 18th, 22 percent in the 20th and 18 percent in the 10th. In the city's wealthiest neighbourhood, the 7th arrondissement, 7 percent lived below the poverty line; 8 percent in the 6th arrondissement; and 9 percent in the 16th arrondissement.
Tourism.
Greater Paris (the city plus surrounding departments) received 22,4 million visitors in 2014, making it one of the world's top tourist destinations. The largest numbers of foreign tourists in 2014 came from the United States (2.74 million), the U.K., Germany, Italy, Japan, Spain and China (532,000). Arrivals from the U.K, Germany, Russia and Japan dropped from 2013, while arrivals from the Near and Middle East grew by twenty percent.
In 2014, visitors to Paris spent $17 billion (€13.58 billion), the third-highest sum globally after London and New York. In 2012, according to the Paris Convention and Visitors Bureau, 263,212 salaried workers in the city of Paris, or 18.4 percent of the total number, were engaged in tourism-related sectors: hotels, catering, transport and leisure.
Monuments and attractions.
There were 72.1 million visitors to the city's museums and monuments in 2013. The city's top tourist attraction was the Notre Dame Cathedral, which welcomed 14 million visitors in 2013. The Louvre museum had more than 9.2 million visitors in 2013, making it the most visited museum in the world. The other top cultural attractions in Paris in 2013 were the Basilique du Sacré-Cœur (10.5 million visitors); the Eiffel Tower (6,740,000 visitors); the Centre Pompidou (3,745,000 visitors) and Musée d'Orsay (3,467,000 visitors). In the Paris region, Disneyland Paris, in Marne-la-Vallée, 32 km (20 miles) east of the centre of Paris, was the most visited tourist attraction in France, with 14.9 million visitors in 2013.
The centre of Paris contains the most visited monuments in the city, including the Notre Dame Cathedral and the Louvre as well as the Sainte-Chapelle; Les Invalides, where the tomb of Napoleon is located, and the Eiffel Tower are located on the Left Bank south-west of the centre. The banks of the Seine from the Pont de Sully to the Pont d'Iéna have been listed as a UNESCO World Heritage Site since 1991. Other landmarks are laid out east to west along the historic axis of Paris, which runs from the Louvre through the Tuileries Garden, the Luxor Column in the Place de la Concorde, the Arc de Triomphe, to the Grande Arche of La Défense.
Several other much-visited landmarks are located in the suburbs of the city; the Basilica of St Denis, in Seine-Saint-Denis, is the birthplace of the Gothic style of architecture and the royal necropolis of French kings and queens. The Paris region hosts three other UNESCO Heritage sites: the Palace of Versailles in the west, the Palace of Fontainebleau in the south and the medieval fairs site of Provins in the east.
Hotels.
As of 2013 the City of Paris had 1,570 hotels with 70,034 rooms, of which 55 were rated five-star, mostly belonging to international chains and mostly located close to the centre and the Champs-Élysées. Paris has long been famous for its grand hotels. The Hotel Meurice, opened for British travellers in 1817, was one of the first luxury hotels in Paris. The arrival of the railroads and the Paris Exposition of 1855 brought the first flood of tourists and the first modern grand hotels; the Hôtel du Louvre (now an antiques marketplace) in 1855; the Grand Hotel (now the Intercontinental LeGrand) in 1862; and the Hôtel Continental in 1878. The Hôtel Ritz on Place Vendôme opened in 1898, followed by the Hôtel Crillon in an 18th-century building on the Place de la Concorde in 1909; the Hotel Bristol on rue de Fabourg Saint-Honoré in 1925; and the Hotel George V in 1928.
Culture.
Painting and sculpture.
For centuries, Paris has attracted artists from around the world, who arrive in the city to educate themselves and to seek inspiration from its vast pool of artistic resources and galleries. As a result, Paris has acquired a reputation as the "City of Art". Italian artists were a profound influence on the development of art in Paris in the 16th and 17th centuries, particularly in sculpture and reliefs. Painting and sculpture became the pride of the French monarchy and the French royals commissioned many Parisian artists to adorn their palaces during the French Baroque and Classicism era. Sculptors such as Girardon, Coysevox and Coustou acquired reputations as the finest artists in the royal court in 17th-century France. Pierre Mignard became the first painter to King Louis XIV during this period. In 1648, the "Académie royale de peinture et de sculpture" (Royal Academy of Painting and Sculpture) was established to accommodate for the dramatic interest in art in the capital. This served as France's top art school until 1793.
Paris was in its artistic prime in the 19th century and early 20th century, when it had a colony of artists established in the city and in art schools associated with some of the finest painters of the times: Manet, Monet, Berthe Morisot, Gauguin, Renoir and others. The French Revolution and political and social change in France had a profound influence on art in the capital. Paris was central to the development of Romanticism in art, with painters such as Gericault. Impressionism, Art Nouveau, Symbolism, Fauvism Cubism and Art Deco movements all evolved in Paris. In the late 19th century, many artists in the French provinces and worldwide flocked to Paris to exhibit their works in the numerous salons and expositions and make a name for themselves. Artists such as Pablo Picasso, Henri Matisse, Vincent van Gogh, Paul Cézanne, Jean Metzinger, Albert Gleizes, Henri Rousseau, Marc Chagall, Amedeo Modigliani and many others became associated with Paris. Picasso, living in Montmartre, painted his famous "La Famille de Saltimbanques" and "Les Demoiselles d'Avignon" between 1905 and 1907. Montmartre and Montparnasse became centres for artistic production.
The most prestigious names of French and foreign sculptors, who made their reputation in Paris in the modern era, are Frédéric Auguste Bartholdi (Statue of Liberty), Auguste Rodin, Camille Claudel, Antoine Bourdelle, Paul Landowski (statue of Christ the Redeemer in Rio de Janeiro) and Aristide Maillol. The Golden Age of the School of Paris ended between the two world wars, but Paris remains extremely important to world art and art education, with schools ranging from the École nationale supérieure des Beaux-Arts (the former "Académie royale de peinture et de sculpture") and Paris College of Art to the Paris American Academy, which specialises in teaching fashion and interior design.
Photography.
The inventor Nicéphore Niépce produced the first permanent photograph on a polished pewter plate in Paris in 1825, and then developed the process with Louis Daguerre. The work of Étienne-Jules Marey in the 1880s contributed considerably to the development of modern photography. Photography came to occupy a central role in Parisian Surrealist activity, in the works of Man Ray and Maurice Tabard. Numerous photographers achieved renown for their photography of Paris, including Eugène Atget, noted for his depictions of street scenes, Robert Doisneau, noted for his playful pictures of people and market scenes (among which "Le baiser de l'hôtel de ville" has became iconic of the romantic vision of Paris), Marcel Bovis, noted for his night scenes, and others such as Jacques-Henri Lartigue and Cartier-Bresson. Poster art also became an important art form in Paris in the late nineteenth century, through the work of Henri de Toulouse-Lautrec, Jules Chéret, Eugène Grasset, Adolphe Willette, Pierre Bonnard, Georges de Feure, Henri-Gabriel Ibels, Gavarni, and Alphonse Mucha.
Museums.
The Louvre was the world's most visited art museum in 2014, with 9.3 million visitors. Its treasures include the Mona Lisa ("La Joconde") and the Venus de Milo statue. Starkly apparent with its service-pipe exterior, the Centre Georges Pompidou, the second-most visited art museum in Paris, also known as Beaubourg, houses the Musée National d'Art Moderne. The Musée d'Orsay, in the former Orsay railway station, was the third-most visited museum in the city in 2014; it displays French art of the 19th century, including major collections of the Impressionists and Post-Impressionists. The original building - a railway station - was constructed for the Universal Exhibition of 1900. The Musée du quai Branly was the fourth-most visited national museum in Paris in 2014; it displays art objects from Africa, Asia, Oceania, and the Americas. The Musée national du Moyen Âge, or Cluny Museum, presents Medieval art, including the famous tapestry cycle of The Lady and the Unicorn. The Guimet Museum, or "Musée national des arts asiatiques", has one of the largest collections of Asian art in Europe. There are also notable museums devoted to individual artists, including the Picasso Museum the Rodin Museum, and the Musée national Eugène Delacroix.
Paris hosts one of the largest science museums in Europe, the Cité des Sciences et de l'Industrie at La Villette. The National Museum of Natural History, on the Left Bank, is famous for its dinosaur artefacts, mineral collections, and its Gallery of Evolution. The military history of France, from the Middle Ages to World War II, is vividly presented by displays at the Musée de l'Armée at Les Invalides, near the tomb of Napoleon. In addition to the national museums, run by the French Ministry of Culture, the City of Paris operates 14 museums, including the Carnavalet Museum on the history of Paris; Musée d'Art Moderne de la Ville de Paris; Palais de Tokyo; the House of Victor Hugo and House of Balzac, and the Catacombs of Paris. There are also notable private museums; The Contemporary Art museum of the Louis Vuitton Foundation, designed by architect Frank Gehry, opened on October 2014 in the Bois de Boulogne.
Theatre.
The largest opera houses of Paris are the 19th-century Opéra Garnier (historical Paris Opéra) and modern Opéra Bastille; the former tends toward the more classic ballets and operas, and the latter provides a mixed repertoire of classic and modern. In middle of the 19th century, there were three other active and competing opera houses: the Opéra-Comique (which still exists), Théâtre-Italien, and Théâtre Lyrique (which in modern times changed its profile and name to Théâtre de la Ville). Philharmonie de Paris, the modern symphonic concert hall of Paris, opened in January 2015. Another musical landmark is the Théâtre des Champs-Élysées, where the first performances of Diaghilev's Ballets Russes took place in 1913.
Theatre traditionally has occupied a large place in Parisian culture, and many of its most popular actors today are also stars of French television. The oldest and most famous Paris theatre is the Comédie-Française, founded in 1680. Run by the French government, it performs mostly French classics at the Salle Richelieu in the Palais-Royal at 2 rue de Richelieu, next to the Louvre. of Other famous theaters include the Odéon-Théâtre de l'Europe, next to the Luxembourg Gardens, also a state institution and theatrical landmark; the Théâtre Mogador, and the Théâtre de la Gaîté-Montparnasse.
The music hall and cabaret are famous Paris institutions. The "Moulin Rouge" was opened in 1889. It was highly visible because of its large red imitation windmill on its roof, and became the birthplace of the dance known as the French Cancan. It helped make famous the singers Mistinguett and Édith Piaf and the painter Toulouse-Lautrec, who made posters for the venue. In 1911, the dance hall Olympia Paris invented the grand staircase as a settling for its shows, competing with its great rival, the "Folies Bergère," Its stars in the 1920s included the American singer and dancer Josephine Baker. The Casino de Paris presented many famous French singers, including Mistinguett, Maurice Chevalier, and Tino Rossi. Other famous Paris music halls include "Le Lido", on the Champs-Élysées, opened in 1946; and the Crazy Horse Saloon, featuring strip-tease, dance and magic, opened in 1951. The Olympia Paris has presented Edith Piaf, Marlene Dietrich, Miles Davis, Judy Garland, and the Grateful Dead. A half dozen music halls exist today in Paris, attended mostly visitors to the city. 
Literature.
The first book printed in France, "Epistolae" ("Letters"), by Gasparinus de Bergamo (Gasparino da Barzizza), was published in Paris in 1470 by the press established by Johann Heynlin. Since then, Paris has been the centre of the French publishing industry, the home of some of the world's best-known writers and poets, and the setting for many classic works of French literature. Almost all the books published in Paris in the Middle Ages were in Latin, rather than French. Paris did not become the acknowledged capital of French literature until the 17th century, with authors such as Boileau, Corneille, La Fontaine, Molière, Racine, several coming from the provinces, and the foundation of the Académie française. In the 18th century, the literary life of Paris revolved around the cafés and salons, and was dominated by Voltaire, Jean-Jacques Rousseau, Pierre de Marivaux, and Beaumarchais.
During the 19th century, Paris was the home and subject for some of France's greatest writers, including Charles Baudelaire, Stéphane Mallarmé, Mérimée, Alfred de Musset, Marcel Proust, Émile Zola, Alexandre Dumas, Gustave Flaubert, Guy de Maupassant and Honoré de Balzac. Victor Hugo's "The Hunchback of Notre Dame" inspired the renovation of its setting, the Notre-Dame de Paris. Another of Victor Hugo's works, "Les Misérables", written while he was in exile outside of France during the Second Empire, described the social change and political turmoil in Paris in the early 1830s. One of the most popular of all French writers, Jules Verne, worked at the Theatre Lyrique and the Paris stock exchange, while he did research for his stories at the National Library.
In the 20th century, the Paris literary community was dominated by Colette, André Gide, François Mauriac, André Malraux, Albert Camus, and, after World War II, by Simone de Beauvoir and Jean-Paul Sartre; Between the wars it was the home of many important expatriate writers, including Ernest Hemingway, Samuel Beckett, and, in the 1970s, Milan Kundera. The winner of the 2014 Nobel Prize in Literature, Patrick Modiano–who lives in Paris–, based most of his literary work on the depiction of the city during World War II and the 1960s-1970s.
Paris is a city of books and bookstores. In the 1970s, 80 percent of French-language publishing houses were found in Paris, almost all on the Left Bank in the 5th, 6th and 7th arrondissements. Since that time, because of high prices, some publishers have moved out to the less expensive areas. It is also a city of small bookstores; There are about 150 bookstores in the 5th arrondissement alone, plus another 250 book stalls along the Seine. Small Paris bookstores are protected against competition from discount booksellers by French law; books, even e-books, cannot be discounted more than five percent below their publisher's cover price.
Music.
In the late 12th-century, a school of polyphony was established at the Notre-Dame. A group of Parisian aristocrats, known as Trouvères, became known for their poetry and songs. During the reign of Francois I, the lute became popular in the French court, and a national musical printing house was established. During the Renaissance era, the French royals "disported themselves in masques, ballets, allegorical dances, recitals, opera and comedy", and composers such as Jean-Baptiste Lully became popular. The Conservatoire de Musique de Paris was founded in 1795. By 1870, Paris had become the most important centre for ballet music, and composers such as Debussy and Ravel contributed much to symphonic music.
Bal-musette is a style of French music and dance that first became popular in Paris in the 1870s and 1880s; by 1880 Paris had some 150 dance halls in the working-class neighbourhoods of the city. Patrons danced the bourrée to the accompaniment of the cabrette (a bellows-blown bagpipe locally called a "musette") and often the vielle à roue (hurdy-gurdy) in the cafés and bars of the city. Parisian and Italian musicians who played the accordion adopted the style and established themselves in Auvergnat bars especially in the 19th arrondissement, and the romantic sounds of the accordion has since become one of the musical icons of the city. Paris became a major centre for jazz and still attracts jazz musicians from all around the world to its clubs and cafés.
Paris is the spiritual home of gypsy jazz in particular, and many of the Parisian jazzmen who developed in the first half of the 20th century began by playing Bal-musette in the city. Django Reinhardt rose to fame in Paris, having moved to the 18th arrondissement in a caravan as a young boy, and performed with violinist Stéphane Grappelli and their Quintette du Hot Club de France in the 1930s and 1940s.
Immediately after the War The Saint-Germain-des-Pres quarter and the nearby Saint-Michel quarter became home to many small jazz clubs, mostly found in cellars because of a lack of space; these included the Caveau des Lorientais, the Club Saint-Germain, the Rose Rouge, the Vieux-Colombier, and the most famous, Le Tabou. They introduced Parisians to the music of Claude Luter, Boris Vian, Sydney Bechet Mezz Mezzrow, and Henri Salvador. Most of the clubs closed by the early 1960s, as musical tastes shifted toward rock and roll. 
Some of the finest manouche musicians in the world are found here playing the cafés of the city at night. Some of the more notable jazz venues include the New Morning, Le Sunset, La Chope des Puces and Bouquet du Nord. Several yearly festivals take place in Paris, including the Paris Jazz Festival() and the rock festival Rock en Seine. The Orchestre de Paris was established in 1967.
Paris has a big hip hop scene. This music became popular during the 1980s. The presence of a large African and Caribbean community helped to its development, it gave a voice, a political and social status for many minorities.
Cinema.
The movie industry was born in Paris when Auguste and Louis Lumière projected the first motion picture for a paying audience at the Grand Café on 28 December 1895. Many of Paris's concert/dance halls were transformed into movie theatres when the media became popular beginning in the 1930s. Later, most of the largest cinemas were divided into multiple, smaller rooms. Paris's largest cinema room today is in Le Grand Rex theatre with 2,700 seats.Big multiplex movie theaters have been built since the 1990s. UGC Ciné Cité Les Halles with 27 screens, MK2 Bibliothèque with 20 screens and UGC Ciné Cité Bercy with 18 screens are among the largest.
Parisians tend to share the same movie-going trends as many of the world's global cities, with cinemas primarily dominated by Hollywood-generated film entertainment. French cinema comes a close second, with major directors ("réalisateurs") such as Claude Lelouch, Jean-Luc Godard, and Luc Besson, and the more slapstick/popular genre with director Claude Zidi as an example. European and Asian films are also widely shown and appreciated. On 2 February 2000, Philippe Binant realised the first digital cinema projection in Europe, with the DLP CINEMA technology developed by Texas Instruments, in Paris.
Restaurants and cuisine.
Since the late 18th century, Paris has been famous for its restaurants and "haute cuisine", food meticulously prepared and artfully presented. A luxury restaurant, La Taverne Anglaise, opened in 1786 in the arcades of the Palais-Royal by Antoine Beauvilliers; it featured an elegant dining room, an extensive menu, linen tablecloths, a large wine list and well-trained waiters; it became a model for future Paris restaurants. The restaurant Le Grand Véfour in the Palais-Royal dates from the same period. The famous Paris restaurants of the 19th century, including the Café de Paris, the Rocher de Cancale, the Café Anglais, Maison Dorée and the Café Riche, were mostly located near the theatres on the Boulevard des Italiens; they were immortalised in the novels of Balzac and Emile Zola. Several of the best-known restaurants in Paris today appeared during the Belle Epoque, including Maxim's on Rue Royale, Ledoyen in the gardens of the Champs-Élysées, and the Tour d'Argent on the Quai de la Tournelle.
Today, thanks to Paris' cosmopolitan population, every French regional cuisine and almost every national cuisine in the world can be found there; the city has more than 9,000 restaurants. The Michelin Guide has been a standard guide to French restaurants since 1900, awarding its highest award, three stars, to the best restaurants in France. In 2015, of the 29 Michelin three-star restaurants in France, nine are located in Paris. These include both restaurants which serve classical French cuisine, such as L'Ambroisie in the Place des Vosges, and those which serve non-traditional menus, such as L'Astrance, which combines French and Asian cuisines. Several of France's most famous chefs, including Pierre Gagnaire, Alain Ducasse, Yannick Alléno and Alain Passard, have three-star restaurants in Paris.
In addition to the classical restaurants, Paris has several other kinds of traditional eating places. The café arrived in Paris in the 17th century, when the beverage was first brought from Turkey, and by the 18th century Parisian cafés were centres of the city's political and cultural life. The Cafe Procope on the Left Bank dates from this period. In the 20th century, the cafés of the Left Bank, especially Café de la Rotonde and Le Dôme Café in Montparnasse and Café de Flore and Les Deux Magots on Boulevard Saint Germain, all still in business, were important meeting places for painters, writers and philosophers. A bistro is a type of eating place loosely defined as a neighbourhood restaurant with a modest decor and prices and a regular clientele and a congenial atmosphere. Its name is said to have come in 1814 from the Russian soldiers who occupied the city; "bistro" means "quickly" in Russian, and they wanted their meals served rapidly so they could get back their encampment. Real bistros are increasingly rare in Paris, due to rising costs, competition from cheaper ethnic restaurants, and different eating habits of Parisian diners. A brasserie originally was a tavern located next to a brewery, which served beer and food at any hour. Beginning with the Paris Exposition of 1867; it became a popular kind of restaurant which featured beer and other beverages served by young women in the national costume associated with the beverage, particular German costumes for beer. Now brasseries, like cafés, serve food and drinks throughout the day.
Fashion.
Paris has been an international capital of high fashion since the 19th century, particularly in the domain of haute couture, clothing hand-made to order for private clients. It is home of some of the largest fashion houses in the world, including Dior and Chanel, and of many well-known fashion designers, including Karl Lagerfeld, Jean-Paul Gaultier, Christophe Josse and Christian Lacroix. Paris Fashion Week, held in January and July in the Carrousel du Louvre and other city locations, is among the top four events of the international fashion calendar, along with the fashion weeks in Milan, London and New York. Paris is also the home of the world's largest cosmetics company, L'Oréal, and three of the five top global makers of luxury fashion accessories; Louis Vuitton, Hermés and Cartier.
Holidays and festivals.
Bastille Day, a celebration of the storming of the Bastille in 1789, the biggest festival in the city, is a military parade taking place every year on 14 July on the Champs-Élysées, from the Arc de Triomphe to Place de la Concorde. It includes a flypast over the Champs Élysées by the "Patrouille de France", a parade of military units and equipment, and a display of fireworks in the evening, the most spectacular being the one at the Eiffel Tower.
Other yearly festivals are "Paris-Plages", a festive event that lasts from mid-July to mid-August when the Right Bank of the Seine is converted into a temporary beach with sand, deck chairs and palm trees; "Journées du Patrimoine", "Fête de la Musique", "Techno Parade", "Nuit Blanche", "Cinéma au clair de lune", "Printemps des rues", "Festival d'automne" and "Fête des jardins." "Carnaval de Paris", one of the oldest festivals in Paris, dates back to the Middle Ages.
Education.
Paris is the département with the highest proportion of highly educated people. In 2009, around 40 percent of Parisians held a "licence"-level diploma or higher, the highest proportion in France, while 13 percent have no diploma, the third lowest percentage in France.
Education in Paris and the Île-de-France region employs approximately 330,000 people, 170,000 of whom are teachers and professors teaching approximately 2.9 million children and students in around 9,000 primary, secondary, and higher education schools and institutions.
The University of Paris, founded in the 12th century, is often called the Sorbonne after one of its original medieval colleges. It was broken up into thirteen autonomous universities in 1970, following the student demonstrations in 1968. Most of the campuses today are in the Latin Quarter where the old university was located, while others are scattered around the city and the suburbs.
The Paris region hosts France's highest concentration of the "grandes écoles" – 55 specialised centres of higher-education outside the public university structure. The prestigious public universities are usually considered "grands établissements". Most of the "grandes écoles" were relocated to the suburbs of Paris in the 1960s and 1970s, in new campuses much larger than the old campuses within the crowded city of Paris, though the École Normale Supérieure has remained on rue d'Ulm in the 5th arrondissement. There are a high number of engineering schools, led by the Paris Institute of Technology which comprises several colleges such as "École Polytechnique", "École des Mines", "AgroParisTech", "Télécom Paris", "Arts et Métiers", and "École des Ponts et Chaussées". There are also many business schools, including HEC, INSEAD, ESSEC, and ESCP Europe. The administrative school such as ENA has been relocated to Strasbourg, the political science school Sciences-Po is still located in Paris's 7th arrondissement and the most prestigious university of economics and finance, Paris-Dauphine, is located in Paris's 16th. The Parisian school of journalism CELSA department of the Paris-Sorbonne University is located in Neuilly-sur-Seine. Paris is also home to several of France's most famous high-schools such as Lycée Louis-le-Grand, Lycée Henri-IV, Lycée Janson de Sailly and Lycée Condorcet. The National Institute of Sport and Physical Education, located in the 12th arrondissement, is both a physical education institute and high-level training centre for elite athletes.
Libraries.
The "Bibliothèque nationale de France" (BnF) operates public libraries in Paris, among them the François Mitterrand Library, Richelieu Library, Louvois, Opéra Library, and Arsenal Library. There are three public libraries in the 4th arrondissement. The Forney Library, in the Marais district, is dedicated to the decorative arts; the Arsenal Library occupies a former military building, and has a large collection on French literature; and the Bibliothèque historique de la ville de Paris, also in Le Marais, contains the Paris historical research service. The Sainte-Geneviève Library is in 5th arrondissement; designed by Henri Labrouste and built in the mid-1800s, it contains a rare book and manuscript division. Bibliothèque Mazarine, in the 6th arrondissement, is the oldest public library in France. The Médiathèque Musicale Mahler in the 8th arrondissement opened in 1986 and contains collections related to music. The François Mitterrand Library (nicknamed "Très Grande Bibliothèque") in the 13th arrondissement was completed in 1994 to a design of Dominique Perrault and contains four glass towers.
There are several academic libraries and archives in Paris. The Sorbonne Library in the 5th arrondissement is the largest university library in Paris. In addition to the Sorbonne location, there are branches in Malesherbes, Clignancourt-Championnet, Michelet-Institut d'Art et d'Archéologie, Serpente-Maison de la Recherche, and Institut des Etudes Ibériques. Other academic libraries include Interuniversity Pharmaceutical Library, Leonardo da Vinci University Library, Paris School of Mines Library, and the René Descartes University Library.
Churches, Mosques and Temples.
Christianity.
Like the rest of France, Paris has been predominantly Roman Catholic since the early Middle Ages, though religious attendance is now low. A majority of Parisians are still nominally Roman Catholic. According to 2011 statistics, there are 106 parishes and curates in the city, plus separate parishes for Spanish, Polish and Portuguese Catholics. There are an additional 10 Eastern Orthodox parishes, and bishops for the Armenian and Ukrainian Orthodox Churches. In addition there are eighty male religious orders and 140 female religious orders in the city, as well as 110 Catholic schools with 75,000 students.
The principal Roman Catholic church in Paris is the Cathedral of Notre-Dame de Paris, the seat of the Archbishop of Paris. There are two officially recognised pilgrimage sites in Paris: the Basilica of Sacré-Cœur on Montmartre and the Chapel of Our Lady of the Miraculous Medal. Cardinal André Vingt-Trois became the Archbishop of Paris in March 2005.
Almost all Protestant denominations are represented in Paris, with 74 evangelical churches from various denominations, including 21 parishes of the United Protestant Church of France and two parishes of the Church of Jesus Christ of the Latter-Day Saints. There are several important churches for the English-speaking community: the American Church in Paris, founded in 1814, was the first American church outside the United States; the current church was finished in 1931. The Saint George's Anglican Church in the 16th arrondissement is the principal Anglican church in the city.
Islam.
The Grand Mosque of Paris, the oldest mosque in Paris, was dedicated in 1926. It was funded by the French government and built to honor the 38,000 soldiers from Algeria, Tunisia and Morocco who died fighting for France in the First World War.
In 2011 there were nineteen large mosques within the city limits of Paris, all except the Grand Mosque located in the outer arrondissements of the city, as well as hundreds of small prayer rooms. The number of mosques doubled between 1991 and 2011.
Judaism.
During the Middle Ages, Paris was a center of Jewish learning with famous Talmudic scholars, such as Yechiel of Paris who took part in the Disputation of Paris between Christian and Jewish intellectuals. The Parisian Jewish community was victim of persecution, alternating expulsions and returns, until France became the first country in Europe to emancipate its Jewish population during the French Revolution. Although 75% of the Jewish population in France survived the Holocaust during World War II, half the city's Jewish population perished in Nazi concentration camps, while some others fled abroad. A large migration of North Africa Sephardic Jews settled Paris in the 1960s, and represent most of the Paris Jewish community today. There are currently 83 synagogues in the city; The Marais-quarter Agoudas Hakehilos Synagogue, built in 1913 by architect Hector Guimard, is a Paris landmark.
Buddhism and Hinduism.
The Pagode de Vincennes Buddhist temple, near Lake Daumesnil in the Bois de Vincennes, is the former Cameroon pavilion from the 1931 Paris Colonial Exposition. It hosts several different schools of Buddhism, and does not have a single leader. It shelters the biggest Buddha statue in Europe, more than nine metres high. There are two other small temples located in the Asian community in the 13th arrondissement. A Hindu temple, dedicated to Ganesh, on Rue Pajol in the 18th arrondissement, opened in 1985.
Sports.
Paris's most popular sport clubs are the association football club Paris Saint-Germain F.C. and the rugby union club Stade Français. The 80,000-seat Stade de France, built for the 1998 FIFA World Cup, is located just north of Paris in the commune of Saint-Denis. It is used for football, rugby union and track and field athletics. It hosts the French national football team for friendlies and major tournaments qualifiers, annually hosts the French national rugby team's home matches of the Six Nations Championship, and hosts several important matches of the Stade Français rugby team. In addition to Paris Saint-Germain FC, the city has a number of other amateur football clubs: Paris FC, Red Star, RCF Paris and Stade Français Paris.
Paris played host to the 1900 and 1924 Olympic Games and was a candidate city for the Olympics in 1992, 2008 and 2012. The city also played host to the finals of the 1938 FIFA World Cup (at the Stade Olympique de Colombes), as well as the 1998 FIFA World Cup and the 2007 Rugby World Cup Final (both at the Stade de France). Also hosted at the Stade de France, two UEFA Champions League Finals in the current century: 2000 and 2006 editions.
The final stage of the most famous bicycle racing in the world, Tour de France, always finishes in Paris, and, since 1975, the race has finished on the Champs-Elysées.
Tennis is another popular sport in Paris and throughout France; the French Open, held every year on the red clay of the Roland Garros National Tennis Centre, is one of the four Grand Slam events of the world professional tennis tour. The basketball team Paris-Levallois Basket play at the 4,000 capacity Stade Pierre de Coubertin.
The 17,000-seat Bercy Arena (formerly known as the "Palais Omnisports de Paris-Bercy") is the venue for the annual Paris Masters ATP Tour tennis tournament and has been a frequent site of national and international tournaments in basketball, boxing, cycling, handball, ice hockey, show jumping and other sports.
Upcoming events Paris will host include UEFA Euro 2016 at the Parc des Princes and the 2017 IIHF World Championship at Bercy Arena co hosting with Cologne, Germany.
Infrastructure.
Transportation.
Paris is a major rail, highway, and air transport hub. The Syndicat des transports d'Île-de-France (STIF), formerly "Syndicat des transports parisiens" (STP), oversees the transit network in the region. The syndicate coordinates public transport and contracts it out to the RATP (operating 347 bus lines, the Métro, eight tramway lines, and sections of the RER), the SNCF (operating suburban rails, one tramway line and the other sections of the RER) and the Optile consortium of private operators managing 1,176 bus lines.
Rail.
A central hub of the national rail network, Paris' six major railway stations (Gare du Nord, Gare de l'Est, Gare de Lyon, Gare d'Austerlitz, Gare Montparnasse, Gare Saint-Lazare) and a minor one (Gare de Bercy) are connected to three networks: the TGV serving four high-speed rail lines, the normal speed Corail trains, and the suburban rails (Transilien).
Métro, RER, and tramway.
Since the inauguration of its first line in 1900, Paris' "Métro" subway network has grown to become the city's most widely used local transport system; today it carries about 5.23 million passengers daily through 16 lines, 303 stations (385 stops) and of rails. Superimposed on this is a 'regional express network', the RER, whose five lines (A, B, C, D, and E), 257 stops and of rails connect Paris to more distant parts of the urban area.
Over €26.5 billion will be invested over the next 15 years to extend the Métro network into the suburbs, with notably the Grand Paris Express project.
In addition, the Paris region is served by a light rail network of nine lines, the tramway: Line T1 runs from Asnières-Gennevilliers to Noisy-le-Sec, line T2 runs from Pont de Bezons to Porte de Versailles, line T3a runs from Pont du Garigliano to Porte de Vincennes, line T3b runs from Porte de Vincennes to Porte de la Chapelle, line T5 runs from Saint-Denis to Garges-Sarcelles, line T6 runs from Châtillon to Velizy, line T7 runs from Villejuif to Athis-Mons, line T8 runs from Saint-Denis to Épinay-sur-Seine and Villetaneuse, all of which are operated by the "Régie Autonome des Transports Parisiens", and line T4 runs from Bondy RER to Aulnay-sous-Bois, which is operated by the state rail carrier SNCF. Five new light rail lines are currently in various stages of development.
Air.
Paris is a major international air transport hub with the 4th busiest airport system in the world. The city is served by three commercial international airports: Paris-Charles de Gaulle, Paris-Orly and Beauvais-Tillé. Together these three airports recorded traffic of 96.5 million passengers in 2014. There is also one general aviation airport, Paris-Le Bourget, historically the oldest Parisian airport and closest to the city centre, which is now used only for private business flights and air shows.
Orly Airport, located in the southern suburbs of Paris, replaced Le Bourget as the principal airport of Paris from the 1950s to the 1980s. Charles de Gaulle Airport, located on the edge of the northern suburbs of Paris, opened to commercial traffic in 1974 and became the busiest Parisian airport in 1993. Today it is the 4th busiest airport in the world by international traffic, and is the hub for the nation's flag carrier Air France. Beauvais-Tillé Airport, located 69 km (43 mi) north of Paris's city centre, is used by charter airlines and low-cost carriers such as Ryanair.
In 2014 the main domestic and international destinations served by the three commercial airports of Paris were the following:
Domestically, air travel between Paris and some of France's largest cities such as Lyon, Marseille, or Strasbourg has been in a large measure replaced by high-speed rail due to the opening of several high-speed TGV rail lines from the 1980s. For example, after the LGV Méditerranée opened in 2001, air traffic between Paris and Marseille declined from 2,976,793 passengers in 2000 to 1,502,196 passengers in 2014. After the LGV Est opened in 2007, air traffic between Paris and Strasbourg declined from 1,006,327 passengers in 2006 to 157,207 passengers in 2014.
Internationally, air traffic has increased markedly in recent years between Paris and the Gulf airports, the emerging nations of Africa, Russia, Turkey, Portugal, Italy, and mainland China, whereas noticeable decline has been recorded between Paris and the British Isles, Egypt, Tunisia, and Japan.
Motorways.
The city is also the most important hub of France's motorway network, and is surrounded by three orbital freeways: the Périphérique, which follows the approximate path of 19th-century fortifications around Paris, the A86 motorway in the inner suburbs, and finally the Francilienne motorway in the outer suburbs. Paris has an extensive road network with over of highways and motorways.
Waterways.
The Paris region is the most active water transport area in France, with most of the cargo handled by Ports of Paris in facilities located around Paris. The Loire, Rhine, Rhone, Meuse and Scheldt rivers can be reached by canals connecting with the Seine, which include the Canal Saint-Martin, Canal Saint-Denis, and the Canal de l'Ourcq.
Cycling.
There are of cycle paths and routes in Paris. These include "piste cyclable" (bike lanes separated from other traffic by physical barriers such as a kerb) and "bande cyclable" (a bicycle lane denoted by a painted path on the road). Some of specially marked bus lanes are free to be used by cyclists, with a protective barrier protecting against encroachments from vehicles. Cyclists have also been given the right to ride in both directions on certain one-way streets. Paris offers a bike sharing system called Vélib' with more than 20,000 public bicycles distributed at 1,800 parking stations, which can be rented for short and medium distances including one way trips.
Electricity.
Paris is provided in electricity through a 'periphery' grid fed by multiple sources. As of 2012, around 50% of electricity generated in the Île-de-France comes from cogeneration energy plants located near the outer limits of the region; other energy sources include the Nogent nuclear power plant (35%), trash incineration (9% - with cogeneration plants, these provide the city in heat as well), methane gas (5%), hydraulics (1%), solar power (0.1%) and a negligible amount of wind power (0.034 GWh).
Water and sanitation.
Paris in its early history had only the Seine and Bièvre rivers for water. From 1809, the Canal de l'Ourcq provided Paris with water from less-polluted rivers to the north-east of the capital. From 1857, the civil engineer Eugène Belgrand, under Napoleon III, oversaw the construction of a series of new aqueducts that brought water from locations all around the city to several reservoirs built atop the Capital's highest points of elevation. From then on, the new reservoir system became Paris's principal source of drinking water, and the remains of the old system, pumped into lower levels of the same reservoirs, were from then on used for the cleaning of Paris's streets. This system is still a major part of Paris's modern water-supply network. Today Paris has more than of underground passageways dedicated to the evacuation of Paris's liquid wastes.
In 1982, Mayor Chirac introduced the motorcycle-mounted Motocrotte to remove dog faeces from Paris streets. The project was abandoned in 2002 for a new and better enforced local law, under the terms of which dog owners can be fined up to €500 for not removing their dog faeces. The air pollution in Paris, from the point of view of particulate matter (PM10), is the highest in France with 38 µg/m³.
Parks and gardens.
Paris today has more than 421 municipal parks and gardens, covering more than 3,000 hectares and containing more than 250,000 trees. Two of Paris's oldest and most famous gardens are the Tuileries Garden, created in 1564 for the Tuileries Palace, and redone by André Le Nôtre between 1664 and 1672, and the Luxembourg Garden, for the Luxembourg Palace, built for Marie de' Medici in 1612, which today houses the French Senate. The "Jardin des Plantes" was the first botanical garden in Paris, created in 1626 by Louis XIII's doctor Guy de La Brosse for the cultivation of medicinal plants. Between 1853 and 1870, the Emperor Napoleon III and the city's first director of parks and gardens, Jean-Charles Alphand, created the "Bois de Boulogne", the "Bois de Vincennes", "Parc Montsouris" and the "Parc des Buttes-Chaumont", located at the four points of the compass around the city, as well as many smaller parks, squares and gardens in the Paris's quarters. Since 1977, the city has created 166 new parks, most notably the "Parc de la Villette" (1987), "Parc André Citroën" (1992), and "Parc de Bercy" (1997). One of the newest parks, the "Promenade des Berges de la Seine" (2013), built on a former highway on the Left Bank of the Seine between the "Pont de l'Alma" and the "Musée d'Orsay", has floating gardens and gives a view of the city's landmarks.
Cemeteries.
In Paris's Roman era, its main cemetery was located to the outskirts of the Left Bank settlement, but this changed with the rise of Catholicism, where most every inner-city church had adjoining burial grounds for use by their parishes. With Paris's growth many of these, particularly the city's largest cemetery, "les Innocents", were filled to overflowing, creating quite unsanitary conditions for the capital. When inner-city burials were condemned from 1786, the contents of all Paris's parish cemeteries were transferred to a renovated section of Paris's stone mines outside the "Porte d'Enfer" city gate, today place Denfert-Rochereau in the 14th arrondissement. The process of moving bones from "Cimetière des Innocents" to the catacombs took place between 1786 and 1814; part of the network of tunnels and remains can be visited today on the official tour of the catacombs. After a tentative creation of several smaller suburban cemeteries, the Prefect Nicholas Frochot under Napoleon Bonaparte provided a more definitive solution in the creation of three massive Parisian cemeteries outside the city limits. Open from 1804, these were the cemeteries of Père Lachaise, Montmartre, Montparnasse, and later Passy; these cemeteries became inner-city once again when Paris annexed all neighbouring communes to the inside of its much larger ring of suburban fortifications in 1860. New suburban cemeteries were created in the early 20th century: The largest of these are the "Cimetière parisien de Saint-Ouen", the "Cimetière parisien de Pantin" (also known as "Cimetière parisien de Pantin-Bobigny", the "Cimetière parisien d'Ivry", and the "Cimetière parisien de Bagneux"). Some of the most famous people in the world are buried in Parisian cemeteries, including musicians Frédéric Chopin, Édith Piaf and Jim Morrison; writers Alexandre Dumas, Honoré de Balzac, Marcel Proust, Molière and Oscar Wilde; and dancers Isadora Duncan and Vaslav Nijinsky.
Healthcare.
Health care and emergency medical service in the city of Paris and its suburbs are provided by the "Assistance publique - Hôpitaux de Paris (AP-HP)", a public hospital system that employs more than 90,000 people (including practitioners, support personnel, and administrators) in 44 hospitals. It is the largest hospital system in Europe. It provides health care, teaching, research, prevention, education and emergency medical service in 52 branches of medicine. The hospitals receive more than 5.8 million annual patient visits.
One of the most notable hospitals is the Hôtel-Dieu, founded in 651, the oldest hospital in the city. Other hospitals include Pitié-Salpêtrière Hospital (one of the largest in Europe), Hôpital Cochin, Hôpital Bichat, Hôpital Européen Georges-Pompidou, Bicêtre Hospital, Beaujon Hospital, the Curie Institute, Lariboisière Hospital, Necker-Enfants Malades Hospital, Hôpital Saint-Louis, Hôpital de la Charité and the American Hospital of Paris.
Media.
Paris and its close suburbs is home to numerous newspapers, magazines and publications including "Le Monde", "Le Figaro", "Libération", "Le Nouvel Observateur", "Le Canard enchaîné", "La Croix", "Pariscope", "Le Parisien (in" "Saint-Ouen"), "Les Échos", "Paris Match (Neuilly-sur-Seine)", "Réseaux & Télécoms", Reuters France, and "L'Officiel des Spectacles". France's two most prestigious newspapers, "Le Monde" and "Le Figaro", are the centrepieces of the Parisian publishing industry. Agence France-Presse is France's oldest, and one of the world's oldest, continually operating news agencies. AFP, as it is colloquially abbreviated, maintains its headquarters in Paris, as it has since 1835. France 24 is a television news channel owned and operated by the French government, and is based in Paris. Another news agency is France Diplomatie, owned and operated by the Ministry of Foreign and European Affairs, and pertains solely to diplomatic news and occurrences.
The most-viewed network in France, TF1, is in nearby Boulogne-Billancourt; France 2, France 3, Canal+, France 5, M6 (Neuilly-sur-Seine), Arte, D8, W9, NT1, NRJ 12, La Chaîne parlementaire, France 4, BFM TV, and Gulli are other stations located in and around the capital. Radio France, France's public radio broadcaster, and its various channels, is headquartered in Paris's 16th arrondissement. Radio France Internationale, another public broadcaster is also based in the city. Paris also holds the headquarters of the La Poste, France's national postal carrier.
Twin towns and partner cities.
Paris is since April 9, 1956 exclusively and reciprocally twinned only with:
Paris has pact of friendship and cooperation with:

</doc>
<doc id="22990" url="https://en.wikipedia.org/wiki?curid=22990" title="Postmaster">
Postmaster

A postmaster is the head of an individual post office. When a postmaster is responsible for an entire mail distribution organization (usually sponsored by a national government), the title of Postmaster General is commonly used. 
Responsibilities of a postmaster typically include management of a centralized mail distribution facility, establishment of letter carrier routes, supervision of letter carriers and clerks, and enforcement of the organization's rules and procedures.
In the United States, women have served as postmasters since the Revolutionary War and even earlier, under British rule. "Postmaster," regardless of the person's sex, has always been the official title for this position.
In Canada, many early places are named after the first postmaster.
Use in coaching.
In the days of horse-drawn carriages, a postmaster was an individual from whom horses and/or riders (known as postilions or "post-boys") could be hired. The postmaster would reside in a "post house".
Earnings in the US.
In the United States, many postmasters are members of a management organization which consults with the United States Postal Service (USPS) for compensation and policy. The two management organizations are the National Association of Postmasters of the United States (NAPUS) which has approximately 80% of postmasters as members and the National League of Postmasters, which is a smaller group. Some postmasters are members of both organizations.
USPS postmaster annual salaries average around $60,000, with the upper limit being approximately $110,000 and an entry level salary of $55,000.
The level of pay is based on deliveries and revenue of the post office. Levels are from EAS (Executive and Administrative Service) 11 through 26. Smaller part-time post offices are EP levels 51-55. Larger metropolitan post offices are PCES (Postal Career Executive Service).

</doc>
<doc id="22993" url="https://en.wikipedia.org/wiki?curid=22993" title="Postmaster General">
Postmaster General

A Postmaster General, in many countries, is the chief executive officer of the postal service of that country, responsible for oversight over all other Postmasters. The practice of having a government official responsible for overseeing the delivery of mail throughout the nation originated in England, where a "Master of the Posts" is mentioned in the "King's Book of Payments", with a payment of £100 being authorised for Tuke as master of the posts in February 1512. Belatedly, in 1517, he was officially appointed to the office of "Governor of the King's Posts", a precursor to the office of Postmaster General of the United Kingdom, by Henry VIII. In 1609 it was decreed that letters could only be carried and delivered by persons authorised by the Postmaster General.
Other examples include:

</doc>
<doc id="22994" url="https://en.wikipedia.org/wiki?curid=22994" title="Paul Cohen">
Paul Cohen

Paul Joseph Cohen (April 2, 1934 – March 23, 2007) was an American mathematician. He is best known for his proofs that the continuum hypothesis and the axiom of choice are independent from Zermelo–Fraenkel set theory, for which he was awarded a Fields Medal.
Early years.
Cohen was born in Long Branch, New Jersey, into a Jewish family that had immigrated to the United States from what is now Poland; he grew up in Brooklyn. He graduated in 1950, at age 16, from Stuyvesant High School in New York City.
Cohen next studied at the Brooklyn College from 1950 to 1953, but he left before earning his bachelor's degree when he learned that he could start his graduate studies at the University of Chicago with just two years of college. At Chicago, Cohen completed his master's degree in mathematics in 1954 and his Doctor of Philosophy degree in 1958, under supervision of the Professor of Mathematics, Antoni Zygmund. The title of his doctoral thesis was "Topics in the Theory of Uniqueness of Trigonometrical Series".
Contributions to mathematics.
Cohen is noted for developing a mathematical technique called forcing, which he used to prove that neither the continuum hypothesis (CH), nor the axiom of choice, can be proved from the standard Zermelo–Fraenkel axioms (ZF) of set theory. In conjunction with the earlier work of Gödel, this showed that both of these statements are logically independent of the ZF axioms: these statements can be neither proved nor disproved from these axioms. In this sense, the continuum hypothesis is undecidable, and it is the most widely known example of a natural statement that is independent from the standard ZF axioms of set theory.
For his result on the continuum hypothesis, Cohen won the Fields Medal in mathematics in 1966, and also the National Medal of Science in 1967. The Fields Medal that Cohen won continues to be the only Fields Medal to be awarded for a work in mathematical logic, as of 2014.
Apart from his work in set theory, Cohen also made many valuable contributions to analysis. He was awarded the Bôcher Memorial Prize in mathematical analysis in 1964 for his paper "On a conjecture by Littlewood and idempotent measures", and lends his name to the Cohen-Hewitt factorization theorem.
Cohen was a full professor of mathematics at Stanford University, where he supervised Peter Sarnak's graduate research, among those of other students.
Angus MacIntyre of the University of London stated about Cohen: "He was dauntingly clever, and one would have had to be naive or exceptionally altruistic to put one's 'hardest problem' to the Paul I knew in the '60s." He went on to compare Cohen to Kurt Gödel, saying: "Nothing more dramatic than their work has happened in the history of the subject." Gödel himself wrote a letter to Cohen in 1963, a draft of which stated, "Let me repeat that it is really a delight to read your proof of the ind[ependence] of the cont[inuum] hyp[othesis]. I think that in all essential respects you have given the best possible proof & this does not happen frequently. Reading your proof had a similarly pleasant effect on me as seeing a really good play."
On the continuum hypothesis.
While studying the continuum hypothesis, Cohen is quoted as saying in 1985 that he had "had the feeling that people thought the problem was hopeless, since there was no new way of constructing models of set theory. Indeed, they thought you had to be slightly crazy even to think about the problem."
"A point of view which the author [Cohen] feels may eventually come to be accepted is that CH is obviously false. The main reason one accepts the axiom of infinity is probably that we feel it absurd to think that the process of adding only one set at a time can exhaust the entire universe. Similarly with the higher axioms of infinity. Now formula_1 is the cardinality of the set of countable ordinals, and this is merely a special and the simplest way of generating a higher cardinal. The set formula_2 [the continuum] is, in contrast, generated by a totally new and more powerful principle, namely the power set axiom. It is unreasonable to expect that any description of a larger cardinal which attempts to build up that cardinal from ideas deriving from the replacement axiom can ever reach formula_2.
Thus formula_2 is greater than formula_5, where formula_6, etc. This point of view regards formula_2 as an incredibly rich set given to us by one bold new axiom, which can never be approached by any piecemeal process of construction. Perhaps later generations will see the problem more clearly and express themselves more eloquently."
An "enduring and powerful product" of Cohen's work on the continuum hypothesis, and one that has been used by "countless mathematicians" is known as "forcing", and it is used to construct mathematical models to test a given hypothesis for truth or falsehood.
Shortly before his death, Cohen gave a lecture describing his solution to the problem of the continuum hypothesis at the Gödel centennial conference, in Vienna in 2006. A video of this lecture is now available online.

</doc>
<doc id="22995" url="https://en.wikipedia.org/wiki?curid=22995" title="Patti Smith">
Patti Smith

Patricia Lee "Patti" Smith (born December 30, 1946) is an American singer-songwriter, poet and visual artist who became a highly influential component of the New York City punk rock movement with her 1975 debut album "Horses".
Called the "punk poet laureate", Smith fused rock and poetry in her work. Smith's most widely known song is "Because the Night", which was co-written with Bruce Springsteen. The song reached number 13 on the "Billboard" Hot 100 chart in 1978. In 2005, Patti Smith was named a Commander of the Ordre des Arts et des Lettres by the French Ministry of Culture, and in 2007, she was inducted into the Rock and Roll Hall of Fame. On November 17, 2010, she won the National Book Award for her memoir "Just Kids". The book fulfilled a promise she had made to her former long-time roommate and partner, Robert Mapplethorpe. She is also a recipient of the 2011 Polar Music Prize.
Life and career.
1946–1967: Early life.
Patricia Lee Smith was born in Chicago. Her mother, Beverly, was a waitress, and her father, Grant, worked at the Honeywell plant. The family was of Irish ancestry. She spent her early childhood in the Germantown neighborhood of Philadelphia, before her family moved to Woodbury, New Jersey. Her mother was a Jehovah's Witness. Patti had a strong religious upbringing and a Bible education, but left organized religion as a teenager because she felt it was too confining; much later, she wrote the line "Jesus died for somebody's sins, but not mine" in her cover version of Them's "Gloria" in response to this experience. She has described having an avid interest in Tibetan Buddhism around the age of eleven or twelve, saying "I fell in love with Tibet because their essential mission was to keep a continual stream of prayer," but that as an adult she sees clear parallels between different forms of religion, and has come to the conclusion that religious dogmas are "... man-made laws that you can either decide to abide by or not." At this early age Smith was exposed to her first records, including "Shrimp Boats" by Harry Belafonte, Patience and Prudence doing "The Money Tree", and "Another Side of Bob Dylan", which her mother gave to her. Smith graduated from Deptford Township High School in 1964 and went to work in a factory. She gave birth to her first child, a daughter, on April 26, 1967, and chose to place her for adoption.
1967–1973: New York.
In 1967, she left Glassboro State College (now Rowan University) and moved to New York City. She met photographer Robert Mapplethorpe there while working at a book store with a friend, poet Janet Hamill. She and Mapplethorpe had an intense romantic relationship, which was tumultuous as the pair struggled with times of poverty, and Mapplethorpe with his own sexuality. Smith considers Mapplethorpe to be one of the most important people in her life, and in her book "Just Kids" refers to him as "the artist of my life". Mapplethorpe's photographs of her became the covers for the Patti Smith Group LPs, and they remained friends until Mapplethorpe's death in 1989. In 1969 she went to Paris with her sister and started busking and doing performance art. When Smith returned to New York City, she lived in the Hotel Chelsea with Mapplethorpe; they frequented Max's Kansas City and CBGB. Smith provided the spoken word soundtrack for Sandy Daley's art film "Robert Having His Nipple Pierced", starring Mapplethorpe. The same year Smith appeared with Wayne County in Jackie Curtis's play "Femme Fatale". Afterward, she also starred in Tony Ingrassia's play "Island". As a member of the St. Mark's Poetry Project, she spent the early 1970s painting, writing, and performing. In 1971 she performed – for one night only – in "Cowboy Mouth", a play that she co-wrote with Sam Shepard. (The published play's notes call for "a man who looks like a coyote and a woman who looks like a crow".) She wrote several poems, "for sam shepard" and "Sam Shepard: 9 Random Years (7 + 2)" about her relationship with Shepard.
Smith was briefly considered for the lead singer position in Blue Öyster Cult. She contributed lyrics to several of the band's songs, including "Debbie Denise" (inspired by her poem "In Remembrance of Debbie Denise"), "Baby Ice Dog", "Career of Evil", "Fire of Unknown Origin", "The Revenge of Vera Gemini" (on which she performs duet vocals), and "Shooting Shark". She was romantically involved at the time with the band's keyboardist, Allen Lanier. During these years, Smith also wrote rock journalism, some of which was published in "Rolling Stone" and "Creem".
1974–1979: Patti Smith Group.
By 1974, Patti Smith was performing rock music herself, initially with guitarist, bassist and rock archivist Lenny Kaye, and later with a full band comprising Kaye, Ivan Kral on guitar and bass, Jay Dee Daugherty on drums and Richard Sohl on piano. Ivan Kral was a refugee from Czechoslovakia, he moved to the USA in 1966 with his parents who were diplomats. After the Warsaw Pact invasion of Czechoslovakia in 1968, Kral decided not to return. Financed by Sam Wagstaff, the band recorded a first single, "Hey Joe / Piss Factory", in 1974. The A-side was a version of the rock standard with the addition of a spoken word piece about fugitive heiress Patty Hearst ("Patty Hearst, you're standing there in front of the Symbionese Liberation Army flag with your legs spread, I was wondering were you gettin' it every night from a black revolutionary man and his women ..."). The B-side describes the helpless anger Smith had felt while working on a factory assembly line and the salvation she discovered in the form of a shoplifted book, the 19th century French poet Arthur Rimbaud's "Illuminations". In a 1996 interview which discusses artistic influences during her young years, Smith said, "I had devoted so much of my girlish daydreams to Rimbaud. Rimbaud was like my boyfriend."
Later that same year, she performed spoken poetry on "I Wake Up Screaming" from Ray Manzarek's "The Whole Thing Started with Rock & Roll Now It's Out of Control" album.
The Patti Smith Group was signed by Clive Davis of Arista Records, and in 1975 recorded their first album, "Horses", produced by John Cale amid some tension. The album fused punk rock and spoken poetry and begins with a cover of Van Morrison's "Gloria", and Smith's opening words: "Jesus died for somebody's sins but not mine" (an excerpt from "Oath", one of her early poems). The austere cover photograph by Mapplethorpe has become one of rock's classic images. As the popularity of punk rock grew, Patti Smith Group toured the United States and Europe. The rawer sound of the group's second album, "Radio Ethiopia", reflected this. Considerably less accessible than "Horses", "Radio Ethiopia" initially received poor reviews. However, several of its songs have stood the test of time, and Smith still performs them regularly in concert. She has said that "Radio Ethiopia" was influenced by the band MC5.
On January 23, 1977, while touring in support of "Radio Ethiopia", Smith accidentally danced off a high stage in Tampa, Florida, and fell 15 feet into a concrete orchestra pit, breaking several neck vertebrae. The injury required a period of rest and an intensive round of physical therapy, during which time she was able to reassess, re-energize and reorganize her life. Patti Smith Group produced two further albums before the end of the 1970s. "Easter" (1978) was her most commercially successful record, containing the single "Because the Night" co-written with Bruce Springsteen. "Wave" (1979) was less successful, although the songs "Frederick" and "Dancing Barefoot" both received commercial airplay.
1980–1995: Marriage.
Before the release of "Wave", Smith, now separated from long-time partner Allen Lanier, met Fred "Sonic" Smith, former guitar player for Detroit rock band MC5 and his own Sonic's Rendezvous Band, who adored poetry as much as she did. ("Wave"'s "Dancing Barefoot" and "Frederick" were both dedicated to him.) The running joke at the time was that she married Fred only because she would not have to change her name. They had a son, Jackson (b. 1982) who would go on to marry The White Stripes drummer, Meg White in 2009; and a daughter, Jesse (b. 1987). Through most of the 1980s Patti Smith was in semi-retirement from music, living with her family north of Detroit in St. Clair Shores, Michigan. In June 1988, she released the album "Dream of Life", which included the song "People Have the Power". Fred Smith died on November 4, 1994, of a heart attack. Shortly afterward, Patti faced the unexpected death of her brother Todd. When her son Jackson turned 14, Smith decided to move back to New York. After the impact of these deaths, her friends Michael Stipe of R.E.M. and Allen Ginsberg (whom she had known since her early years in New York) urged her to go back out on the road. She toured briefly with Bob Dylan in December 1995 (chronicled in a book of photographs by Stipe).
1996–2003: Re-emergence.
In 1996, Smith worked with her long-time colleagues to record "Gone Again," featuring "About a Boy", a tribute to Kurt Cobain. That same year she collaborated with Stipe on "E-Bow the Letter", a song on R.E.M.'s "New Adventures in Hi-Fi," which she has also performed live with the band. After release of "Gone Again," Patti Smith recorded two new albums: "Peace and Noise" in 1997 (with the single "1959", about the invasion of Tibet) and "Gung Ho" in 2000 (with songs about Ho Chi Minh and Smith's late father). Songs "1959" and "Glitter in Their Eyes" were nominated for Grammy Award for Best Female Rock Vocal Performance. A box set of her work up to that time, "The Patti Smith Masters," came out in 1996, and 2002 saw the release of "Land (1975–2002)," a two-CD compilation that includes a memorable cover of Prince's "When Doves Cry". Smith's solo art exhibition "Strange Messenger" was hosted at The Andy Warhol Museum in Pittsburgh on September 28, 2002.
2004–present.
On April 27, 2004, Patti Smith released "Trampin"' which included several songs about motherhood, partly in tribute to Smith's mother, who had died two years before. It was her first album on Columbia Records, soon to become a sister label to her previous home Arista Records. Smith curated the Meltdown festival in London on June 25, 2005, the penultimate event being the first live performance of "Horses" in its entirety. Guitarist Tom Verlaine took Oliver Ray's place. This live performance was released later in the year as "Horses/Horses".
On July 10, 2005, Smith was named a Commander of the Ordre des Arts et des Lettres by the French Ministry of Culture. In addition to Smith's influence on rock music, the Minister also noted her appreciation of Arthur Rimbaud. In August 2005, Smith gave a literary lecture about the poems of Arthur Rimbaud and William Blake. On October 15, 2006, Patti Smith performed at the CBGB nightclub, with a 3½-hour "tour de force" to close out Manhattan's music venue. She took the stage at 9:30 p.m. (EDT) and closed for the night (and forever for the venue) at a few minutes after 1:00 a.m., performing her song "Elegie", and finally reading a list of punk rock musicians and advocates who had died in the previous years.
On November 10, 2005, Smith received the Woman of Valor Award from ROCKRGRL Magazine at the ROCKRGRL Music Conference, marking the 30th Anniversary of the release of "Horses."
Smith was inducted into the Rock and Roll Hall of Fame on March 12, 2007. She dedicated her award to the memory of her late husband, Fred, and gave a performance of The Rolling Stones staple "Gimme Shelter". As the closing number of the Rock and Roll Hall of Fame Induction Ceremony, Smith's "People Have the Power" was used for the big celebrity jam that always ends the program.
From November 2006 - January 2007, an exhibition called 'Sur les Traces' at Trolley Gallery, London, featured polaroid prints taken by Patti Smith and donated to Trolley to raise awareness and funds for the publication of Double Blind, a book on the war in Lebanon in 2006, with photographs by Paolo Pellegrin, a member of Magnum Photos. She also participated in the DVD commentary for "Aqua Teen Hunger Force Colon Movie Film for Theaters". From March 28 to June 22, 2008, the Fondation Cartier pour l'Art Contemporain in Paris hosted a major exhibition of the visual artwork of Patti Smith, "Land 250", drawn from pieces created between 1967 and 2007. At the 2008 Rowan Commencement ceremony, Smith received an honorary doctorate degree for her contributions to popular culture.
Smith is the subject of a 2008 documentary film, "". A live album by Patti Smith and Kevin Shields, "The Coral Sea" was released in July 2008. On September 10, 2009, after a week of smaller events and exhibitions in the city, Smith played an open-air concert in Florence's Piazza Santa Croce, commemorating her performance in the same city 30 years earlier. In the meantime, she contributed with a special introduction to Jessica Lange's book "50 Photographs" (2009).
In 2010, Patti Smith's book, "Just Kids", a memoir of her time in 1970s Manhattan and her relationship with Robert Mapplethorpe, was published; it later won the National Book Award for Nonfiction. On April 30, 2010, Patti Smith headlined a benefit concert headed by band-mate Tony Shanahan, for The Court Tavern of New Brunswick. Smith's set included "Gloria", "Because the Night" and "People Have the Power." She has a brief cameo in Jean-Luc Godard's 2010 "Film Socialisme", which was first screened in the Un Certain Regard section at the 2010 Cannes Film Festival.
On May 17, 2010, Patti Smith received an honorary doctorate in fine arts from Pratt Institute, along with architect Daniel Libeskind, MoMA director Glenn Lowry, former NYC Landmarks Commissioner Barbaralee Diamonstein-Spielvogel, novelist Jonathan Lethem, and director Steven Soderbergh. Following the conferral of her degree, Smith delivered the commencement address and sang/played two songs accompanied by long-time band member Lenny Kaye. In her remarks, Smith explained that in 1967 when she moved to New York City (Brooklyn), she would never have been accepted into Pratt, but most of her friends (including Mapplethorpe) were students at Pratt and she spent countless hours on the Pratt campus. She added that it was through her friends and their Pratt professors that she learned much of her own artistic skills, making the honour from the institute particularly poignant for Smith 43 years later.
Smith is currently working on a crime novel set in London. "I've been working on a detective story that starts at the St Giles in the Fields church in London for the last two years," she told NME adding that she "loved detective stories" having been a fan of Sherlock Holmes and US crime author Mickey Spillane as a girl. Part of the book will be set in Gothenburg, Sweden.
On May 3, 2011, it was announced that Patti Smith is one of the winners of the Polar Music Prize: "By devoting her life to art in all its forms, Patti Smith has demonstrated how much rock'n'roll there is in poetry and how much poetry there is in rock'n'roll. Patti Smith is a Rimbaud with Marshall amps. She has transformed the way an entire generation looks, thinks and dreams. With her inimitable soul of an artist, Patti Smith proves over and over again that people have the power."
On June 19, 2011, Patti Smith made her television acting debut on the TV series "", appearing in an episode called "Icarus".
Smith has recorded a cover of Buddy Holly's classic "Words of Love" for the CD "Rave On Buddy Holly", a tribute album tied to Holly's seventy-fifth birthday year which was released June 28, 2011.
Smith also contributed a track to "AHK-toong BAY-bi Covered", a U2 covers album released through Q Magazine on October 25, 2011. Smith recorded a cover of "Until The End Of The World" for the compilation.
More recently, Smith has devoted her time to what she terms 'pure photography' (a method of capturing still objects without using a flash), which she began to pursue following the death of her husband in 1994. In 2011, Smith announced the first museum exhibition of her photography in the United States, "Camera Solo". She named the project after a sign she saw in the abode of Pope Celestine V, which translates as 'a room of one's own', and which Smith felt best described her solitary method of photography. The exhibition featured artifacts which were the everyday items or places of significance of artists whom Smith admires, including Rimbaud, Baudelaire, Keats and Blake.
In February 2012, she was a guest at the Sanremo Music Festival.
Patti Smith's newest album, Banga (Believe or explode), was released in early June 2012 with critical acclaim. Music Journalist Hal Horowitz wrote : "These songs aren't as loud or frantic as those of her late 70s heyday, but they resonate just as boldly as she moans, chants, speaks and spits out lyrics with the grace and determination of Mohammad Ali in his prime. It's not an easy listen—the vast majority of her music never has been—but if you're a fan and/or prepared for the challenge, this is as potent, heady and uncompromising as she has ever gotten, and with Smith's storied history as a musical maverick, that's saying plenty." Overall, she has stayed true to her style of blending rock and poetry.
Smith provides lead vocals on the title track to Red Hot Chili Peppers bassist Flea's 2012 debut solo EP titled "Helen Burns".
Smith was honored by Bryn Mawr College by receiving the 2013 Katharine Hepburn Medal on February 7, 2013.
Pope Francis greeted Smith, among other officials, visitors, and faithful, in St. Peter's Square on April 11, 2013. Although Smith maintains she is not Catholic, she says she followed the Conclave after Benedict XVI's resignation.
Smith recorded the song "Capitol Letter" for the of the second film of the "Hunger Games"-series "".
As of late December 2013 Smith was working on her second book and still performing.
The Vatican announced that Smith will play at the Concerto di Natale, the official Vatican Christmas Concert, on December 13, 2014; the performance, to be held at Rome's Auditorium Conciliazione, will also be broadcast live on television.
On August 23, 2015, Smith sang "Aqua Teen Dream", the closing theme song to the final episode of Aqua Teen Hunger Force on Adult Swim.
On September 26, 2015, Smith performed during the American Museum of Tort Law convocation ceremony.
On October 29, 2015, Smith sang "People have the power" with U2 as the closing song during their iNNOCENCE + eXPERIENCE tour.
Influence.
Smith has been a great source of inspiration for Michael Stipe of R.E.M. Listening to her album "Horses" when he was 15 made a huge impact on him; he said later, "I decided then that I was going to start a band." In 1998, Stipe published a collection of photos called "Two Times Intro: On the Road with Patti Smith." Stipe sings backing vocals on Smith's songs "Last Call" and "Glitter in Their Eyes." Patti also sings background vocals on R.E.M.'s songs "E-Bow the Letter" and "Blue".
The Australian alternative rock band, The Go-Betweens dedicated a track ("When She Sang About Angels") off their 2000 album, The Friends of Rachel Worth, to Smith's long time influence.
In 2004, Shirley Manson of Garbage spoke of Smith's influence on her in "Rolling Stone"'s issue "The Immortals: 100 Greatest Artists of All Time", in which Patti Smith was counted number 47. The Smiths members Morrissey and Johnny Marr shared an appreciation for Smith's "Horses," and reveal that their song "The Hand That Rocks the Cradle" is a reworking of one of the album's tracks, "Kimberly". In 2004, Sonic Youth released an album called "Hidros 3 (to Patti Smith)". U2 also cites Patti Smith as an influence. In 2005 Scottish singer-songwriter KT Tunstall released the single "Suddenly I See" as a tribute of sorts to Patti Smith. Canadian actress Ellen Page frequently mentions Smith as one of her idols and has done various photo shoots replicating famous Smith photos, as well as Irish actress Maria Doyle Kennedy who often refers to Smith as a major influence. In 1978 and 1979, Gilda Radner portrayed a character called Candy Slice on "Saturday Night Live" based on Smith.
Alternative rock singer-songwriter Courtney Love of Hole heavily credited Smith as being a huge influence on her; Love received Smith's album "Horses" in juvenile hall as a teenager, and "realized that you could do something that was completely subversive that didn't involve violence [or] felonies. I stopped making trouble," said Love. "I stopped." Hole's classic track "Violet" features the lyrics "And the sky was all violet / I want it again, but violent, more violent", alluding to lyrics from Smith's "Kimberly". Love later stated that she considered "Rock n Roll Nigger" the greatest rock song of all time.
American pop-dance singer Madonna has also named Smith as one of her biggest influences.
Anglo-Celtic rock band The Waterboys' debut single, "A Girl Called Johnny", was written as a tribute to Smith.
The influence of Smith's music is featured in two award-winning young adult novels by Meagan Brothers, "Debbie Harry Sings in French" and especially "Supergirl Mixtapes".
Activism.
In 1993, Smith contributed "Memorial Tribute (Live)" to the AIDS-Benefit Album "No Alternative" produced by the Red Hot Organization.
Furthermore, Smith has been a supporter of the Green Party and backed Ralph Nader in the 2000 United States presidential election. She led the crowd singing "Over the Rainbow" and "People Have the Power" at the campaign's rallies, and also performed at several of Nader's subsequent "Democracy Rising" events. Smith was a speaker and singer at the first protests against the Iraq War as U.S. President George W. Bush spoke to the United Nations General Assembly. Smith supported Democratic candidate John Kerry in the 2004 election. Bruce Springsteen continued performing her "People Have the Power" at Vote for Change campaign events. In the winter of 2004/2005, Smith toured again with Nader in a series of rallies against the Iraq War and called for the impeachment of George W. Bush.
Smith premiered two new protest songs in London in September 2006. Louise Jury, writing in "The Independent", characterized them as "an emotional indictment of American and Israeli foreign policy". The song "Qana" was about the Israeli airstrike on the Lebanese village of Qana. "Without Chains" is about Murat Kurnaz, a Turkish citizen who was born and raised in Germany, held at Guantanamo Bay detainment camp for four years. Jury's article quotes Smith as saying:
In an interview, Smith stated that Kurnaz's family has contacted her and that she wrote a short preface for the book that he was writing. Kurnaz's book, "Five Years of My Life," was published in English by Palgrave Macmillan in March 2008, with Patti's introduction.
On March 26, 2003, ten days after Rachel Corrie's death, Smith appeared in Austin, Texas, and performed an anti-war concert. She subsequently wrote a song "Peaceable Kingdom" which was inspired by and is dedicated to Rachel Corrie.
In 2009, in her Meltdown concert in Festival Hall, she paid homage to the Iranians taking part in post-election protests by saying "Where is My Vote?" in a version of the song "People Have the Power".
On September 26, 2015, Smith appeared with Ralph Nader, spoke and performed the songs "Wing" and "People Have the Power" during the American Museum of Tort Law convocation ceremony in Winsted, Connecticut.

</doc>
<doc id="22996" url="https://en.wikipedia.org/wiki?curid=22996" title="Horses (album)">
Horses (album)

Horses is the debut studio album by American musician Patti Smith, released on December 13, 1975 on Arista Records. Smith, a fixture of the then-burgeoning New York punk rock music scene, began recording "Horses" with her band in 1975 after being signed to Arista Records, with John Cale being enlisted to produce the album. With its fusion of simplistic rock and roll structures and Smith's freeform, Beat poetry-infused lyrics, "Horses" was met with widespread critical acclaim upon its initial release. Despite a lack of airplay or a popular single to support the album, it nonetheless experienced modest commercial success, managing a top 50 placing on the US "Billboard" 200.
"Horses" has since been viewed by critics as one of the greatest and most influential albums in the history of American punk rock movement, as well as one of the greatest albums of all time. "Horses" has also been cited as a key influence on a number of succeeding punk, post-punk, and alternative rock acts, including Siouxsie and the Banshees, R.E.M., The Smiths, and Garbage.
Background and recording.
At the time she recorded "Horses", Patti Smith and her band were favorites in the New York underground club scene along with acts such as Blondie and the Ramones.
According to Smith, "Horses" was a conscious attempt "to make a record that would make a certain type of person not feel alone. People who were like me, different… I wasn't targeting the whole world. I wasn't trying to make a hit record." Guest musicians on the album included Tom Verlaine of Television and Allen Lanier of Blue Öyster Cult.
Music and lyrics.
In Smith's own words, "Horses" was conceived as "three-chord rock merged with the power of the word". Steve Huey of AllMusic calls "Horses" "essentially the first art punk album." Smith and her band's sound, spearheaded by the rudimentary guitar work of Lenny Kaye, drew on the simple aesthetics of garage rock, and the group's use of simplistic chord structures was emblematic of the punk rock scene associated with the band. Smith, however, used such structures as a basis for lyrical and musical improvisation in the album's songs, diverging from other contemporary punk acts who generally shied away from solos. "Horses" drew on genres such as rock and roll, reggae, and jazz. "Redondo Beach" features a reggae backing track, while "Birdland" owed more to jazz, which Smith's mother enjoyed, than to the influence of punk. When recording the latter song, which was improvised by the band in Electric Lady Studios, Smith has said she imagined the spirit of Jimi Hendrix watching her.
Reflecting Smith's background as a poet, the album's lyrics channel the French Symbolism movement, incorporating influences from the works of Charles Baudelaire, William Blake, and Smith's long-time idol Arthur Rimbaud, and recall the "revolutionary spirit" of Rimbaud and resonate with the energy of Beat poetry, according to "CMJ"s Steve Klinge. Several of the album's songs—"Redondo Beach", "Free Money", "Kimberly"—were inspired by moments with members of Smith's family, while others—"Break It Up", "Elegie"—were written about her idols. The lyrics of "Birdland" are based upon "A Book of Dreams", a 1973 memoir of Wilhelm Reich by his son Peter. "Horses" features two adaptations of songs by other artists: "Gloria", a radical retake on the Them song incorporating verses from Smith's own poem "Oath", and "Land", already a live favorite, which features the first verse of Chris Kenner's "Land of a Thousand Dances" and contains a tribute to Arthur Rimbaud.
Artwork.
The cover photograph for "Horses" was taken using natural light by American photographer Robert Mapplethorpe, a close friend of Smith's, at the Greenwich Village penthouse apartment of his partner Sam Wagstaff. Smith is depicted wearing a plain white shirt which she had purchased at the Salvation Army on the Bowery and slinging a black jacket over her shoulder and her favorite black ribbon around her collar. Embedded on the jacket is a horse pin that Smith's friend Allen Lanier had given her. Smith has described her pose on the cover as "a mix of Baudelaire and Sinatra." The record company wanted to make various changes to the photo, but Smith overruled such attempts. The black and white treatment and unisex pose were a departure from the typical promotional images of "girl singers" of the time, but Smith maintains that she "wasn't making a big statement. That's just the way I dressed."
Writer Camille Paglia described the album's cover as "one of the greatest pictures ever taken of a woman."
Critical reception.
Upon initial release, "Horses" was met with near-universal acclaim from music critics and publications. In a contemporary review for "Rolling Stone", John Rockwell wrote that "Horses" is "wonderful in large measure because it recognizes the over-whelming importance of words" in Smith's work, covering a range of concerns "far beyond what most rock records even dream of", and highlighted Smith's adaptions of rock standards as the most striking songs on the record. Robert Christgau gave "Horses" an A– grade in "The Village Voice" and remarked that while the album does not capture Smith's humor, it "gets the minimalist fury of her band and the revolutionary dimension of her singing just fine." He later ranked it at number 38 on his list of the best albums of the 1970s.
"Horses" mix of philosophical elements in Smith's songwriting and rock and roll elements in its music attracted some polarizing reactions, however. Reaction to the album from the British music press in particular was mixed. A review of "Horses" from "Melody Maker" dismissed the album as "precisely what's wrong with rock and roll right now." On the other hand, John Ingham of "Sounds" published a five-star review of "Horses", naming it "the record of the year" and "one of the most stunning, commanding, engrossing platters to come down the turnpike since John Lennon's "Plastic Ono Band"". Charles Shaar Murray of "NME" called it "an album in a thousand" and "an important album in terms of what rock can encompass without losing its identity as a musical form, in that it introduces an artist of greater vision than has been seen in rock for far too long."
At the end of 1975, "Horses" was voted the second best album of the year, behind Bob Dylan and The Band's "The Basement Tapes", in the Pazz & Jop, an annual poll of American critics nationwide, published in "The Village Voice". "NME" placed it at number thirteen on their year-end list of 1975's best albums. Commercially, the album performed modestly well, managing a top 50 peak on the "Billboard" 200 chart despite receiving virtually no airplay.
Legacy and influence.
Chris Jones of BBC Music wrote that the album was a "shock to the system" at the time of its release and still "retains its power to this day." "Horses" established Smith as one of the biggest names of the New York punk rock scene, alongside contemporary acts such as the Ramones, Blondie and Talking Heads, and it has since been cited as the first significant punk rock album. "Horses" is considered one of the key recordings of the early punk rock movement and a landmark for punk and new wave music in general, inspiring a "raw, almost amateurish energy for the former and critical, engaging reflexivity for the latter," according to writer Chris Smith in his book "101 Albums That Changed Popular Music". AllMusic's William Ruhlmann said that it "isn't hard to make the case for Patti Smith as a punk rock progenitor based on "Horses"", while Greg Simpson of Punknews.org called the album a "raw yet poetic slice of the CBGB's scene from a woman who beat the Ramones in releasing the first 'punk' record."
"Q" magazine included it in its list of the 100 greatest punk albums. "NME" put "Horses" at first place in its list of "20 Near-as-Damn-It Perfect Initial Efforts", and it has also ranked on various lists of the greatest albums of the 1970s. In addition to these accolades, "Horses" has also been considered one of the finest albums in recorded music history. In 2003, the album was ranked number 44 on "Rolling Stone" magazine's list of the 500 greatest albums of all time. In 2006, "Time" named it as one of the All-"TIME" 100 Albums, and three years later, it was preserved by the Library of Congress into the National Recording Registry for being "culturally, historically, or aesthetically significant."
Various recording artists have specifically named "Horses" as an influence on their music. English post-punk band Siouxsie and the Banshees said that the song "Carcass" from their album "The Scream", was inspired by "Horses". Michael Stipe of R.E.M. bought the album as a high school student and says that it "tore [his] limbs off and put them back on in a whole different order," citing Smith as his primary inspiration for becoming a musician. Morrissey and Johnny Marr shared an appreciation for the record, and one of their early compositions for The Smiths, "The Hand That Rocks the Cradle", is a reworking of "Kimberly". Courtney Love of Hole has stated that "Horses" helped inspire her to become a rock musician.
30th anniversary edition.
For the 30th anniversary of the original album, a live version was recorded on June 25, 2005 in the Royal Festival Hall at the Meltdown festival, which Smith curated. It followed the same running order as the original release of "Horses", and featured Tom Verlaine on guitar and Flea on bass guitar. The live set was released November 8, 2005 as the second disc of a double CD titled "Horses/Horses", with the digitally remastered version of the original 1975 album (with the bonus track "My Generation") on the first disc. The album was recorded and mixed by Emery Dobyns.

</doc>
<doc id="22997" url="https://en.wikipedia.org/wiki?curid=22997" title="Panama">
Panama

Panama ( ; ), officially called the Republic of Panama (), is a country in Central America situated between North and South America. It is bordered by Costa Rica to the west, Colombia to the southeast, the Caribbean to the north and the Pacific Ocean to the south. The capital and largest city is Panama City, whose metro area is home to nearly half of the country's 4.1 million people.
Panama was inhabited by several indigenous tribes prior to settlement by the Spanish in the 16th century. Panama broke away from Spain in 1821 and joined a union of Nueva Granada, Ecuador, and Venezuela named the Republic of Gran Colombia. When Gran Colombia dissolved in 1831, Panama and Nueva Granada remained joined, eventually becoming the Republic of Colombia. With the backing of the United States, Panama seceded from Colombia in 1903, allowing the Panama Canal to be built by the U.S. Army Corps of Engineers between 1904 and 1914. In 1977, an agreement was signed for the total transfer of the Canal from the United States to Panama by the end of the 20th century, which culminated on 31 December 1999.
Revenue from canal tolls continues to represent a significant portion of Panama's GDP, although commerce, banking, and tourism are major and growing sectors. Panama has the second largest economy in Central America and is also the fastest growing economy and largest per capita consumer in Central America. In 2013, Panama ranked 5th among Latin American countries in terms of the Human Development Index, and 59th in the world. Since 2010, Panama remains the second most competitive economy in Latin America, according to the World Economic Forum's Global Competitiveness Index. Covering around 40 percent of its land area, Panama's jungles are home to an abundance of tropical plants and animals – some of them to be found nowhere else on the planet.
Etymology.
There are several theories about the origin of the name "Panama". Some believe that the country was named after a commonly found species of tree ("Sterculia apetala", the Panama tree). Others believe that the first settlers arrived in Panama in August, when butterflies abound, and that the name means "many butterflies" in an indigenous language.
The best-known version is that a fishing village and its nearby beach bore the name "Panamá", which meant "an abundance of fish". Captain Antonio Tello de Guzmán, while exploring the Pacific side in 1515, stopped in the small indigenous fishing town. This was communicated to the Crown and in 1517 Don Gaspar De Espinosa, a Spanish lieutenant, decided to settle a post there. In 1519, Pedrarias Dávila decided to establish the Empire's Pacific city in this site. The new settlement replaced Santa María La Antigua del Darién, which had lost its function within the Crown's global plan after the beginning of the Spanish exploitation of the riches in the Pacific.
Blending all of the above together, Panamanians believe in general that the word Panama means "abundance of fish, trees and butterflies". This is the official definition given in social studies textbooks approved by the Ministry of Education in Panama. However, others believe the word "Panama" comes from the Kuna word "bannaba" which means "distant" or "far away".
History.
At the time of the arrival of the Spanish in the 16th century, the known inhabitants of Panama included the Cuevas and the Coclé tribes. These people have nearly disappeared, as they had no immunity from European infectious diseases.
Pre-Columbian period.
The Isthmus of Panama was formed about 3 million years ago when the land bridge between North and South America finally closed, after which plants and animals gradually crossed it in both directions. The existence of the isthmus had an impact on the dispersal of people, agriculture and technology throughout the American continent from the appearance of the first hunters and collectors to the era of villages and cities.
The earliest artifacts discovered of indigenous peoples in Panama have included Paleo-Indians projectile points. Later central Panama was home to some of the first pottery-making in the Americas, such as the Monagrillo cultures dating to about 2500–1700 BC. These evolved into significant populations that are best known through the spectacular burials (dating to c. 500–900 AD) at the Monagrillo archaeological site, and the beautiful polychrome pottery of the Gran Coclé style. The monumental monolithic sculptures at the Barriles (Chiriqui) site are other important evidence of the ancient isthmian cultures.
Prior to the arrival of Europeans, Panama was widely settled by Chibchan, Chocoan, and Cueva peoples, among whom the largest group were the Cueva (whose specific language affiliation is poorly documented). There is no accurate knowledge of the size of the indigenous population of the isthmus at the time of the European conquest. Estimates range as high as two million people, but more recent studies place that number closer to 200,000. Archaeological finds as well as testimonials by early European explorers describe diverse native isthmian groups exhibiting cultural variety and suggesting people already conditioned by regular regional routes of commerce.
When Panama was colonized, the indigenous peoples fled into the forest and nearby islands. Scholars believe that, among the various contributing factors, infectious disease was the main cause of the population decline of the American natives. The indigenous peoples had no acquired immunity to such diseases, which had been chronic in Eurasian populations for centuries.
Conquest to 1799.
Rodrigo de Bastidas, sailing westward from Venezuela in 1501 in search of gold, was the first European to explore the isthmus of Panama. A year later, Christopher Columbus visited the isthmus and established a short-lived settlement in the Darien. Vasco Núñez de Balboa's tortuous trek from the Atlantic to the Pacific in 1513 demonstrated that the Isthmus was, indeed, the path between the seas, and Panama quickly became the crossroads and marketplace of Spain's empire in the New World. Gold and silver were brought by ship from South America, hauled across the isthmus, and loaded aboard ships for Spain. The route became known as the Camino Real, or Royal Road, although it was more commonly known as Camino de Cruces (Road of the Crosses) because of the abundance of gravesites along the way.
Panama, under Spanish rule for almost 300 years (1538–1821) became part of the Viceroyalty of Peru, along with all other Spanish possessions in South America. From the outset, Panamanian identity was based on a sense of "geographic destiny", and Panamanian fortunes fluctuated with the geopolitical importance of the isthmus. The colonial experience also spawned Panamanian nationalism as well as a racially complex and highly stratified society, the source of internal conflicts that ran counter to the unifying force of nationalism.
In 1538, the Real Audiencia de Panama was established, initially with jurisdiction from Nicaragua to Cape Horn before the conquest of Peru. A Real Audiencia (royal audiency) was a judicial district that functioned as an appeals court. Each audiencia had oidores (Spanish: hearer, a judge).
Spanish authorities exercised little control over much of the territory of Panama, large sections managing to resist conquest until very late in the colonial era. Because of this, indigenous people of the area were often referred to as "indios de guerra" (war Indians) and resisted Spanish attempts to conquer them or missionize them. However, Panama was enormously important to Spain strategically because it was the easiest way to transship silver mined in Peru to Europe. Silver cargos were landed at Panama and then taken overland to Portobello or Nombre de Dios on the Caribbean side of the isthmus for further shipment.
Because of the incomplete Spanish control, the Panama route was vulnerable to attack from pirates (mostly Dutch and English) and from 'new world' Africans called cimarrons who had freed themselves from enslavement and lived in communes or palenques around the Camino Real in Panama's Interior, and on some of the islands off Panama's Pacific coast. One such famous community amounted to a small kingdom under Bayano, which emerged in the 1552 to 1558. Sir Francis Drake's famous raids on Panama in 1572–73 were aided by Panama cimarrons, and Spanish authorities were only able to bring them under control by making an alliance with them that guaranteed their freedom in exchange for military support in 1582.
The prosperity enjoyed during the first two centuries (1540–1740) while contributing to colonial growth; the placing of extensive regional judicial authority (Real Audiencia) as part of its jurisdiction; and the pivotal role it played at the height of the Spanish Empire – the first modern global empire – helped define a distinctive sense of autonomy and of regional or national identity within Panama well before the rest of the colonies.
The end of the encomienda system in Azuero, however, sparked the conquest of Veraguas in that same year. Under the leadership of Francisco Vázquez, the region of Veraguas passed into Castillan rule in 1558. In the newly conquered region, the old system of encomienda was imposed. On the other hand, the Panamanian movement for independence can be indirectly attributed to the abolishment of the encomienda system in the Azuero Peninsula, set forth by the Spanish Crown, in 1558 because of repeated protests by locals against the mistreatment of the native population. In its stead, a system of medium and smaller-sized landownership was promoted, thus taking away the power from the large landowners and into the hands of medium and small sized proprietors.
Panama was the site of the ill-fated Darien scheme, which set up a Scottish colony in the region in 1698. This failed for a number of reasons, and the ensuing debt contributed to the union of England and Scotland in 1707.
In 1671, the privateer Henry Morgan, licensed by the English government, sacked and burned the city of Panama – the second most important city in the Spanish New World at the time. In 1717, the viceroyalty of New Granada (northern South America) was created in response to other Europeans trying to take Spanish territory in the Caribbean region. The Isthmus of Panama was placed under its jurisdiction. However, the remoteness of New Granada's capital, Santa Fe de Bogotá (the modern capital of Colombia) proved a greater obstacle than the Spanish crown anticipated as the authority of New Granada was contested by the seniority, closer proximity, and previous ties to the viceroyalty of Lima and even by Panama's own initiative. This uneasy relationship between Panama and Bogotá would persist for centuries.
In 1744, Bishop Francisco Javier de Luna Victoria DeCastro established the College of San Ignacio de Loyola and on June 3, 1749, founded La Real y Pontificia Universidad de San Javier. By this time, however, Panama's importance and influence had become insignificant as Spain's power dwindled in Europe and advances in navigation technique increasingly permitted to round Cape Horn in order to reach the Pacific. While the Panama route was short it was also labor-intensive and expensive because of the loading and unloading and laden-down trek required to get from the one coast to the other.
During the last half of the 18th century and the first half of the 19th century, migrations to the countryside decreased Panama City's population and the isthmus' economy shifted from the tertiary to the primary sector.
1800s.
As the Spanish American wars of independence were heating up all across Latin America, Panama City was preparing for independence; however, their plans were accelerated by the unilateral Grito de La Villa de Los Santos (Cry From the Town of Saints), issued on November 10, 1821 by the residents of Azuero without backing from Panama City to declare their separation from the Spanish Empire. In both Veraguas and the capital this act was met with disdain, although on differing levels. To Veraguas, it was the ultimate act of treason, while to the capital, it was seen as inefficient and irregular, and furthermore forced them to accelerate their plans.
Nevertheless, the Grito was an event that shook the isthmus to its very core. It was a sign, on the part of the residents of Azuero, of their antagonism toward the independence movement in the capital. Those in the capital region in turn regarded the Azueran movement with contempt, since the separatists in Panama City believed that their counterparts in Azuero were fighting not only for independence from Spain, but also for their right to self-rule apart from Panama City once the Spaniards were gone.
It was an incredibly brave move on the part of Azuero, which lived in fear of Colonel José Pedro Antonio de Fábrega y de las Cuevas (1774–1841), and with good reason; the Colonel was a staunch loyalist, and had the entirety of the isthmus' military supplies in his hands. They feared quick retaliation and swift retribution against the separatists.
What they had counted on, however, was the influence of the separatists in the capital. Ever since October 1821, when the former Governor General, Juan de la Cruz Murgeón, left the isthmus on a campaign in Quito and left the Veraguan colonel in charge, the separatists had been slowly converting Fábrega to the separatist side. As such, by November 10, Fábrega was now a supporter of the independence movement. Soon after the separatist declaration of Los Santos, Fábrega convened every organization in the capital with separatist interests and formally declared the city's support for independence. No military repercussions occurred because of the skillful bribing of royalist troops.
Post-colonial Panama.
In the first eighty years following independence from Spain, Panama was a department of Colombia, since voluntarily becoming part of it at the end of 1821. The people of the isthmus made several attempts to secede and came close to success in 1831, and again during the Thousand Days' War of 1899–1902. When the Senate of Colombia rejected the Hay–Herrán Treaty, the United States decided to support the Panamanian independence movement.
In November 1903 Panama proclaimed its independence and concluded the Hay–Bunau-Varilla Treaty with the United States. The treaty granted rights to the United States "as if it were sovereign" in a zone roughly wide and long. In that zone, the U.S. would build a canal, then administer, fortify, and defend it "in perpetuity". In 1914, the United States completed the existing 83 km (52 mi) canal. The early 1960s saw the beginning of sustained pressure in Panama for the renegotiation of this treaty.
The United States of America's intentions to influence the area (especially the Panama Canal construction and control) led to the separation of Panama from Colombia in 1903 and the establishment of it as a nation (the United States intensively encouraged the Panamanian separatist movement). From 1903 until 1968, Panama was a constitutional democracy dominated by a commercially oriented oligarchy. During the 1950s, the Panamanian military began to challenge the oligarchy's political hegemony.
Amid negotiations for the Robles–Johnson treaty, Panama held elections in 1968. The candidates were Dr. Arnulfo Arias Madrid, Antonio González Revilla, and engineer David Samudio, who had the government's support. Samudio was the candidate of Alianza del Pueblo ("People's Alliance"), Arias Madrid was the candidate of Unión Nacional ("National Union"), and González Revilla was the candidate of Democracia Cristiana ("Christian Democrats") (see Pizzurno Gelós and Araúz, Estudios sobre el Panamá republicano 508).
Arias Madrid was declared the winner of elections that were marked by violence and accusations of fraud against Alianza del Pueblo. On October 1, 1968, Arias Madrid took office as president of Panama, promising to lead a government of "national union" that would end the reigning corruption and pave the way for a new Panama. A week and a half later, on October 11, 1968, the National Guard (Guardia Nacional) ousted Arias and initiated the downward spiral that would culminate with the United States' invasion in 1989. Arias, who had promised to respect the hierarchy of the National Guard, broke the pact and started a large restructuring of the Guard. To preserve the Guard's interests, Lieutenant Colonel Omar Torrijos Herrera and Major Boris Martínez commanded the first coup of a military force against a civilian government in Panamanian republican history.
The military justified itself by declaring that Arias Madrid was trying to install a dictatorship, and promised a return to constitutional rule. In the meantime, the Guard began a series of populist measures that would gain support for the coup. Among them were the freezing of prices on food, medicine and other goods until January 31, 1969, the freezing of renting prices, and the legalization of the permanence of squatting families in boroughs surrounding the historic site of Panama Viejo. Parallel to this, the military began a policy of repression against the opposition, who were labeled communists. The military appointed a Provisional Government Junta that would arrange new elections. However, the National Guard would prove to be very reluctant to abandon power and soon began calling itself El Gobierno Revolucionario ("The Revolutionary Government").
Post-1970.
During Omar Torrijos's control, the military regime transformed the political and economic structure of the country by initiating massive coverage of social security services and expanding public education. The constitution was changed in 1972. For the reform to the constitution, the military created a new organization, the Assembly of Corregimiento Representatives, which replaced the National Assembly. The new assembly, also known as the Poder Popular ("Power of the People"), was composed of 505 members selected by the military without the participation of political parties, which had been eliminated by the military. The new constitution proclaimed Omar Torrijos the "Maximum Leader of the Panamanian Revolution", and conceded him unlimited power for six years, although, to keep a façade of constitutionality, Demetrio B. Lakas was appointed president for the same period (Pizzurno Gelós and Araúz, "Estudios sobre el Panamá republicano" 541).
In 1981, Torrijos died in a plane crash. Torrijos' death altered the tone of Panama's political evolution. Despite the 1983 constitutional amendments, which proscribed a political role for the military, the Panama Defense Forces (PDF), as they were then known, continued to dominate Panamanian political life. By this time, General Manuel Noriega was firmly in control of both the PDF and the civilian government.
In the 1984 elections, the candidates were Nicolás Ardito Barletta Vallarino, supported by the military in a union called UNADE; Dr. Arnulfo Arias Madrid, for the opposition union ADO; the ex-General Rubén Darío Paredes, who had been forced to an early retirement by Noriega, running for Partido Nacionalista Popular PNP ("Popular Nationalist Party"), and Carlos Iván Zúñiga, running for Partido Acción Popular (PAPO) meaning "Popular Action Party". Nicolás Ardito Barletta was declared the winner of elections that had been clearly won by Arnulfo Arias Madrid. Ardito Barletta inherited a country in economic ruin and hugely indebted to the IMF and the World Bank. Amid the economic crisis and Barletta's efforts to calm the country's creditors, street protests arose, and so did military repression.
Meanwhile, Noriega's regime had fostered the development of a well-hidden criminal economy that operated as a parallel source of income for the military and their allies, providing revenues from drugs and money laundering. Toward the end of the military dictatorship, a new wave of Chinese migrants arrived on the isthmus in the hope of migrating to the United States. The smuggling of Chinese became an enormous business, with revenues of up to 200 million dollars for Noriega's regime (see Mon 167).
The military dictatorship, at that time supported by the United States, perpetrated the assassination and torture of more than one hundred Panamanians and forced into exile at least another hundred dissidents (see Zárate 15). Noriega also began playing a double role in Central America under the supervision of the CIA. While the Contadora group conducted diplomatic efforts to achieve peace in the region, Noriega supplied the Nicaraguan Contras and other guerrillas in the region with weapons and ammunition.
On June 6, 1987, the recently retired Colonel Roberto Díaz Herrera, resentful for Noriega's violation of the "Torrijos Plan" of succession that would turn him into the chief of the military after Noriega, decided to denounce the regime. He revealed details of the electoral fraud, accused Noriega of planning Torrijos's death, declared that Torrijos had received 12 million dollars from the Shah of Iran so that Panama would give the exiled Iranian leader asylum, and blamed Noriega for the assassination by decapitation of opposition leader Dr. Hugo Spadafora.
On the night of June 9, 1987, the Cruzada Civilista ("Civic Crusade") was created and began organizing actions of civil disobedience. The Crusade called for a general strike. In response, the military suspended constitutional rights and declared a state of emergency in the country. On July 10, the Civic Crusade called for a massive demonstration that was violently repressed by the "Dobermans", the military's special riot control unit. That day, later known as El Viernes Negro ("Black Friday"), left six hundred people injured and another six hundred detained, many of whom were later tortured and raped.
United States President Ronald Reagan began a series of sanctions against the military regime. The United States froze economic and military assistance to Panama in the summer of 1987 in response to the domestic political crisis in Panama and an attack on the U.S. Embassy. Yet these sanctions did little to overthrow Noriega but instead severely damaged Panama's economy. The sanctions hit the Panamanian population hard and caused the Gross Domestic Product (GDP) to decline almost 25% between 1987–1989 (see Acosta n.p.).
On February 5, 1988, General Manuel Antonio Noriega was accused of drug trafficking by federal juries in Tampa and Miami.
In April 1988, the U.S. President Ronald Reagan invoked the International Emergency Economic Powers Act, freezing Panamanian government assets in all U.S. organizations. In May 1989 Panamanians voted overwhelmingly for the anti-Noriega candidates. The Noriega regime promptly annulled the election and embarked on a new round of repression.
U.S. invasion (1989).
The United States government justified Operation Just Cause, which commenced on December 20, 1989 as necessary to safeguard the lives of U.S. citizens in Panama, defend democracy and human rights, combat drug trafficking, and secure the neutrality of the Canal as required by the Torrijos–Carter Treaties ("New York Times", A Transcript of President Bush's Address n.p.). Human Rights Watch wrote in the 1989 report: "Washington turned a blind eye to abuses in Panama for many years until concern over drug trafficking prompted indictments of the general [Noriega] by two grand juries in Florida in February 1988". The U.S. reported 23 servicemen killed and 324 wounded, with estimated Panamanian casualties around 450. Although described as a surgical maneuver, the action led to civilian deaths whose estimated numbers range from 400 to 4,000 during the two weeks of armed activities in the largest United States military operation to that date since the end of the Vietnam War (Cajar Páez 22) The United Nations put the Panamanian civilian death toll at 500. Others had larger numbers. The number of U.S. civilians (and their dependents), who had worked for the Panama Canal Commission and the U.S. Military, and were killed by the Panamanian Defense Forces, has never been fully disclosed.
On December 29, the UN General Assembly approved a resolution calling the intervention in Panama a "flagrant violation of international law and of the independence, sovereignty and territorial integrity of the States". The resolution was vetoed by the United States, United Kingdom, and France.
The urban population, with many living below the poverty level, was greatly affected by the 1989 intervention. As pointed out in 1995 by a UN Technical Assistance Mission to Panama, the bombardments during the invasion caused the displacement of 20,000 people. The most heavily affected district was impoverished El Chorrillo, where several blocks of apartments were completely destroyed; El Chorrillo had been since Canal construction days a series of wooden barracks; these easily caught fire under the United States attack. The economic damage caused by the intervention has been estimated to be between 1.5 and 2 billion dollars. n.p. Many Panamanians supported the intervention.
Post-intervention era.
Panama's Electoral Tribunal moved quickly to restore the civilian constitutional government, reinstated the results of the May 1989 election on December 27, 1989, and confirmed the victory of President Guillermo Endara and Vice Presidents Guillermo Ford and Ricardo Arias Calderon.
During its five-year term, the often-fractious government struggled to meet the public's high expectations. Its new police force was a major improvement over its predecessor but was not fully able to deter crime. Ernesto Pérez Balladares was sworn in as President on September 1, 1994, after an internationally monitored election campaign.
Perez Balladares ran as the candidate for a three-party coalition dominated by the Democratic Revolutionary Party (PRD), the erstwhile political arm of military dictatorships. Perez Balladares worked skillfully during the campaign to rehabilitate the PRD's image, emphasizing the party's populist Torrijos roots rather than its association with Noriega. He won the election with only 33% of the vote when the major non-PRD forces splintered into competing factions. His administration carried out economic reforms and often worked closely with the U.S. on implementation of the Canal treaties.
On September 1, 1999, Mireya Moscoso, the widow of former President Arnulfo Arias Madrid, took office after defeating PRD candidate Martin Torrijos, son of Omar Torrijos, in a free and fair election. During her administration, Moscoso attempted to strengthen social programs, especially for child and youth development, protection, and general welfare. Moscoso's administration successfully handled the Panama Canal transfer and was effective in the administration of the Canal.
The PRD's Martin Torrijos won the presidency and a legislative majority in the National Assembly in 2004. Torrijos ran his campaign on a platform of, among other pledges, a "zero tolerance" for corruption, a problem endemic to the Moscoso and Perez Balladares administrations. After taking office, Torrijos passed a number of laws which made the government more transparent. He formed a National Anti-Corruption Council whose members represented the highest levels of government, as well as civil society, labor organizations, and religious leadership. In addition, many of his closest Cabinet ministers were non-political technocrats known for their support for the Torrijos government's anti-corruption aims. Despite the Torrijos administration's public stance on corruption, many high-profile cases, particularly involving political or business elites, were never acted upon.
Conservative supermarket magnate Ricardo Martinelli was elected to succeed Martin Torrijos with a landslide victory at the May 2009 presidential election. Mr. Martinelli's business credentials drew voters worried by slowing growth due to the world financial crisis. Standing for the four-party opposition Alliance for Change, Mr. Martinelli gained 60% of the vote, against 37% for the candidate of the governing left-wing Democratic Revolutionary Party.
On May 4, 2014, Juan Carlos Varela won the 2014 presidential election with over 39% of the votes, against the party of his former political partner Ricardo Martinelli, Cambio Democrático, and their candidate José Domingo Arias. He was sworn in on 1 July 2014.
Geography.
Panama is located in Central America, bordering both the Caribbean Sea and the Pacific Ocean, between Colombia and Costa Rica. It mostly lies between latitudes 7° and 10°N, and longitudes 77° and 83°W (a small area lies west of 83°).
Its location on the Isthmus of Panama is strategic. By 2000, Panama controlled the Panama Canal which connects the Atlantic Ocean and the Caribbean Sea to the North of the Pacific Ocean. Panama's total area is 75,515 km2.
The dominant feature of Panama's landform is the central spine of mountains and hills that forms the continental divide. The divide does not form part of the great mountain chains of North America, and only near the Colombian border are there highlands related to the Andean system of South America. The spine that forms the divide is the highly eroded arch of an uplift from the sea bottom, in which peaks were formed by volcanic intrusions.
The mountain range of the divide is called the Cordillera de Talamanca near the Costa Rican border. Farther east it becomes the Serranía de Tabasará, and the portion of it closer to the lower saddle of the isthmus, where the Panama Canal is located, is often called the Sierra de Veraguas. As a whole, the range between Costa Rica and the canal is generally referred to by geographers as the Cordillera Central.
The highest point in the country is the Volcán Barú, which rises to 3,475 metres (11,401 ft). A nearly impenetrable jungle forms the Darién Gap between Panama and Colombia where Colombian guerrilla and drug dealers are operating with hostage-taking. This and forest protection movements create a break in the Pan-American Highway, which otherwise forms a complete road from Alaska to Patagonia.
Panama's wildlife holds the most diversity of all the countries in Central America. It is home to many South American species as well as North American wildlife.
Waterways.
Nearly 500 rivers lace Panama's rugged landscape. Mostly unnavigable, many originate as swift highland streams, meander in valleys, and form coastal deltas. However, the Río Chagres ("Rio Chagres"), located in central Panama, is one of the few wide rivers and a source of enormous hydroelectric power. The central part of the river is dammed by the Gatun Dam and forms Gatun Lake, an artificial lake that constitutes part of the Panama Canal. The lake was created between 1907 and 1913 by the building of the Gatun Dam across the Chagres River. When it was created, Gatun Lake was the largest man-made lake in the world, and the dam was the largest earth dam. The river drains northwest into the Caribbean. The Kampia and Madden Lakes (also filled from the Río Chagres) provide hydroelectricity for the area of the former Canal Zone.
The Río Chepo, another source of hydroelectric power, is one of the more than 300 rivers emptying into the Pacific. These Pacific-oriented rivers are longer and slower running than those of the Caribbean side. Their basins are also more extensive. One of the longest is the Río Tuira, which flows into the Golfo de San Miguel and is the nation's only river navigable by larger vessels.
Harbors.
The Caribbean coastline is marked by several good natural harbors. However, Cristóbal, at the Caribbean terminus of the canal, had the only important port facilities in the late 1980s. The numerous islands of the Archipiélago de Bocas del Toro, near the Beaches of Costa Rica, provide an extensive natural roadstead and shield the banana port of Almirante. The over 350 San Blas Islands, near Colombia, are strung out for more than 160 km along the sheltered Caribbean coastline.
Currently, the terminal ports located at each end of the Panama Canal, namely the Port of Cristobal and the Port of Balboa, are ranked second and third respectively in Latin America in terms of numbers of containers units (TEU) handled. The Port of Balboa covers 182 hectares and contains four berths for containers and two multi-purpose berths. In total, the berths are over 2,400 meters long with alongside depth of 15 meters. The Port of Balboa has 18 super post-Panamax and Panamax quay cranes and 44 gantry cranes. The Port of Balboa also contains 2,100 square meters of warehouse space.
The Ports of Cristobal (encompassing the container terminals of Panama Ports Cristobal, Manzanillo International Terminal and Colon Container Terminal) handled 2,210,720 TEU in 2009, second only to the Port of Santos, Brazil, in Latin America.
Excellent deep water ports capable of accommodating large VLCC (Very Large Crude Oil Carriers) are located at Charco Azul, Chiriquí (Pacific) and Chiriquí Grande, Bocas del Toro (Atlantic) near Panama's western border with Costa Rica. The Trans-Panama pipeline, running across the isthmus with a length of 131 km, has been operating between Charco Azul and Chiriquí Grande since 1979.
Climate.
Panama has a tropical climate. Temperatures are uniformly high—as is the relative humidity—and there is little seasonal variation. Diurnal ranges are low; on a typical dry-season day in the capital city, the early morning minimum may be and the afternoon maximum . The temperature seldom exceeds for more than a short time. Temperatures on the Pacific side of the isthmus are somewhat lower than on the Caribbean, and breezes tend to rise after dusk in most parts of the country. Temperatures are markedly cooler in the higher parts of the mountain ranges, and frosts occur in the Cordillera de Talamanca in western Panama.
Climatic regions are determined less on the basis of temperature than on rainfall, which varies regionally from less than to more than per year. Almost all of the rain falls during the rainy season, which is usually from April to December, but varies in length from seven to nine months. In general, rainfall is much heavier on the Caribbean than on the Pacific side of the continental divide. The annual average in Panama City is little more than half of that in Colón. Although rainy-season thunderstorms are common, the country is outside the hurricane belt.
Panama's tropical environment supports an abundance of plants. Forests dominate, interrupted in places by grasslands, scrub, and crops. Although nearly 40% of Panama is still wooded, deforestation is a continuing threat to the rain-drenched woodlands. Tree cover has been reduced by more than 50% since the 1940s. Subsistence farming, widely practiced from the northeastern jungles to the southwestern grasslands, consists largely of corn, bean, and tuber plots. Mangrove swamps occur along parts of both coasts, with banana plantations occupying deltas near Costa Rica. In many places, a multi-canopied rain forest abuts the swamp on one side of the country and extends to the lower reaches of slopes in the other.
Politics.
Panama's politics take place in a framework of a presidential representative democratic republic, whereby the President of Panama is both head of state and head of government, and of a multi-party system. Executive power is exercised by the government. Legislative power is vested in both the government and the National Assembly. The judiciary is independent of the executive and the legislature.
For all people national elections are universal and mandatory for all citizens 18 years and older. National elections for the executive and legislative branches take place every five years. Members of the judicial branch (justices) are appointed by the head of state. Panama's National Assembly is elected by proportional representation in fixed electoral districts, so many smaller parties are represented. Presidential elections do not require a simple majority; out of the four last presidents only one, incumbent president Ricardo Martinelli, was elected with over 50% of the popular vote.
Political culture.
In December 1989 the United States invaded Panama to depose the dictator Manuel Noriega. Since the U.S. invasion, and resulting end to the 21-year military dictatorship, Panama has successfully completed four peaceful transfers of power to opposing political factions. The political landscape is dominated by two major parties and many smaller parties, many of which are driven by individual leaders more than ideologies. Former President Martin Torrijos is the son of Maximum Leader of the Panamanian Revolution Omar Torrijos. He succeeded Mireya Moscoso, the widow of Arnulfo Arias. Panama's most recent national elections occurred on May 4, 2014 with Incumbent Vice-President Juan Carlos Varela declared the victor.
Foreign relations.
The United States cooperates with the Panamanian government in promoting economic, political, security, and social development through U.S. and international agencies. Cultural ties between the two countries are strong, and many Panamanians come to the United States for higher education and advanced training.
Military.
The Panamanian Public Forces are the national security forces of Panama. Panama is the second country in Latin America (the other being Costa Rica) to permanently abolish standing armies. Panama maintains armed police and security forces, and small air and maritime forces. They are tasked with law enforcement and can perform limited military actions.
Administrative divisions.
Panama is divided into ten provinces with their respective local authorities (governors), which are divided into districts and "corregimientos" (townships) and has a total of ten cities. Also, there are five "Comarcas" (literally: "Shires") populated by a variety of indigenous groups.
Economy.
According to the CIA World Factbook, as of 2012 Panama had an unemployment rate of 2.7%. A food surplus was registered in August 2008. On the Human Development Index, Panama ranked 58th in 2012. In recent years, Panama's economy has experienced a boom, with growth in real gross domestic product (GDP) averaging over 10.4% from 2006–2008. Panama's economy has been among the fastest growing and best managed in Latin America. Latin Business Chronicle had predicted that Panama would be the fastest growing economy in Latin America during the five years 2010–14, matching Brazil's 10% rate.
The expansion project of the Panama Canal, combined with the conclusion of a free trade agreement with the United States, are expected to boost and extend economic expansion for some time.
Despite Panama's upper-middle per capita GDP, it remains a country of stark contrasts. Perpetuated by dramatic educational disparities, over 25% of Panama's population lived in national poverty in 2013 and 3% of the population lives in extreme poverty, according to latest reports by the World Bank.
Economic sectors.
Panama's economy, because of its key geographic location, is mainly based on a well developed service sector especially commerce, tourism, and trading. The handover of the Canal and military installations by the United States has given rise to large construction projects.
A project to build of a third set of locks for the Panama Canal A was overwhelmingly approved in referendum (with low voter turnout, however) on October 22, 2006. The official estimated cost of the project is US$5.25 billion. The canal is of major economic importance because it pumps millions of dollars from toll revenue to the national economy and provides massive employment. Transfer of control of the Canal to the Panamanian government began in 1999, according to the Torrijos–Carter Treaties of 1977, after being controlled by the US for 85 years.
Copper and gold deposits are being developed by foreign investors, to the dismay of some environmental groups, as all of the projects are located within protected areas.
Transportation.
Panama is home to Tocumen International Airport, Central America's largest airport. Additionally there are more than 20 smaller airfields in the country. See list of airports in Panama. 
Panama's roads, traffic and transportation systems are generally safe, though night driving is difficult and in many cases, restricted by local authorities, this usually occurs in informal settlements.. Traffic in Panama moves on the right, and Panamanian law requires that drivers and passengers wear seat belts. Highways are generally well-developed for a Latin American country. 
Currently, Panama has colorfully painted buses colloquially known as '. A ' is usually "customized" or painted with bright colors, usually depicting famous actors, politicians or singers. Panama City's streets experience frequent traffic jams due to poor planning for the now extensive private vehicle fleet.
Tourism.
Tourism in Panama is rapidly growing. It has maintained its growth over the past five years due to government tax and price discounts to foreign guests and retirees. These economic incentives have caused Panama to be regarded as a relatively good place to retire in the world. Real estate developers in Panama have increased the number of tourism destinations in the past five years because of the interest for these visitor incentives. 2,200,000 tourists arrived in 2012.
The number of tourists from Europe grew by 23.1% during the first nine months of 2008. According to the Tourism Authority of Panama (ATP), from January to September, 71,154 tourists from Europe entered Panama, which is 13,373 more than figures for same period the previous year. Most of the European tourists were Spaniards (14,820), followed by Italians (13,216), French (10,174) and British (8,833). There were 6997 from Germany, the most populous country in the European Union. Europe has become one of the key markets to promote Panama as a tourist destination.
In 2012, 4.345.5 million entered into the Panamanian economy as a result of tourism. This accounted for 9.5% of gross domestic product in the country, surpassing other productive sectors.
Panama enacted Law No. 80 in 2012 for the promotion of foreign investment in tourism. Law 80 replaced an older Law 8 of 1994. Law 80 provides 100% exemption from income tax and real estate taxes for 15 years, duty-free imports for construction materials and equipment for five years, and capital gains tax exemption for five years.
Currency.
The Panamanian currency is officially the balboa, fixed at a rate of 1:1 with the United States dollar since independence in 1903. In practice Panama is dollarized: US dollars are legal tender and used for all paper currency, while Panama has its own coinage. Because of the tie to US dollars, Panama has traditionally had low inflation. According to the Economic Commission for Latin American and the Caribbean, Panama's inflation in 2006 was 2.0% as measured by weight Consumer Price Index (CPI).
The balboa replaced the Colombian peso in 1904 after Panama's independence. Balboa banknotes were printed in 1941 by President Arnulfo Arias. They were recalled several days later, giving them the name "The Seven Day Dollar". The notes were burned after the seven days but occasionally balboa notes can be found with collectors. These were the only banknotes issued by Panama and U.S. notes have circulated both before and since.
International trade.
The high levels of Panamanian trade are in large part from the Colón Free Trade Zone, the largest free trade zone in the Western Hemisphere. Last year the zone accounted for 92% of Panama's exports and 64% of its imports, according to an analysis of figures from the Colon zone management and estimates of Panama's trade by the United Nations Economic Commission for Latin America and the Caribbean. Panama's economy is also very much supported by the trade and export of coffee and other agricultural products.
The Bilateral Investment Treaty (BIT) between the governments of the United States and Panama was signed on October 27, 1982. The treaty protects US investment and assists Panama in its efforts to develop its economy by creating conditions more favorable for US private investment and thereby strengthening the development of its private sector. The BIT was the first such treaty signed by the US in the Western Hemisphere. A Panama - United States Trade Promotion Agreement (TPA) was signed in 2007, approved by Panama on July 11, 2007 and by US President Obama on October 21, 2011, and the agreement entered into force on October 31, 2012.
Society.
Demographics.
Panama's population was 3,678,000 in 2010, compared to 860,000 in 1950. The proportion of the population aged below 15 in 2010 was 29%. 64.5% of the population were aged between 15 and 65, with 6.6% of the population being 65 years or older.
More than half the population lives in the Panama City–Colón metropolitan corridor, which spans several cities. Panama's urban population exceeds 70%, making Panama's population the most urbanized in Central America.
Ethnic groups.
In 2010 the population was 65% Mestizo (mixed white, Native American), 12.3% Native Americans, 9.2% Black/mulattoes and 6.7% White.
Ethnic groups in Panama include Mestizo people, who are a mix of European and native ancestry. Black, or Afro-Panamanians account for 15-20% of the population, and in addition, black ancestry is present in 50%, or half the population of Panama. Most Afro-Panamanians live on the Panama-Colón metropolitan area, the Darien Province, La Palma, and Bocas Del Toro. Neighborhoods in Panama City that have large black populations include; Curundu, El Chorrillo, Rio Abajo, San Joaquín, El Marañón, San Miguelito, Colón, and Santa Ana. Black Panamanians are descendents of African slaves stolen from Africa and brought to the Americas on the 1500 Atlantic Slave Trade. The second wave of black people brought to Panama came from the Caribbean during the construction of the Panama Canal. Panama also has a considerable Chinese and Indian (India) population. They were brought to work on the canal during its construction. Most Chinese-Panamanians reside in the province of Chiriquí. Europeans and white-Panamanians are a minority in Panama. They are descendents of the people who colonized Panama, worked, on the canal, and who moved to the country. Panama is also home to a small Arab community that have Mosques to practice Islam.
The Amerindian population includes seven ethnic groups: the Ngäbe, Kuna (Guna), Emberá, Buglé, Wounaan, Naso Tjerdi (Teribe), and Bri Bri.
Languages.
Spanish is the official and dominant language. The Spanish spoken in Panama is known as Panamanian Spanish. About 93% of the population speak Spanish as their first language, though many citizens who hold jobs at international levels, or who are apart of business corporations speak both English and Spanish. Native languages, such as Ngäbere are spoken throughout the country, mostly in their native grounds. Over 400,000 Panamanians hold their native languages and customs. Some new statistics show that as second language, English is spoken by 8%, French by 4% and Arabic by 1%.
Largest cities.
These are the 10 largest Panamanian cities and towns. Most of Panama's largest cities are part of the Panama City Metropolitan Area.
Religion.
The government of Panama does not collect statistics on the religious affiliation of citizens, but various sources estimate that 75% to 85% of the population identifies itself as Roman Catholic and 15%–25% as Protestant. The Bahá'í Faith community of Panama is estimated at 2.00% of the national population, or about 60,000 including about 10% of the Guaymí population.
The Church of Jesus Christ of Latter-day Saints (LDS Church) claim more than 40,000 members. Smaller religious groups include Seventh-day Adventists, Jehovah's Witnesses, Episcopalians with between 7,000 and 10,000 members, Jewish and Muslim communities with approximately 10,000 members each, Hindus, Buddhists, and other Christians. Indigenous religions include Ibeorgun (among Kuna) and Mamatata (among Ngobe). There are also a small number of Rastafarians.
Education.
Originally, during the 16th century, education in Panama was provided by Jesuit priests. Public education, as a national and governmental institution, began in 1903. The principles underlying this early education system were that children should receive different types of education in accordance with their social class and therefore the position they were expected to occupy in society.
Public education began in Panama soon after the separation from Colombia in 1903. The first efforts were guided by an extremely paternalistic view of the goals of education, as evidenced in comments made in a 1913 meeting of the First Panamanian Educational Assembly, "The cultural heritage given to the child should be determined by the social position he will or should occupy. For this reason education should be different in accordance with the social class to which the student should be related." This elitist focus changed rapidly under United States influence.
In 2010, it was estimated that 94.1% of the population was literate (94.7% of males and 93.5% of females). Education in Panama is compulsory for the children of age group between 6 and 18. In recent decades, school enrollment at all levels, but especially at upper levels, has increased significantly. Panama used to participate in the PISA exams but due to debts and unsatisfactory exam results is postponing participation until 2018.
Culture.
The culture of Panama derived from European music, art and traditions that were brought over by the Spanish to Panama. Hegemonic forces have created hybrid forms of this by blending African and Native American culture with European culture. For example, the "tamborito" is a Spanish dance that was blended with African rhythms, themes and dance moves.
Dance is a symbol of the diverse cultures that have coupled in Panama. The local folklore can be experienced through a multitude of festivals, dances and traditions that have been handed down from generation to generation. Local cities host live "reggae en español", "reggaeton", "haitiano (compas)", jazz, blues, "salsa", reggae, and rock music performances.
Handicraft.
Outside Panama City, regional festivals take place throughout the year featuring local musicians and dancers. Another example of Panama's blended culture is reflected in the traditional products, such as woodcarvings, ceremonial masks and pottery, as well as in its architecture, cuisine and festivals. In earlier times, baskets were woven for utilitarian uses, but now many villages rely almost exclusively on the baskets they produce for tourists.
An example of undisturbed, unique culture in Panama is that of the Guna who are known for "molas". "Mola" is the Guna word for blouse, but the term "mola" has come to mean the elaborate embroidered panels made by Guna women, that make up the front and back of a Guna woman's blouse. They are several layers of cloth, varying in color, that are loosely stitched together, made using an appliqué process referred to as "reverse appliqué".
Holidays and festivities.
The Christmas parade, known as "El desfile de Navidad", is celebrated in the capital, Panama City. This holiday is celebrated on December 25. The floats in the parade are decorated with the Panamanian colors, and the women dress in dresses called "Pollera" while the men dress in the traditional "Montuno". In addition, the marching band in the parade, consisting of drummers, keeps the crowds entertained. In the city, a big Christmas tree is lit with Christmas lights, and everybody surrounds the tree and sings Christmas carols.
Traditional cuisine.
Panamanian Cuisine is a mix of African, Spanish, and Native American techniques, dishes, and ingredients, reflecting its diverse population. Since Panama is a land bridge between two continents, it has a large variety of tropical fruits, vegetables and herbs that are used in native cooking.
Typical Panamanian foods are mildly flavored, without the pungency of some of Panama's Latin American and Caribbean neighbors. Common ingredients are maize, rice, wheat flour, plantains, "yuca" (cassava), beef, chicken, pork and seafood.
Traditional clothing.
Panamanian men's traditional clothing consists of white cotton shirts, trousers and woven straw hat.
The traditional women's clothing is the "pollera". It originated in Spain in the 16th century, and by the early 1800s it was a typical in Panama, worn by women servants, especially wet nurses ("De Zarate" 5). Later, it was adopted by upper-class women.
A "pollera" is made of "cambric" or "fine linen" (Baker 177). It is white, and is usually about 13 yards of material.
The original "pollera" consists of a ruffled blouse worn off the shoulders and a skirt is on the waistline with gold buttons. The skirt is also ruffled, so that when it is lifted up, it looks like a peacock's tail or a "mantilla" fan. The designs on the skirt and blouse are usually flowers or birds. Two large matching pom poms ("mota") are on the front and back, four ribbons hang from the front and back on the waist line, five gold chains ("caberstrillos") hang from the neck to the waist, a gold cross or medallion on a black ribbon is worn as a choker, and a silk purse is worn on the waistline. Earrings ("zaricillos") are usually gold or coral. Slippers usually match the color of the "pollera". Hair is usually worn in a bun, held by three large gold combs that have pearls ("tembleques") worn like a crown. Quality "pollera" can cost up to $10,000, and may take a year to complete.
Today, there are different types of "polleras"; the "pollera de gala" consists of a short-sleeved ruffle skirt blouse, two full-length skirts and a petticoat. Girls wear "tembleques" in their hair. Gold coins and jewelry are added to the outfit. The "pollera montuna" is a daily dress, with a blouse, a skirt with a solid color, a single gold chain, and pendant earrings and a natural flower in the hair. Instead of an off-the-shoulder blouse is a fitted white jacket with, shoulder pleats, and a flared hem.
Traditional clothing in Panama can be worn in parades, where the females and males do a traditional dance. Females do a gentle sway and twirl their skirts, while the men hold their hats in their hands and dance behind the females.
Literature.
According to Professor Rodrigo Miró, the first story about Panama was written by Gonzalo Fernández de Oviedo y Valdés and published as part of the "Historia General y Natural de Las Indias" in 1535. Some poets and novelists born in Panamá are Manuel María Ayala (1785–1824), Amelia Denis de Icaza (1836–1911), Darío Herrera (1870–1914), Ricardo Miró (1883–1940), Gaspar Octavio Hernández (1893–1918), Demetrio Korsi (1899–1957), Ricardo Bermúdez (1914–2000), Mario Augusto Rodriguez (1917–2008), José María Sánchez (1918–1973), Ramón H. Jurado (1922–1978), Carlos Francisco Changmarín (1922– ), Joaquín Beleño (1922–1988), Tristán Solarte (1924– ), Pedro Rivera (1939– ), Moravia Ochoa López (1941– ), Gloria Guardia (1940– ), Dimas Lidio Pitty (1941– ), Roberto Fernández Iglesias (1941– ), Jarl Ricardo Babot (1946– ), Manuel Orestes Nieto (1951– ), Moisés Pascual (1955– ), Héctor Miguel Collado (1960– ), David Robinson Orobio (1960– ), Katia Chiari (1969– ), Carlos Oriel Wynter Melo (1971– ), José Luis Rodríguez Pittí (1971– ) and Sofía Santim (1982– ).
Sports.
The U.S. influence in Panama can be seen in the country's sports. Baseball is Panama's national sport and the country has regional teams and a national team that represents it in international events. At least 140 Panamanian players have played professional baseball in the United States, more than any other Central American country. Notable players include Bruce Chen, Rod Carew, Mariano Rivera, Carlos Lee, Manny Sanguillén, and Carlos Ruiz.
In boxing, four Panamanians are in the International Boxing Hall of Fame: Roberto Durán, Eusebio Pedroza, Ismael Laguna and Panama Al Brown. Panama presently has two reigning world boxing champions: Guillermo Jones and Anselmo Moreno.
Basketball is popular in Panama, there are regional teams as well as a squad that competes internationally. Among Panama's most prominent basketball players are Rolando Blackman (four-time NBA All-Star) and Harlem Globetrotters' star Kevin Daley. Long jumper Irving Saladino became the first Panamanian Olympic gold medalist in 2008.
Other popular sports include volleyball, taekwondo, soccer, golf, and tennis. A long-distance hiking trail called the TransPanama Trail is being built from Colombia to Costa Rica.
Other non-traditional sports in the country have had great importance such as the triathlon that has captured the attention of many athletes nationwide and the country has hosted international competitions. Flag football has also been growing in popularity in both men and women and with international participation in world of this discipline being among the best teams in the world, the sport was introduced by Americans residing in the Canal Zone for veterans and retirees who even had a festival called the Turkey Ball. Other popular sports are American football, rugby, hockey, softball and other amateur sports including skateboarding, BMX and surfing, because the many beaches of Panama such as Santa Catalina and Venao that have hosted events the likes of ISA World Surfing Games.
In 2012, eight different athletes represented Panama in the London 2012 Olympics. Irving Saladino in Long Jump, Alonso Edward in Track and Field, Andrea Ferris in Track and Field, Diego Castillo in Swimming, and the youngest on the team, Carolena Carstens who was 16 competing in the taekwondo. She was the first representative to compete for Panama in that sport.

</doc>
<doc id="23000" url="https://en.wikipedia.org/wiki?curid=23000" title="Polynomial">
Polynomial

In mathematics, a polynomial is an expression consisting of variables (or indeterminates) and coefficients, that involves only the operations of addition, subtraction, multiplication, and non-negative integer exponents. An example of a polynomial of a single indeterminate (or variable), , is , which is a quadratic polynomial. An example in three variables is .
Polynomials appear in a wide variety of areas of mathematics and science. For example, they are used to form polynomial equations, which encode a wide range of problems, from elementary word problems to complicated problems in the sciences; they are used to define polynomial functions, which appear in settings ranging from basic chemistry and physics to economics and social science; they are used in calculus and numerical analysis to approximate other functions. In advanced mathematics, polynomials are used to construct polynomial rings and algebraic varieties, central concepts in algebra and algebraic geometry.
Etymology.
According to the Oxford English Dictionary, "polynomial" succeeded the term "binomial", and was made simply by replacing the Latin root "bi-" with the Greek "poly-", which comes from the Greek word for "many". The word "polynomial" was first used in the 17th century.
Notation and terminology.
The "x" occurring in a polynomial is commonly called either a "variable" or an "indeterminate". When the polynomial is considered for itself, "x" is a fixed symbol which does not have any value (its value is "indeterminate"). It is thus more correct to call it an "indeterminate". However, when one considers the function defined by the polynomial, then "x" represents the argument of the function, and is therefore called a "variable". Many authors use these two words interchangeably, but this may be sometimes confusing and is not done in this article.
It is a common convention to use uppercase letters for the indeterminates and the corresponding lowercase letters for the variables (arguments) of the associated function.
It may be confusing that a polynomial "P" in the indeterminate "X" may appear in the formulas either as "P" or as "P"("X").
Normally, the name of the polynomial is "P", not "P"("X"). However, if "a" denotes a number, a variable, another polynomial, or, more generally any expression, then "P"("a") denotes, by convention, the result of substituting "X" by "a" in "P". For example, the polynomial "P" defines the function
In particular, if "a" = "X", then the definition of "P"("a") implies
This equality allows writing "let "P"("X") be a polynomial" as a shorthand for "let "P" be a polynomial in the indeterminate "X"". On the other hand, when it is not necessary to emphasize the name of the indeterminate, many formulas are much simpler and easier to read if the name(s) of the indeterminate(s) do not appear at each occurrence of the polynomial.
Definition.
A polynomial in a single indeterminate can be written in the form
where formula_4 are numbers, or more generally elements of a ring, and formula_5 is a symbol which is called an indeterminate or, for historical reasons, a variable. The symbol formula_5 does not represent any value, although the usual (commutative, distributive) laws valid for arithmetic operations also apply to it.
This can be expressed more concisely by using summation notation:
That is, a polynomial can either be zero or can be written as the sum of a finite number of non-zero terms. Each term consists of the product of a number—called the coefficient of the term—and a finite number of indeterminates, raised to nonnegative integer powers. The exponent on an indeterminate in a term is called the degree of that indeterminate in that term; the degree of the term is the sum of the degrees of the indeterminates in that term, and the degree of a polynomial is the largest degree of any one term with nonzero coefficient. Because , the degree of an indeterminate without a written exponent is one. A term and a polynomial with no indeterminates are called respectively a constant term and a constant polynomial; the degree of a constant term and of a nonzero constant polynomial is 0. The degree of the zero polynomial (which has no term) is generally treated as not defined (but see below).
For example:
is a term. The coefficient is , the indeterminates are and , the degree of is two, while the degree of is one. The degree of the entire term is the sum of the degrees of each indeterminate in it, so in this example the degree is .
Forming a sum of several terms produces a polynomial. For example, the following is a polynomial:
It consists of three terms: the first is degree two, the second is degree one, and the third is degree zero.
Polynomials of small degree have been given specific names. A polynomial of degree zero is a "constant polynomial" or simply a "constant". Polynomials of degree one, two or three are respectively "linear polynomials," "quadratic polynomials" and "cubic polynomials". For higher degrees the specific names are not commonly used, although "quartic polynomial" (for degree four) and "quintic polynomial" (for degree five) are sometimes used. The names for the degrees may be applied to the polynomial or to its terms. For example, in the term is a linear term in a quadratic polynomial.
The polynomial 0, which may be considered to have no terms at all, is called the zero polynomial. Unlike other constant polynomials, its degree is not zero. Rather the degree of the zero polynomial is either left explicitly undefined, or defined as negative (either −1 or −∞). These conventions are useful when defining Euclidean division of polynomials. The zero polynomial is also unique in that it is the only polynomial having an infinite number of roots. In the case of polynomials in more than one indeterminate, a polynomial is called "homogeneous" of if "all" its non-zero terms have . The zero polynomial is homogeneous, and, as homogeneous polynomial, its degree is undefined. For example, is homogeneous of degree 5. For more details, see homogeneous polynomial.
The commutative law of addition can be used to rearrange terms into any preferred order. In polynomials with one indeterminate, the terms are usually ordered according to degree, either in "descending powers of ", with the term of largest degree first, or in "ascending powers of ". The polynomial in the example above is written in descending powers of . The first term has coefficient , indeterminate , and exponent . In the second term, the coefficient . The third term is a constant. Because the "degree" of a non-zero polynomial is the largest degree of any one term, this polynomial has degree two.
Two terms with the same indeterminates raised to the same powers are called "similar terms" or "like terms", and they can be combined, using the distributive law, into a single term whose coefficient is the sum of the coefficients of the terms that were combined. It may happen that this makes the coefficient 0. Polynomials can be classified by the number of terms with nonzero coefficients, so that a one-term polynomial is called a monomial, a two-term polynomial is called a binomial, and a three-term polynomial is called a "trinomial". The term "quadrinomial" is occasionally used for a four-term polynomial.
A polynomial in one indeterminate is called a "univariate polynomial", a polynomial in more than one indeterminate is called a multivariate polynomial. A polynomial with two indeterminates is called a bivariate polynomial. These notions refer more to the kind of polynomials one is generally working with than to individual polynomials; for instance when working with univariate polynomials one does not exclude constant polynomials (which may result, for instance, from the subtraction of non-constant polynomials), although strictly speaking constant polynomials do not contain any indeterminates at all. It is possible to further classify multivariate polynomials as "bivariate", "trivariate", and so on, according to the maximum number of indeterminates allowed. Again, so that the set of objects under consideration be closed under subtraction, a study of trivariate polynomials usually allows bivariate polynomials, and so on. It is common, also, to say simply "polynomials in , and ", listing the indeterminates allowed.
The "evaluation of a polynomial" consists of substituting a numerical value to each indeterminate and carrying out the indicated multiplications and additions. For polynomials in one indeterminate, the evaluation is usually more efficient (lower number of arithmetic operations to perform) using Horner's method:
Arithmetic of polynomials.
Polynomials can be added using the associative law of addition (grouping all their terms together into a single sum), possibly followed by reordering, and combining of like terms. For example, if
then
which can be simplified to
To work out the product of two polynomials into a sum of terms, the distributive law is repeatedly applied, which results in each term of one polynomial being multiplied by every term of the other. For example, if
then
which can be simplified to
Polynomial evaluation can be used to compute the remainder of polynomial division by a polynomial of degree one, because the remainder of the division of by is ; see the polynomial remainder theorem. This is more efficient than the usual algorithm of division when the quotient is not needed.
As for the integers, two kinds of divisions are considered for the polynomials. The "Euclidean division of polynomials" that generalizes the Euclidean division of the integers. It results in two polynomials, a "quotient" and a "remainder" that are characterized by the following property of the polynomials: given two polynomials "a" and "b" such that "b" ≠ 0, there exists a unique pair of polynomials, "q", the quotient, and "r", the remainder, such that and (here the polynomial zero is supposed to have a negative degree). By hand as well as with a computer, this division can be computed by the polynomial long division algorithm.
All polynomials with coefficients in a unique factorization domain (for example, the integers or a field) also have a factored form in which the polynomial is written as a product of irreducible polynomials and a constant. This factored form is unique up to the order of the factors and their multiplication by an invertible constant. In the case of the field of complex numbers, the irreducible factors are linear. Over the real numbers, they have the degree either one or two. Over the integers and the rational numbers the irreducible factors may have any degree. For example, the factored form of
is
over the integers and the reals and
over the complex numbers.
The computation of the factored form, called "factorization" is, in general, too difficult to be done by hand-written computation. However, efficient polynomial factorization algorithms are available in most computer algebra systems.
A formal quotient of polynomials, that is, an algebraic fraction wherein the numerator and denominator are polynomials, is called a "rational expression" or "rational fraction" and is not, in general, a polynomial. Division of a polynomial by a number, however, yields another polynomial. For example, is considered a valid term in a polynomial (and a polynomial by itself) because it is equivalent to and is just a constant. When this expression is used as a term, its coefficient is therefore . For similar reasons, if complex coefficients are allowed, one may have a single term like ; even though it looks like it should be expanded to two terms, the complex number is one complex number, and is the coefficient of that term. The expression is not a polynomial because it includes division by a non-constant polynomial. The expression is not a polynomial, because it contains an indeterminate used as exponent.
Because subtraction can be replaced by addition of the opposite quantity, and because positive integer exponents can be replaced by repeated multiplication, all polynomials can be constructed from constants and indeterminates using only addition and multiplication.
Polynomial functions.
A "polynomial function" is a function that can be defined by evaluating a polynomial. A function of one argument is called a polynomial function if it satisfies
for all arguments , where is a non-negative integer and are constant coefficients.
For example, the function , taking real numbers to real numbers, defined by
is a polynomial function of one variable. Polynomial functions of multiple variables can also be defined, using polynomials in multiple indeterminates, as in
An example is also the function formula_23 which, although it doesn't look like a polynomial, is a polynomial function on formula_24 because for every formula_5 from formula_24 it is true that formula_27 (see Chebyshev polynomials).
Polynomial functions are a class of functions having many important properties. They are all continuous, smooth, entire, computable, etc.
Graphs of polynomial functions.
A polynomial function in one real variable can be represented by a graph.
The graph of a non-constant (univariate) polynomial always tends to infinity when the variable increases indefinitely (in absolute value).
Polynomial graphs are analyzed in calculus using intercepts, slopes, concavity, and end behavior.
Polynomial equations.
A "polynomial equation", also called "algebraic equation", is an equation of the form
For example,
is a polynomial equation.
In case of a univariate polynomial equation, the variable is considered an unknown, and one seeks to find the possible values for which both members of the equation evaluate to the same value (in general more than one solution may exist). A polynomial equation stands in contrast to a "polynomial identity" like , where both expressions represent the same polynomial in different forms, and as a consequence any evaluation of both members gives a valid equality.
In elementary algebra, methods such as the quadratic formula are given for solving all first degree and second degree polynomial equations in one variable. There are also formulas for the cubic and quartic equations. For higher degrees, the Abel–Ruffini theorem asserts that there can not exist a general formula in radicals. However, root-finding algorithms may be used to find numerical approximations of the roots of a polynomial expression of any degree.
The number of real solutions of a polynomial equation with real coefficients may not exceed the degree, and equals the degree when the complex solutions are counted with their multiplicity. This fact is called the fundamental theorem of algebra.
Solving polynomial equations.
Every polynomial in corresponds to a function, (where the occurrences of in are interpreted as the argument of ), called the "polynomial function" of ; the equation in setting is the "polynomial equation" corresponding to . The solutions of this equation are called the "roots" of the polynomial; they are the "zeroes" of the function (corresponding to the points where the graph of meets the -axis). A number is a root of if and only if the polynomial (of degree one in ) divides . It may happen that divides more than once: if divides then is called a "multiple root" of , and otherwise is called a "simple root" of . If is a nonzero polynomial, there is a highest power such that divides , which is called the "multiplicity" of the root in . When is the zero polynomial, the corresponding polynomial equation is trivial, and this case is usually excluded when considering roots: with the above definitions every number would be a root of the zero polynomial, with undefined (or infinite) multiplicity. With this exception made, the number of roots of , even counted with their respective multiplicities, cannot exceed the degree of . The relation between the roots of a polynomial and its coefficients is described by Viète's formulas.
Some polynomials, such as , do not have any roots among the real numbers. If, however, the set of allowed candidates is expanded to the complex numbers, every non-constant polynomial has at least one root; this is the fundamental theorem of algebra. By successively dividing out factors , one sees that any polynomial with complex coefficients can be written as a constant (its leading coefficient) times a product of such polynomial factors of degree 1; as a consequence, the number of (complex) roots counted with their multiplicities is exactly equal to the degree of the polynomial.
There is a difference between approximating roots and finding exact expressions for roots. Formulas for expressing the roots of polynomials of degree 2 in terms of square roots have been known since ancient times (see quadratic equation), and for polynomials of degree 3 or 4 similar formulas (using cube roots in addition to square roots) were found in the 16th century (see cubic function and quartic function for the formulas and Niccolò Fontana Tartaglia, Lodovico Ferrari, Gerolamo Cardano, and Vieta for historical details). But formulas for degree 5 eluded researchers. In 1824, Niels Henrik Abel proved the striking result that there can be no general (finite) formula, involving only arithmetic operations and radicals, that expresses the roots of a polynomial of degree 5 or greater in terms of its coefficients (see Abel–Ruffini theorem). In 1830, Évariste Galois, studying the permutations of the roots of a polynomial, extended the Abel–Ruffini theorem by showing that, given a polynomial equation, one may decide whether it is solvable by radicals, and, if it is, solve it. This result marked the start of Galois theory and group theory, two important branches of modern mathematics. Galois himself noted that the computations implied by his method were impracticable. Nevertheless, formulas for solvable equations of degrees 5 and 6 have been published (see quintic function and sextic equation).
Numerical approximation of roots of polynomials in one unknown is easily done on a computer by the Jenkins–Traub method, Laguerre's method, Durand–Kerner method, or by some other root-finding algorithm.
For polynomials in more than one indeterminate the notion of root does not exist, and there are usually infinitely many combinations of values for the variables for which the polynomial function takes the value zero. However, for certain "sets" of such polynomials it may happen that for only finitely many combinations all polynomial functions take the value zero.
For a set of polynomial equations in several unknowns, there are algorithms to decide whether they have a finite number of complex solutions. If the number of solutions is finite, there are algorithms to compute the solutions. The methods underlying these algorithms are described in the article systems of polynomial equations.
The special case where all the polynomials are of degree one is called a system of linear equations, for which another range of different solution methods exist, including the classical Gaussian elimination.
Generalizations of polynomials.
There are at least two ways to generalize polynomials:
Trigonometric polynomials.
A trigonometric polynomial is a finite linear combination of functions sin("nx") and cos("nx") with "n" taking on the values of one or more natural numbers. The coefficients may be taken as real numbers, for real-valued functions. For complex coefficients, there is no difference between such a function and a finite Fourier series.
Trigonometric polynomials are widely used, for example in trigonometric interpolation applied to the interpolation of periodic functions. They are used also in the discrete Fourier transform.
The term "trigonometric polynomial" for the real-valued case can be seen as using the analogy: the functions sin("nx") and cos("nx") are similar to the monomial basis for polynomials. In the complex case the trigonometric polynomials are spanned by the positive and negative powers of "e""ix".
Matrix polynomials.
A matrix polynomial is a polynomial with matrices as variables. Given an ordinary, scalar-valued polynomial
this polynomial evaluated at a matrix "A" is
where "I" is the identity matrix.
A matrix polynomial equation is an equality between two matrix polynomials, which holds for the specific matrices in question. A matrix polynomial identity is a matrix polynomial equation which holds for all matrices "A" in a specified matrix ring "Mn"("R").
Laurent polynomials.
Laurent polynomials are like polynomials, but allow negative powers of the variable(s) to occur.
Rational functions.
A rational fraction is the quotient (algebraic fraction) of two polynomials. Any algebraic expression that can be rewritten as a rational fraction is a rational function.
While polynomial functions are defined for all values of the variables, a rational function is defined only for the values of the variables for which the denominator is not zero.
The rational fractions include the Laurent polynomials, but do not limit denominators to powers of an indeterminate.
Power series.
Formal power series are like polynomials, but allow infinitely many non-zero terms to occur, so that they do not have finite degree. Unlike polynomials they cannot in general be explicitly and fully written down (just like real numbers cannot), but the rules for manipulating their terms are the same as for polynomials. Non-formal power series also generalize polynomials, but the multiplication of two power series may not converge.
Applications of polynomials.
Calculus.
The simple structure of polynomial functions makes them quite useful in analyzing general functions using polynomial approximations. An important example in calculus is Taylor's theorem, which roughly states that every differentiable function locally looks like a polynomial function, and the Stone–Weierstrass theorem, which states that every continuous function defined on a compact interval of the real axis can be approximated on the whole interval as closely as desired by a polynomial function.
Calculating derivatives and integrals of polynomial functions is particularly simple. For the polynomial function
the derivative with respect to "x" is
and the indefinite integral is
Abstract algebra.
In abstract algebra, one distinguishes between "polynomials" and "polynomial functions". A "polynomial" in one indeterminate over a ring is defined as a formal expression of the form
where is a natural number, the coefficients are elements of , and is a formal symbol, whose powers are just placeholders for the corresponding coefficients , so that the given formal expression is just a way to encode the sequence , where there is an such that for all . Two polynomials sharing the same value of "n" are considered equal if and only if the sequences of their coefficients are equal; furthermore any polynomial is equal to any polynomial with greater value of obtained from it by adding terms in front whose coefficient is zero. These polynomials can be added by simply adding corresponding coefficients (the rule for extending by terms with zero coefficients can be used to make sure such coefficients exist). Thus each polynomial is actually equal to the sum of the terms used in its formal expression, if such a term is interpreted as a polynomial that has zero coefficients at all powers of other than . Then to define multiplication, it suffices by the distributive law to describe the product of any two such terms, which is given by the rule
Thus the set of all polynomials with coefficients in the ring forms itself a ring, the "ring of polynomials" over , which is denoted by . The map from to sending to is an injective homomorphism of rings, by which is viewed as a subring of . If is commutative, then is an algebra over .
One can think of the ring as arising from by adding one new element "X" to "R", and extending in a minimal way to a ring in which satisfies no other relations than the obligatory ones, plus commutation with all elements of (that is ). To do this, one must add all powers of and their linear combinations as well.
Formation of the polynomial ring, together with forming factor rings by factoring out ideals, are important tools for constructing new rings out of known ones. For instance, the ring (in fact field) of complex numbers, which can be constructed from the polynomial ring over the real numbers by factoring out the ideal of multiples of the polynomial . Another example is the construction of finite fields, which proceeds similarly, starting out with the field of integers modulo some prime number as the coefficient ring (see modular arithmetic).
If is commutative, then one can associate to every polynomial in , a "polynomial function" with domain and range equal to (more generally one can take domain and range to be the same unital associative algebra over ). One obtains the value by substitution of the value for the symbol in . One reason to distinguish between polynomials and polynomial functions is that over some rings different polynomials may give rise to the same polynomial function (see Fermat's little theorem for an example where is the integers modulo ). This is not the case when is the real or complex numbers, whence the two concepts are not always distinguished in analysis. An even more important reason to distinguish between polynomials and polynomial functions is that many operations on polynomials (like Euclidean division) require looking at what a polynomial is composed of as an expression rather than evaluating it at some constant value for .
Divisibility.
In commutative algebra, one major focus of study is "divisibility" among polynomials. If is an integral domain and and are polynomials in , it is said that "divides" or is a divisor of if there exists a polynomial in such that . One can show that every zero gives rise to a linear divisor, or more formally, if is a polynomial in and is an element of such that , then the polynomial () divides . The converse is also true. The quotient can be computed using the polynomial long division.
If is a field and and are polynomials in with , then there exist unique polynomials and in with
and such that the degree of is smaller than the degree of (using the convention that the polynomial 0 has a negative degree). The polynomials and are uniquely determined by and . This is called "Euclidean division, division with remainder" or "polynomial long division" and shows that the ring is a Euclidean domain.
Analogously, "prime polynomials" (more correctly, "irreducible polynomials") can be defined as "non-zero polynomials which cannot be factorized into the product of two non constant polynomials". In the case of coefficients in a ring, "non constant" must be replaced by "non constant or non unit" (both definitions agree in the case of coefficients in a field). Any polynomial may be decomposed into the product of an invertible constant by a product of irreducible polynomials. If the coefficients belong to a field or a unique factorization domain this decomposition is unique up to the order of the factors and the multiplication of any non unit factor by a unit (and division of the unit factor by the same unit). When the coefficients belong to integers, rational numbers or a finite field, there are algorithms to test irreducibility and to compute the factorization into irreducible polynomials (see Factorization of polynomials). These algorithms are not practicable for hand written computation, but are available in any computer algebra system. Eisenstein's criterion can also be used in some cases to determine irreducibility.
Other applications.
Polynomials serve to approximate other functions, such as the use of splines.
Polynomials are frequently used to encode information about some other object. The characteristic polynomial of a matrix or linear operator contains information about the operator's eigenvalues. The minimal polynomial of an algebraic element records the simplest algebraic relation satisfied by that element. The chromatic polynomial of a graph counts the number of proper colourings of that graph.
The term "polynomial", as an adjective, can also be used for quantities or functions that can be written in polynomial form. For example, in computational complexity theory the phrase "polynomial time" means that the time it takes to complete an algorithm is bounded by a polynomial function of some variable, such as the size of the input.
History.
Determining the roots of polynomials, or "solving algebraic equations", is among the oldest problems in mathematics. However, the elegant and practical notation we use today only developed beginning in the 15th century. Before that, equations were written out in words. For example, an algebra problem from the Chinese Arithmetic in Nine Sections, circa 200 BCE, begins "Three sheafs of good crop, two sheafs of mediocre crop, and one sheaf of bad crop are sold for 29 dou." We would write .
History of the notation.
The earliest known use of the equal sign is in Robert Recorde's "The Whetstone of Witte", 1557. The signs + for addition, − for subtraction, and the use of a letter for an unknown appear in Michael Stifel's "Arithemetica integra", 1544. René Descartes, in "La géometrie", 1637, introduced the concept of the graph of a polynomial equation. He popularized the use of letters from the beginning of the alphabet to denote constants and letters from the end of the alphabet to denote variables, as can be seen above, in the general formula for a polynomial in one variable, where the 's denote constants and denotes a variable. Descartes introduced the use of superscripts to denote exponents as well.

</doc>
<doc id="23001" url="https://en.wikipedia.org/wiki?curid=23001" title="Polymer">
Polymer

A polymer () (Greek "poly-", "many" + "-mer", "parts") is a large molecule, or macromolecule, composed of many repeated subunits. Because of their broad range of properties, both synthetic and natural polymers play an essential and ubiquitous role in everyday life. Polymers range from familiar synthetic plastics such as polystyrene to natural biopolymers such as DNA and proteins that are fundamental to biological structure and function. Polymers, both natural and synthetic, are created via polymerization of many small molecules, known as monomers. Their consequently large molecular mass relative to small molecule compounds produces unique physical properties, including toughness, viscoelasticity, and a tendency to form glasses and semicrystalline structures rather than crystals.
The term "polymer" derives from the ancient Greek word πολύς ("polus", meaning "many, much") and μέρος ("meros", meaning "parts"), and refers to a molecule whose structure is composed of multiple repeating units, from which originates a characteristic of high relative molecular mass and attendant properties. The units composing polymers derive, actually or conceptually, from molecules of low relative molecular mass. The term was coined in 1833 by Jöns Jacob Berzelius, though with a definition distinct from the modern IUPAC definition. The modern concept of polymers as covalently bonded macromolecular structures was proposed in 1920 by Hermann Staudinger, who spent the next decade finding experimental evidence for this hypothesis.
Polymers are studied in the fields of biophysics and macromolecular science, and polymer science (which includes polymer chemistry and polymer physics). Historically, products arising from the linkage of repeating units by covalent chemical bonds have been the primary focus of polymer science; emerging important areas of the science now focus on non-covalent links. Polyisoprene of latex rubber and the polystyrene of styrofoam are examples of polymeric natural/biological and synthetic polymers, respectively. In biological contexts, essentially all biological macromolecules—i.e., proteins (polyamides), nucleic acids (polynucleotides), and polysaccharides—are purely polymeric, or are composed in large part of polymeric components—e.g., isoprenylated/lipid-modified glycoproteins, where small lipidic molecule and oligosaccharide modifications occur on the polyamide backbone of the protein.
The simplest theoretical models for polymers are ideal chains.
Common examples.
Polymers are of two types:
Most commonly, the continuously linked backbone of a polymer used for the preparation of plastics consists mainly of carbon atoms. A simple example is polyethylene ('polythene' in British English), whose repeating unit is based on ethylene monomer. However, other structures do exist; for example, elements such as silicon form familiar materials such as silicones, examples being Silly Putty and waterproof plumbing sealant. Oxygen is also commonly present in polymer backbones, such as those of polyethylene glycol, polysaccharides (in glycosidic bonds), and DNA (in phosphodiester bonds).
Polymer synthesis.
Polymerization is the process of combining many small molecules known as monomers into a covalently bonded chain or network. During the polymerization process, some chemical groups may be lost from each monomer. This is the case, for example, in the polymerization of PET polyester. The monomers are terephthalic acid (HOOC-C6H4-COOH) and ethylene glycol (HO-CH2-CH2-OH) but the repeating unit is -OC-C6H4-COO-CH2-CH2-O-, which corresponds to the combination of the two monomers with the loss of two water molecules. The distinct piece of each monomer that is incorporated into the polymer is known as a repeat unit or monomer residue.
Laboratory synthetic methods are generally divided into two categories, step-growth polymerization and chain-growth polymerization. The essential difference between the two is that in chain growth polymerization, monomers are added to the chain one at a time only, such as in polyethylene, whereas in step-growth polymerization chains of monomers may combine with one another directly, such as in polyester. However, some newer methods such as plasma polymerization do not fit neatly into either category. Synthetic polymerization reactions may be carried out with or without a catalyst. Laboratory synthesis of biopolymers, especially of proteins, is an area of intensive research.
Biological synthesis.
There are three main classes of biopolymers: polysaccharides, polypeptides, and polynucleotides.
In living cells, they may be synthesized by enzyme-mediated processes, such as the formation of DNA catalyzed by DNA polymerase. The synthesis of proteins involves multiple enzyme-mediated processes to transcribe genetic information from the DNA to RNA and subsequently translate that information to synthesize the specified protein from amino acids. The protein may be modified further following translation in order to provide appropriate structure and functioning. There are other biopolymers such as rubber, suberin, melanin and lignin.
Modification of natural polymers.
Naturally occurring polymers such as cotton, starch and rubber were familiar materials for years before synthetic polymers such as polyethene and perspex appeared on the market. 
Many commercially important polymers are synthesized by chemical modification of naturally occurring polymers. Prominent examples include the reaction of nitric acid and cellulose to form nitrocellulose and the formation of vulcanized rubber by heating natural rubber in the presence of sulfur.
Ways in which polymers can be modified include oxidation, cross-linking and end-capping.
Especially in the production of polymers, the gas separation by membranes has acquired increasing importance in the petrochemical industry and is now a relatively well-established unit operation.
The process of polymer degassing is necessary to suit polymer for extrusion and pelletizing, increasing safety, environmental, and product quality aspects. Nitrogen is generally used for this purpose, resulting in a vent gas primarily composed of monomers and nitrogen.
Polymer properties.
Polymer properties are broadly divided into several classes based on the scale at which the property is defined as well as upon its physical basis. The most basic property of a polymer is the identity of its constituent monomers. A second set of properties, known as microstructure, essentially describe the arrangement of these monomers within the polymer at the scale of a single chain. These basic structural properties play a major role in determining bulk physical properties of the polymer, which describe how the polymer behaves as a continuous macroscopic material. Chemical properties, at the nano-scale, describe how the chains interact through various physical forces. At the macro-scale, they describe how the bulk polymer interacts with other chemicals and solvents.
Monomers and repeat units.
The identity of the repeat units (monomer residues, also known as "mers") comprising a polymer is its first and most important attribute. Polymer nomenclature is generally based upon the type of monomer residues comprising the polymer. Polymers that contain only a single type of repeat unit are known as homopolymers, while polymers containing a mixture of repeat units are known as copolymers. Poly(styrene), for example, is composed only of styrene monomer residues, and is therefore classified as a homopolymer. Ethylene-vinyl acetate, on the other hand, contains more than one variety of repeat unit and is thus a copolymer. Some biological polymers are composed of a variety of different but structurally related monomer residues; for example, polynucleotides such as DNA are composed of a variety of nucleotide subunits.
A polymer molecule containing ionizable subunits is known as a polyelectrolyte or ionomer.
Microstructure.
The microstructure of a polymer (sometimes called configuration) relates to the physical arrangement of monomer residues along the backbone of the chain. These are the elements of polymer structure that require the breaking of a covalent bond in order to change. Structure has a strong influence on the other properties of a polymer. For example, two samples of natural rubber may exhibit different durability, even though their molecules comprise the same monomers.
Polymer architecture.
An important microstructural feature of a polymer is its architecture and shape, which relates to the way branch points lead to a deviation from a simple linear chain. A branched polymer molecule is composed of a main chain with one or more substituent side chains or branches. Types of branched polymers include star polymers, comb polymers, brush polymers, dendronized polymers, "ladders", and dendrimers. There exist also two-dimensional polymers which are composed of topologically planar repeat units. A polymer's architecture affects many of its physical properties including, but not limited to, solution viscosity, melt viscosity, solubility in various solvents, glass transition temperature and the size of individual polymer coils in solution. A variety of techniques may be employed for the synthesis of a polymeric material with a range of architectures, for example Living polymerization.
Chain length.
The physical properties of a polymer are strongly dependent on the size or length of the polymer chain. For example, as chain length is increased, melting and boiling temperatures increase quickly. Impact resistance also tends to increase with chain length, as does the viscosity, or resistance to flow, of the polymer in its molten state. Melt viscosity formula_1 is related to polymer chain length Z roughly as formula_1 ~ Z3.2, so that a tenfold increase in polymer chain length results in a viscosity increase of over 1000 times. Increasing chain length furthermore tends to decrease chain mobility, increase strength and toughness, and increase the glass transition temperature (Tg). This is a result of the increase in chain interactions such as Van der Waals attractions and entanglements that come with increased chain length. These interactions tend to fix the individual chains more strongly in position and resist deformations and matrix breakup, both at higher stresses and higher temperatures.
A common means of expressing the length of a chain is the degree of polymerization, which quantifies the number of monomers incorporated into the chain. As with other molecules, a polymer's size may also be expressed in terms of molecular weight. Since synthetic polymerization techniques typically yield a polymer product including a range of molecular weights, the weight is often expressed statistically to describe the distribution of chain lengths present in the same. Common examples are the number average molecular weight and weight average molecular weight. The ratio of these two values is the polydispersity index, commonly used to express the "width" of the molecular weight distribution. A final measurement is contour length, which can be understood as the length of the chain backbone in its fully extended state.
The flexibility of an unbranched chain polymer is characterized by its persistence length.
Monomer arrangement in copolymers.
Monomers within a copolymer may be organized along the backbone in a variety of ways.
Tacticity.
Tacticity describes the relative stereochemistry of chiral centers in neighboring structural units within a macromolecule. There are three types: isotactic (all substituents on the same side), atactic (random placement of substituents), and syndiotactic (alternating placement of substituents).
Polymer morphology.
Polymer morphology generally describes the arrangement and microscale ordering of polymer chains in space.
Crystallinity.
When applied to polymers, the term "crystalline" has a somewhat ambiguous usage. In some cases, the term "crystalline" finds identical usage to that used in conventional crystallography. For example, the structure of a crystalline protein or polynucleotide, such as a sample prepared for x-ray crystallography, may be defined in terms of a conventional unit cell composed of one or more polymer molecules with cell dimensions of hundreds of angstroms or more.
A synthetic polymer may be loosely described as crystalline if it contains regions of three-dimensional ordering on atomic (rather than macromolecular) length scales, usually arising from intramolecular folding and/or stacking of adjacent chains. Synthetic polymers may consist of both crystalline and amorphous regions; the degree of crystallinity may be expressed in terms of a weight fraction or volume fraction of crystalline material. Few synthetic polymers are entirely crystalline.
The crystallinity of polymers is characterized by their degree of crystallinity, ranging from zero for a completely non-crystalline polymer to one for a theoretical completely crystalline polymer. 
Polymers with microcrystalline regions are generally tougher (can be bent more without breaking) and more impact-resistant than totally amorphous polymers.
Polymers with a degree of crystallinity approaching zero or one will tend to be transparent, while polymers with intermediate degrees of crystallinity will tend to be opaque due to light scattering by crystalline or glassy regions. Thus for many polymers, reduced crystallinity may also be associated with increased transparency.
Chain conformation.
The space occupied by a polymer molecule is generally expressed in terms of radius of gyration, which is an average distance from the center of mass of the chain to the chain itself. Alternatively, it may be expressed in terms of pervaded volume, which is the volume of solution spanned by the polymer chain and scales with the cube of the radius of gyration.
Mechanical properties.
The bulk properties of a polymer are those most often of end-use interest. These are the properties that dictate how the polymer actually behaves on a macroscopic scale.
Tensile strength.
The tensile strength of a material quantifies how much elongating stress the material will endure before failure. This is very important in applications that rely upon a polymer's physical strength or durability. For example, a rubber band with a higher tensile strength will hold a greater weight before snapping. In general, tensile strength increases with polymer chain length and crosslinking of polymer chains.
Young's modulus of elasticity.
Young's Modulus quantifies the elasticity of the polymer. It is defined, for small strains, as the ratio of rate of change of stress to strain. Like tensile strength, this is highly relevant in polymer applications involving the physical properties of polymers, such as rubber bands. The modulus is strongly dependent on temperature. Viscoelasticity describes a complex time-dependent elastic response, which will exhibit hysteresis in the stress-strain curve when the load is removed. Dynamic mechanical analysis or DMA measures this complex modulus by oscillating the load and measuring the resulting strain as a function of time.
Transport properties.
Transport properties such as diffusivity relate to how rapidly molecules move through the polymer matrix. These are very important in many applications of polymers for films and membranes.
Phase behavior.
Melting point.
The term "melting point", when applied to polymers, suggests not a solid–liquid phase transition but a transition from a crystalline or semi-crystalline phase to a solid amorphous phase. Though abbreviated as simply "Tm", the property in question is more properly called the crystalline melting temperature. Among synthetic polymers, crystalline melting is only discussed with regards to thermoplastics, as thermosetting polymers will decompose at high temperatures rather than melt.
Glass transition temperature.
A parameter of particular interest in synthetic polymer manufacturing is the glass transition temperature (Tg), at which amorphous polymers undergo a transition from a rubbery, viscous liquid, to a brittle, glassy amorphous solid on cooling. The glass transition temperature may be engineered by altering the degree of branching or crosslinking in the polymer or by the addition of plasticizer.
Mixing behavior.
In general, polymeric mixtures are far less miscible than mixtures of small molecule materials. This effect results from the fact that the driving force for mixing is usually entropy, not interaction energy. In other words, miscible materials usually form a solution not because their interaction with each other is more favorable than their self-interaction, but because of an increase in entropy and hence free energy associated with increasing the amount of volume available to each component. This increase in entropy scales with the number of particles (or moles) being mixed. Since polymeric molecules are much larger and hence generally have much higher specific volumes than small molecules, the number of molecules involved in a polymeric mixture is far smaller than the number in a small molecule mixture of equal volume. The energetics of mixing, on the other hand, is comparable on a per volume basis for polymeric and small molecule mixtures. This tends to increase the free energy of mixing for polymer solutions and thus make solvation less favorable. Thus, concentrated solutions of polymers are far rarer than those of small molecules.
Furthermore, the phase behavior of polymer solutions and mixtures is more complex than that of small molecule mixtures. Whereas most small molecule solutions exhibit only an upper critical solution temperature phase transition, at which phase separation occurs with cooling, polymer mixtures commonly exhibit a lower critical solution temperature phase transition, at which phase separation occurs with heating.
In dilute solution, the properties of the polymer are characterized by the interaction between the solvent and the polymer. In a good solvent, the polymer appears swollen and occupies a large volume. In this scenario, intermolecular forces between the solvent and monomer subunits dominate over intramolecular interactions. In a bad solvent or poor solvent, intramolecular forces dominate and the chain contracts. In the theta solvent, or the state of the polymer solution where the value of the second virial coefficient becomes 0, the intermolecular polymer-solvent repulsion balances exactly the intramolecular monomer-monomer attraction. Under the theta condition (also called the Flory condition), the polymer behaves like an ideal random coil. The transition between the states is known as a coil-globule transition.
Inclusion of plasticizers.
Inclusion of plasticizers tends to lower Tg and increase polymer flexibility. Plasticizers are generally small molecules that are chemically similar to the polymer and create gaps between polymer chains for greater mobility and reduced interchain interactions. A good example of the action of plasticizers is related to polyvinylchlorides or PVCs. An uPVC, or unplasticized polyvinylchloride, is used for things such as pipes. A pipe has no plasticizers in it, because it needs to remain strong and heat-resistant. Plasticized PVC is used in clothing for a flexible quality. Plasticizers are also put in some types of cling film to make the polymer more flexible.
Chemical properties.
The attractive forces between polymer chains play a large part in determining polymer's properties. Because polymer chains are so long, these interchain forces are amplified far beyond the attractions between conventional molecules. Different side groups on the polymer can lend the polymer to ionic bonding or hydrogen bonding between its own chains. These stronger forces typically result in higher tensile strength and higher crystalline melting points.
The intermolecular forces in polymers can be affected by dipoles in the monomer units. Polymers containing amide or carbonyl groups can form hydrogen bonds between adjacent chains; the partially positively charged hydrogen atoms in N-H groups of one chain are strongly attracted to the partially negatively charged oxygen atoms in C=O groups on another. These strong hydrogen bonds, for example, result in the high tensile strength and melting point of polymers containing urethane or urea linkages. Polyesters have dipole-dipole bonding between the oxygen atoms in C=O groups and the hydrogen atoms in H-C groups. Dipole bonding is not as strong as hydrogen bonding, so a polyester's melting point and strength are lower than Kevlar's (Twaron), but polyesters have greater flexibility.
Ethene, however, has no permanent dipole. The attractive forces between polyethylene chains arise from weak van der Waals forces. Molecules can be thought of as being surrounded by a cloud of negative electrons. As two polymer chains approach, their electron clouds repel one another. This has the effect of lowering the electron density on one side of a polymer chain, creating a slight positive dipole on this side. This charge is enough to attract the second polymer chain. Van der Waals forces are quite weak, however, so polyethylene can have a lower melting temperature compared to other polymers.
Optical properties.
Polymers such as PMMA and HEMA:MMA are used as matrices in the gain medium of solid-state dye lasers that are also known as polymer lasers. These polymers have a high surface quality and are also highly transparent so that the laser properties are dominated by the laser dye used to dope the polymer matrix. These type of lasers, that also belong to the class of organic lasers, are known to yield very narrow linewidths which is useful for spectroscopy and analytical applications. An important optical parameter in the polymer used in laser applications is the change in refractive index with temperature 
also known as dn/dT. For the polymers mentioned here the (dn/dT) ~ −1.4 × 10−4 in units of K−1 in the 297 ≤ T ≤ 337 K range.
Standardized polymer nomenclature.
There are multiple conventions for naming polymer substances. Many commonly used polymers, such as those found in consumer products, are referred to by a common or trivial name. The trivial name is assigned based on historical precedent or popular usage rather than a standardized naming convention. Both the American Chemical Society (ACS) and IUPAC have proposed standardized naming conventions; the ACS and IUPAC conventions are similar but not identical. Examples of the differences between the various naming conventions are given in the table below:
In both standardized conventions, the polymers' names are intended to reflect the monomer(s) from which they are synthesized rather than the precise nature of the repeating subunit. For example, the polymer synthesized from the simple alkene ethene is called polyethylene, retaining the "-ene" suffix even though the double bond is removed during the polymerization process:
Polymer characterization.
The characterization of a polymer requires several parameters which need to be specified. This is because a polymer actually consists of a statistical distribution of chains of varying lengths, and each chain consists of monomer residues which affect its properties.
A variety of lab techniques are used to determine the properties of polymers. Techniques such as wide angle X-ray scattering, small angle X-ray scattering, and small angle neutron scattering are used to determine the crystalline structure of polymers. Gel permeation chromatography is used to determine the number average molecular weight, weight average molecular weight, and polydispersity. FTIR, Raman and NMR can be used to determine composition. Thermal properties such as the glass transition temperature and melting point can be determined by differential scanning calorimetry and dynamic mechanical analysis. Pyrolysis followed by analysis of the fragments is one more technique for determining the possible structure of the polymer. Thermogravimetry is a useful technique to evaluate the thermal stability of the polymer. Detailed analysis of TG curves also allow us to know a bit of the phase segregation in polymers. Rheological properties are also commonly used to help determine molecular architecture (molecular weight, molecular weight distribution and branching) as well as to understand how the polymer will process, through measurements of the polymer in the melt phase. Another polymer characterization technique is Automatic Continuous Online Monitoring of Polymerization Reactions (ACOMP) which provides real-time characterization of polymerization reactions. It can be used as an analytical method in R&D, as a tool for reaction optimization at the bench and pilot plant level and, eventually, for feedback control of full-scale reactors. ACOMP measures in a model-independent fashion the evolution of average molar mass and intrinsic viscosity, monomer conversion kinetics and, in the case of copolymers, also the average composition drift and distribution. It is applicable in the areas of free radical and controlled radical homo- and copolymerization, polyelectrolyte synthesis, heterogeneous phase reactions, including emulsion polymerization, adaptation to batch and continuous reactors, and modifications of polymers.
Polymer degradation.
Polymer degradation is a change in the properties—tensile strength, color, shape, or molecular weight—of a polymer or polymer-based product under the influence of one or more environmental factors, such as heat, light, chemicals and, in some cases, galvanic action. It is often due to the scission of polymer chain bonds via hydrolysis, leading to a decrease in the molecular mass of the polymer.
Although such changes are frequently undesirable, in some cases, such as biodegradation and recycling, they may be intended to prevent environmental pollution. Degradation can also be useful in biomedical settings. For example, a copolymer of polylactic acid and polyglycolic acid is employed in hydrolysable stitches that slowly degrade after they are applied to a wound.
The susceptibility of a polymer to degradation depends on its structure. Epoxies and chains containing aromatic functionalities are especially susceptible to UV degradation while polyesters are susceptible to degradation by hydrolysis, while polymers containing an unsaturated backbone are especially susceptible to ozone cracking. Carbon based polymers are more susceptible to thermal degradation than inorganic polymers such as polydimethylsiloxane and are therefore not ideal for most high-temperature applications. High-temperature matrices such as bismaleimides (BMI), condensation polyimides (with an O-C-N bond), triazines (with a nitrogen (N) containing ring), and blends thereof are susceptible to polymer degradation in the form of galvanic corrosion when bare carbon fiber reinforced polymer CFRP is in contact with an active metal such as aluminium in salt water environments.
The degradation of polymers to form smaller molecules may proceed by random scission or specific scission. The degradation of polyethylene occurs by random scission—a random breakage of the bonds that hold the atoms of the polymer together. When heated above 450 °C, polyethylene degrades to form a mixture of hydrocarbons. Other polymers, such as poly(alpha-methylstyrene), undergo specific chain scission with breakage occurring only at the ends. They literally unzip or depolymerize back to the constituent monomer.
The sorting of polymer waste for recycling purposes may be facilitated by the use of the Resin identification codes developed by the Society of the Plastics Industry to identify the type of plastic.
Product failure.
In a finished product, such a change is to be prevented or delayed. Failure of safety-critical polymer components can cause serious accidents, such as fire in the case of cracked and degraded polymer fuel lines. Chlorine-induced cracking of acetal resin plumbing joints and polybutylene pipes has caused many serious floods in domestic properties, especially in the USA in the 1990s. Traces of chlorine in the water supply attacked vulnerable polymers in the plastic plumbing, a problem which occurs faster if any of the parts have been poorly extruded or injection molded. Attack of the acetal joint occurred because of faulty molding, leading to cracking along the threads of the fitting which is a serious stress concentration.
Polymer oxidation has caused accidents involving medical devices. One of the oldest known failure modes is ozone cracking caused by chain scission when ozone gas attacks susceptible elastomers, such as natural rubber and nitrile rubber. They possess double bonds in their repeat units which are cleaved during ozonolysis. Cracks in fuel lines can penetrate the bore of the tube and cause fuel leakage. If cracking occurs in the engine compartment, electric sparks can ignite the gasoline and can cause a serious fire. In medical use degradation of polymers can lead to changes of physical and chemical characteristics of implantable devices. 
Fuel lines can also be attacked by another form of degradation: hydrolysis. Nylon 6,6 is susceptible to acid hydrolysis, and in one accident, a fractured fuel line led to a spillage of diesel into the road. If diesel fuel leaks onto the road, accidents to following cars can be caused by the slippery nature of the deposit, which is like black ice.

</doc>
<doc id="23002" url="https://en.wikipedia.org/wiki?curid=23002" title="Perfect competition">
Perfect competition

In economic theory, perfect competition (sometimes called pure competition) describes markets such that no participants are large enough to have the market power to set the price of a homogeneous product. Because the conditions for perfect competition are strict, there are few if any perfectly competitive markets. Still, buyers and sellers in some auction-type markets, say for commodities or some financial assets, may approximate the concept. As a Pareto efficient allocation of economic resources, perfect competition serves as a natural benchmark against which to contrast other market structures.
Basic structural characteristics.
Generally, a perfectly competitive market exists when every participant is a "price taker", and no participant influences the price of the product it buys or sells. Specific characteristics may include:
Perfectly competitive markets are not productively efficient as output will not occur where marginal cost is equal to average cost (MC = AC). 
They are allocatively efficient, as output will always occur where marginal cost is equal to marginal revenue (MC = MR).
In the long run, perfectly competitive markets are not allocatively and productively efficient because it is essentially "sweatshop" economics and limits the growth and productivity of the firm.
In perfect competition, any profit-maximizing producer faces a market price equal to its marginal cost (P = MC). This implies that a factor's price equals the factor's marginal revenue product. It allows for derivation of the supply curve on which the neoclassical approach is based. This is also the reason why "a monopoly does not have a supply curve". The abandonment of price taking creates considerable difficulties for the demonstration of a general equilibrium except under other, very specific conditions such as that of monopolistic competition.
Approaches and conditions.
In neoclassical economics there have been two strands of looking at what perfect competition is. The first emphasis is on the inability of any one agent to affect prices. Usually justified by the fact that any one firm or consumer is so small relative to the whole market that their presence or absence leaves the equilibrium price very nearly unaffected. This assumption of negligible impact of each agent on the equilibrium price has been formalized by Aumann (1964) by postulating a continuum of infinitesimal agents. The difference between Aumann's approach and that found in undergraduate textbooks is that in the first, agents have the power to choose their own prices but do not individually affect the market price, while in the second it is simply assumed that agents treat prices as parameters. Both approaches lead to the same result.
The second view of perfect competition conceives of it in terms of agents taking advantage of – and hence, eliminating – profitable exchange opportunities. The faster this arbitrage takes place, the more competitive a market. The implication is that the more competitive a market is under this definition, the faster the average market price will adjust so as to equate supply and demand (and also equate price to marginal costs). In this view, "perfect" competition means that this adjustment takes place instantaneously. This is usually modeled via the use of the Walrasian auctioneer (see article for more information). The widespread recourse to the auctioneer tale appears to have favored an interpretation of perfect competition as meaning price taking "always", i.e. also at non-equilibrium prices; but this is rejected e.g. by Arrow (1959) or Mas-Colell et al.
Steve Keen notes, following George Stigler, that if firms do not react strategically to one another, the slope of the demand curve that a firm faces is the same as the slope of the market demand curve. Hence, if firms are to produce at a level that equates marginal cost and marginal revenue, the model of perfect competition must include at least an infinite number of firms, each producing an output quantity of zero. As noted above, an influential model of perfect competition in neoclassical economics assumes that the number of buyers and sellers are both of the power of the continuum, that is, an infinity even larger than the number of natural numbers. K. Vela Velupillai quotes Maury Osborne as noting the inapplicability of such models to actual economies since money and the commodities sold each have a smallest positive unit.
Thus nowadays the dominant intuitive idea of the conditions justifying price taking and thus rendering a market perfectly competitive is an amalgam of several different notions, not all present, nor given equal weight, in all treatments. Besides product homogeneity and absence of collusion, the notion more generally associated with perfect competition is the negligibility of the size of agents, which makes them believe that they can sell as much of the good as they wish at the equilibrium price but nothing at a higher price (in particular, firms are described as each one of them facing a horizontal demand curve). However, also widely accepted as part of the notion of perfectly competitive market are perfect information about price distribution and very quick adjustments (whose joint operation establish the law of one price), to the point sometimes of identifying perfect competition with an essentially instantaneous reaching of equilibrium between supply and demand. Finally, the idea of free entry with free access to technology is also often listed as a characteristic of perfectly competitive markets, probably owing to a difficulty with abandoning completely the older conception of free competition. In recent decades it has been rediscovered that free entry can be a foundation of absence of market power, alternative to negligibility of agents.
Free entry also makes it easier to justify the absence of collusion: any collusion by existing firms can be undermined by entry of new firms. The necessarily long-period nature of the analysis (entry requires time!) also allows a reconciliation of the horizontal demand curve facing each firm according to the theory, with the feeling of businessmen that "contrary to economic theory, sales are by no means unlimited at the current market price" (Arrow 1959 p. 49). Sraffian economists see the assumption of free entry and exit as characteristic of the theory of free competition in Classical economics, an approach that is not expressed in terms of schedules of supply and demand.
Results.
In a perfectly competitive market, the demand curve facing a firm is perfectly elastic.
As mentioned above, the perfect competition model, if interpreted as applying also to short-period or very-short-period behaviour, is approximated only by markets of homogeneous products produced and purchased by very many sellers and buyers, usually organized markets for agricultural products or raw materials. In real-world markets, assumptions such as perfect information cannot be verified and are only approximated in organized double-auction markets where most agents wait and observe the behaviour of prices before deciding to exchange (but in the long-period interpretation perfect information is not necessary, the analysis only aims at determining the average around which market prices gravitate, and for gravitation to operate one does not need perfect information).
In the absence of externalities and public goods, perfectly competitive equilibria are Pareto-efficient, i.e. no improvement in the utility of a consumer is possible without a worsening of the utility of some other consumer. This is called the First Theorem of Welfare Economics. The basic reason is that no productive factor with a non-zero marginal product is left unutilized, and the units of each factor are so allocated as to yield the same indirect marginal utility in all uses, a basic efficiency condition (if this indirect marginal utility were higher in one use than in other ones, a Pareto improvement could be achieved by transferring a small amount of the factor to the use where it yields a higher marginal utility).
A simple proof assuming differentiable utility functions and production functions is the following. Let wj be the 'price' (the rental) of a certain factor j, let MPj1 and MPj2 be its marginal product in the production of goods 1 and 2, and let p1 and p2 be these goods' prices. In equilibrium these prices must equal the respective marginal costs MC1 and MC2; remember that marginal cost equals factor 'price' divided by factor marginal productivity (because increasing the production of good by one very small unit through an increase of the employment of factor j requires increasing the factor employment by 1/MPji and thus increasing the cost by wj/MPji, and through the condition of cost minimization that marginal products must be proportional to factor 'prices' it can be shown that the cost increase is the same if the output increase is obtained by optimally varying all factors). Optimal factor employment by a price-taking firm requires equality of factor rental and factor marginal revenue product, wj=piMPji, so we obtain p1=MC1=wj/MPj1, p2=MCj2=wj/MPj2.
Now choose any consumer purchasing both goods, and measure his utility in such units that in equilibrium his marginal utility of money (the increase in utility due to the last unit of money spent on each good), MU1/p1=MU2/p2, is 1. Then p1=MU1, p2=MU2. The indirect marginal utility of the factor is the increase in the utility of our consumer achieved by an increase in the employment of the factor by one (very small) unit; this increase in utility through allocating the small increase in factor utilization to good 1 is MPj1MU1=MPj1p1=wj, and through allocating it to good 2 it is MPj2MU2=MPj2p2=wj again. With our choice of units the marginal utility of the amount of the factor consumed directly by the optimizing consumer is again w, so the amount supplied of the factor too satisfies the condition of optimal allocation.
Monopoly violates this optimal allocation condition, because in a monopolized industry market price is above marginal cost, and this means that factors are underutilized in the monopolized industry, they have a higher indirect marginal utility than in their uses in competitive industries. Of course this theorem is considered irrelevant by economists who do not believe that general equilibrium theory correctly predicts the functioning of market economies; but it is given great importance by neoclassical economists and it is the theoretical reason given by them for combating monopolies and for antitrust legislation.
Profit.
In contrast to a monopoly or oligopoly, in perfect competition it is impossible for a firm to earn economic profit in the long run, which is to say that a firm cannot make any more money than is necessary to cover its economic costs. In order not to misinterpret this zero-long-run-profits thesis, it must be remembered that the term 'profit' is used in different ways: 
Thus, if one leaves aside risk coverage for simplicity, the neoclassical zero-long-run-profit thesis would be re-expressed in classical parlance as profits coinciding with interest in the long period (i.e. the rate of profit tending to coincide with the rate of interest). Profits in the classical meaning do not necessarily disappear in the long period but tend to normal profit. 
With this terminology, if a firm is earning abnormal profit in the short term, this will act as a trigger for other firms to enter the market. As other firms enter the market, the market supply curve will shift out, causing prices to fall. Existing firms will react to this lower price by adjusting their capital stock downward. This adjustment will cause their marginal cost to shift to the left causing the market supply curve to shift inward. However, the net effect of entry by new firms and adjustment by existing firms will be to shift the supply curve outward. The market price will be driven down until all firms are earning normal profit only.
It is important to note that perfect competition is a sufficient condition for allocative and productive efficiency, but it is not a necessary condition. Laboratory experiments in which participants have significant price setting power and little or no information about their counterparts consistently produce efficient results given the proper trading institutions.
The shutdown point.
In the short run, a firm operating at a loss [R < TC (revenue less than total cost) or P < ATC (price less than unit cost)] must decide whether to continue to operate or temporarily shutdown. The shutdown rule states "in the short run a firm should continue to operate if price exceeds average variable costs." Restated, the rule is that for a firm to continue producing in the short run it must earn sufficient revenue to cover its variable costs. The rationale for the rule is straightforward. By shutting down a firm avoids all variable costs. However, the firm must still pay fixed costs. Because fixed cost must be paid regardless of whether a firm operates they should not be considered in deciding whether to produce or shutdown.
Thus in determining whether to shut down a firm should compare total revenue to total variable costs (VC) rather than total costs (FC + VC). If the revenue the firm is receiving is greater than its total variable cost (R > VC) then the firm is covering all variable cost plus there is additional revenue ("contribution"), which can be applied to fixed costs. (The size of the fixed costs is irrelevant as it is a sunk cost. The same consideration is used whether fixed costs are one dollar or one million dollars.) On the other hand, if VC > R then the firm is not even covering its production costs and it should immediately shut down. The rule is conventionally stated in terms of price (average revenue) and average variable costs. The rules are equivalent (If you divide both sides of inequality TR > TVC by Q gives P > AVC). If the firm decides to operate, the firm will continue to produce where marginal revenue equals marginal costs because these conditions insure not only profit maximization (loss minimization) but also maximum contribution.
Another way to state the rule is that a firm should compare the profits from operating to those realized if it shutdown and select the option that produces the greater profit. A firm that is shutdown is generating zero revenue and incurring no variable costs. However, the firm still has to pay fixed cost. So the firm's profit equals fixed costs or −FC. An operating firm is generating revenue, incurring variable costs and paying fixed costs. The operating firm's profit is R − VC − FC. The firm should continue to operate if R − VC − FC ≥ −FC, which simplified is R ≥ VC. The difference between revenue, R, and variable costs, VC, is the contribution to fixed costs and any contribution is better than none. Thus, if R ≥ VC then firm should operate. If R < VC the firm should shut down.
A decision to shut down means that the firm is temporarily suspending production. It does not mean that the firm is going out of business (exiting the industry). If market conditions improve, and prices increase, the firm can resume production. Shutting down is a short-run decision. A firm that has shut down is not producing. The firm still retains its capital assets; however, the firm cannot leave the industry or avoid its fixed costs in the short run. Exit is a long-term decision. A firm that has exited an industry has avoided all commitments and freed all capital for use in more profitable enterprises.
However, a firm cannot continue to incur losses indefinitely. In the long run, the firm will have to earn sufficient revenue to cover all its expenses and must decide whether to continue in business or to leave the industry and pursue profits elsewhere. The long-run decision is based on the relationship of the price and long-run average costs. If P ≥ AC then the firm will not exit the industry. If P < AC, then the firm will exit the industry. These comparisons will be made after the firm has made the necessary and feasible long-term adjustments. In the long run a firm operates where marginal revenue equals long-run marginal costs.
Short-run supply curve.
The short run supply curve for a perfectly competitive firm is the marginal cost (MC) curve at and above the shutdown point. Portions of the marginal cost curve below the shut down point are not part of the SR supply curve because the firm is not producing in that range. Technically the SR supply curve is a discontinuous function composed of the segment of the MC curve at and above minimum of the average variable cost curve and a segment that runs with the vertical axis from the origin to but not including a point "parallel" to minimum average variable costs.
Examples.
Though there is no actual perfectly competitive market in the real world, a number of approximations exist:
An example is that of a large action of identical goods with all potential buyers and sellers present. By design, a stock exchange resembles this, not as a complete description (for no markets may satisfy all requirements of the model) but as an approximation. The flaw in considering the stock exchange as an example of Perfect Competition is the fact that large institutional investors (e.g. investment banks) may solely influence the market price. This, of course, violates the condition that "no one seller can influence market price".
Horse betting is also quite a close approximation. When placing bets, consumers can just look down the line to see who is offering the best odds, and so no one bookie can offer worse odds than those being offered by the market as a whole, since consumers will just go to another bookie. This makes the bookies price-takers. Furthermore, the product on offer is very homogeneous, with the only differences between individual bets being the pay-off and the horse. Of course, there are not an infinite amount of bookies, and some barriers to entry exist, such as a license and the capital required to set up.
Free software works along lines that approximate perfect competition as well. Anyone is free to enter and leave the market at no cost. All code is freely accessible and modifiable, and individuals are free to behave independently. Free software may be bought or sold at whatever price that the market may allow.
Some believe that one of the prime examples of a perfectly competitive market anywhere in the world is street food in developing countries. This is so since relatively few barriers to entry/exit exist for street vendors. Furthermore, there are often numerous buyers and sellers of a given street food, in addition to consumers/sellers possessing perfect information of the product in question. It is often the case that street vendors may serve a homogenous product, in which little to no variations in the product's nature exist.
Another very near example of perfect competition would be the fish market and the vegetable or fruit vendors who sell at the same place, the bars in "Le Carré" (Liège, Belgium) or the "kebab street" near the Grand Place in Brussels:
Criticisms.
The use of the assumption of perfect competition as the foundation of price theory for product markets is often criticized as representing all agents as passive, thus removing the active attempts to increase one's welfare or profits by price undercutting, product design, advertising, innovation, activities that - the critics argue – characterize most industries and markets. These criticisms point to the frequent lack of realism of the assumptions of product homogeneity and impossibility to differentiate it, but apart from this the accusation of passivity appears correct only for short-period or very-short-period analyses, in long-period analyses the inability of price to diverge from the natural or long-period price is due to active reactions of entry or exit.
Some economists have a different kind of criticism concerning perfect competition model. They are not criticizing the price taker assumption because it makes economic agents too "passive", but because it then raises the question of who sets the prices. Indeed, if everyone is price taker, there is the need for a benevolent planner who gives and sets the prices, in other word, there is a need for a "price maker". Therefore, it makes the perfect competition model appropriate not to describe a decentralize "market" economy but a centralized one. This in turn means that such kind of model has more to do with communism than capitalism.
Another frequent criticism is that it is often not true that in the short run differences between supply and demand cause changes in price; especially in manufacturing, the more common behaviour is alteration of production without nearly any alteration of price.
The critics of the assumption of perfect competition in product markets seldom question the basic neoclassical view of the working of market economies for this reason. The Austrian School insists strongly on this criticism, and yet the neoclassical view of the working of market economies as fundamentally efficient, reflecting consumer choices and assigning to each agent his contribution to social welfare, is esteemed to be fundamentally correct. Some non-neoclassical schools, like Post-Keynesians, reject the neoclassical approach to value and distribution, but not because of their rejection of perfect competition as a reasonable approximation to the working of most product markets; the reasons for rejection of the neoclassical 'vision' are different views of the determinants of income distribution and of aggregated demand.
In particular, the rejection of perfect competition does not generally entail the rejection of free competition as characterizing most product markets; indeed it has been argued that competition is stronger nowadays than in 19th century capitalism, owing to the increasing capacity of big conglomerate firms to enter any industry: therefore the classical idea of a tendency toward a uniform rate of return on investment in all industries owing to free entry is even more valid today; and the reason why General Motors, Exxon or Nestle do not enter the computers or pharmaceutical industries is not insurmountable barriers to entry but rather that the rate of return in the latter industries is already sufficiently in line with the average rate of return elsewhere as not to justify entry. On this few economists, it would seem, would disagree, even among the neoclassical ones. Thus when the issue is normal, or long-period, product prices, differences on the validity of the perfect competition assumption do not appear to imply important differences on the existence or not of a tendency of rates of return toward uniformity as long as entry is possible, and what is found fundamentally lacking in the perfect competition model is the absence of marketing expenses and innovation as causes of costs that do enter normal average cost.
The issue is different with respect to factor markets. Here the acceptance or denial of perfect competition in labour markets does make a big difference to the view of the working of market economies. One must distinguish neoclassical from non-neoclassical economists. For the former, absence of perfect competition in labour markets, e.g. due to the existence of trade unions, impedes the smooth working of competition, which if left free to operate would cause a decrease of wages as long as there were unemployment, and would finally ensure the full employment of labour: labour unemployment is due to absence of perfect competition in labour markets. Most non-neoclassical economists deny that a full flexibility of wages would ensure the full employment of labour and find a stickiness of wages an indispensable component of a market economy, without which the economy would lack the regularity and persistence indispensable to its smooth working. This was, for example, John Maynard Keynes's opinion.
Particularly radical is the view of the Sraffian school on this issue: the labour demand curve cannot be determined hence a level of wages ensuring the equality between supply and demand for labour does not exist, and economics should resume the viewpoint of the classical economists, according to whom competition in labour markets does not and cannot mean indefinite price flexibility as long as supply and demand are unequal, it only means a tendency to equality of wages for similar work, but the level of wages is necessarily determined by complex sociopolitical elements; custom, feelings of justice, informal allegiances to classes, as well as overt coalitions such as trade unions, far from being impediments to a smooth working of labour markets that would be able to determine wages even without these elements, are on the contrary indispensable because without them there would be no way to determine wages.
Equilibrium in perfect competition.
Equilibrium in perfect competition is the point where market demands will be equal to market supply. A firm's price will be determined at this point. In the short run, equilibrium will be affected by demand. In the long run, both demand and supply of a product will affect the equilibrium in perfect competition. A firm will receive only normal profit in the long run at the equilibrium point.

</doc>
<doc id="23003" url="https://en.wikipedia.org/wiki?curid=23003" title="Philosophy of religion">
Philosophy of religion

Philosophy of religion according to the Stanford Encyclopedia of Philosophy is, "the philosophical examination of the central themes and concepts involved in religious traditions." It is an ancient discipline, being found in the earliest known manuscripts concerning philosophy, and relates to many other branches of philosophy and general thought, including metaphysics, logic, and history.
The philosophy of religion differs from religious philosophy in that it seeks to discuss questions regarding the nature of religion as a whole, rather than examining the problems brought forth by a particular belief system. It is designed such that it can be carried out dispassionately by those who identify as believers or non-believers.
As a part of metaphysics.
Philosophy of religion has classically been regarded as a part of metaphysics. In Aristotle's "Metaphysics", the necessarily prior cause of eternal motion was an unmoved mover, who, like the object of desire, or of thought, inspires motion without itself being moved. This, according to Aristotle, is God, the subject of study in theology. Today, however, philosophers have adopted the term "philosophy of religion" for the subject, and typically it is regarded as a separate field of specialization, although it is also still treated by some, particularly Catholic philosophers, as a part of metaphysics.
History.
Although the term did not come into general use until the nineteenth century, perhaps the earliest strictly philosophical writings about religion can be found in the Hindu Upanishads. Around the same time, the works of Daoism and Confucianism also dealt, in part, with reasoning about religious concepts. The Buddhist writing in the Pali canon "contains acute philosophical thinking", and "we have in Buddhism a very shrewd grasp of the nature of religion as philosophy illuminates it."
Field of study.
Philosophy of religion covers alternative beliefs about God, the varieties of religious experience, the interplay between science and religion, the nature and scope of good and evil, and religious treatments of birth, history, and death. The field also includes the ethical implications of religious commitments, the relation between faith, reason, experience and tradition, concepts of the miraculous, the sacred revelation, mysticism, power, and salvation.
The philosophy of religion has been distinguished from theology by pointing out that, for theology, "its critical reflections are based on religious convictions". Also, "theology is responsible to an authority that initiates its thinking, speaking, and witnessing ... [while] philosophy bases its arguments on the ground of timeless evidence."
Basic themes and problems.
Three considerations that are basic to the philosophy of religion concerning deities are: the existence of God, the nature of God, and the knowledge of God.
Existence of God.
There are several main positions with regard to the existence of God that one might take:
These are not mutually exclusive positions. For example, agnostic theists choose to believe God exists while asserting that knowledge of God's existence is inherently unknowable. Similarly, agnostic atheists reject belief in the existence of all deities, while asserting that whether any such entities exist or not is inherently unknowable.
Natural theology.
The attempt to provide proofs or arguments for the existence of God is one aspect of what is known as natural theology or the natural theistic project. This strand of natural theology attempts to justify belief in God by independent grounds. There is plenty of philosophical literature on faith (especially fideism) and other subjects generally considered to be outside the realm of natural theology. Perhaps most of philosophy of religion is predicated on natural theology's assumption that the existence of God can be justified or warranted on rational grounds. There has been considerable philosophical and theological debate about the kinds of proofs, justifications and arguments that are appropriate for this discourse.
The philosopher Alvin Plantinga has shifted his focus to justifying belief in God (that is, those who believe in God, for whatever reasons, are rational in doing so) through Reformed epistemology, in the context of a theory of warrant and proper cognitive function.
Other reactions to natural theology are those of Wittgensteinian philosophers of religion, most notably D. Z. Phillips. Phillips rejects "natural theology" and its evidentialist approach as confused, in favor of a grammatical approach which investigates the meaning of belief in God. For Phillips, belief in God is not a proposition with a particular truth value, but a form of life. Consequently, the question of whether God exists confuses the logical categories which govern theistic language with those that govern other forms of discourse (most notably, scientific discourse). According to Phillips, the question of whether or not God exists cannot be "objectively" answered by philosophy because the categories of truth and falsity, which are necessary for asking the question, have no application in the religious contexts wherein religious belief has its sense and meaning. In other words, the question cannot be answered because it cannot be asked without entering into confusion. As Phillips sees things, the job of the philosopher is not to investigate the "rationality" of belief in God but to elucidate its meaning.
Problem of evil.
The problem of evil is the question of how to reconcile the existence of evil with that of a deity who is, in either absolute or relative terms, omnipotent, omniscient, and omnibenevolent. An argument from evil attempts to show that the co-existence of evil and such a deity is unlikely or impossible if placed in absolute terms. Attempts to show the contrary have traditionally been discussed under the heading of theodicy.
Analytic philosophy of religion.
In "Analytic Philosophy of Religion", James Franklin Harris noted that
As with the study of ethics, early analytic philosophy tended to avoid the study of philosophy of religion, largely dismissing (as per the logical positivists view) the subject as part of metaphysics and therefore meaningless. The collapse of logical positivism renewed interest in philosophy of religion, prompting philosophers like William Alston, John Mackie, Alvin Plantinga, Robert Merrihew Adams, Richard Swinburne, and Antony Flew not only to introduce new problems, but to re-open classical topics such as the nature of miracles, theistic arguments, the problem of evil, (see existence of God) the rationality of belief in God, concepts of the nature of God, and many more.
Plantinga, Mackie and Flew debated the logical validity of the "free will defense" as a way to solve the problem of evil. Alston, grappling with the consequences of analytic philosophy of language, worked on the nature of religious language. Adams worked on the relationship of faith and morality. Analytic epistemology and metaphysics has formed the basis for a number of philosophically-sophisticated theistic arguments, like those of the reformed epistemologists like Plantinga.
Analytic philosophy of religion has also been preoccupied with Ludwig Wittgenstein, as well as his interpretation of Søren Kierkegaard's philosophy of religion. Using first-hand remarks (which would later be published in "Philosophical Investigations", "Culture and Value", and other works), philosophers such as Peter Winch and Norman Malcolm developed what has come to be known as "contemplative philosophy", a Wittgensteinian school of thought rooted in the "Swansea tradition" and which includes Wittgensteinians such as Rush Rhees, Peter Winch and D. Z. Phillips, among others. The name "contemplative philosophy" was first coined by D. Z. Phillips in "Philosophy's Cool Place", which rests on an interpretation of a passage from Wittgenstein's "Culture and Value." This interpretation was first labeled, "Wittgensteinian Fideism," by Kai Nielsen but those who consider themselves Wittgensteinians in the Swansea tradition have relentlessly and repeatedly rejected this construal as a caricature of Wittgenstein's considered position; this is especially true of D. Z. Phillips. Responding to this interpretation, Kai Nielsen and D.Z. Phillips became two of the most prominent philosophers on Wittgenstein's philosophy of religion.

</doc>
<doc id="23004" url="https://en.wikipedia.org/wiki?curid=23004" title="Precedent">
Precedent

In common law legal systems, a precedent or authority is a principle or rule established in a previous legal case that is either binding on or persuasive for a court or other tribunal when deciding subsequent cases with similar issues or facts. Common law legal systems place great value on deciding cases according to consistent principled rules so that similar facts will yield similar and predictable outcomes, and observance of precedent is the mechanism by which that goal is attained. Black's Law Dictionary defines "precedent" as a "rule of law established for the first time by a court for a particular type of case and thereafter referred to in deciding similar cases." Common law precedent is a third kind of law, on equal footing with statutory law (statutes and codes enacted by legislative bodies), and Delegated legislation (in U.K. parlance) or regulatory law (in U.S. parlance) (regulations promulgated by executive branch agencies).
Case law or common law is the set of decisions of adjudicatory tribunals that can be cited as precedent. In most countries, including most European countries, the term is applied to any set of rulings on law which is guided by previous rulings, for example, previous decisions of a government agency.
Precedential (whether strongly binding or weakly persuasive) case law can arise from a ruling by either a judicial court, or by an executive branch agency. Trials and hearings that do not result in written decisions, written decisions that are designated "nonprecedential" by the tribunal, or written decisions of agencies that are not issued and indexed with sufficient formality to gain precedential effect, do not create precedent for future court decisions.
Principle.
Stare decisis (Anglo-Latin pronunciation: ) is a legal principle by which judges are obligated to respect the precedent established by prior decisions. The words originate from the phrasing of the principle in the Latin maxim "Stare decisis et non quieta movere": "to stand by decisions and not disturb the undisturbed." In a legal context, this is understood to mean that courts should generally abide by precedent and not disturb settled matters. The principle of "stare decisis" can be divided into two components.
The first is the rule that a decision made by a superior court, or by the same court in an earlier decision, is binding precedent that the court itself and all its inferior courts are obligated to follow. The second is the principle that a court should not overturn its own precedent unless there is a strong reason to do so and should be guided by principles from lateral and inferior courts. The second principle, regarding persuasive precedent, is an advisory one that courts can and do ignore occasionally.
Case law in common law systems.
In the common law tradition, courts decide the law applicable to a case by interpreting statutes and applying precedent which record how and why prior cases have been decided. Unlike most civil law systems, common law systems follow the doctrine of "stare decisis", by which most courts are bound by their own previous decisions in similar cases, and all lower courts should make decisions consistent with previous decisions of higher courts. For example, in England, the High Court and the Court of Appeal are each bound by their own previous decisions, but the Supreme Court of the United Kingdom is able to deviate from its earlier decisions, although in practice it rarely does so.
Generally speaking, higher courts do not have direct oversight over day-to-day proceedings in lower courts, in that they cannot reach out on their own initiative ("sua sponte") at any time to reverse or overrule judgments of the lower courts. Normally, the burden rests with litigants to appeal rulings (including those in clear violation of established case law) to the higher courts. If a judge acts against precedent and the case is not appealed, the decision will stand.
A lower court may not rule against a binding precedent, even if the lower court feels that the precedent is unjust; the lower court may only express the hope that a higher court or the legislature will reform the rule in question. If the court believes that developments or trends in legal reasoning render the precedent unhelpful, and wishes to evade it and help the law evolve, the court may either hold that the precedent is inconsistent with subsequent authority, or that the precedent should be "distinguished" by some material difference between the facts of the cases. If that judgment goes to appeal, the appellate court will have the opportunity to review both the precedent and the case under appeal, perhaps overruling the previous case law by setting a new precedent of higher authority. This may happen several times as the case works its way through successive appeals. Lord Denning, first of the High Court of Justice, later of the Court of Appeal, provided a famous example of this evolutionary process in his development of the concept of estoppel starting in the "High Trees" case: "Central London Property Trust Ltd v. High Trees House Ltd" [1947] K.B. 130.
Judges may refer to various types of persuasive authority to reach a decision in a case. Widely cited non-binding sources include legal encyclopedias such as "Corpus Juris Secundum" and "Halsbury's Laws of England", or the published work of the Law Commission or the American Law Institute. Some bodies are given statutory powers to issue Guidance with persuasive authority or similar statutory effect, such as the Highway Code.
In federal or multi-jurisdictional law systems there may exist conflicts between the various lower appellate courts. Sometimes these differences may not be resolved and it may be necessary to distinguish how the law is applied in one district, province, division or appellate department. Usually only an appeal accepted by the court of last resort will resolve such differences and, for many reasons, such appeals are often not granted.
Any court may seek to distinguish its present case from that of a binding precedent, in order to reach a different conclusion. The validity of such a distinction may or may not be accepted on appeal. An appellate court may also propound an entirely new and different analysis from that of junior courts, and may or may not be bound by its own previous decisions, or in any case may distinguish the decisions based on significant differences in the facts applicable to each case. Or, a court may view the matter before it as one of "first impression," not governed by any controlling precedent.
Where there are several members of a court, there may be one or more judgments given; only the ratio decidendi of the majority can constitute a binding precedent, but all may be cited as persuasive, or their reasoning may be adopted in argument. Quite apart from the rules of precedent, the weight actually given to any reported judgment may depend on the reputation of both the court and the judges.
Type of precedent.
Verticality.
Generally, a common law court system has trial courts, intermediate appellate courts and a supreme court. The inferior courts conduct almost all trial proceedings. The inferior courts are bound to obey precedent established by the appellate court for their jurisdiction, and all supreme court precedent.
The Supreme Court of California's explanation of this principle is that
An Intermediate state appellate court is generally bound to follow the decisions of the highest court of that state.
The application of the doctrine of "stare decisis" from a superior court to an inferior court is sometimes called "vertical stare decisis".
Horizontality.
The idea that a judge is bound by (or at least should respect) decisions of earlier judges of similar or coordinate level is called horizontal "stare decisis".
In the United States federal court system, the intermediate appellate courts are divided into thirteen "circuits," each covering some range of territory ranging in size from the District of Columbia alone up to seven states. Each panel of judges on the court of appeals for a circuit is bound to obey the prior appellate decisions of the same circuit. Precedent of a United States court of appeals may be overruled only by the court "en banc," that is, a session of all the active appellate judges of the circuit, or by the United States Supreme Court, not simply by a different three-judge panel.
When a court binds itself, this application of the doctrine of precedent is sometimes called "horizontal stare decisis". The state of New York has a similar appellate structure as it is divided into four appellate departments supervised by the final New York Court of Appeals. Decisions of one appellate department are not binding upon another, and in some cases the departments differ considerably on interpretations of law.
Federalism and parallel state and federal courts.
In federal systems the division between federal and state law may result in complex interactions. In the United States, state courts are not considered inferior to federal courts but rather constitute a parallel court system. State courts must follow decisions of the federal courts on issues of federal law, and federal courts must follow decisions of the state courts on issues of state law.
If an issue of state law arises during a case in federal court, and there is no decision on point from the highest court of the state, the federal court must either attempt to predict how the state courts would resolve the issue by looking at decisions from state appellate courts, or, if allowed by the constitution of the relevant state, submit the question to the state's courts.
In practice, however, judges in one system will almost always choose to follow relevant case law in the other system to prevent divergent results and to minimize forum shopping.
Binding precedent.
Precedent that must be applied or followed is known as "binding precedent" (alternately "metaphorically precedent", "mandatory" or "binding authority", etc.). Under the doctrine of "stare decisis", a lower court must honor findings of law made by a higher court that is within the appeals path of cases the court hears. In state and federal courts in the United States of America, jurisdiction is often divided geographically among local trial courts, several of which fall under the territory of a regional appeals court. All appellate courts fall under a highest court (sometimes but not always called a "supreme court"). By definition, decisions of lower courts are not binding on courts higher in the system, nor are appeals court decisions binding on local courts that fall under a different appeals court. Further, courts must follow their own proclamations of law made earlier on other cases, and honor rulings made by other courts in disputes among the parties before them pertaining to the same pattern of facts or events, unless they have a strong reason to change these rulings (see Law of the case re: a court's previous holding being binding precedent for that court).
In law, a binding precedent (also mandatory precedent or binding authority) is a precedent which must be followed by all lower courts under common law legal systems. In English law it is usually created by the decision of a higher court, such as the Supreme Court of the United Kingdom, which took over the judicial functions of the House of Lords in 2009. In Civil law and pluralist systems precedent is not binding but case law is taken into account by the courts.
Binding precedent relies on the legal principle of "stare decisis". "Stare decisis" means to stand by things decided. It ensures certainty and consistency in the application of law. Existing binding precedent from past cases are applied in principle to new situations by analogy.
One law professor has described mandatory precedent as follows:
In extraordinary circumstances a higher court may overturn or overrule mandatory precedent, but will often attempt to distinguish the precedent before overturning it, thereby limiting the scope of the precedent.
Under the U.S. legal system, courts are set up in a hierarchy. At the top of the federal or national system is the Supreme Court, and underneath are lower federal courts. The state court systems have hierarchy structures similar to that of the federal system.
The U.S. Supreme Court has final authority on questions about the meaning of federal law, including the U.S. Constitution. For example, when the Supreme Court says that the First Amendment applies in a specific way to suits for slander, then every court is bound by that precedent in its interpretation of the First Amendment as it applies to suits for slander. If a lower court judge disagrees with a higher court precedent on what the First Amendment should mean, the lower court judge must rule according to the binding precedent. Until the higher court changes the ruling (or the law itself is changed), the binding precedent is authoritative on the meaning of the law.
Although state courts are not part of the federal system, they are also bound by U.S. Supreme Court rulings on federal law. State courts are not generally bound by Federal District courts or Circuit courts, however. A federal court interpreting state law is bound by prior decisions of the state supreme court.
Lower courts are bound by the precedent set by higher courts within their region. Thus, a federal district court that falls within the geographic boundaries of the Third Circuit Court of Appeals is bound by rulings of the Third Circuit Court, but not by rulings in the Ninth Circuit, since the Circuit Courts of Appeals have jurisdiction defined by geography. The Circuit Courts of Appeals can interpret the law how they want, so long as there is no binding Supreme Court precedent. One of the common reasons the Supreme Court grants certiorari (that is, they agree to hear a case) is if there is a conflict among the circuit courts as to the meaning of a federal law.
There are three elements needed for a precedent to work. Firstly, the hierarchy of the courts needs to be accepted, and an efficient system of law reporting. 'A balance must be struck between the need on one side for the legal certainty resulting from the binding effect of previous decisions, and on the other side the avoidance of undue restriction on the proper development of the law (1966 Practice Statement (Judicial Precedent) by Lord Gardiner L.C.)'.
Binding precedent in English law.
Judges are bound by the law of binding precedent in England and Wales and other common law jurisdictions. This is a distinctive feature of the English legal system. In Scotland and many countries throughout the world, particularly in mainland Europe, civil law means that judges take case law into account in a similar way, but are not obliged to do so and are required to consider the precedent in terms of principle. Their fellow judges' decisions may be persuasive but are not binding. Under the English legal system, judges are not necessarily entitled to make their own decisions about the development or interpretations of the law. They may be bound by a decision reached in a previous case. Two facts are crucial to determining whether a precedent is binding:
Super "stare decisis".
Super-"stare decisis" is a term used for important precedent that is resistant or immune from being overturned, without regard to whether correctly decided in the first place. It may be viewed as one extreme in a range of precedential power, or alternatively, to express a belief, or a critique of that belief, that some decisions should not be overturned.
In 1976, Richard Posner and William Landes coined the term "super-precedent," in an article they wrote about testing theories of precedent by counting citations. Posner and Landes used this term to describe the influential effect of a cited decision. The term "super-precedent" later became associated with different issue: the difficulty of overturning a decision. In 1992, Rutgers professor Earl Maltz criticized the Supreme Court's decision in "Planned Parenthood v. Casey" for endorsing the idea that if one side can take control of the Court on an issue of major national importance (as in "Roe v. Wade"), that side can protect its position from being reversed "by a kind of super-stare decisis." The controversial idea that some decisions are virtually immune from being overturned, regardless of whether they were decided correctly in the first place, is the idea to which the term "super "stare decisis"" now usually refers.
The concept of super-"stare decisis" (or "super-precedent") was mentioned during the interrogations of Chief Justice John Roberts and Justice Samuel Alito before the Senate Judiciary Committee. Prior to the commencement of the Roberts hearings, the chair of that committee, Senator Arlen Specter of Pennsylvania, wrote an op/ed in the "New York Times" referring to "Roe" as a "super-precedent." He revisited this concept during the hearings, but neither Roberts nor Alito endorsed the term or the concept.
Persuasive precedent.
Persuasive precedent (also persuasive authority) is precedent or other legal writing that is not binding precedent but that is useful or relevant and that may guide the judge in making the decision in a current case. Persuasive precedent includes cases decided by lower courts, by peer or higher courts from other geographic jurisdictions, cases made in other parallel systems (for example, military courts, administrative courts, indigenous/tribal courts, state courts versus federal courts in the United States), statements made in dicta, treatises or academic law reviews, and in some exceptional circumstances, cases of other nations, treaties, world judicial bodies, etc.
In a "case of first impression", courts often rely on persuasive precedent from courts in other jurisdictions that have previously dealt with similar issues. Persuasive precedent may become binding through its adoption by a higher court.
In civil law and pluralist systems, as under Scots law, precedent is not binding but case law is taken into account by the courts.
Lower courts.
A lower court's opinion may be considered as persuasive authority if the judge believes they have applied the correct legal principle and reasoning.
Higher courts in other circuits.
A court may consider the ruling of a higher court that is not binding. For example, a district court in the United States First Circuit could consider a ruling made by the United States Court of Appeals for the Ninth Circuit as persuasive authority.
Horizontal courts.
Courts may consider rulings made in other courts that are of equivalent authority in the legal system. For example, an appellate court for one district could consider a ruling issued by an appeals court in another district.
Statements made in "obiter dicta".
Courts may consider "obiter dicta" in opinions of higher courts. Dicta of a higher court, though not binding, will often be persuasive to lower courts. The phrase "obiter dicta" is usually translated as "other things said", but due to the high number of judges and individual concurring opinions, it is often hard to distinguish from the "ratio decidendi" (reason for the decision). For these reasons, the obiter dicta may often be taken into consideration by a court. A litigant may also consider "obiter dicta" if a court has previously signaled that a particular legal argument is weak and may even warrant sanctions if repeated.
Dissenting opinions.
A case decided by a multi-judge panel could result in a split decision. While only the majority opinion is considered precedential, an outvoted judge can still publish a dissenting opinion. Common patterns for dissenting opinions include:
A judge in a subsequent case, particularly in a different jurisdiction, could find the dissenting judge's reasoning persuasive. In the jurisdiction of the original decision, however, a judge should only overturn the holding of a court lower or equivalent in the hierarchy. A district court, for example, could not rely on a Supreme Court dissent as a basis to depart from the reasoning of the majority opinion. However, lower courts occasionally cite dissents, either for either a limiting principle on the majority, or for propositions that are not stated in the majority opinion and not inconsistent with that majority, or to explain a disagreement with the majority and to urge reform (while following the majority in the outcome).
Treatises, restatements, law review articles.
Courts may consider the writings of eminent legal scholars in treatises, restatements of the law, and law reviews. The extent to which judges find these types of writings persuasive will vary widely with elements such as the reputation of the author and the relevance of the argument.
Persuasive effect of decisions from other jurisdictions.
The courts of England and Wales are free to consider decisions of other jurisdictions, and give them whatever persuasive weight the English court sees fit, even though these other decisions are not binding precedent. Jurisdictions that are closer to modern English common law are more likely to be given persuasive weight, for example Commonwealth states (for example Canada, Australia, or New Zealand). Persuasive weight might be given to other common law courts, such as from the United States, most often where the American courts have been particularly innovative, e.g. in product liability and certain areas of contract law.
In the United States, in the late 20th and early 21st centuries, the concept of a U.S. court considering foreign law or precedent has been considered controversial by some parties. The Supreme Court splits on this issue. In "Atkins v. Virginia", for example, the majority cited as part of their reasoning the fact that the European Union forbids the death penalty. But, Chief Justice Rehnquist opposed the "Court's decision to place weight on foreign laws." The House of Representatives passed a nonbinding resolution criticizing the citing of foreign law and "reaffirming American independence." This critique is recent, as in the early history of the United States, citation of English authority was ubiquitous. One of the first acts of many of the new state legislatures was to adopt the body of English common law into the law of the state. See here. Citation to English cases was common through the 19th and well into the 20th centuries. Even in the late 20th and early 21st centuries, it is relatively uncontroversial for American state courts to rely on English decisions for matters of pure common (i.e. judge-made) law.
Within the federal legal systems of several common-law countries, and most especially the United States, it is relatively common for the distinct lower-level judicial systems (e.g. state courts in the United States and Australia, provincial courts in Canada) to regard the decisions of other jurisdictions within the same country as persuasive precedent. Particularly in the United States, the adoption of a legal doctrine by a large number of other state judiciaries is regarded as highly persuasive evidence that such doctrine is preferred. A good example is the adoption in Tennessee of comparative negligence (replacing contributory negligence as a complete bar to recovery) by the 1992 Tennessee Supreme Court decision "McIntyre v. Balentine" (by this point all US jurisdictions save Tennessee, five other states, and the District of Columbia had adopted comparative negligence schemes). Moreover, in American law, the "Erie" doctrine requires federal courts sitting in diversity actions to apply state substantive law, but in a manner consistent with how the court believes the state's highest court would rule in that case. Since such decisions are not binding on state courts, but are often very well-reasoned and useful, state courts cite federal interpretations of state law fairly often as persuasive precedent, although it is also fairly common for a state high court to reject a federal court's interpretation of its jurisprudence.
Nonprecedential decisions: non-publication and depublication, noncitation rules.
Non-publication of opinions, or unpublished opinions, are those decisions of courts that are not available for citation as precedent because the judges making the opinion deem the case as having less precedential value. Selective publication is the legal process which a judge or justices of a court decide whether a decision is to be or not published in a reporter. "Unpublished" federal appellate decisions are published in the Federal Appendix. Depublication is the power of a court to make a previously published order or opinion unpublished.
"Res judicata", claim preclusion, collateral estoppel, issue preclusion, law of the case.
Several rules may cause a decision to apply as narrow "precedent" to preclude future legal positions of the specific parties to a case, even if a decision is non-precedential with respect to all other parties.
"Res judicata", claim preclusion.
Once a case is decided, the same plaintiff cannot sue the same defendant again on any claim arising out of the same facts. The law requires plaintiffs to put all issues on the table in a single case, not split the case. For example, in a case of an auto accident, the plaintiff cannot sue first for property damage, and then personal injury in a separate case. This is called "res judicata" or claim preclusion ("'Res judicata'" is the traditional name going back centuries; the name shifted to "claim preclusion" in the United States over the late 20th century). Claim preclusion applies whether the plaintiff wins or loses the earlier case, even if the later case raises a different legal theory, even the second claim is unknown at the time of the first case. Exceptions are extremely limited, for example if the two claims for relief must necessarily be brought in different courts (for example, one claim might be exclusively federal, and the other exclusively state).
collateral estoppel, issue preclusion.
Once a case is finally decided, any issues decided in the previous case may be binding against the party that lost the issue in later cases, even in cases involving other parties. For example, if a first case decides that a party was negligent, then other plaintiffs may rely on that earlier determination in later cases, and need not re-prove the issue of negligence. For another example, if a patent is shown to be invalid in a case against one accused infringer, that same patent is invalid against all other accused infringers--invalidity need not be re-proved. Again, there are limits and exceptions on this principle. The principle is called collateral estoppel or issue preclusion.
law of the case.
Within a single case, once there's been a first appeal, both the lower court and the appellate court itself will not further review the same issue, and will not re-review an issue that could have been appealed in the first appeal. Exceptions are limited to three "exceptional circumstances:" (1) when substantially different evidence is raised at a subsequent trial, (2) when the law changes after the first appeal, for example by a decision of a higher court, or (3) when a decision is clearly erroneous and would result in a manifest injustice. This principle is called "law of the case."
Splits, tensions.
On many questions, reasonable people may differ. When two of those people are judges, the tension among two lines of precedent may be resolved as follows.
Jurisdictional splits: disagreements among different geographical regions or levels of federalism.
If the two courts are in separate, parallel jurisdictions, there is no conflict, and two lines of precedent may persist. Courts in one jurisdiction are influenced by decisions in others, and notably better rules may be adopted over time.
Splits among different areas of law.
Courts try to formulate the common law as a "seamless web" so that principles in one area of the law apply to other areas. However, this principle does not apply uniformly. Thus, a word may have different definitions in different areas of the law, or different rules may apply so that a question has different answers in different legal contexts. Judges try to minimize these conflicts, but they arise from time to time, and under principles of 'stare decisis', may persist for some time.
Matter of first impression.
First impression (known as "primae impressionis" in Latin) is a legal case in which there is no binding authority on the matter presented. Such a case can set forth a completely original issue of law for decision by the courts. A first impression case may be a first impression in only a particular jurisdiction. In that situation, courts will look to holdings of other jurisdictions for persuasive authority.
In the latter meaning, the case in question cannot be decided through referring to and/or relying on precedent. Since the legal issue under consideration has never been decided by an appeals court and, therefore, there is no precedent for the court to follow, the court uses analogies from prior rulings by appeals courts, refers to commentaries and articles by legal scholars, and applies its own logic. In cases of first impression, the trial judge will often ask both sides' attorneys for legal briefs.
In some situations, a case of first impression may exist in a jurisdiction until a reported appellate court decision is rendered.
Contrasting role of case law in common law, civil law, and mixed systems.
The different roles of case law in civil law and common law traditions create differences in the way that courts render decisions. Common law courts generally explain in detail the legal rationale behind their decisions, with citations of both legislation and previous relevant judgments, and often an exegesis of the wider legal principles. The necessary analysis, called "ratio decidendi", then constitutes a precedent binding on other courts; further analyses not strictly necessary to the determination of the current case are called "obiter dicta", which constitute persuasive authority but are not technically binding. By contrast, decisions in civil law jurisdictions are generally very short, referring only to statutes. The reason for this difference is that these civil law jurisdictions adhere to a tradition that the reader should be able to deduce the logic from the decision and the statutes, so that, in some cases, it is somewhat difficult to apply previous decisions to the facts presented in future cases.
Civil law systems.
"Stare decisis" is not usually a doctrine used in civil law systems, because it violates the principle that only the legislature may make law. However, the civil law system does have jurisprudence constante, which is similar to "stare decisis" and dictates that the Court's decision condone a cohesive and predictable result. In theory, inferior courts are generally not bound to precedent established by superior courts. In practice, the need for predictability means that inferior courts generally defer to precedent by superior courts. In a sense, the most superior courts in civil law jurisdictions, such as the "Cour de cassation" and the "Conseil d'État" in France are recognized as being bodies of a quasi-legislative nature.
The doctrine of jurisprudence constante also influences how court decisions are structured. In general, court decisions of common law jurisdictions give a sufficient statement of rationale as to guide future courts. This occurs to justify a court decision on the basis of previous case law as well as to make it easier to use the decision as a precedent for future cases.
By contrast, court decisions in some civil law jurisdictions (most prominently France) tend to be extremely brief, mentioning only the relevant legislation and not going into great detail about how a decision was reached. This is the result of the theoretical view that the court is only interpreting the view of the legislature and that detailed exposition is unnecessary. Because of this, much more of the exposition of the law is done by academic jurists which provide the explanations that in common law nations would be provided by the judges themselves.
In other civil law jurisdictions, such as the German-speaking countries, court opinions tend to be much longer than in France, and courts will frequently cite previous cases and academic writing. However, some courts (such as German courts) have less emphasis on the particular facts of the case than common law courts, but have more emphasis on the discussion of various doctrinal arguments and on finding what the correct interpretation of the law is.
The legal systems of the Nordic countries are sometimes included among the civil law systems, but as a separate branch, and sometimes counted as separate from the civil law tradition. In Sweden, for instance, case law arguably plays a more important role than in some of the Continental civil law systems. The two highest courts, the Supreme Court ("Högsta domstolen") and the Supreme Administrative Court ("Högsta förvaltningsdomstolen"), have the right to set precedent which is in practice (however not formally) binding on all future application of the law. Courts of appeal, both general courts ("hovrätter") and administrative courts ("kammarrätter") may also issue decisions that act as guides for the application of the law, but these decisions may be overturned by higher courts.
Mixed or bijuridical systems.
Some pluralist systems, such as Scots law in Scotland and so-called civil law jurisdictions in Quebec and Louisiana, do not precisely fit into the dual "common-civil" law system classifications. Such systems may have been heavily influenced by the Anglo-American common law tradition; however, their substantive law is firmly rooted in the civil law tradition. Because of their position between the two main systems of law, these types of legal systems are sometimes referred to as "mixed" systems of law.
The role of academics in compiling and interpreting case law in civil law jurisdictions.
Law professors in common law traditions play a much smaller role in developing case law than professors in civil law traditions. Because court decisions in civil law traditions are brief and not amenable to establishing precedent, much of the exposition of the law in civil law traditions is done by academics rather than by judges; this is called doctrine and may be published in treatises or in journals such as "Recueil Dalloz" in France. Historically, common law courts relied little on legal scholarship; thus, at the turn of the twentieth century, it was very rare to see an academic writer quoted in a legal decision (except perhaps for the academic writings of prominent judges such as Coke and Blackstone). Today academic writers are often cited in legal argument and decisions as persuasive authority; often, they are cited when judges are attempting to implement reasoning that other courts have not yet adopted, or when the judge believes the academic's restatement of the law is more compelling than can be found in precedent. Thus common law systems are adopting one of the approaches long common in civil law jurisdictions.
Critical analysis of precedent.
Court formulations.
Justice Louis Brandeis, in a heavily-footnoted dissent to "Burnet v. Coronado Oil & Gas Co.", 285 U.S. 393, 405-411 (1932), explained (citations and quotations omitted):
The United States Court of Appeals for the Third Circuit has stated:
The United States Court of Appeals for the Ninth Circuit has stated:
Justice McHugh of the High Court of Australia in relation to precedents remarked in "Perre v Apand":
Academic study.
Precedent viewed against passing time can serve to establish trends, thus indicating the next logical step in evolving interpretations of the law. For instance, if immigration has become more and more restricted under the law, then the next legal decision on that subject may serve to restrict it further still. The existence of submerged precedent (reasoned opinions not made available through conventional legal research sources) has been identified as a potentially distorting force in the evolution of law.
Scholars have recently attempted to apply network theory to precedent in order to establish which precedent is most important or authoritative, and how the court's interpretations and priorities have changed over time.
Application.
Development.
Early English common law did not have or require the "stare decisis" doctrine for a range of legal and technological reasons:
These features changed over time, opening the door to the doctrine of "stare decisis":
United States legal system.
"Stare decisis" applies to the holding of a case, rather than to obiter dicta ("things said by the way"). As the United States Supreme Court has put it: "dicta may be followed if sufficiently persuasive but are not binding."
In the United States Supreme Court, the principle of stare decisis is most flexible in constitutional cases:
For example, in the years 1946–1992, the U.S. Supreme Court reversed itself in about 130 cases. The U.S. Supreme Court has further explained as follows:
The United States Supreme Court has stated that where a court gives multiple reasons for a given result, each alternative reason that is "explicitly" labeled by the court as an "independent" ground for the decision is not treated as "simply a dictum."
English legal system.
The doctrine of binding precedent or "stare decisis" is basic to the English legal system, as described in the rest of this article. Special features of the English legal system include the following:
Last resort and strict "stare decisis" in the House of Lords and UK Supreme Court.
The British House of Lords, as the court of last appeal outside Scotland before the creation of the UK Supreme Court, was not strictly bound to always follow its own decisions until the case "London Street Tramways v London County Council [1898] AC 375". After this case, once the Lords had given a ruling on a point of law, the matter was closed unless and until Parliament made a change by statute. This is the most strict form of the doctrine of "stare decisis" (one not applied, previously, in common law jurisdictions, where there was somewhat greater flexibility for a court of last resort to review its own precedent).
This situation changed, however, after the issuance of the Practice Statement of 1966. It enabled the House of Lords to adapt English law to meet changing social conditions. In "R v G & R" 2003, the House of Lords overruled its decision in "Caldwell" 1981, which had allowed the Lords to establish mens rea ("guilty mind") by measuring a defendant's conduct against that of a "reasonable person," regardless of the defendant's actual state of mind.
However, the Practice Statement has been seldom applied by the House of Lords, usually only as a last resort. As of 2005, the House of Lords has rejected its past decisions no more than 20 times. They are reluctant to use it because they fear to introduce uncertainty into the law. In particular, the Practice Statement stated that the Lords would be especially reluctant to overrule themselves in criminal cases because of the importance of certainty of that law. The first case involving criminal law to be overruled with the Practice Statement was "Anderton v Ryan" (1985), which was overruled by "R v Shivpuri" (1986), two decades after the Practice Statement. Remarkably, the precedent overruled had been made only a year before, but it had been criticised by several academic lawyers. As a result, Lord Bridge stated he was "undeterred by the consideration that the decision in "Anderton v Ryan" was so recent. The Practice Statement is an effective abandonment of our pretention to infallibility. If a serious error embodied in a decision of this House has distorted the law, the sooner it is corrected the better." Still, the House of Lords has remained reluctant to overrule itself in some cases; in "R v Kansal" (2002), the majority of House members adopted the opinion that "R v Lambert" had been wrongly decided and agreed to depart from their earlier decision.
Distinguishing precedent on legal (rather than fact) grounds.
A precedent does not bind a court if it finds there was a lack of care in the original "Per Incuriam". For example, if a statutory provision or precedent had not been brought to the previous court's attention before its decision, the precedent would not be binding.
Rules of Statutory Interpretation.
Statutory Interpretation in the U.K..
Judges and barristers in the U.K use three primary rules for interpreting the law.
The normal aids that a judge has include access to all previous cases in which a precedent has been set, and a good English dictionary.
Under the literal rule, the judge should do what the actual legislation states rather than trying to do what the judge thinks that it means. The judge should use the plain everyday ordinary meaning of the words, even if this produces an unjust or undesirable outcome. A good example of problems with this method is "R v Maginnis" (1987) in which several judges in separate opinions found several different dictionary meanings of the word "supply." Another example might be "Fisher v Bell", where it was held that a shopkeeper who placed an illegal item in a shop window with a price tag did not make an offer to sell it, because of the specific meaning of "offer for sale" in contract law. As a result of this case, Parliament amended the statute concerned to end this discrepancy.
The golden rule is used when use of the literal rule would obviously create an absurd result. The court must find genuine difficulties before it declines to use the literal rule. There are two ways in which the Golden Rule can be applied: the narrow method, and the broad method. Under the narrow method, when there are apparently two contradictory meanings to a word used in a legislative provision or it is ambiguous, the least absurd is to be used. For example, in "Adler v George" (1964), the defendant was found guilty under the Official Secrets Act of 1920. The act said it was an offence to obstruct HM Forces in the vicinity of a prohibited place. Mr. Adler argued that he was not in the "vicinity" of a prohibited place but was actually "in" a prohibited place. The court chose not to accept the wording literally. Under the broad method, the court may reinterpret the law at will when it is clear that there is only one way to read the statute. This occurred in "Re Sigsworth" (1935) where a man who murdered his mother was forbidden from inheriting her estate, despite a statute to the contrary.
The mischief rule is the most flexible of the interpretation methods. Stemming from "Heydon's Case" (1584), it allows the court to enforce what the statute is intended to remedy rather than what the words actually say. For example, in "Corkery v Carpenter" (1950), a man was found guilty of being drunk in charge of a carriage, although in fact he only had a bicycle.
Statutory Interpretation in the United States.
In the United States, the courts have stated consistently that the text of the statute is read as it is written, using the ordinary meaning of the words of the statute.
Practical application.
Although inferior courts are bound in theory by superior court precedent, in practice a judge may believe that justice requires an outcome at some variance with precedent, and may distinguish the facts of the individual case on reasoning that does not appear in the binding precedent. On appeal, the appellate court may either adopt the new reasoning, or reverse on the basis of precedent. On the other hand, if the losing party does not appeal (typically because of the cost of the appeal), the lower court decision may remain in effect, at least as to the individual parties.
Judicial resistance.
Occasionally, a lower court judge explicitly states personal disagreement with the judgment he or she has rendered, but that he or she is required to do so by binding precedent. Note that inferior courts cannot evade binding precedent of superior courts, but a court can depart from its own prior decisions.
Structural considerations.
In the United States, "stare decisis" can interact in counterintuitive ways with the federal and state court systems. On an issue of federal law, a state court is not bound by an interpretation of federal law at the district or circuit level, but is bound by an interpretation by the United States Supreme Court. On an interpretation of state law, whether common law or statutory law, the federal courts are bound by the interpretation of a state court of last resort, and are required normally to defer to the precedent of intermediate state courts as well.
Courts may choose to obey precedent of international jurisdictions, but this is not an application of the doctrine of "stare decisis", because foreign decisions are not binding. Rather, a foreign decision that is obeyed on the basis of the soundness of its reasoning will be called "persuasive authority" — indicating that its effect is limited to the persuasiveness of the reasons it provides.
Originalism.
Originalism — the doctrine that holds that the meaning of a written text must be applied — is in tension with "stare decisis", but is not necessarily opposed irrevocably. As noted above, ""Stare decisis" is not usually a doctrine used in civil law systems, because it violates the principle that only the legislature may make law"; Justice Antonin Scalia argues in "A Matter of Interpretation" that America is a civil law nation, not a common law nation. By principle, originalists are generally unwilling to defer to precedent when precedent seems to come into conflict with the Constitution. However, there is still room within an originalist paradigm for "stare decisis"; whenever the plain meaning of the text has alternative constructions, past precedent is generally considered a valid guide, with the qualifier being that it cannot change what the text actually says.
Some originalists may be even more extreme. In his confirmation hearings, Justice Clarence Thomas answered a question from Senator Strom Thurmond, qualifying his willingness to change precedent in this way:
Possibly he has changed his mind, or there are a very large body of cases which merit "the additional step" of ignoring the doctrine; according to Scalia, "Clarence Thomas doesn't believe in stare decisis, period. If a constitutional line of authority is wrong, he would say, let's get it right."
Professor Caleb Nelson, a former clerk for Justice Thomas and law professor at the University of Virginia, has elaborated on the role of "stare decisis" in originalist jurisprudence:
Advantages and disadvantages.
There are disadvantages and advantages of binding precedent, as noted by scholars and jurists.
Criticism of precedent.
In a 1997 book, attorney Michael Trotter blamed over-reliance by American lawyers on binding and persuasive authority, rather than the merits of the case at hand, as a major factor behind the escalation of legal costs during the 20th century. He argued that courts should ban the citation of persuasive precedent from outside their jurisdiction, with two exceptions:
The disadvantages of "stare decisis" include its rigidity, the complexity of learning law, the differences between some cases may be very small and appear illogical, and the slow growth or incremental changes to the law that are in need of major overhaul.
An argument often used against the system is that it is undemocratic as it allows judges, which may or may not be elected, to make law.
Regarding constitutional interpretations, there is concern that over-reliance on the doctrine of "stare decisis" can be subversive. An erroneous precedent may at first be only slightly inconsistent with the Constitution, and then this error in interpretation can be propagated and increased by further precedent until a result is obtained that is greatly different from the original understanding of the Constitution. "Stare decisis" is not mandated by the Constitution, and if it causes unconstitutional results then the historical evidence of original understanding can be re-examined. In this opinion, predictable fidelity to the Constitution is more important than fidelity to unconstitutional precedent. See also the living tree doctrine.
Agreement with precedent.
A counter-argument (in favor of the advantages of "stare decisis") is that if the legislature wishes to alter the case law (other than constitutional interpretations) by statute, the legislature is empowered to do so. Critics sometimes accuse particular judges of applying the doctrine selectively, invoking it to support precedent that the judge supported anyway, but ignoring it in order to change precedent with which the judge disagreed.
There is much discussion about the virtue of using "stare decisis". Supporters of the system, such as minimalists, argue that obeying precedent makes decisions "predictable." For example, a business person can be reasonably assured of predicting a decision where the facts of his or her case are sufficiently similar to a case decided previously. This parallels the arguments against retroactive (ex post facto) laws banned by the U.S. Constitution.

</doc>
<doc id="23005" url="https://en.wikipedia.org/wiki?curid=23005" title="Philip K. Dick">
Philip K. Dick

Philip Kindred Dick (December 16, 1928March 2, 1982) was an American novelist, short story writer, essayist, and philosopher whose published works mainly belong to the genre of science fiction. Dick explored philosophical, sociological, political, and metaphysical themes in novels dominated by monopolistic corporations, authoritarian governments, and altered states of consciousness. In his later works, Dick's thematic focus strongly reflected his personal interest in metaphysics and theology. He often drew upon his life experiences in addressing the nature of drug abuse, paranoia, schizophrenia, and transcendental experiences in novels such as "A Scanner Darkly" and "VALIS". Later in life, he wrote non-fiction on philosophy, theology, the nature of reality, and science. This material was published posthumously as "The Exegesis".
The novel "The Man in the High Castle" bridged the genres of alternate history and science fiction, earning Dick a Hugo Award for Best Novel in 1963. "Flow My Tears, the Policeman Said", a novel about a celebrity who awakens one day to find that he is unknown, won the John W. Campbell Memorial Award for best novel in 1975. "I want to write about people I love, and put them into a fictional world spun out of my own mind, not the world we actually have, because the world we actually have does not meet my standards," Dick wrote of these stories. "In my writing I even question the universe; I wonder out loud if it is real, and I wonder out loud if all of us are real."
In addition to 44 published novels, Dick wrote approximately 121 short stories, most of which appeared in science fiction magazines during his lifetime. Although Dick spent most of his career as a writer in near-poverty, eleven popular films based on his works have been produced, including "Blade Runner", "Total Recall", "A Scanner Darkly", "Minority Report", "Paycheck", "Next", "Screamers", "The Adjustment Bureau" and "Impostor". In 2005, "Time" magazine named "Ubik" one of the hundred greatest English-language novels published since 1923. In 2007, Dick became the first science fiction writer to be included in The Library of America series.
Personal life.
Philip Kindred Dick and his twin sister, Jane Charlotte Dick, were born six weeks prematurely on December 16, 1928, in Chicago, Illinois, to Dorothy Kindred Dick and Joseph Edgar Dick, who worked for the United States Department of Agriculture. The death of Jane six weeks later, on January 26, 1929, profoundly affected Philip's life, leading to the recurrent motif of the "phantom twin" in his books.
His family later moved to the San Francisco Bay Area. When Philip was five, his father was transferred to Reno, Nevada; when Dorothy refused to move, she and Joseph divorced. Both parents fought for custody of Philip, which was awarded to the mother. Dorothy, determined to raise Philip alone, took a job in Washington, D.C., and moved there with her son. Philip was enrolled at John Eaton Elementary School (1936–38), completing the second through fourth grades. His lowest grade was a "C" in Written Composition, although a teacher remarked that he "shows interest and ability in story telling." He was educated in Quaker schools. In June 1938, Dorothy and Philip returned to California, and it was around this time that he became interested in science fiction. Dick stated that he read his first science fiction magazine, "Stirring Science Stories" in 1940 at the age of twelve.
Dick attended Berkeley High School in Berkeley, California. He and fellow science fiction author Ursula K. Le Guin were members of the same graduating class (1947) but did not know each other at the time. After graduation, he briefly attended the University of California, Berkeley, (September 1949 to November 11, 1949) with an honorable dismissal granted January 1, 1950. Dick did not declare a major and took classes in history, psychology, philosophy, and zoology. Through his studies in philosophy, he believed that existence is based on the internal-based perception of a human, which does not necessarily correspond to external reality; he described himself as "an acosmic panentheist," believing in the universe only as an extension of God. After reading the works of Plato and pondering the possibilities of metaphysical realms, Dick came to the conclusion that, in a certain sense, the world is not entirely real and there is no way to confirm whether it is truly there. This question from his early studies persisted as a theme in many of his novels. Dick dropped out because of ongoing anxiety problems, according to his third wife Anne's memoir. She also says he disliked the mandatory ROTC training. At Berkeley, Dick befriended poet Robert Duncan and poet and linguist Jack Spicer, who gave Dick ideas for a Martian language. Dick claimed to have been host of a classical music program on KSMO Radio in 1947.
From 1948 to 1952, Dick worked at Art Music Company, a record store on Telegraph Avenue. In 1955, he and his second wife, Kleo Apostolides, received a visit from the FBI, which they believed to be the result of Kleo's socialist views and left-wing activities. The couple briefly befriended one of the FBI agents.
Dick was married five times:
Dick had three children, Laura Archer (February 25, 1960), Isolde Freya (now Isa Dick Hackett) (March 15, 1967), and Christopher Kenneth (July 25, 1973).
Dick tried to stay out of the political scene because of high societal turmoil from the Vietnam War; however, he did show some anti-Vietnam War and anti-governmental sentiments. In 1968, he joined the "Writers and Editors War Tax Protest", an anti-war pledge to pay no U.S. federal income tax, which resulted in the confiscation of his car by the IRS.
Career.
Dick sold his first story in 1951, and from then on wrote full-time. During 1952 his first speculative fiction publications appeared in July and September numbers of "Planet Stories", edited by Jack O'Sullivan, and in "If" and "The Magazine of Fantasy and Science Fiction" that fall. His debut novel was "Solar Lottery", published in 1955 as half of Ace Double #D-103 alongside "The Big Jump" by Leigh Brackett. The 1950s were a difficult and impoverished time for Dick, who once lamented, "We couldn't even pay the late fees on a library book." He published almost exclusively within the science fiction genre, but dreamed of a career in mainstream American literature. During the 1950s he produced a series of non-genre, relatively conventional novels. In 1960 he wrote that he was willing to "take twenty to thirty years to succeed as a literary writer." The dream of mainstream success formally died in January 1963 when the Scott Meredith Literary Agency returned all of his unsold mainstream novels. Only one of these works, "Confessions of a Crap Artist", was published during Dick's lifetime.
In 1963, Dick won the Hugo Award for "The Man in the High Castle". Although he was hailed as a genius in the science fiction world, the mainstream literary world was unappreciative, and he could publish books only through low-paying science fiction publishers such as Ace. Even in his later years, he continued to have financial troubles. In the introduction to the 1980 short story collection "The Golden Man", Dick wrote:
In 1972, Dick donated manuscripts, papers and other materials to the Special Collections Library at California State University, Fullerton where they are archived in the Philip K. Dick Science Fiction Collection in the Pollak Library. It was in Fullerton that Philip K. Dick befriended budding science-fiction writers K. W. Jeter, James Blaylock, and Tim Powers. The last novel Dick wrote was "The Transmigration of Timothy Archer"; it was published shortly after his death in 1982.
Flight to Canada and suicide attempt.
In 1971, Dick's marriage to Nancy Hackett broke down, and she moved out of their shared home. Dick descended into amphetamine abuse, eventually allowing a number of other drug users to move into the house with him. One day in November of that year, Dick returned to his home in San Rafael to discover that it had been burgled, with his safe blown open and personal papers missing. The police were unable to determine the culprit, and even suspected Dick of having done so himself. Shortly afterwards, he was invited to be guest of honor at the Vancouver Science Fiction Convention in February 1972. Within a day of arriving at the conference and giving his speech "The Android and the Human", he informed people that he had fallen in love with a woman that he had met there, called Janis, and announced that he would be remaining in Vancouver. An attendee of the conference, Michael Walsh, movie critic for local newspaper The Province, invited Dick to stay in his home, but had to ask him to leave two weeks later due to his erratic behavior. This was followed by Janis ending her and Dick's relationship and moving away. On the 23rd of March 1972, Dick attempted unsuccessfully to commit suicide by consuming an overdose of the sedative potassium bromide. Subsequently, after deciding to seek help, Dick became a participant in X-Kalay (a Canadian Synanon-type recovery program), and was well enough by April that he was able to return to California.
Dick returned to the events of these months while writing his 1977 novel "A Scanner Darkly", which contains fictionalized depictions of the burglary of his home, his time using amphetamines and living with addicts, and his experiences of X-Kalay (portrayed in the novel as "New-Path"). A factual account of Dick's recovery program participation was portrayed in his posthumously released book "The Dark Haired Girl", a collection of letters and journals from the period.
Paranormal experiences and mental health issues.
On February 20, 1974, while recovering from the effects of sodium pentothal administered for the extraction of an impacted wisdom tooth, Dick received a home delivery of Darvon from a young woman. When he opened the door, he was struck by the beauty of the dark-haired girl and was especially drawn to her golden necklace. He asked her about its curious fish-shaped design. "This is a sign used by the early Christians," she said, and then left. Dick called the symbol the "vesicle pisces". This name seems to have been based on his conflation of two related symbols, the Christian ichthys symbol (two intersecting arcs delineating a fish in profile) which the woman was wearing, and the vesica piscis.
Dick recounted that as the sun glinted off the gold pendant, the reflection caused the generation of a "pink beam" of light that mesmerized him. He came to believe the beam imparted wisdom and clairvoyance, and also believed it to be intelligent. On one occasion, Dick was startled by a separate recurrence of the pink beam. It imparted the information to him that his infant son was ill. The Dicks rushed the child to the hospital, where his suspicion was confirmed by professional diagnosis.
After the woman's departure, Dick began experiencing strange hallucinations. Although initially attributing them to side effects from medication, he considered this explanation implausible after weeks of continued hallucinations. "I experienced an invasion of my mind by a transcendentally rational mind, as if I had been insane all my life and suddenly I had become sane," Dick told Charles Platt.
Throughout February and March 1974, Dick experienced a series of hallucinations, which he referred to as "2-3-74", shorthand for February–March 1974. Aside from the "pink beam", Dick described the initial hallucinations as geometric patterns, and, occasionally, brief pictures of Jesus and ancient Rome. As the hallucinations increased in length and frequency, Dick claimed he began to live two parallel lives, one as himself, "Philip K. Dick", and one as "Thomas", a Christian persecuted by Romans in the first century AD. He referred to the "transcendentally rational mind" as "Zebra", "God" and "VALIS". Dick wrote about the experiences, first in the semi-autobiographical novel "Radio Free Albemuth" and then in "VALIS", "The Divine Invasion" and the unfinished "The Owl in Daylight" (the VALIS trilogy).
At one point Dick felt that he had been taken over by the spirit of the prophet Elijah. He believed that an episode in his novel "Flow My Tears, the Policeman Said" was a detailed retelling of a biblical story from the Book of Acts, which he had never read. Dick documented and discussed his experiences and faith in a private journal, later published as "The Exegesis of Philip K. Dick".
Pen names.
Dick had two professional stories published under the pen names Richard Phillipps and Jack Dowland. "Some Kinds of Life" was published in October 1953 in Fantastic Universe under byline Richard Phillipps, apparently because the magazine had a policy against publishing multiple stories by the same author in the same issue; "Planet for Transients" was published in the same issue under his own name.
The short story "Orpheus with Clay Feet" was published under the pen name Jack Dowland. The protagonist desires to be the muse for fictional author Jack Dowland, considered the greatest science fiction author of the 20th century. In the story, Dowland publishes a short story titled "Orpheus with Clay Feet" under the pen name Philip K. Dick.
The surname Dowland refers to Renaissance composer John Dowland, who is featured in several works. The title "Flow My Tears, the Policeman Said" directly refers to Dowland's best-known composition, "Flow My Tears". In the novel "The Divine Invasion", the character Linda Fox, created specifically with Linda Ronstadt in mind, is an intergalactically famous singer whose entire body of work consists of recordings of John Dowland compositions. Also, some protagonists in Dick's short fiction are named Dowland.
Style and works.
Themes.
Dick's stories typically focus on the fragile nature of what is "real" and the construction of personal identity. His stories often become surreal fantasies, as the main characters slowly discover that their everyday world is actually an illusion constructed by powerful external entities (such as in "Ubik"), vast political conspiracies, or simply from the vicissitudes of an unreliable narrator. "All of his work starts with the basic assumption that there cannot be one, single, objective reality", writes science fiction author Charles Platt. "Everything is a matter of perception. The ground is liable to shift under your feet. A protagonist may find himself living out another person's dream, or he may enter a drug-induced state that actually makes better sense than the real world, or he may cross into a different universe completely."
Alternate universes and simulacra were common plot devices, with fictional worlds inhabited by common, working people, rather than galactic elites. "There are no heroes in Dick's books", Ursula K. Le Guin wrote, "but there are heroics. One is reminded of Dickens: what counts is the honesty, constancy, kindness and patience of ordinary people." Dick made no secret that much of his thinking and work was heavily influenced by the writings of Carl Jung. The Jungian constructs and models that most concerned Dick seem to be the archetypes of the collective unconscious, group projection/hallucination, synchronicities, and personality theory. Many of Dick's protagonists overtly analyze reality and their perceptions in Jungian terms (see "Lies Inc."). Dick's self-named "Exegesis" also contained many notes on Jung in relation to theology and mysticism.
Dick identified one major theme of his work as the question, "What constitutes the authentic human being?" In works such as "Do Androids Dream of Electric Sheep?", beings can appear totally human in every respect while lacking soul or compassion, while completely alien beings such as Glimmung in "Galactic Pot-Healer" may be more humane and complex than Dick's human characters.
Mental illness was a constant interest of Dick's, and themes of mental illness permeate his work. The character Jack Bohlen in the 1964 novel "Martian Time-Slip" is an "ex-schizophrenic". The novel "Clans of the Alphane Moon" centers on an entire society made up of descendants of lunatic asylum inmates. In 1965 he wrote the essay titled "Schizophrenia and the Book of Changes".
Drug use (including religious, recreational, and abuse) was also a theme in many of Dick's works, such as "A Scanner Darkly" and "The Three Stigmata of Palmer Eldritch". Dick himself was a drug user for much of his life. According to a 1975 interview in "Rolling Stone", Dick wrote all of his books published before 1970 while on amphetamines. ""A Scanner Darkly" (1977) was the first complete novel I had written without speed", said Dick in the interview. He also experimented briefly with psychedelics, but wrote "The Three Stigmata of Palmer Eldritch", which "Rolling Stone" dubs "the classic LSD novel of all time", before he had ever tried them. Despite his heavy amphetamine use, however, Dick later said that doctors told him the amphetamines never actually affected him, that his liver had processed them before they reached his brain.
Summing up all these themes in "Understanding Philip K. Dick", Eric Carl Link discussed eight themes or 'ideas and motifs': Epistemology and the Nature of Reality, Know Thyself, The Android and the Human, Entropy and Pot Healing, The Theodicy Problem, Warfare and Power Politics, The Evolved Human, and 'Technology, Media, Drugs and Madness'.
Selected works.
"The Man in the High Castle" (1962) is set in an alternative universe in which the United States is ruled by the victorious Axis powers. It is considered a defining novel of the alternate history subgenre, and is the only Dick novel to win a Hugo Award.
"The Three Stigmata of Palmer Eldritch" (1965) utilizes an array of science fiction concepts and features several layers of reality and unreality. It is also one of Dick's first works to explore religious themes. The novel takes place in the 21st century, when, under UN authority, mankind has colonized the Solar System's every habitable planet and moon. Life is physically daunting and psychologically monotonous for most colonists, so the UN must draft people to go to the colonies. Most entertain themselves using "Perky Pat" dolls and accessories manufactured by Earth-based "P.P. Layouts". The company also secretly creates "Can-D", an illegal but widely available hallucinogenic drug allowing the user to "translate" into Perky Pat (if the drug user is a woman) or Pat's boyfriend, Walt (if the drug user is a man). This recreational use of Can-D allows colonists to experience a few minutes of an idealized life on Earth by participating in a collective hallucination.
"Do Androids Dream of Electric Sheep?" (1968) is the story of a bounty hunter policing the local android population. It occurs on a dying, poisoned Earth de-populated of all "successful" humans; the only remaining inhabitants of the planet are people with no prospects off-world. The 1968 novel is the literary source of the film "Blade Runner" (1982). It is both a conflation and an intensification of the pivotally Dickian question, What is real, what is fake? What crucial factor defines humanity as distinctly 'alive', versus those merely alive only in their outward appearance?
"Ubik" (1969) uses extensive networks of psychics and a suspended state after death in creating a state of eroding reality. A group of psychics is sent to investigate a group of rival psychics, but several of them are apparently killed by a saboteur's bomb. Much of the novel flicks between a number of equally plausible realities; the "real" reality, a state of half-life and psychically manipulated realities. In 2005, "Time" magazine listed it among the "All-TIME 100 Greatest Novels" published since 1923.
"Flow My Tears, the Policeman Said" (1974) concerns Jason Taverner, a television star living in a dystopian near-future police state. After being attacked by an angry ex-girlfriend, Taverner awakens in a dingy Los Angeles hotel room. He still has his money in his wallet, but his identification cards are missing. This is no minor inconvenience, as security checkpoints (manned by "pols" and "nats", the police and National Guard) are set up throughout the city to stop and arrest anyone without valid ID. Jason at first thinks that he was robbed, but soon discovers that his entire identity has been erased. There is no record of him in any official database, and even his closest associates do not recognize or remember him. For the first time in many years, Jason has no fame or reputation to rely on. He has only his innate charisma to help him as he tries to find out what happened to his past while avoiding the attention of the pols. The novel was Dick's first published novel after years of silence, during which time his critical reputation had grown, and this novel was awarded the John W. Campbell Memorial Award for Best Science Fiction Novel. It is the only Philip K. Dick novel nominated for both a Hugo and a Nebula Award.
In an essay written two years before dying, Dick described how he learned from his Episcopalian priest that an important scene in "Flow My Tears, the Policeman Said" – involving its other main character, Police General Felix Buckman, the policeman of the title – was very similar to a scene in "Acts of the Apostles", a book of the Christian New Testament. Film director Richard Linklater discusses this novel in his film "Waking Life", which begins with a scene reminiscent of another Dick novel, "Time Out of Joint".
"A Scanner Darkly" (1977) is a bleak mixture of science fiction and police procedural novels; in its story, an undercover narcotics police detective begins to lose touch with reality after falling victim to the same permanently mind-altering drug, Substance D, he was enlisted to help fight. Substance D is instantly addictive, beginning with a pleasant euphoria which is quickly replaced with increasing confusion, hallucinations and eventually total psychosis. In this novel, as with all Dick novels, there is an underlying thread of paranoia and dissociation with multiple realities perceived simultaneously. It was adapted to film by Richard Linklater.
"The Philip K. Dick Reader" is an introduction to the variety of Dick's short fiction.
"VALIS" (1980) is perhaps Dick's most postmodern and autobiographical novel, examining his own unexplained experiences. It may also be his most academically studied work, and was adapted as an opera by Tod Machover. Later works like the VALIS trilogy were heavily autobiographical, many with "two-three-seventy-four" (2-3-74) references and influences. The word VALIS is the acronym for "Vast Active Living Intelligence System". Later, Dick theorized that VALIS was both a "reality generator" and a means of extraterrestrial communication. A fourth VALIS manuscript, "Radio Free Albemuth", although composed in 1976, was posthumously published in 1985. This work is described by the publisher (Arbor House) as "an introduction and key to his magnificent VALIS trilogy."
Regardless of the feeling that he was somehow experiencing a divine communication, Dick was never fully able to rationalize the events. For the rest of his life, he struggled to comprehend what was occurring, questioning his own sanity and perception of reality. He transcribed what thoughts he could into an eight-thousand-page, one-million-word journal dubbed the "Exegesis". From 1974 until his death in 1982, Dick spent many nights writing in this journal. A recurring theme in "Exegesis" is Dick's hypothesis that history had been stopped in the first century CE, and that "the Empire never ended". He saw Rome as the pinnacle of materialism and despotism, which, after forcing the Gnostics underground, had kept the population of Earth enslaved to worldly possessions. Dick believed that VALIS had communicated with him, and anonymous others, to induce the impeachment of U.S. President Richard Nixon, whom Dick believed to be the current Emperor of Rome incarnate.
In a 1968 essay titled "Self Portrait", collected in the 1995 book "The Shifting Realities of Philip K. Dick", Dick reflects on his work and lists which books he feels "might escape World War Three": "Eye in the Sky", "The Man in the High Castle", "Martian Time-Slip", "Dr. Bloodmoney, or How We Got Along After the Bomb", "The Zap Gun", "The Penultimate Truth", "The Simulacra", "The Three Stigmata of Palmer Eldritch" (which he refers to as "the most vital of them all"), "Do Androids Dream of Electric Sheep?", and "Ubik". In a 1976 interview, Dick cited "A Scanner Darkly" as his best work, feeling that he "had finally written a true masterpiece, after 25 years of writing".
Adaptations.
Films.
A number of Dick's stories have been made into films. Dick himself wrote a screenplay for an intended film adaptation of "Ubik" in 1974, but the film was never made. Many film adaptations have not used Dick's original titles. When asked why this was, Dick's ex-wife Tessa said, "Actually, the books rarely carry Phil's original titles, as the editors usually wrote new titles after reading his manuscripts. Phil often commented that he couldn't write good titles. If he could, he would have been an advertising writer instead of a novelist." Films based on Dick's writing have accumulated a total revenue of over US $1 billion as of 2009.
Future films based on Dick's writing include an animated adaptation of "The King of the Elves" from Walt Disney Animation Studios, set to be released in the spring of 2016; and a film adaptation of "Ubik" which, according to Dick's daughter, Isa Dick Hackett, is in advanced negotiation. Ubik is set to be made into a film by Michel Gondry.
The "Terminator" series also uses the theme of humanoid assassination machines portrayed in "Second Variety". The Halcyon Company, known for developing the "Terminator" franchise, acquired right of first refusal to film adaptations of the works of Philip K. Dick in 2007. In May 2009, they announced plans for an adaptation of "Flow My Tears, the Policeman Said".
Television.
It was reported in 2010 that Ridley Scott would produce an adaptation of "The Man in the High Castle" for the BBC, in the form of a mini-series. A pilot episode was released on Amazon Prime in January 2015 and Season 1 was fully released in ten episodes of about 60 minutes each on 20 Nov 2015.
Stage and radio.
Four of Dick's works have been adapted for the stage.
One was the opera "VALIS", composed and with libretto by Tod Machover, which premiered at the Pompidou Center in Paris on December 1, 1987, with a French libretto. It was subsequently revised and readapted into English, and was recorded and released on CD (Bridge Records BCD9007) in 1988.
Another was "Flow My Tears, the Policeman Said", adapted by Linda Hartinian and produced by the New York-based avant-garde company Mabou Mines. It premiered in Boston at the Boston Shakespeare Theatre (June 18–30, 1985) and was subsequently staged in New York and Chicago. Productions of "Flow My Tears, the Policeman Said" were also staged by the Evidence Room in Los Angeles in 1999 and by the Fifth Column Theatre Company at the Oval House Theatre in London in the same year.
A play based on "Radio Free Albemuth" also had a brief run in the 1980s.
In November 2010, a production of "Do Androids Dream of Electric Sheep?", adapted by Edward Einhorn, premiered at the 3LD Art and Technology Center in Manhattan.
A radio drama adaptation of Dick's short story "Mr. Spaceship" was aired by the Finnish Broadcasting Company (Yleisradio) in 1996 under the name "Menolippu Paratiisiin". Radio dramatizations of Dick's short stories "Colony" and "The Defenders" were aired by NBC in 1956 as part of the series "X Minus One".
Comics.
Marvel Comics adapted Dick's short story "The Electric Ant" as a limited series which was released in 2009. The comic was produced by writer David Mack ("Daredevil") and artist Pascal Alixe ("Ultimate X-Men"), with covers provided by artist Paul Pope. "The Electric Ant" had earlier been loosely adapted by Frank Miller and Geof Darrow in their 3-issue mini-series "Hard Boiled" published by Dark Horse Comics in 1990-1992.
In 2009, BOOM! Studios started publishing a 24-issue miniseries comic book adaptation of "Do Androids Dream of Electric Sheep?" "Blade Runner", the 1982 film adapted from "Do Androids Dream of Electric Sheep?", had previously been adapted to comics as "".
In 2011, Dynamite Entertainment published a 4-issue miniseries "Total Recall," a sequel to the 1990 film "Total Recall", inspired by Philip K. Dick's short story "We Can Remember It for You Wholesale". In 1990, DC Comics published the official adaptation of the original film as a "".
Alternate formats.
In response to a 1975 request from the National Library for the Blind for permission to make use of "The Man in the High Castle", Dick responded, "I also grant you a general permission to transcribe any of my former, present or future work, so indeed you can add my name to your 'general permission' list." A number of his books and stories are available in braille and other specialized formats through the NLS.
As of December 2012, thirteen of Philip K. Dick's early works in the public domain in the United States are available in ebook form from Project Gutenberg. As of April 4, 2012, Wikisource has one of Philip K. Dick's early works in the public domain in the United States available in ebook form which is not from Project Gutenberg. See .
Death.
On February 17, 1982, after completing an interview, Dick contacted his therapist, complaining of failing eyesight, and was advised to go to a hospital immediately; but he did not. The next day, he was found unconscious on the floor of his Santa Ana, California, home, having suffered a stroke. In the hospital, he suffered another stroke, after which his brain activity ceased. Five days later, on March 2, 1982, he was disconnected from life support and died. After his death, Dick's father, Joseph, took his son's ashes to Riverside Cemetery in Fort Morgan, Colorado, (section K, block 1, lot 56) where they were buried next to his twin sister Jane, whose tombstone had been inscribed with both their names when she died 53 years earlier.
Influence and legacy.
Lawrence Sutin's 1989 biography of Dick, "Divine Invasions: A Life of Philip K. Dick", is considered the standard biographical treatment of Dick's life.
In 1993, French writer Emmanuel Carrère published "Je suis vivant et vous êtes morts" which was first translated and published in English in 2004 as "I Am Alive and You Are Dead: A Journey Into the Mind of Philip K. Dick", which the author describes in his preface in this way:The book you hold in your hands is a very peculiar book. I have tried to depict the life of Philip K. Dick from the inside, in other words, with the same freedom and empathy – indeed with the same truth – with which he depicted his own characters. Critics of the book have complained about the lack of fact checking, sourcing, notes and index, "the usual evidence of deep research that gives a biography the solid stamp of authority." It can be considered a non-fiction novel about his life.
Dick has influenced many writers, including Jonathan Lethem, and Ursula K. Le Guin. The prominent literary critic Fredric Jameson proclaimed Dick the "Shakespeare of Science Fiction", and praised his work as "one of the most powerful expressions of the society of spectacle and pseudo-event". The author Roberto Bolaño also praised Dick, describing him as “Thoreau plus the death of the American dream”. Dick has also influenced filmmakers, his work being compared to films such as the Wachowskis' "The Matrix", David Cronenberg's "Videodrome", "eXistenZ", and "Spider", Spike Jonze's "Being John Malkovich", "Adaptation", Michel Gondry's "Eternal Sunshine of the Spotless Mind", Alex Proyas's "Dark City", Peter Weir's "The Truman Show", Andrew Niccol's "Gattaca", "In Time", Terry Gilliam's "12 Monkeys", Wes Craven's "A Nightmare on Elm Street", David Lynch's "Mulholland Drive", Alejandro Amenábar's "Open Your Eyes", David Fincher's "Fight Club", Cameron Crowe's "Vanilla Sky", Darren Aronofsky's "Pi", Richard Kelly's "Donnie Darko" and "Southland Tales", and Christopher Nolan's "Memento" and "Inception".
The Philip K. Dick Society was an organization dedicated to promoting the literary works of Dick and was led by Dick's longtime friend and music journalist Paul Williams. Williams also served as Dick's literary executor for several years after Dick's death and wrote one of the first biographies of Dick, entitled "Only Apparently Real: The World of Philip K. Dick". 
The Philip K. Dick estate owns and operates the production company Electric Shepherd Productions, which has produced the films "Adjustment Bureau" (2011) and the upcoming Walt Disney Company film "King of the Elves", the TV series "The Man in the High Castle" and also a Marvel Comics 5-issue adaptation of "Electric Ant".
Dick was recreated by his fans in the form of a simulacrum or remote-controlled android designed in his likeness. Such simulacra had been themes of many of Dick's works. The Philip K. Dick simulacrum was included on a discussion panel in a San Diego Comic Con presentation about the film adaptation of the novel, "A Scanner Darkly". In February 2006, an America West Airlines employee misplaced the android's head, and it has not yet been found. In January 2011, it was announced that Hanson Robotics had built a replacement.
Contemporary philosophy.
Dick's foreshadowing of postmodernity has been noted by philosophers as diverse as Jean Baudrillard, Fredric Jameson, Laurence Rickels and Slavoj Žižek. Jean Baudrillard offers this interpretation:
It is hyperreal. It is a universe of simulation, which is something altogether different. And this is so not because Dick speaks specifically of simulacra. SF has always done so, but it has always played upon the double, on artificial replication or imaginary duplication, whereas here the double has disappeared. There is no more double; one is always already in the other world, an other world which is not another, without mirrors or projection or utopias as means for reflection. The simulation is impassable, unsurpassable, checkmated, without exteriority. We can no longer move "through the mirror" to the other side, as we could during the golden age of transcendence.
For his anti-government skepticism, Philip K. Dick was afforded minor mention in "Mythmakers and Lawbreakers", a collection of interviews about fiction by anarchist authors. Noting his early authorship of "The Last of the Masters", an anarchist-themed novelette, author Margaret Killjoy expressed that while Dick never fully sided with anarchism, his opposition to government centralization and organized religion has influenced anarchist interpretations of gnosticism.
Awards and honors.
The Science Fiction Hall of Fame inducted Dick in 2005.
During his lifetime he received numerous annual literary awards and nominations for particular works.
Philip K. Dick award.
The Philip K. Dick Award is a science fiction award that annually recognizes the previous year's best SF paperback original published in the U.S. It is conferred at Norwescon, sponsored by the Philadelphia Science Fiction Society, and since 2005 supported by the Philip K. Dick Trust. Winning works are identified on their covers as "Best Original SF Paperback". It is currently administered by David G. Hartwell and Gordon Van Gelder.
The award was inaugurated in 1983, the year after Dick's death. It was founded by Thomas Disch with assistance from David G. Hartwell, Paul S. Williams, and Charles N. Brown. Past administrators include Algis J. Budrys and David Alexander Smith.

</doc>
<doc id="23006" url="https://en.wikipedia.org/wiki?curid=23006" title="Penélope Cruz">
Penélope Cruz

Penélope Cruz Sánchez (; born 28 April 1974) is a Spanish actress and model. Signed by an agent at age 15, she made her acting debut at 16 on television and her feature film debut the following year in "Jamón, jamón" (1992) to critical acclaim. Her subsequent roles in the 1990s and 2000s included "Open Your Eyes" (1997), "The Hi-Lo Country" (1999), "The Girl of Your Dreams" (2000) and "Woman on Top" (2000). Cruz achieved recognition for her lead roles in the 2001 films "Vanilla Sky", "All the Pretty Horses", "Captain Corelli's Mandolin" and "Blow".
She has since appeared in films in a range of genres, including the comedy "Waking Up in Reno" (2002), the thriller "Gothika" (2003), the Christmas film "Noel" (2004), and the action adventure "Sahara" (2005). She was critically acclaimed for her roles in "Volver" (2006) and "Nine" (2009), receiving Golden Globe and Academy Award nominations for each. She won the Academy Award for Best Supporting Actress in 2008 for playing María Elena in "Vicky Cristina Barcelona". She was the first Spanish actress in history to receive an Academy Award and the first Spanish actress to receive a star at the Hollywood Walk of Fame.
Cruz has modelled for Mango, Ralph Lauren and L'Oréal. Penélope and her younger sister Mónica Cruz have designed clothing for Mango. Cruz has volunteered in Uganda and India, where she spent one week working with Mother Teresa; she donated her salary from "The Hi-Lo Country" to help fund the late nun's mission.
Early life.
Penélope Cruz Sánchez was born in Alcobendas, Madrid, Spain, the daughter of Encarna (née Sánchez), a hairdresser and personal manager, and Eduardo Cruz, a retailer and car mechanic. She has two siblings, Monica, an actress and Eduardo, Jr. Penelope also has a paternal half-sister Salma. She was raised Roman Catholic. Cruz grew up in Alcobendas, a working-class town, and spent long hours at her grandmother's apartment. She says she had a happy childhood. Cruz remembers "playing with some friends and being aware that I was acting as I was playing with them. I would think of a character and pretend to be someone else."
Initially, Cruz focused on dance, having studied classical ballet for nine years at Spain's National Conservatory. She took three years of Spanish ballet training and four years of theatre at Cristina Rota's New York school. She says that ballet instilled in her discipline that would be important in her future acting career. When she became a fan of films at age 10 or 11, her father bought a Betamax machine, which was a very rare thing to own in her neighbourhood at the time.
As a teenager, Cruz became interested in acting after seeing the film "Tie Me Up! Tie Me Down!" by Spanish director Pedro Almodóvar. She did casting calls for an agent, but was rejected multiple times because the agent felt that she was too young. Cruz commented on the experience that "I was very extroverted as a kid. [...] I was studying when I was in high school at night, I was in ballet and I was doing castings. I looked for an agent and she sent me away three times because I was a little girl but I kept coming back. I'm still with her after all these years." In 1989, at the age of 15, Cruz won an audition at a talent agency over more than 300 other girls. In 1999, Katrina Bayonas, Cruz's agent, commented, "She was absolutely magic [at the audition]. It was obvious there was something very impressive about this kid. [...] She was very green, but there was a presence. There was just something coming from within."
Her father Eduardo died at his home in Spain in 2015 at the age 62, of a heart attack.
Acting career.
Early work, 1989–1996.
In 1989, 15-year-old Cruz made her acting debut in a music video for the Spanish pop group Mecano's song "La Fuerza del Destino". Between 1990 and 1997, she hosted the Spanish TV channel Telecinco's talk show "La Quinta Marcha", a programme that was hosted by teenagers, aimed at a teenage audience. She also played in the "Elle et lui" episode of an erotic French TV series called "Série rose" in 1991, where she appeared nude. In 1992, Cruz made her feature film debut at 18 as the lead female role in the comedy drama art house film, "Jamón, jamón". In the film, she portrayed Silvia, a young woman who is expecting her first child with a man whose mother does not approve of the relationship and attempts to sabotage it by paying Javier Bardem's character to seduce her. "People" magazine noted that after Cruz appeared topless in the film, she became "a major sex symbol". In an interview with the "Los Angeles Daily News" in 1999, Cruz commented that "it was a great part, but...I wasn't really ready for the nudity. [...] But I have no regrets because I wanted to start working and it changed my life." Charlie Rose of "60 Minutes" noted that Cruz "became an overnight sensation as much for her nude scenes as for her talent". When Rose asked Cruz if she was concerned about how she would be perceived after her role in the film, Cruz replied, "I just knew I had to do the complete opposite."
"Jamón, jamón" received favorable reviews, with Chris Hicks of the "Deseret News" describing Cruz's portrayal of Silvia as "enchanting". Writing for the "Chicago Sun-Times", film critic Roger Ebert wrote "it stars actors of considerable physical appeal, most particularly Penélope Cruz as Silvia". For her performance, Cruz was nominated for a Spanish Actors Union Newcomer Award and a Goya Award for Best Actress. The same year she appeared in the Academy-Award winning "Belle Epoque" as the virginal Luz. "People" magazine noted that Cruz's role as Luz showed that she was versatile. From 1993 to 1996, Cruz appeared in ten Spanish and Italian films. At 20, she went to live in New York for two years at Christopher and Greenwich to study ballet and English between films. She recalls learning English "kind of late" only knowing the dialogue she had learned for the casting beyond that, she could only say, "How are you?" and "Thank you."
Early critical success, 1997–2000.
Cruz's agent is Hylda Queally, shared with Cate Blanchett and Kate Winslet. In 1997, Cruz appeared in the Spanish comedy film "Love Can Seriously Damage Your Health". She portrays Diana, a fan of the Beatles band member John Lennon; she tries unsuccessfully to meet him. Years later, after multiple failed relationships, Diana re-unites with an acquaintance under unusual circumstances. Also in 1997, she appeared in the opening scene of Pedro Almodóvar's "Live Flesh" as a prostitute who gives birth on a bus and in "Et hjørne af paradis" (A Corner of Paradise) as Doña Helena. Cruz's final appearance in 1997 was the Amenabar-directed Spanish sci-fi drama, "Abre Los Ojos"/ "Open Your Eyes". She plays Sofia, the love interest of Eduardo Noriega's lead character. "Open Your Eyes" received positive reviews, and was later remade by U.S. director Cameron Crowe as "Vanilla Sky" (who cast Cruz in the same role and Tom Cruise in Noriega's role), but "Open Your Eyes" was not commercially successful. Kevin N. Laforest of the Montreal Film Journal commented in his September 2002 review that Cruz "has been getting some really bad reviews for her recent American work, but I personally think that she's a more than decent actress, especially here, where she's charming, moving and always believable. [...] There's one shot in particular, where Cruz enters a room in a greenish glow, which is right out of Hitchcock's picture ["Vertigo"]."
The following year, Cruz appeared in her first American film as Billy Crudup's consolation-prize Mexican girlfriend in Stephen Frears' western film, "The Hi-Lo Country". Cruz stated that she had difficulties understanding people speaking English while she was filming "The Hi-Lo Country". The film was critically and commercially unsuccessful. Kevin Lally of the "Film Journal International" commented in his review for the film that "in an ironic casting twist, the Spanish actress Penélope Cruz [...] is much more appealing as Josepha [than in her previous roles]". For her performance in the film, she was nominated for an ALMA Award for Best Actress. Also in 1998 Cruz appeared in "Don Juan" and "The Girl of Your Dreams".
In the period drama "The Girl of Your Dreams" (La niña de tus ojos), Cruz portrayed Macarena Granada, a singer who is in an on-and-off relationship with Antonio Resines's character, Blas. They are part of a Francoist film troupe that travels from Spain during the Spanish Civil War to Nazi Germany for a joint production with UFA. Cruz's performance in the film was praised by film critics, with Jonathan Holloland of "Variety" magazine writing "if confirmation is still needed that Cruz is an actress first and a pretty face second, then here it is". A writer for "Film4" commented that "Cruz herself is the inevitable focus of the film" but noted that overall the film "looks great". Cruz's role as Macerna has been viewed as her "largest role to date". For her performance, Cruz received a Goya Award and Spanish Actors' Union Award, and was nominated for a European Film Award. In 1999, Cruz worked with Almodóvar again in "All About My Mother", playing Sister María Rosa Sanz, a pregnant nun with AIDS. The film received favorable reviews, and was commercially successful, grossing over $67 million worldwide, although it performed better at the box office internationally than domestically.
In 2000, she appeared in "Woman on Top" in the lead female role as Isabelle, a world-class chef who has suffered from motion sickness since birth, her first American lead role. Lisa Nesselson of "Variety" magazine praised the performances of both Cruz and her co-star, Harold Perrineau, saying they "burst off the screen", and added that Cruz has a charming accent. BBC News film critic Jane Crowther said that "Cruz is wonderfully ditzy as the innocent abroad" but remarked that "it's Harold Perrineau Jr as Monica who pockets the movie". Annlee Ellingson of "Box Office" magazine wrote "Cruz is stunning in the role—innocent and vulnerable yet possessing a mature grace and determined strength, all while sizzling with unchecked sensuality." Also in 2000, she played Alejandra Villarreal, who is Matt Damon's love interest in Billy Bob Thornton's film adaptation of the western bestselling novel, "All the Pretty Horses". Susan Stark of the "Detroit News" commented that in the film Thornton was able to guide Damon, Henry Thomas and Cruz to "their most impressive performances in a major movie yet". However, Bob Longigo of "The Atlanta Journal Constitution" was less enthusiastic about Cruz and Damon's performance, saying that their "resulting onscreen chemistry would hardly warm a can of beans".
Breakthrough acting, 2001–2005.
2001 marked a turning point year when Cruz starred in the feature films "Vanilla Sky" and "Blow". In "Vanilla Sky", Cameron Crowe's interpretation of "Open Your Eyes", she played Sofia Serrano, the love interest of Tom Cruise's character. The film received mixed reviews but made $200 million worldwide. Her performance was well received by critics, with BBC film critic Brandon Graydon saying that Cruz "is an enchanting screen presence", and Ethan Alter of the "Film Journal International" noting that Cruz and her co-star Cruise were "able to generate some actual chemistry". Her next film was "Blow", adapted from Bruce Porter's 1993 book "Blow: How a Small Town Boy Made $100 million with the Medellin Cocaine Cartel and Lost It All". She had a supporting role as Mirtha Jung, the wife of Johnny Depp's character. The film received mixed reviews, but made $80 million worldwide. Nina Willdorf of the "Boston Phoenix" described Cruz as "multi-talented" and Mark Salvo of "The Austin Chronicle" wrote "I may be one of the last male holdouts to join the Cruz-Rules camp, but her tour de force performance here sucks you right in."
In 2001, she also appeared in "Don't Tempt Me", playing Carmen Ramos. The film received negative reviews. Jeff Vice of the "Deseret News" commented that "unfortunately, casting Cruz as a tough girl is a hilariously bad [idea]" and Michael Miller of the "Village Voice" writing that "as Satan's helper Carmen, Penélope Cruz doesn't hold a candle to her cocaine-huffing enabler in "Blow"". Cruz's last film in 2001 was "Captain Corelli's Mandolin", film adaption of the novel of the same name. She played Pelagia, who falls in love with another man while her fiancé is in battle during the Second World War. "Captain Corelli's Mandolin" was not well received by critics, but made $62 million worldwide. In 2002, she had a minor role in "Waking Up in Reno". It had negative reviews and was a box office failure, making $267,000 worldwide. The following year, Cruz had a supporting role in the horror film "Gothika", as Chloe Sava, a patient at a mental hospital. David Rooney of "Variety" wrote that Cruz "adds a serviceably malevolent edge to Chole's apparent madness". Cruz's performance in "Fanfan la Tulipe", also in 2003, was not well received, Peter Bradshaw of "The Guardian" commenting that Cruz "deserves a special Cannes Razzie for a performance of purest teak".
In 2004, Cruz appeared in the Christmas film "Noel" as Nina, the girlfriend of Paul Walker's character and as Mia in the romantic drama, "Head in the Clouds", set in the 1930s. "Head in the Clouds" performed poorly at the box office. For "Head in the Clouds", Bruce Birkland of "Jam! Canoe" said, "The story feels forced and the performances dreary, with the notable exception of Cruz, who seems to be in a different film from the rest of the cast." Desson Thompson of "The Washington Post" was more critical; his comment about the character's "pronounced limp" was that "Cruz (hardly the world's greatest actress) can't even perform without looking fake". She also starred in Sergio Castellitto's melodrama "Don't Move". Cruz, who learned Italian for the role, earned critical acclaim for her performance and won the David di Donatello. She was also awarded the European Film Award for Best Actress for the film in 2004.
In 2005, Cruz appeared as Dr. Eva Rojas in the action adventure "Sahara". She earned $1.6 million for her supporting role. The film grossed $110 million worldwide but did not recoup its $160 million budget. Moviefone dubbed the film "one of the most famous flops in history" and in 2007, listed it at 24 on its list of "Biggest Box-Office Turkeys of All Time". Lori Hoffman of the "Atlantic City Weekly" felt Cruz put her "considerable [acting] skills on cruise control as Dr Eva Rojas" and James Berardnelli of ReelViews described Cruz's performance as a "black hole", that she "lacks screen presence". Also in 2005, Cruz appeared in "Chromophobia", screened at the 2005 Cannes Film Festival and released the following year. Mathew Turner of "View London" said Cruz's character Gloria, a cancer-riddled prostitute, is "actually more interesting than the main storyline" while Time Evan's of "Sky Movies" wrote, "The Cruz/Ifans storyline—featuring the only two remotely sympathetic characters—never really fuses with the main plot." Her final 2005 film was "Don't Move" playing Italia. Eric Harrison of the "Houston Chronicle" noted that Cruz "goes all out" with her appearance and Patrick Peters of "Empire" magazine commented that the film's director, who also appears in the film, was able to draw a "sensitive performance" from Cruz.
Worldwide recognition, 2006–present.
Cruz appeared alongside her good friend Salma Hayek in the 2006 Western comedy film, "Bandidas". Randy Cordova of the "Arizona Republic" said the film "sports" Cruz and her co-star Salma Hayek as the "lusty dream team" and that they were the "marketing fantasy" for the film. Also in 2006, Cruz received favourable reviews for her performance as Raimunda in Pedro Almodóvar's "Volver". Carina Chocano of "The Los Angeles Times" wrote, "Cruz, who has remarked that in Hollywood she's rarely allowed to be anything more than pretty, instills her with an awesome resoluteness and strength of character." She shared a Best Actress award at the 2006 Cannes Film Festival with five of her co-stars, as well as receiving a Goya Award and European Film Award, and was nominated for the Golden Globe, the Screen Actors Guild Award, the BAFTA Award, and the Academy Award for Best Actress in a leading role. She was the first Spaniard to ever be nominated for an Academy Award for Best Actress.
In 2007, Cruz appeared in the lead female role in "Manolete", a biopic of bullfighter Manuel Laureano Rodríguez Sánchez, playing Antoñita "Lupe" Sino. She also appeared in "The Good Night", playing two characters, Anna and Melody. TV Guide film critic Maitland McDonagh noted that in the film Cruz "expertly mines the contrast between chic, compliant, white-clad Anna and funky, street-wise Melody, who treats [Martin Freeman's character] Gary like the world-class drag he is". In 2008, Cruz appeared in Isabel Coixet's film "Elegy", which was based on the Philip Roth story "The Dying Animal", as the lead female role, Consuela Castillo. Ray Bennett of "The Hollywood Reporter" described Cruz's performance as being "outstanding in an otherwise lame male fantasy [film]".
Later that year, she starred in Woody Allen's "Vicky Cristina Barcelona" as María Elena, a mentally unstable woman, which was praised. Peter Bradshaw of "The Guardian" praised Cruz's performance in the film. Cruz received a Goya Award and her first Academy Award and BAFTA Award for Best Supporting Actress. She also received a Golden Globe and SAG nomination. Cruz was the first Spanish actress to ever be awarded an Academy Award in that category and the sixth Hispanic person to ever receive the award.
Cruz's next film was the kid-friendly "G-Force" voicing a guinea pig spy named Juarez. "G-Force" was a commercial success, making over $290 million worldwide. Also in 2009, she appeared in the film "Broken Embraces" as Lena. Stephanie Zacharek of Salon.com noted in her review for the film that Cruz "doesn't coast on her beauty in "Broken Embraces", and she has the kind of role that can be difficult to flesh out". Cruz received nominations from the Satellite Awards and European Film Awards for her performance in "Broken Embraces". Cruz's final 2009 film was the film version of the musical "Nine", playing the character Carla Albanese, the lead character's mistress. "Variety" reported that Cruz had originally auditioned for the role of the film within a film's star, Claudia, which eventually went to Nicole Kidman. Cruz said that she trained for three months for the dance routine in the film. Claudia Puig of "USA Today" commented that while Cruz "does a steamy song and dance", her "acting is strangely caricatured". Cruz's performance as Carla garnered her nominations for Best Supporting Actress from the Academy Awards, Golden Globes and SAG Awards.
In 2010, Cruz appeared in the film "Sex and the City 2", the sequel to the 2008 film, in a cameo role. Cruz appeared in her biggest Hollywood turn to date, in the , as Angelica. On , prior to the film's release, Cruz received the 2,436th star on the Hollywood Walk of Fame in front of the El Capitan Theatre. She became the first Spanish actress to receive a Star. She spoke Italian again, this time as a prostitute in Woody Allen's 2012 film "To Rome with Love" and she is set to reunite with Italian director Sergio Castellitto in his war tale Twice Born ("Venuto al Mondo") as Gemma. After being shelved since 2007, Cruz's film "Manolete" (originally shot in 2005) released on demand via cable, satellite, telco and online in June 7, 2011 under the title "A Matador's Mistress".
In 2012, Cruz appeared in the first ever Nintendo commercial to promote "New Super Mario Bros. 2" and the Nintendo 3DS XL in which she played the role of Mario in the ad.
Public image.
In 2006, Cruz became spokesmodel for French cosmetics company L'Oréal to promote products such as the L'Oréal Paris hair dye Natural Match and L'Oreal mascara products. She receives $2 million a year for her work for the company. Cruz has appeared in print ads for Mango and had a contract with Ralph Lauren in 2001. Cruz and her sister designed their second collection for Mango in 2007. It was inspired by Brigitte Bardot and summers in St Tropez.
Cruz ranked as No. 58 in "Maxim" "Hot 100" of 2007 list, and was chosen by "Empire" magazine as being one of the 100 Sexiest Movie Stars in the world. Cruz was also ranked on Askmen.com's Most Desirable Women of 2008 at No. 26, in 2009 at No. 25, and in 2010 at No. 7. In April 2010, she replaced Kate Winslet as the new face and ambassador of Lancôme's Trésor fragrance. Lancôme has signed Cruz as the brand's third superstar spokesmodel, along with Julia Roberts and Winslet. The campaign was shot by Mario Testino at Paris's Hotel de Crillon and debuted in the autumn of 2010.
In 2010, Cruz was a guest editor for the French "Vogue" magazine, focusing on larger-size models in a provocative photo shoot. Almodóvar described her as his muse. On the cover of Spanish Vogue's December 2010 issue, she agreed to be photographed by fashion photographer Peter Lindbergh only if her pregnancy was not shown. In 2011, "The Telegraph" reported the most sought after body parts of the rich and famous revealed by two Hollywood plastic surgeons who carried out a survey among their patients to build up the picture of the perfect woman. Under the category of the most sought after body shape, Penélope Cruz, known for her voluptuous figure, was voted as having the top body. "Men's Health" ranked her at No. 32. on their "100 Hottest Women of All-Time" list.
"Esquire" named her the "Sexiest Woman Alive" in 2014.
During the 2014 Israel–Gaza conflict, Cruz along with her husband signed an open letter, denouncing Israel's actions as a "genocide".
Philanthropy.
Cruz has donated money and time to charity. In addition to work in Nepal, she has volunteered in Uganda and India, where she spent a week working with Mother Teresa that included assisting in a leprosy clinic. That trip inspired Cruz to help start a foundation to support homeless girls in India, where she sponsors two young women. She donated her salary from her first Hollywood film, "The Hi-Lo Country", to Mother Teresa's mission. In the early 2000s, she spent time in Nepal photographing Tibetan children for an exhibition attended by the Dalai Lama. She also photographed residents at the Pacific Lodge Boys' Home, most of whom are former gang members and recovering substance abusers. She said: "These kids break my heart. I have to control myself not to cry. Not out of pity, but seeing how tricky life is and how hard it is to make the right choices." A pregnant Cruz showed her support for the battle against AIDS by lighting up the Empire State Building with red lights in New York City on 1 December 2010 on International AIDS Day, as part of (RED)'s new awareness campaign, 'An AIDS Free Generation is Due in 2015,' which aims to eradicate the HIV virus from pregnant mothers to their babies. In 2012, she posed for an ad supporting PETA's anti-fur campaign.
Personal life.
Cruz is married to Spanish actor Javier Bardem. Bardem was her co-star in her first breakthrough role as Silvia in "Jamon, Jamon" as well as starring alongside her in "Vicky Cristina Barcelona". 
They were also both in the 2013 film "The Counselor".
Cruz began dating Bardem in 2007 and they married in early July 2010 in a private ceremony at a friend's home in the Bahamas. They have a son born in 2011 in Los Angeles, and a daughter born in 2013. She has become a public advocate of breastfeeding since the birth of her children.
Cruz had a three-year relationship with Tom Cruise after they appeared together in "Vanilla Sky". It ended in January 2004. In April 2003, she filed a lawsuit against the Australian magazine "New Idea" for defamation over an article about her relationship with Cruise.
Cruz is a friend of Spanish director Pedro Almodóvar, whom she has known for more than two decades and with whom she has worked on films. She is known to friends as "Pe". Cruz owns a clothing store in Madrid and designed jewelry and handbags with her younger sister for a company in Japan.

</doc>
<doc id="23008" url="https://en.wikipedia.org/wiki?curid=23008" title="Preliminary hearing">
Preliminary hearing

Within some criminal justice systems, a preliminary hearing, preliminary examination, evidentiary hearing or probable cause hearing is a proceeding, after a criminal complaint has been filed by the prosecutor, to determine whether there is enough evidence to require a trial. In the United States, the judge must find that such evidence provides probable cause to believe that the crime was committed by the defendant.
In Scotland, a preliminary hearing is a non-evidential diet in cases to be tried before the High Court of Justiciary. It is a pre-trial diet to enable the court to be advised whether both parties, the prosecution and the defence, are ready to proceed to trial and may also deal with ancillary procedural matters.
At such a hearing, the defendant may be assisted by counsel; in U.S. jurisdictions, there is a right to counsel at the preliminary hearing. A preliminary hearing is not always required, and its requirement varies by jurisdiction. In the U.S., for example, some states hold these hearings in every criminal case; in others, they are held upon request by the defense, and still others, they are only held in felony cases. If, on the other hand, the defendant is charged with a felony under Federal law, [s]he has the right to an indictment by a grand jury pursuant to the Fifth Amendment to the Constitution. At grand jury proceedings, the defendant is not entitled to counsel, and indeed may not even know that a grand jury is considering his or her case.
The conduct of the preliminary hearing as well as the specific rules regarding the admissibility of evidence vary from jurisdiction to jurisdiction. Hearsay is typically allowed. Should the court decide that there is probable cause, a formal charging instrument (called the information in some jurisdictions) will issue; and the prosecution will continue. If the court should find that there is no probable cause, then typically the prosecution will cease. Many jurisdictions, however, allow the prosecution to seek a new preliminary hearing, or even seek a bill of indictment from a grand jury.
Some important questions that such a hearing generally addresses are:
If a judge determines that there is sufficient evidence to believe that the defendant committed the crime, it is said that the defendant is "held to answer" or "bound over" (in U.S. jurisdictions).
In some jurisdictions, after the court holds a defendant to answer, the court schedules an arraignment, while in other jurisdictions the arraignment precedes the preliminary hearing. The prosecutor files a new pleading with the court (sometimes called an "information") and the defendant can enter a plea at the arraignment. If that plea is not guilty, a trial normally follows and the court sets a trial date at the arraignment or preliminary hearing, depending on which comes later.

</doc>
<doc id="23010" url="https://en.wikipedia.org/wiki?curid=23010" title="Paul Ehrlich">
Paul Ehrlich

 (14 March 1854 – 20 August 1915) was a German physician and scientist who worked in the fields of hematology, immunology, and antimicrobial chemotherapy. He invented the precursor technique to Gram staining bacteria. The methods he developed for staining tissue made it possible to distinguish between different types of blood cells, which led to the capability to diagnose numerous blood diseases.
His laboratory discovered arsphenamine (Salvarsan), the first effective medicinal treatment for syphilis, thereby initiating and also naming the concept of chemotherapy. Ehrlich popularized the concept of a magic bullet. He also made a decisive contribution to the development of an antiserum to combat diphtheria and conceived a method for standardizing therapeutic serums.
In 1908, he received the Nobel Prize in Physiology or Medicine for his contributions to immunology. He was the founder and first director of what is now known as the Paul Ehrlich Institute.
Life and career.
Born 14 March 1854 in Strehlen near Breslau, Paul Ehrlich was the second child of Rosa (Weigert) and Ismar Ehrlich. His father was a distiller of liqueurs and the royal lottery collector in Strehelen, a town of some 5,000 inhabitants in the province of Lower Silesia, now in Poland. His grandfather, Heymann Ehrlich, had been a fairly successful distiller and tavern manager. Ismar Ehrlich was the leader of the local Jewish community.
After elementary school, Paul attended the time-honored secondary school Maria-Magdalenen-Gymnasium in Breslau, where he met Albert Neisser, who later became a professional colleague. As a schoolboy (inspired by his cousin Karl Weigert who owned one of the first microtomes), he became fascinated by the process of staining microscopic tissue substances. He retained that interest during his subsequent medical studies at the universities of Breslau, Strasbourg, Freiburg im Breisgau and Leipzig. After obtaining his doctorate in 1882, he worked at the Charité in Berlin as an assistant medical director under Theodor Frerichs, the founder of experimental clinical medicine, focusing on histology, hematology and color chemistry (dyes).
He married Hedwig Pinkus (then aged 19) in 1883. The couple had two daughters, Stephanie and Marianne.
After completing his clinical education and habilitation at the prominent Charité medical school and teaching hospital in Berlin in 1886, Ehrlich traveled to Egypt and other countries in 1888 and 1889, in part to cure a case of tuberculosis which he had contracted in the laboratory. Upon his return he established a private medical practice and small laboratory in Berlin-Steglitz. In 1891, Robert Koch invited Ehrlich to join the staff at his Berlin Institute of Infectious Diseases, where in 1896 a new branch, the Institute for Serum Research and Testing ("Institut für Serumforschung und Serumprüfung"), was established for Ehrlich’s specialization. Ehrlich was named its founding director.
In 1899 his institute moved to Frankfurt am Main and was renamed the Institute of Experimental Therapy ("Institut für experimentelle Therapie"). One of his important collaborators there was Max Neisser. In 1906 Ehrlich became the director of the Georg Speyer House in Frankfurt, a private research foundation affiliated with his institute. Here he discovered in 1909 the first drug to be targeted against a specific pathogen: Salvarsan, a treatment for syphilis, which was at that time one of the most lethal and infectious diseases in Europe. Among the foreign guest scientists working with Ehrlich were two Nobel Prize winners, Henry Hallett Dale and Paul Karrer. The institute was renamed Paul Ehrlich Institute in Ehrlich's honour in 1947.
In 1914 Ehrlich signed the controversial Manifesto of the Ninety-Three which was a defense of Germany’s World War I politics and militarism. On 17 August 1915 Ehrlich suffered a heart attack and died on 20 August in Bad Homburg vor der Höhe. Wilhelm II the German emperor, wrote in a telegram of condolence, “I, along with the entire civilized world, mourn the death of this meritorious researcher for his great service to medical science and suffering humanity; his life’s work ensures undying fame and the gratitude of both his contemporaries and posterity”.
Paul Ehrlich was buried at the Old Jewish Cemetery, Frankfurt (Block 114 N).
Research.
Hematological staining.
In the early 1870s, Ehrlich’s cousin Karl Weigert was the first person to stain bacteria with dyes and to introduce aniline pigments for histological studies and bacterial diagnostics. During his studies in Strassburg under the anatomist Heinrich Wilhelm Waldeyer, Ehrlich continued the research started by his cousin in pigments and staining tissues for microsopic study. He spent his eighth university semester in Freiburg im Breisgau investigating primarily the red dye dahlia (monophenylrosanilin), giving rise to his first publication.
In 1878 he followed his dissertation supervisor Julius Friedrich Cohnheim to Leipzig, and that year obtained a doctorate with a dissertation entitled "Contributions to the Theory and Practice of Histological Staining" ("Beiträge zur Theorie und Praxis der histologischen Färbung").
One of the most outstanding results of his dissertation investigations was the discovery of a new cell type. Ehrlich discovered in the protoplasm of supposed plasma cells a granulate which could be made visible with the help of an alkaline dye. He thought this granulate was a sign of good nourishment, and accordingly named these cells mast cells, (from the German word for an animal-fattening feed, "Mast"). This focus on chemistry was unusual for a medical dissertation. In it, Ehrlich presented the entire spectrum of known staining techniques and the chemistry of the pigments employed.
While he was at the Charité, Ehrlich elaborated upon the differentiation of white blood cells according to their different granules. A precondition was a dry specimen technique, which he also developed. A drop of blood placed between two glass slides and heated over a Bunsen burner fixed the blood cells while still allowing them to be stained. Ehrlich used both alkaline and acid dyes, and also created new “neutral” dyes. For the first time this made it possible to differentiate the lymphocytes among the leucocytes (white blood cells). By studying their granulation he could distinguish between nongranular lymphocytes, mono- and poly-nuclear leucocytes, eosinophil granulocytes, and mast cells.
Starting in 1880, Ehrlich also studied red blood cells. He demonstrated the existence of nucleated red blood cells, which he subdivided into normoblasts, megaloblasts, microblasts and poikiloblasts; he had discovered the precursors of erythrocytes. Ehrlich thus also laid the basis for the analysis of anemias, after he had created the basis for systematizing leukemias with his investigation of white blood cells.
His duties at the Charité included analyzing patients’ blood and urine specimens. In 1881 he published a new urine test which could be used to distinguish various types of typhoid from simple cases of diarrhea. The intensity of staining made possible a disease prognosis. The pigment solution he used is known today as Ehrlich’s reagent.
Ehrlich’s great achievement, but also a source of problems during his further career, was that he had initiated a new field of study interrelating chemistry, biology and medicine. Much of his work was rejected by the medical profession, which lacked the requisite chemical knowledge. It also meant that there was no suitable professorship in sight for Ehrlich.
Serum research.
Friendship with Robert Koch.
When a student in Breslau, the pathologist Julius Friedrich Cohnheim gave Ehrlich an opportunity to conduct extensive research and also introduced him to Robert Koch, who was at the time a district physician in Wollstein, Posen Province. In his spare time, Koch had clarified the life cycle of the anthrax pathogen and contacted Ferdinand Cohn who was quickly convinced by Koch’s work and introduced him to his Breslau colleagues. From 30 April to 2 May 1876, Koch presented his investigations in Breslau, which the student Paul Ehrlich was able to attend 
On 24 March 1882 Ehrlich was present when Robert Koch, working since 1880 at the Imperial Public Health Office ("Kaiserliches Gesundheitsamt") in Berlin, presented the lecture in which he reported how he was able to identify the tuberculosis pathogen. Ehrlich later described this lecture as his “greatest experience in science.” The day after Koch’s lecture, Ehrlich had already made an improvement to Koch’s staining method, which Koch unreservedly welcomed. From this date on, the two men were bound in friendship.
In 1887 Ehrlich became an unsalaried lecturer in internal medicine ("Privatdozent für Innere Medizin") at Berlin University, and in 1890 took over the tuberculosis station at a public hospital in Berlin-Moabit at Koch’s request. This was where Koch’s hoped-for tuberculosis therapeutic agent tuberculin was under study; and Ehrlich had even injected himself with it. In the ensuing tuberculin scandal, Ehrlich tried to support Koch and stressed the value of tuberculin for diagnostic purposes. In 1891 Koch invited Ehrlich to work at the newly founded Institute of Infectious Diseases ("Institut für Infektionskrankheiten" – now the Robert Koch Institute) at "Friedrich-Wilhelms-Universität" (now Humboldt University) in Berlin. Koch was unable to give him any remuneration, but did offer him full access to laboratory staff, patients, chemicals and laboratory animals, which Ehrlich always remembered with gratitude.
First work on immunity.
Ehrlich had started his first experiments on immunization already in his private laboratory. He accustomed mice to the poisons ricin and abrin. After feeding them with small but increasing dosages of ricin he ascertained that they had become "ricin-proof." Ehrlich interpreted this as immunization and observed that it was abruptly initiated after a few days and was still in existence after several months, but mice immunized against ricin were just as sensitive to abrin as untreated animals.
This was followed by investigations on the "inheritance" of acquired immunity. It was already known that in some cases after a smallpox or syphilis infection, specific immunity was transmitted from the parents to their offspring. Ehrlich rejected inheritance in the genetic sense because the offspring of a male mouse immunized against abrin and an untreated female mouse were not immune to abrin. He concluded that the fetus was supplied with antibodies via the pulmonary circulation of the mother. This idea was supported by the fact that this “inherited immunity” decreased after a few months. In another experiment he exchanged the offspring of treated and untreated female mice. The mice which were nursed by the treated females were protected from the poison, providing the proof that antibodies can also be conveyed in breast milk.
Ehrlich also researched autoimmunity, calling it "horror autotoxicus."
Work with Behring on a diphtheria serum.
Emil Behring had worked at the Berlin Institute of Infectious Diseases until 1893 on developing an antiserum for treating diphtheria and tetanus but with inconsistent results. Koch suggested that Behring and Ehrlich cooperate on the project. This joint work was successful to the extent that Ehrlich was quickly able to increase the level of immunity of the laboratory animals based on his experience with mice. Clinical tests with diphtheria serum early in 1894 were successful and in August the chemical company Hoechst started to market Behring’s “Diphtheria Remedy synthesized by Behring-Ehrlich.” The two discoverers had originally agreed to share any profits after the Hoechst share had been subtracted. Their contract was changed several times and finally Ehrlich was eventually pressured into accepting a profit share of only eight percent. Ehrlich resented what he considered as unfair treatment, and his relationship with Behring was thereafter problematic, a situation which later escalated over the issue of the valency of tetanus serum. Ehrlich recognized that the principle of serum therapy had been developed by Behring and Kitasato. But he was of the opinion that he had been the first to develop a serum which could also be used on humans, and that his role in developing the diphtheria serum had been insufficiently acknowledged. Behring, for his part, schemed against Ehrlich at the Prussian Ministry of Culture, and from 1900 on Ehrlich refused to collaborate with him. von Behring was the sole recipient of the first Nobel Prize in Medicine, in 1901, for contributions to research on diphtheria.
The valency of serums.
Since antiserums were an entirely new type of medicine whose quality was highly variable, a government system was established to guarantee their safety and effectiveness. Beginning 1 April 1895, only government-approved serum could be sold in the German Reich. The testing station for diphtheria serum was provisionally housed at the Institute of Infectious Diseases. At the initiative of Friedrich Althoff, an Institute of Serum Research and Testing ("Institut für Serumforschung und Serumprüfung") was established in 1896 in Berlin-Steglitz, with Paul Ehrlich as director (which required him to cancel all his contracts with Hoechst). In this function and as honorary professor at Berliner University he had annual earnings of 6,000 marks, approximately the salary of a university professor. In addition to a testing department the institute also had a research department.
In order to determine the effectiveness of diphtheria antiserum, a stable concentration of diphtheria toxin was required. Ehrlich discovered that the toxin being used was perishable, in contrast to what had been assumed, which for him led to two consequences: He did not use the toxin as a standard, but instead a serum powder developed by Behring, which had to be dissolved in liquid shortly before use. The strength of a test toxin was first determined in comparison with this standard. The test toxin could then be used as a reference for testing other serums. For the test itself, toxin and serum were mixed in a ratio so that their effects just cancelled each other when injected into a guinea pig. But since there was a large margin in determining whether symptoms of illness were present, Ehrlich established an unambiguous target: the death of the animal. The mixture was to be such that the test animal would die after four days. If it died earlier, the serum was too weak and was rejected. Ehrlich claimed to have made the determination of the valency of serum as accurate as it would be with chemical titration. This again demonstrates his tendency to quantify the life sciences.
Influenced by the mayor of Frankfurt am Main, Franz Adickes, who endeavored to establish science institutions in Frankfurt in preparation of the founding of a university, Ehrlich’s institute moved to Frankfurt In 1899 and was renamed the Royal Prussian Institute of Experimental Therapy ("Königlich Preußisches Institut für Experimentelle Therapie"). The German quality-control methodology was copied by government serum institutes all over the world, and they also obtained the standard serum from Frankfurt. After diphtheria antiserum, tetanus serum and various bactericide serums for use in veterinary medicine were developed in rapid sequence. These were also evaluated at the institute, as was tuberculin and later on various vaccines. Ehrlich’s most important colleague at the institute was the Jewish doctor and biologist Julius Morgenroth.
Ehrlich’s side-chain theory.
This research inspired Ehrlich in 1897 to develop his famous side-chain theory. As he saw it, the reaction between a toxin and the operative components of a serum is a chemical reaction. He explained the toxic effect using the example of tetanus toxin.
He postulated that cell protoplasm contains special structures which have chemical "side chains" (today’s term is macromolecules) to which the toxin binds, affecting function. If the organism survives the effects of the toxin, the blocked side-chains are replaced by new ones. This regeneration can be trained, the name for this phenomenon being "immunization." If the cell produces a surplus of side chains, these might also be released into the blood as antibodies.
In the following years Ehrlich expanded his side chain theory using concepts (“amboceptors,” “receptors of the first, second and third order,” etc.) which are no longer customary. Between the antigen and the antibody he assumed there was an additional immune molecule, which he called an “additive” or a “complement.” For him, the side chain contained at least two functional groups.
For providing a theoretical basis for immunology as well as for his work on serum valency, Ehrlich was awarded the Nobel Prize for Physiology or Medicine in 1908 together with Élie Metchnikoff. Metchnikoff, who had researched the cellular branch of immunity, Phagocytosis, at the Pasteur Institute had previously sharply attacked Ehrlich.
Cancer research.
In 1901, the Prussian Ministry of Finance criticized Ehrlich for exceeding his budget and as a consequence reduced his income. In this situation Althoff arranged a contact with Georg Speyer, a Jewish philanthropist and joint owner of the bank house Lazard Speyer-Ellissen. The cancerous disease of Princess Victoria, the widow of the German Emperor Friedrich II, had received much public attention and prompted a collection among wealthy Frankfurt citizens, including Speyer, in support of cancer research. Ehrlich had also received from the German Emperor Wilhelm II a personal request to devote all his energy to cancer research. Such efforts led to the founding of a department for cancer research affiliated with the Institute of Experimental Therapy. The chemist Gustav Embden, among others, worked there. Ehrlich informed his sponsors that cancer research meant basic research, and that a cure could not be expected soon.
Among the results achieved by Ehrlich and his research colleagues was the insight that when tumors are cultivated by transplanting tumor cells, their malignancy increases from generation to generation. If the primary tumor is removed, then metastasis precipitously increases. Ehrlich applied bacteriological methods to cancer research. In analogy to vaccination, he attempted to generate immunity to cancer by injecting weakened cancer cells. Both in cancer research and chemotherapy research (see below) he introduced the methodologies of Big Science.
Chemotherapy.
In vivo staining.
In 1885 Ehrlich‘s monograph "The Need of the Organism for Oxygen," ("Das Sauerstoffbedürfnis des Organismus- Eine farbenanalytische Studie") appeared, which he also submitted as a habilitation thesis. In it he introduced the new technology of in vivo staining. One of his findings was that pigments can only be easily assimilated by living organisms if they are in granular form. He injected the dyes alizarin blue and indophenol blue into laboratory animals and established after their death that various organs had been colored to different degrees. In organs with high oxygen saturation, indophenol was retained; in organs with medium saturation, indophenol was reduced, but not alizarin blue. And in areas with low oxygen saturation, both pigments were reduced. With this work, Ehrlich also formulated the conviction which guided his research: that all life processes can be traced to processes of physical chemistry occurring in the cell.
Methylene blue.
In the course of his investigations Ehrlich came across methylene blue, which he regarded as particularly suitable for staining bacteria. Later, Robert Koch also used methylene blue as a dye in his research on the tuberculosis pathogen. In Ehrlich’s view, an added benefit was that methylene blue also stained the long appendages of nerve cells, the axons. He initiated a doctoral dissertation on the subject, but did not follow up the topic himself. It was the opinion of the neurologist Ludwig Edinger that Ehrlich had thereby opened up a major new topic in the field of neurology.
After mid-1889, when Ehrlich was unemployed, he privately continued his research on methylene blue. His work on in vivo staining gave him the idea of using it therapeutically. Since the parasite family of "Plasmodiidae" – which includes the malaria pathogen – can be stained with methylene blue, he thought it could possibly be used in the treatment of malaria. In the case of two patients so treated at the city hospital in Berlin-Moabit, their fever indeed subsided and the malaria plasmodia disappeared from their blood. Ehrlich obtained methylene blue from the company Meister Lucius & Brüning AG (later renamed Hoechst AG), which started a long collaboration with this company.
The search for a “Chemotherapia specifica”.
Before the Institute of Experimental Therapy had moved to Frankfurt, Ehrlich had already resumed work on methylene blue. After the death of Georg Speyer, his widow Franziska Speyer endowed the Georg-Speyer House in his memory which was erected next door to Ehrlich’s institute. As director of the Georg-Speyer House, Ehrlich transferred his chemotherapeutic research there. He was looking for an agent which was as effective as methylene blue, but without its side effects. His model was on the one hand the impact of quinine on malaria, and on the other hand, in analogy to serum therapy, he thought there must also be chemical pharmaceuticals which would have just as specific an effect on individual diseases. His goal was to find a "Therapia sterilisans magna," in other words a treatment that could kill all disease pathogens.
As a model for experimental therapy Ehrlich used a guinea pig disease trypanosoma and tested out various chemical substances on laboratory animals. The trypanosomes could indeed be successfully killed with the dye trypan red. Beginning in 1906, he intensively investigated atoxyl and had it tested by Robert Koch along with other arsenic compounds during Koch's sleeping sickness expedition of 1906/07. Although the name literally means “nonpoisonous,” atoxyl does cause damage, especially to the optic nerve. Ehrlich elaborated the systematic testing of chemical compounds in the sense of screening as now practiced in the pharmaceutical industry. He discovered that Compound 418 - Arsenophenylglycine - had an impressive therapeutic effect and had it tested in Africa.
With the support of his assistant Sahachiro Hata Ehrlich discovered in 1909 that Compound 606, Arsphenamine effectively combatted "spirillum" spirochaetes bacteria, one of whose subspecies causes syphilis. The compound proved to have few side effects in human trials, and the spirochetes disappeared in seven syphilis patients after this treatment.
After extensive clinical testing (all the research participants had the negative example of tuberculin in mind) the Hoechst company began to market the compound toward the end of 1910 under the name Salvarsan. This was the first agent with a specific therapeutic effect to be created on the basis of theoretical considerations. Salvarsan proved to be amazingly effective, particularly when compared with the conventional therapy of mercury salts. Manufactured by Hoechst AG, Salvarsan became the most widely prescribed drug in the world. It was the most effective drug for treating syphilis until penicillin became available in the 1940s. Salvarsan required improvement as to side effects and solubility and was replaced in 1911 with Neosalvarsan. Ehrlich's work illuminated the existence of the blood-brain barrier.
The medication triggered the so-called "Salvarsan war." On one side there was hostility on the part of those who feared a resulting moral breakdown of sexual inhibitions. Ehrlich was also accused, with clearly anti-Semitic undertones, of excessively enriching himself. In addition, Ehrlich's associate, Paul Uhlenhuth claimed priority in discovering the drug.
Because some people died during the clinical testing, Ehrlich was accused of "stopping at nothing." In 1914, one of the most prominent accusers was convicted of criminal libel at a trial for which Ehrlich was called to testify. Though Ehrlich was thereby exonerated, the ordeal threw him into a depression from which he never fully recovered.
Magic bullet.
Ehrlich reasoned that if a compound could be made that selectively targeted a disease-causing organism, then a toxin for that organism could be delivered along with the agent of selectivity. Hence, a "magic bullet" ("magische Kugel", his term for an ideal therapeutic agent) would be created that killed only the organism targeted. The concept of a "magic bullet" has to some extent been realized by the development of antibody-drug conjugates (a monoclonal antibody linked to a cytotoxic biologically active drug), as they enable cytotoxic drugs to be selectively delivered to their designated targets (e.g cancer cells).
Legacy.
In 1910, a street was named after Ehrlich in Frankfurt-Sachsenhausen. During the Third Reich, Ehrlich's achievements were ignored while Emil Adolf von Behring was stylized as the ideal Aryan scientist, and the street named after Ehrlich was given another name. Shortly after the end of the war the name Paul-Ehrlich-Strasse was reinstated, and today numerous German cities have streets named after Paul Ehrlich.
West Germany issued a postage stamp in 1954 on the 100th anniversary of the births of Paul Ehrlich (14 March 1854) and Emil von Behring (15 March 1854).
A 200 Deutsche Mark bank note featured Paul Ehrlich.
The German Paul Ehrlich Institute, the successor to the Steglitz Institute for Serum Research and Serum Testing and the Frankfurt Royal Institute for Experimental Therapy, was named in 1947 after its first director, Paul Ehrlich.
His name is also borne by many schools and pharmacies, by the Paul-Ehrlich-Gesellschaft für Chemotherapie e. V. (PEG) in Frankfurt am Main, and the Paul-Ehrlich-Klinik in Bad Homburg vor der Höhe. The Paul Ehrlich and Ludwig Darmstaedter Prize is the most distinguished German award for biomedical research. A European network of PhD studies in Medicinal Chemistry has been named after him (Paul Ehrlich MedChem Euro PhD Network).
The Anti-Defamation League awards a Paul Ehrlich–Günther K. Schwerin Human Rights Prize.
A crater of the moon was named after Paul Ehrlich in 1970.
Ehrlich’s life and work was featured in the 1940 U.S. film "Dr. Ehrlich's Magic Bullet" with Edward G. Robinson in the title role. It focused on Salvarsan (arsphenamine, "compound 606"), his cure for syphilis. Since the Nazi government was opposed to this tribute to a Jewish scientist, attempts were made to keep the film a secret in Germany.

</doc>
<doc id="23012" url="https://en.wikipedia.org/wiki?curid=23012" title="Philosophical methodology">
Philosophical methodology

Philosophical method (or philosophical methodology) is the study of how to do philosophy. A common view among philosophers is that philosophy is distinguished by the ways that philosophers follow in addressing philosophical questions. There is not just one method that philosophers use to answer philosophical questions.
Methodology process.
Systematic philosophy is a generic term that applies to philosophical methods and approaches that attempt to provide a framework in reason that can explain all questions and problems related to human life. Examples of systematic philosophers include Plato, Aristotle, Descartes, Spinoza, and Hegel. In a meaningful sense, all of western philosophy from Plato to the modern schools of theoretical metaphysics. In many ways, any attempts to formulate a philosophical method that provides the ultimate constituents of reality, a metaphysics, can be considered systematic philosophy. In modern philosophy the reaction to systematic philosophy began with Kierkegaard and continued in various forms through analytic philosophy, existentialism, hermeneutics, and deconstructionism.
Some common features of the methods that philosophers follow (and discuss when discussing philosophical method) include:
Doubt and the sense of wonder.
Plato said that "philosophy begins in wonder", a view which is echoed by Aristotle: "It was their wonder, astonishment, that first led men to philosophize and still leads them." Philosophizing may begin with some simple doubts about accepted beliefs. The initial impulse to philosophize may arise from suspicion, for example that we do not fully understand, and have not fully justified, even our most basic beliefs about the world.
Formulate questions and problems.
Another element of philosophical method is to formulate questions to be answered or problems to be solved. The working assumption is that the more clearly the question or problem is stated, the easier it is to identify critical issues.
A relatively small number of major philosophers prefer not to be quick, but to spend more time trying to get extremely clear on what the problem is all about.
Enunciate a solution.
Another approach is to enunciate a theory, or to offer a definition or analysis, which constitutes an attempt to solve a philosophical problem. Sometimes a philosophical theory by itself can be stated quite briefly. All the supporting philosophical text is offered by way of hedging, explanation, and argument.
Not all proposed solutions to philosophical problems consist of definitions or generalizations. Sometimes what is called for is a certain sort of explanation — not a causal explanation, but an explanation for example of how two different views, which seem to be contrary to one another, can be held at the same time, consistently. One can call this a philosophical explanation.
Justify the solution.
An argument is a set of statements, one of which (the conclusion), it is said or implied, follows from the others (the premises). One might think of arguments as bundles of reasons — often not just a list, but logically interconnected statements — followed by the claim they are reasons for. The reasons are the premises, the claim they support is the conclusion; together they make an argument.
Philosophical arguments and justifications are another important part of philosophical method. It is rare to find a philosopher, particularly in the Western philosophical tradition, who lacks many arguments. Philosophers are, or at least are expected to be, very good at giving arguments. They constantly demand and offer arguments for different claims they make. This therefore indicates that philosophy is a quest for arguments.
A good argument — a clear, organized, and sound statement of reasons — may ultimately cure the original doubts that motivated us to take up philosophy. If one is willing to be satisfied without any good supporting reasons, then a Western philosophical approach may not be what one actually requires.
Philosophical criticism.
In philosophy, which concerns the most fundamental aspects of the universe, the experts all disagree. It follows that another element of philosophical method, common in the work of nearly all philosophers, is philosophical criticism. It is this that makes much philosophizing a social endeavor.
Philosophers offer definitions and explanations in solution to problems; they argue for those solutions; and then other philosophers provide counter arguments, expecting to eventually come up with better solutions. This exchange and resulting revision of views is called dialectic. Dialectic (in one sense of this history-laden word) is simply philosophical conversation amongst people who do not always agree with each other about everything.
One can do this sort of harsh criticism on one's own, but others can help greatly, if important assumptions are shared with the person offering the criticisms. Others are able to think of criticisms from another perspective.
Some philosophers and ordinary people dive right in and start trying to solve the problem. They immediately start giving arguments, pro and con, on different sides of the issue. Doing philosophy is different from this. It is about questioning assumptions, digging for deeper understanding. Doing philosophy is about the journey, the process, as much as it is about the destination, the conclusion. Its method differs from other disciplines, in which the experts can agree about most of the fundamentals.
Motivation.
Method in philosophy is in some sense rooted in motivation, only by understanding why people take up philosophy can one properly understand what philosophy is. People often find themselves believing things that they do not understand. For example, about God, themselves, the natural world, human society, morality and human productions. Often, people fail to understand what it is they believe, and fail to understand the reasons they believe in what they do. Some people have questions about the meaning of their beliefs and questions about the justification (or rationality) of their beliefs. A lack of these things shows a lack of understanding, and some dislike not having this understanding.
These questions about are only the tip of the philosophical iceberg. There are many other things about this universe about which people are also fundamentally ignorant. Philosophers are in the business of investigating all sorts of those areas of ignorance.
A bewilderingly huge number of basic concepts are poorly understood. For example:
One might also consider some of the many questions about justification. Human lives are deeply informed with many basic assumptions. Different assumptions, would lead to different ways of living.

</doc>
<doc id="23013" url="https://en.wikipedia.org/wiki?curid=23013" title="Punch and Judy">
Punch and Judy

Punch and Judy is a traditional, popular, and usually very violent puppet show featuring Pulcinella (Mr. Punch) and his wife, Judy. The performance consists of a sequence of short scenes, each depicting an interaction between two characters, most typically Mr. Punch and one other character (who usually falls victim to Mr. Punch's club). It is often associated with traditional British seaside culture. The various episodes of Punch and Judy are performed in the spirit of outrageous comedy — often provoking shocked laughter — and are dominated by the anarchic clowning of Mr. Punch.
The show is performed by a single puppeteer inside the booth, known since Victorian times as a "professor" or "punchman", and assisted sometimes by a "bottler", who corrals the audience outside the booth, introduces the performance, and collects the money ("the bottle"). The bottler might also play accompanying music or sound effects on a drum or guitar, and engage in back chat with the puppets, sometimes repeating the same or the copied lines that may have been difficult for the audience to understand. In Victorian times the drum and pan pipes were the instruments of choice. Today, the audience is also encouraged to participate, calling out to the characters on the stage to warn them of danger, or clue them into what is going on behind their backs. Also nowadays, most professors work solo, since the need for a bottler became less important when busking with the show gave way to paid engagements at private parties or public events.
History.
The Punch and Judy show has roots in the 16th-century Italian commedia dell'arte. The figure of Punch derives from the Neapolitan stock character of Pulcinella, which was anglicized to "Punchinello". He is a manifestation of the Lord of Misrule and Trickster figures of deep-rooted mythologies. Punch's wife was originally called "Joan."
The figure who later became Mr. Punch made his first recorded appearance in England on 9 May 1662, which is traditionally reckoned as Punch's UK birthday. The diarist Samuel Pepys observed a marionette show featuring an early version of the Punch character in Covent Garden in London. It was performed by an Italian puppet showman, Pietro Gimonde, a.k.a. "Signor Bologna." Pepys described the event in his diary as "an Italian puppet play, that is within the rails there, which is very pretty."
In the British Punch and Judy show, Punch wears a brightly coloured jester's motley and sugarloaf hat with a tassel. He is a hunchback whose hooked nose almost meets his curved, jutting chin. He carries a stick (called a slapstick) as large as himself, which he freely uses upon most of the other characters in the show. He speaks in a distinctive squawking voice, produced by a contrivance known as a "swazzle" or "swatchel" which the professor holds in his mouth, transmitting his gleeful cackle. This gives Punch a vocal quality as though he were speaking through a kazoo. So important is Punch's signature sound that it is a matter of some controversy within Punch and Judy circles as to whether a "non-swazzled" show can be considered a true Punch and Judy Show. Other characters do not use the swazzle, so the Punchman has to switch back and forth while still holding the device in his mouth.
In the early 18th century, the marionette theatre starring Punch was at its height, with showman Martin Powell attracting sizable crowds at both his "Punch's Theatre" at Covent Garden and earlier in provincial Bath, Somerset. Powell has been credited with being "largely responsible for the form taken by the drama of Punch and Judy". In 1721, a puppet theatre that would run for decades opened in Dublin. The cross-dressing actress Charlotte Charke ran the successful but short-lived Punch's Theatre in the Old Tennis Court at St. James's, Westminster, presenting adaptations of Shakespeare as well as plays by herself, her father Colley Cibber, and her friend Henry Fielding. Fielding eventually ran his own puppet theatre under the pseudonym Madame de la Nash to avoid the censorship concomitant with the Theatre Licensing Act of 1737.
Punch was extremely popular in Paris, and, by the end of the 18th century, he was also playing in Britain's American colonies, where even George Washington bought tickets for a show. However, marionette productions presented in empty halls, the back rooms of taverns, or within large tents at England's yearly agricultural events at Bartholomew Fair and Mayfair were expensive and cumbersome to mount and transport. In the latter half of the 18th century, marionette companies began to give way to glove-puppet shows, performed from within a narrow, lightweight booth by one puppeteer, usually with an assistant, or "bottler," to gather a crowd and collect money. These shows might travel through country towns or move from corner to corner along busy London streets, giving many performances in a single day. The character of Punch adapted to the new format, going from a stringed comedian who might say outrageous things to a more aggressive glove-puppet who could do outrageous—and often violent—things to the other characters. About this time, Punch's wife's name changed from "Joan" to "Judy."
The mobile puppet booth of the late 18th- and early 19th-century Punch and Judy glove-puppet show was originally covered in checked bed ticking or whatever inexpensive cloth might come to hand. Later Victorian booths, particularly those used for Christmas parties and other indoor performances, were gaudier affairs. In the 20th century, however, red-and-white-striped puppet booths became iconic features on the beaches of many English seaside and summer holiday resorts. Such striped cloth is the most common covering today, wherever the show might be performed.
A more substantial change came over time to the show's target audience. Originally intended for adults, the show evolved into primarily a children's entertainment in the late Victorian era. Ancient members of the show's cast, like the Devil and Punch's mistress "Pretty Polly," ceased to be included when they came to be seen as inappropriate for young audiences. The term "pleased as Punch" is derived from Punch and Judy; specifically, Mr. Punch's characteristic sense of gleeful self-satisfaction.
The story changes, but some phrases remain the same for decades or even centuries: for example, Punch, after dispatching his foes each in turn, still squeaks his famous catchphrase: ""That's" the way to do it!" Modern British performances of Punch and Judy are no longer exclusively the traditional seaside children's entertainments they had become. They can now be seen at carnivals, festivals, birthday parties, and other celebratory occasions.
Characters.
The characters in a Punch and Judy show are not fixed as in a Shakespeare play, for instance. They are similar to the cast of a soap opera or a folk tale like Robin Hood. While the principal characters must appear, the lesser characters are included at the discretion of the performer. New characters may be added as the tradition evolves, and older characters dropped.
Along with Punch and Judy, the cast of characters usually includes their baby, a hungry crocodile, a clown, an officious policeman, and a prop string of sausages. The devil and the generic hangman Jack Ketch may still make their appearances but, if so, Punch will always get the better of them. The cast of a typical Punch and Judy show today will include:
Characters once regular but now occasional include:
Other characters included Boxers, Chinese Plate Spinners, topical figures, a trick puppet with an extending neck (the "Courtier") and a monkey. A live Dog Toby which sat on the playboard and performed 'with' the puppets was once a regular featured novelty routine.
Story.
Glyn Edwards (2011, p.19) has likened the story of Punch and Judy to the story of Cinderella. He points out there are parts of the story everyone knows, namely, the cruel step sisters, the invitation to the ball, the handsome prince, the fairy godmother, Cinderella's dress turning to rags at midnight, the glass slipper left behind, the prince searching for its owner and the happy ending. None of these elements can be omitted and the famous story still told. The same principle applies to Punch and Judy. Everyone knows that Punch mishandles the baby, that Punch and Judy quarrel and fight, that a policeman comes for Punch and gets a taste of his stick, that Punch has a gleeful run-in with a variety of other figures and takes his stick to them all, that eventually he faces his final foe (which might be a hangman, the devil, a crocodile, or a ghost). Edwards contends that a proper Punch and Judy show requires these elements or the audience will feel let down.
Peter Fraser writes (1970, p.8), "the drama developed as a succession of incidents which the audience could join or leave at any time, and much of the show was impromptu." This was elaborated by George Speaight (1970, p.78), who explained that the plotline "is like a story compiled in a parlour game of Consequences ... the show should, indeed, not be regarded as a story at all but a succession of encounters." Robert Leach makes it clear that "the story is a conceptual entity, not a set text: the means of telling it, therefore, are always variable." Rosalind Crone (2006, p.1058) asserts the story needed to be episodic so that passers by on the street could easily join or leave the audience during a performance.
Much emphasis is often placed on the first printed script of Punch and Judy (1827). Based on a show by travelling performer Giovanni Piccini, it was illustrated by George Cruikshank and written by John Payne Collier. While this is the only surviving script of a performance, its accuracy is questioned. The performance was stopped frequently to allow Collier and Cruikshank to write and sketch, and Collier, in the words of Speaight (1970, p.82), is someone of whom "the full list of his forgeries has not yet been reckoned, and the myths he propagated are still being repeated. (His) 'Punch and Judy' is to be warmly welcomed as the first history of puppets in England, but it is also sadly to be examined as the first experiment of a literary criminal."
The tale of Punch and Judy, as previously with Punchinello and Joan, varies from puppeteer to puppeteer and has changed over time. Nonetheless, the skeletal outline is often recognizable. It typically involves Punch behaving outrageously, again, struggling with his wife Judy and the baby and then triumphing in a series of encounters with the forces of law and order (and often the supernatural), interspersed with jokes and songs.
As performed currently in the UK a typical show will start with the arrival of Mr. Punch followed by the introduction of Judy. They may well kiss and dance before Judy requests Mr. Punch to look after the baby. Punch will fail to carry this task out appropriately. It is rare for Punch to hit his baby these days, but he may well sit on it in a failed attempt to "babysit", or drop it, or even let it go through a sausage machine. In any event Judy will return, will be outraged, will fetch a stick and the knockabout will commence. A policeman will arrive in response to the mayhem and will himself be felled by Punch's slapstick. All this is carried out at breakneck farcical speed with much involvement from a gleefully shouting audience. From here on anything goes. Joey the Clown might appear and suggest that "It's dinner time." This will lead to the production of a string of sausages, which Mr. Punch must look after, although the audience will know this really signals the arrival of a crocodile whom Mr. Punch might not see until the audience shouts out and lets him know. Punch's subsequent comic struggle with the crocodile might then leave him in need of a Doctor who will arrive and attempt to treat Punch by walloping him with a stick until Punch turns the tables on him. Punch may next pause to count his "victims" by laying puppets on the stage only for Joey the Clown to move them about behind his back in order to frustrate him. A ghost might then appear and give Mr. Punch a fright before it too is chased off with a slapstick. In less squeamish times a hangman would arrive to punish Mr. Punch, only to himself be tricked into sticking his head in the noose. "Do you do the hanging?" is a question often asked of performers. Some will include it where circumstances warrant (such as for an adult audience) but most do not. Some will choose to include it whatever the circumstances and will face down any critics. Finally the show will often end with the Devil arriving for Mr. Punch (and possibly to threaten his audience as well). Punch — in his final gleefully triumphant moment — will win his fight with the Devil and bring the show to a rousing conclusion and earn a round of applause.
While Punch and Judy, as with the tale of Robin Hood, might follow no one fixed storyline, there are nevertheless episodes common to many recorded versions. It is these set piece encounters or "routines" which are used by performers to construct their own Punch and Judy shows. A visit to a Punch and Judy Festival at Punch's "birthplace" in London's Covent Garden will reveal a whole variety of changes that are wrung by puppeteers from this basic material and although scripts have been published at different times since the early 19th century, none can be claimed as being the definitive traditional script of Punch and Judy. Each printed script reflects the era in which it was performed and the circumstances under which it was printed.
The various episodes of the show are performed in the spirit of outrageous comedy — often provoking shocked laughter — and are dominated by the anarchic clowning of Mr. Punch. While the Victorian version of the show drew on the morality of its day, the Punch & Judy College of Professors considers that the 20th- and 21st-century versions of the tale have evolved into something more akin to a primitive version of The Simpsons, in which a bizarre family is used as vehicle for grotesque visual comedy and a sideways look at contemporary society.
While censorious political correctness threatened Punch and Judy performances in the UK and other English speaking countries for a time, the show is having one of its cyclical recurrences and can now be seen not only in England, Wales, and Ireland, but also in Canada, the United States, Puerto Rico, Australia, New Zealand and South Africa. In 2001, the characters were honoured in the UK with a set of British commemorative postage stamps, issued by the Royal Mail. In a 2006 UK poll, the public voted Punch and Judy onto the list of icons of England. 
Comedy.
Despite Punch’s unapologetic murder throughout the performances, it is still a comedy. The humour is aided by a few things. Rosalind Crone (2006, p.1065) suggests that since the puppets are carved from wood, their facial expressions cannot change, but are stuck in the same exaggerated pose, which helps to deter any sense of realism and to distance the audience. The use of the swazzle also helps to create humour. It was suggested to Proschan (1981, p.546) the swazzled sound of Punch’s voice takes the cruelty out of Punch. According to Crone, a third aspect that helped make the violence humorous was that Punch’s violence toward his wife was prompted by her own violence toward him. In this aspect, he retains some of his previous hen-pecked persona. This would suggest that since Punch was merely acting violently out of self-defence, it was okay. This is a possible explanation for the humour of his violence toward his wife, and even towards others who may have somehow "had it coming." . This suggestion better explains the humour of the violence toward the baby. Other characters that had to incur the wrath of Punch varied depending on the punchman, but the most common were the foreigner, the blind man, the publican, the constable, and the devil.
Published scripts.
In 1828, the critic John Payne Collier published a Punch and Judy script under the title "The Tragical Comedy or Comical Tragedy of Punch and Judy". The script was illustrated by the well-known caricaturist George Cruikshank. Collier said his script was based on the version performed by the "professor" Giovanni Piccini in the early 19th century, and Piccini himself had begun performing in the streets of London in the late 18th century. The Collier/Cruickshank "Punch" has been republished in facsimile several times. Collier's later career as a literary forger has cast some doubt on the authenticity of the script, which is rather literary in style and may well have been tidied up from the rough-and-tumble street-theatre original. Punch is primarily an oral tradition, adapted by a succession of exponents from live performances rather than authentic scripts, and in constant evolution. A transcript of a typical Punch and Judy show in London of the 1840s can be found in Henry Mayhew's "London Labour and the London Poor".
Origin of the characters.
In 1996 David Bryson (a British scientist) in the "European Journal of Internal Medicine" suggested that Punch's rages and facial features may have been copied from someone suffering from acromegaly. In late 2015 researchers at the University of Zurich including Frank Rühli suggested that Punch's hunchback and bad temper may have been copied from someone suffering from tuberculous spondylitis.

</doc>
<doc id="23014" url="https://en.wikipedia.org/wiki?curid=23014" title="Poker">
Poker

Poker is a family of gambling card games involving betting and individual play, whereby the winner is determined by the ranks and combinations of players' cards, some of which remain hidden until the end of the game. Poker games vary in the number of cards dealt, the number of shared or "community" cards, and the number of cards that remain hidden. Betting procedures vary widely among dozens of different poker game variants.
In most modern poker games, the first round of betting begins with one or more of the players making some form of a forced bet (the "blind" and/or "ante"). In standard poker, each player bets according to the rank he believes his hand is worth as compared to the other players. The action then proceeds clockwise as each player in turn must either match, or "call", the maximum previous bet or fold, losing the amount bet so far and all further interest in the hand. A player who matches a bet may also "raise", or increase the bet. The betting round ends when all players have either matched the last bet or folded. If all but one player folds on any round, the remaining player collects the pot without being required to reveal their hand. If more than one player remains in contention after the final betting round, the hands are revealed, and the player with the winning hand takes the pot.
With the exception of initial forced bets, money is only placed into the pot voluntarily by a player who either believes the bet has positive expected value or who is trying to bluff other players for various strategic reasons. Thus, while the outcome of any particular hand significantly involves chance, the long-run expectations of the players are determined by their actions chosen on the basis of probability, psychology, and game theory.
Poker has gained in popularity since the beginning of the twentieth century and has gone from being primarily a recreational activity confined to small groups of enthusiasts to a widely popular activity, both for participants and spectators, including online, with many professional players and multimillion-dollar tournament prizes.
History.
English actor Joseph Cowell reported in his memoirs that the game was played in New Orleans, Louisiana in 1829, with a deck of 20 cards, and four players betting on which player's hand was the most valuable. Jonathan H. Green's book, "An Exposure of the Arts and Miseries of Gambling" (G. B. Zieber, Philadelphia, 1843), described the spread of the game from there to the rest of the country by Mississippi riverboats, on which gambling was a common pastime. As it spread north along the Mississippi River and to the West during the gold rush, it is thought to have become a part of the frontier pioneer ethos.
Soon after this spread, the full 52-card French deck was used and the flush was introduced. The draw was added prior to 1850 (when it was first mentioned in print in a handbook of games). During the American Civil War, many additions were made including stud poker (specifically five-card stud) and the straight. Further American developments followed, such as the wild card (around 1875), lowball and split-pot poker (around 1900), and community card poker games (around 1925).
Modern tournament play became popular in American casinos after the World Series of Poker (WSOP) began in 1970. Among the champions from these early WSOP tournaments were Johnny Moss, Amarillo Slim, Bobby Baldwin, Doyle Brunson, and Puggy Pearson. Later in the 1970s, the first serious poker strategy books appeared, including "Super/System" by Doyle Brunson and "Caro's Book of Poker Tells" by Mike Caro , followed later by "The Theory of Poker" by David Sklansky. By the 1980s, poker was being depicted in popular culture as a commonplace recreational activity. For example, it was featured in at least 10 episodes of "" as a weekly event of the senior staff of the fictional ship's crew. In the 1990s, poker and casino gambling began to expand across the United States.
Poker's popularity experienced an unprecedented spike at the beginning of the 21st century, largely because of the introduction of online poker and hole-card cameras, which turned the game into a spectator sport. Not only could viewers now follow the action and drama of the game on television, but they could also play the game in the comfort of their own homes. In the 2003 World Series of Poker, accountant Chris Moneymaker, who had never played professional poker, won the main event. He won his seat into the $10,000 tournament via a $40 multi-table satellite and turned his $40 into $2.5 million. This helped popularize the game further, which became known as the "Moneymaker effect".
Following the surge in popularity, new poker tours soon emerged, including the World Poker Tour and European Poker Tour, both televised, and the latter sponsored by online poker company PokerStars. Subsequent tours have since been created by PokerStars, such as Latin American Poker Tour and Asia Pacific Poker Tour, as well as other national tours.
In 2009 the International Federation of Poker was founded in Lausanne, Switzerland, becoming the official governing body for poker and promoting the game as a mind sport. In 2011 it announced plans for two new events: The Nations Cup, a duplicate poker team event, to be staged on the London Eye on the banks of the River Thames and “The Table”, the invitation-only IFP World Championship, featuring roughly 130 of the world’s best poker players, in an event to find the 2011 official "World Champion".
Gameplay.
In casual play, the right to deal a hand typically rotates among the players and is marked by a token called a "dealer button" (or "buck"). In a casino, a house dealer handles the cards for each hand, but the button (typically a white plastic disk) is rotated clockwise among the players to indicate a nominal dealer to determine the order of betting. The cards are dealt clockwise around the poker table, one at a time.
One or more players are usually required to make forced bets, usually either an "ante" or a "blind bet" (sometimes both). The dealer shuffles the cards, the player on the chair to his right cuts, and the dealer deals the appropriate number of cards to the players one at a time, beginning with the player to his left. Cards may be dealt either face-up or face-down, depending on the variant of poker being played. After the initial deal, the first of what may be several betting rounds begins. Between rounds, the players' hands develop in some way, often by being dealt additional cards or replacing cards previously dealt. At the end of each round, all bets are gathered into the central pot.
At any time during a betting round, if one player bets, no opponents choose to "call" (match) the bet, and all opponents instead "fold", the hand ends immediately, the bettor is awarded the pot, no cards are required to be shown, and the next hand begins. This is what makes bluffing possible. Bluffing is a primary feature of poker, one that distinguishes it from other vying games and from other games that make use of poker hand rankings.
At the end of the last betting round, if more than one player remains, there is a showdown, in which the players reveal their previously hidden cards and evaluate their hands. The player with the best hand according to the poker variant being played wins the pot. A poker hand comprises five cards; in variants where a player has more than five cards, the best five cards play.
Variants.
Poker has many variations, all following a similar pattern of play and generally using the same hand ranking hierarchy. There are four main families of variants, largely grouped by the protocol of card-dealing and betting:
Other games that use poker hand rankings may likewise be referred to as "poker". Video poker is a single-player video game that functions much like a slot machine; most video poker machines play draw poker, where the player bets, a hand is dealt, and the player can discard and replace cards. Payout is dependent on the hand resulting after the draw and the player's initial bet.
Strip poker is a traditional poker variation where players remove clothing when they lose bets. Since it depends only on the basic mechanic of betting in rounds, strip poker can be played with any form of poker; however, it is usually based on simple variants with few betting rounds, like five card draw.
Another game with the "poker" name, but with a vastly different mode of play, is called "Acey-Deucey" or "Red Dog" poker. This game is more similar to Blackjack in its layout and betting; each player bets against the house, and then is dealt two cards. For the player to win, the third card dealt (after an opportunity to raise the bet) must have a value in-between the first two. Payout is based on the odds that this is possible, based on the difference in values of the first two cards. Other poker-like games played at casinos against the house include three card poker and pai gow poker.
Computer programs.
In a January 2015 article published in Science, a group of researchers mostly from the University of Alberta announced that they "essentially weakly solved" heads-up limit "Texas hold 'em" with their development of their Cepheus poker bot. The authors claimed that Cepheus, in 1000 games, would lose at most 1 big blind on average against its worst-case opponent, a strategy that is so "close to optimal" that "it can't be beaten with statistical significance within a lifetime of human poker playing".
Less autonomous poker programs exist whose primary purpose is not to play poker by themselves, but is instead to calculate the odds of certain hand outcomes. For example, one might input a hand which contains three 7s and two unrelated low cards, the program in question would then return that holding just the 7s results in a 10.37% chance of an improved hand being drawn.

</doc>
<doc id="23015" url="https://en.wikipedia.org/wiki?curid=23015" title="Programming language">
Programming language

A programming language is a formal constructed language designed to communicate instructions to a machine, particularly a computer. Programming languages can be used to create programs to control the behavior of a machine or to express algorithms.
The earliest programming languages preceded the invention of the digital computer and were used to direct the behavior of machines such as Jacquard looms and player pianos. Thousands of different programming languages have been created, mainly in the computer field, and many more still are being created every year. Many programming languages require computation to be specified in an imperative form (i.e., as a sequence of operations to perform), while other languages use other forms of program specification such as the declarative form (i.e. the desired result is specified, not how to achieve it).
The description of a programming language is usually split into the two components of syntax (form) and semantics (meaning). Some languages are defined by a specification document (for example, the C programming language is specified by an ISO Standard), while other languages (such as Perl) have a dominant implementation that is treated as a reference.
Definitions.
A programming language is a notation for writing programs, which are specifications of a computation or algorithm. Some, but not all, authors restrict the term "programming language" to those languages that can express "all" possible algorithms. Traits often considered important for what constitutes a programming language include:
Markup languages like XML, HTML or troff, which define structured data, are not usually considered programming languages. Programming languages may, however, share the syntax with markup languages if a computational semantics is defined. XSLT, for example, is a Turing complete XML dialect. Moreover, LaTeX, which is mostly used for structuring documents, also contains a Turing complete subset.
The term "computer language" is sometimes used interchangeably with programming language. However, the usage of both terms varies among authors, including the exact scope of each. One usage describes programming languages as a subset of computer languages. In this vein, languages used in computing that have a different goal than expressing computer programs are generically designated computer languages. For instance, markup languages are sometimes referred to as computer languages to emphasize that they are not meant to be used for programming.
Another usage regards programming languages as theoretical constructs for programming abstract machines, and computer languages as the subset thereof that runs on physical computers, which have finite hardware resources. John C. Reynolds emphasizes that formal specification languages are just as much programming languages as are the languages intended for execution. He also argues that textual and even graphical input formats that affect the behavior of a computer are programming languages, despite the fact they are commonly not Turing-complete, and remarks that ignorance of programming language concepts is the reason for many flaws in input formats.
History.
Early developments.
The first programming languages designed to communicate instructions to a computer were written in the 1950s. An early high-level programming language to be designed for a computer was Plankalkül, developed for the German Z3 by Konrad Zuse between 1943 and 1945. However, it was not implemented until 1998 and 2000.
John Mauchly's Short Code, proposed in 1949, was one of the first high-level languages ever developed for an electronic computer. Unlike machine code, Short Code statements represented mathematical expressions in understandable form. However, the program had to be translated into machine code every time it ran, making the process much slower than running the equivalent machine code.
At the University of Manchester, Alick Glennie developed Autocode in the early 1950s. A programming language, it used a compiler to automatically convert the language into machine code. The first code and compiler was developed in 1952 for the Mark 1 computer at the University of Manchester and is considered to be the first compiled high-level programming language.
The second autocode was developed for the Mark 1 by R. A. Brooker in 1954 and was called the "Mark 1 Autocode". Brooker also developed an autocode for the Ferranti Mercury in the 1950s in conjunction with the University of Manchester. The version for the EDSAC 2 was devised by D. F. Hartley of University of Cambridge Mathematical Laboratory in 1961. Known as EDSAC 2 Autocode, it was a straight development from Mercury Autocode adapted for local circumstances, and was noted for its object code optimisation and source-language diagnostics which were advanced for the time. A contemporary but separate thread of development, Atlas Autocode was developed for the University of Manchester Atlas 1 machine.
Another early programming language was devised by Grace Hopper in the US, called FLOW-MATIC. It was developed for the UNIVAC I at Remington Rand during the period from 1955 until 1959. Hopper found that business data processing customers were uncomfortable with mathematical notation, and in early 1955, she and her team wrote a specification for an English programming language and implemented a prototype. The FLOW-MATIC compiler became publicly available in early 1958 and was substantially complete in 1959. Flow-Matic was a major influence in the design of COBOL, since only it and its direct descendent AIMACO were in actual use at the time. The language Fortran was developed at IBM in the mid '50s, and became the first widely used high-level general purpose programming language.
Refinement.
The period from the 1960s to the late 1970s brought the development of the major language paradigms now in use:
Each of these languages spawned descendants, and most modern programming languages count at least one of them in their ancestry.
The 1960s and 1970s also saw considerable debate over the merits of "structured programming", and whether programming languages should be designed to support it. Edsger Dijkstra, in a famous 1968 letter published in the Communications of the ACM, argued that GOTO statements should be eliminated from all "higher level" programming languages.
Consolidation and growth.
The 1980s were years of relative consolidation. C++ combined object-oriented and systems programming. The United States government standardized Ada, a systems programming language derived from Pascal and intended for use by defense contractors. In Japan and elsewhere, vast sums were spent investigating so-called "fifth generation" languages that incorporated logic programming constructs. The functional languages community moved to standardize ML and Lisp. Rather than inventing new paradigms, all of these movements elaborated upon the ideas invented in the previous decade.
One important trend in language design for programming large-scale systems during the 1980s was an increased focus on the use of "modules", or large-scale organizational units of code. Modula-2, Ada, and ML all developed notable module systems in the 1980s, which were often wedded to generic programming constructs.
The rapid growth of the Internet in the mid-1990s created opportunities for new languages. Perl, originally a Unix scripting tool first released in 1987, became common in dynamic websites. Java came to be used for server-side programming, and bytecode virtual machines became popular again in commercial settings with their promise of "Write once, run anywhere" (UCSD Pascal had been popular for a time in the early 1980s). These developments were not fundamentally novel, rather they were refinements to existing languages and paradigms, and largely based on the C family of programming languages.
Programming language evolution continues, in both industry and research. Current directions include security and reliability verification, new kinds of modularity (mixins, delegates, aspects), and database integration such as Microsoft's LINQ.
The 4GLs are examples of languages which are domain-specific, such as SQL, which manipulates and returns sets of data rather than the scalar values which are canonical to most programming languages. Perl, for example, with its "here document" can hold multiple 4GL programs, as well as multiple JavaScript programs, in part of its own perl code and use variable interpolation in the "here document" to support multi-language programming.
Elements.
All programming languages have some primitive building blocks for the description of data and the processes or transformations applied to them (like the addition of two numbers or the selection of an item from a collection). These primitives are defined by syntactic and semantic rules which describe their structure and meaning respectively.
Syntax.
A programming language's surface form is known as its syntax. Most programming languages are purely textual; they use sequences of text including words, numbers, and punctuation, much like written natural languages. On the other hand, there are some programming languages which are more graphical in nature, using visual relationships between symbols to specify a program.
The syntax of a language describes the possible combinations of symbols that form a syntactically correct program. The meaning given to a combination of symbols is handled by semantics (either formal or hard-coded in a reference implementation). Since most languages are textual, this article discusses textual syntax.
Programming language syntax is usually defined using a combination of regular expressions (for lexical structure) and Backus–Naur Form (for grammatical structure). Below is a simple grammar, based on Lisp:
This grammar specifies the following:
The following are examples of well-formed token sequences in this grammar: codice_1, codice_2 and codice_3.
Not all syntactically correct programs are semantically correct. Many syntactically correct programs are nonetheless ill-formed, per the language's rules; and may (depending on the language specification and the soundness of the implementation) result in an error on translation or execution. In some cases, such programs may exhibit undefined behavior. Even when a program is well-defined within a language, it may still have a meaning that is not intended by the person who wrote it.
Using natural language as an example, it may not be possible to assign a meaning to a grammatically correct sentence or the sentence may be false:
The following C language fragment is syntactically correct, but performs operations that are not semantically defined (the operation *p » 4 has no meaning for a value having a complex type and p->im is not defined because the value of p is the null pointer):
If the type declaration on the first line were omitted, the program would trigger an error on compilation, as the variable "p" would not be defined. But the program would still be syntactically correct, since type declarations provide only semantic information.
The grammar needed to specify a programming language can be classified by its position in the Chomsky hierarchy. The syntax of most programming languages can be specified using a Type-2 grammar, i.e., they are context-free grammars. Some languages, including Perl and Lisp, contain constructs that allow execution during the parsing phase. Languages that have constructs that allow the programmer to alter the behavior of the parser make syntax analysis an undecidable problem, and generally blur the distinction between parsing and execution. In contrast to Lisp's macro system and Perl's codice_4 blocks, which may contain general computations, C macros are merely string replacements, and do not require code execution.
Semantics.
The term Semantics refers to the meaning of languages, as opposed to their form (syntax).
Static semantics.
The static semantics defines restrictions on the structure of valid texts that are hard or impossible to express in standard syntactic formalisms. For compiled languages, static semantics essentially include those semantic rules that can be checked at compile time. Examples include checking that every identifier is declared before it is used (in languages that require such declarations) or that the labels on the arms of a case statement are distinct. Many important restrictions of this type, like checking that identifiers are used in the appropriate context (e.g. not adding an integer to a function name), or that subroutine calls have the appropriate number and type of arguments, can be enforced by defining them as rules in a logic called a type system. Other forms of static analyses like data flow analysis may also be part of static semantics. Newer programming languages like Java and C# have definite assignment analysis, a form of data flow analysis, as part of their static semantics.
Dynamic semantics.
Once data has been specified, the machine must be instructed to perform operations on the data. For example, the semantics may define the strategy by which expressions are evaluated to values, or the manner in which control structures conditionally execute statements. The "dynamic semantics" (also known as "execution semantics") of a language defines how and when the various constructs of a language should produce a program behavior. There are many ways of defining execution semantics. Natural language is often used to specify the execution semantics of languages commonly used in practice. A significant amount of academic research went into formal semantics of programming languages, which allow execution semantics to be specified in a formal manner. Results from this field of research have seen limited application to programming language design and implementation outside academia.
Type system.
A type system defines how a programming language classifies values and expressions into "types", how it can manipulate those types and how they interact. The goal of a type system is to verify and usually enforce a certain level of correctness in programs written in that language by detecting certain incorrect operations. Any decidable type system involves a trade-off: while it rejects many incorrect programs, it can also prohibit some correct, albeit unusual programs. In order to bypass this downside, a number of languages have "type loopholes", usually unchecked casts that may be used by the programmer to explicitly allow a normally disallowed operation between different types. In most typed languages, the type system is used only to type check programs, but a number of languages, usually functional ones, infer types, relieving the programmer from the need to write type annotations. The formal design and study of type systems is known as "type theory".
Typed versus untyped languages.
A language is "typed" if the specification of every operation defines types of data to which the operation is applicable, with the implication that it is not applicable to other types. For example, the data represented by codice_5 is a string, and in many programming languages dividing a number by a string has no meaning and will be rejected by the compilers. The invalid operation may be detected when the program is compiled ("static" type checking) and will be rejected by the compiler with a compilation error message, or it may be detected when the program is run ("dynamic" type checking), resulting in a run-time exception. Many languages allow a function called an exception handler to be written to handle this exception and, for example, always return "-1" as the result.
A special case of typed languages are the "single-type" languages. These are often scripting or markup languages, such as REXX or SGML, and have only one data type—most commonly character strings which are used for both symbolic and numeric data.
In contrast, an "untyped language", such as most assembly languages, allows any operation to be performed on any data, which are generally considered to be sequences of bits of various lengths. High-level languages which are untyped include BCPL, Tcl, and some varieties of Forth.
In practice, while few languages are considered typed from the point of view of type theory (verifying or rejecting "all" operations), most modern languages offer a degree of typing. Many production languages provide means to bypass or subvert the type system, trading type-safety for finer control over the program's execution (see casting).
Static versus dynamic typing.
In "static typing", all expressions have their types determined prior to when the program is executed, typically at compile-time. For example, 1 and (2+2) are integer expressions; they cannot be passed to a function that expects a string, or stored in a variable that is defined to hold dates.
Statically typed languages can be either "manifestly typed" or "type-inferred". In the first case, the programmer must explicitly write types at certain textual positions (for example, at variable declarations). In the second case, the compiler "infers" the types of expressions and declarations based on context. Most mainstream statically typed languages, such as C++, C# and Java, are manifestly typed. Complete type inference has traditionally been associated with less mainstream languages, such as Haskell and ML. However, many manifestly typed languages support partial type inference; for example, Java and C# both infer types in certain limited cases. Additionally, some programming languages allow for some types to be automatically converted to other types; for example, an int can be used where the program expects a float.
"Dynamic typing", also called "latent typing", determines the type-safety of operations at run time; in other words, types are associated with "run-time values" rather than "textual expressions". As with type-inferred languages, dynamically typed languages do not require the programmer to write explicit type annotations on expressions. Among other things, this may permit a single variable to refer to values of different types at different points in the program execution. However, type errors cannot be automatically detected until a piece of code is actually executed, potentially making debugging more difficult. Lisp, Perl, Python, JavaScript, and Ruby are dynamically typed.
Weak and strong typing.
"Weak typing" allows a value of one type to be treated as another, for example treating a string as a number. This can occasionally be useful, but it can also allow some kinds of program faults to go undetected at compile time and even at run time.
"Strong typing" prevents the above. An attempt to perform an operation on the wrong type of value raises an error. Strongly typed languages are often termed "type-safe" or "safe".
An alternative definition for "weakly typed" refers to languages, such as Perl and JavaScript, which permit a large number of implicit type conversions. In JavaScript, for example, the expression codice_6 implicitly converts codice_7 to a number, and this conversion succeeds even if codice_7 is codice_9, codice_10, an codice_11, or a string of letters. Such implicit conversions are often useful, but they can mask programming errors.
"Strong" and "static" are now generally considered orthogonal concepts, but usage in the literature differs. Some use the term "strongly typed" to mean "strongly, statically typed", or, even more confusingly, to mean simply "statically typed". Thus C has been called both strongly typed and weakly, statically typed.
It may seem odd to some professional programmers that C could be "weakly, statically typed". However, notice that the use of the generic pointer, the void* pointer, does allow for casting of pointers to other pointers without needing to do an explicit cast. This is extremely similar to somehow casting an array of bytes to any kind of datatype in C without using an explicit cast, such as codice_12 or codice_13.
Standard library and run-time system.
Most programming languages have an associated core library (sometimes known as the 'standard library', especially if it is included as part of the published language standard), which is conventionally made available by all implementations of the language. Core libraries typically include definitions for commonly used algorithms, data structures, and mechanisms for input and output.
The line between a language and its core library differs from language to language. In some cases, the language designers may treat the library as a separate entity from the language. However, a language's core library is often treated as part of the language by its users, and some language specifications even require that this library be made available in all implementations. Indeed, some languages are designed so that the meanings of certain syntactic constructs cannot even be described without referring to the core library. For example, in Java, a string literal is defined as an instance of the java.lang.String class; similarly, in Smalltalk, an anonymous function expression (a "block") constructs an instance of the library's BlockContext class. Conversely, Scheme contains multiple coherent subsets that suffice to construct the rest of the language as library macros, and so the language designers do not even bother to say which portions of the language must be implemented as language constructs, and which must be implemented as parts of a library.
Design and implementation.
Programming languages share properties with natural languages related to their purpose as vehicles for communication, having a syntactic form separate from its semantics, and showing "language families" of related languages branching one from another. But as artificial constructs, they also differ in fundamental ways from languages that have evolved through usage. A significant difference is that a programming language can be fully described and studied in its entirety, since it has a precise and finite definition. By contrast, natural languages have changing meanings given by their users in different communities. While constructed languages are also artificial languages designed from the ground up with a specific purpose, they lack the precise and complete semantic definition that a programming language has.
Many programming languages have been designed from scratch, altered to meet new needs, and combined with other languages. Many have eventually fallen into disuse. Although there have been attempts to design one "universal" programming language that serves all purposes, all of them have failed to be generally accepted as filling this role. The need for diverse programming languages arises from the diversity of contexts in which languages are used:
One common trend in the development of programming languages has been to add more ability to solve problems using a higher level of abstraction. The earliest programming languages were tied very closely to the underlying hardware of the computer. As new programming languages have developed, features have been added that let programmers express ideas that are more remote from simple translation into underlying hardware instructions. Because programmers are less tied to the complexity of the computer, their programs can do more computing with less effort from the programmer. This lets them write more functionality per time unit.
Natural language programming has been proposed as a way to eliminate the need for a specialized language for programming. However, this goal remains distant and its benefits are open to debate. Edsger W. Dijkstra took the position that the use of a formal language is essential to prevent the introduction of meaningless constructs, and dismissed natural language programming as "foolish". Alan Perlis was similarly dismissive of the idea. Hybrid approaches have been taken in Structured English and SQL.
A language's designers and users must construct a number of artifacts that govern and enable the practice of programming. The most important of these artifacts are the language "specification" and "implementation".
Specification.
The specification of a programming language is an artifact that the language users and the implementors can use to agree upon whether a piece of source code is a valid program in that language, and if so what its behavior shall be.
A programming language specification can take several forms, including the following:
Implementation.
An "implementation" of a programming language provides a way to write programs in that language and execute them on one or more configurations of hardware and software. There are, broadly, two approaches to programming language implementation: "compilation" and "interpretation". It is generally possible to implement a language using either technique.
The output of a compiler may be executed by hardware or a program called an interpreter. In some implementations that make use of the interpreter approach there is no distinct boundary between compiling and interpreting. For instance, some implementations of BASIC compile and then execute the source a line at a time.
Programs that are executed directly on the hardware usually run several orders of magnitude faster than those that are interpreted in software.
One technique for improving the performance of interpreted programs is just-in-time compilation. Here the virtual machine, just before execution, translates the blocks of bytecode which are going to be used to machine code, for direct execution on the hardware.
Proprietary languages.
Although most of the most commonly used programming languages have fully open specifications and implementations, many programming languages exist only as proprietary programming languages with the implementation available only from a single vendor, which may claim that such a proprietary language is their intellectual property. Proprietary programming languages are commonly domain specific languages or internal scripting languages for a single product; some proprietary languages are used only internally within a vendor, while others are available to external users.
Some programming languages exist on the border between proprietary and open; for example, Oracle Corporation asserts proprietary rights to some aspects of the Java programming language, and Microsoft's C# programming language, which has open implementations of most parts of the system, also has Common Language Runtime (CLR) as a closed environment.
Many proprietary languages are widely used, in spite of their proprietary nature; examples include MATLAB and VBScript. Some languages may make the transition from closed to open; for example, Erlang was originally an Ericsson's internal programming language.
Usage.
Thousands of different programming languages have been created, mainly in the computing field.
Software is commonly built with 5 programming languages or more.
Programming languages differ from most other forms of human expression in that they require a greater degree of precision and completeness. When using a natural language to communicate with other people, human authors and speakers can be ambiguous and make small errors, and still expect their intent to be understood. However, figuratively speaking, computers "do exactly what they are told to do", and cannot "understand" what code the programmer intended to write. The combination of the language definition, a program, and the program's inputs must fully specify the external behavior that occurs when the program is executed, within the domain of control of that program. On the other hand, ideas about an algorithm can be communicated to humans without the precision required for execution by using pseudocode, which interleaves natural language with code written in a programming language.
A programming language provides a structured mechanism for defining pieces of data, and the operations or transformations that may be carried out automatically on that data. A programmer uses the abstractions present in the language to represent the concepts involved in a computation. These concepts are represented as a collection of the simplest elements available (called primitives). "Programming" is the process by which programmers combine these primitives to compose new programs, or adapt existing ones to new uses or a changing environment.
Programs for a computer might be executed in a batch process without human interaction, or a user might type commands in an interactive session of an interpreter. In this case the "commands" are simply programs, whose execution is chained together. When a language can run its commands through an interpreter (such as a Unix shell or other command-line interface), without compiling, it is called a scripting language.
Measuring language usage.
It is difficult to determine which programming languages are most widely used, and what usage means varies by context. One language may occupy the greater number of programmer hours, a different one have more lines of code, and a third may consume the most CPU time. Some languages are very popular for particular kinds of applications. For example, COBOL is still strong in the corporate data center, often on large mainframes; Fortran in scientific and engineering applications; Ada in aerospace, transportation, military, real-time and embedded applications; and C in embedded applications and operating systems. Other languages are regularly used to write many different kinds of applications.
Various methods of measuring language popularity, each subject to a different bias over what is measured, have been proposed:
Combining and averaging information from various internet sites, langpop.com claims that in 2013 the ten most popular programming languages are (in descending order by overall popularity): C, Java, PHP, JavaScript, C++, Python, Shell, Ruby, Objective-C and C#.
Taxonomies.
There is no overarching classification scheme for programming languages. A given programming language does not usually have a single ancestor language. Languages commonly arise by combining the elements of several predecessor languages with new ideas in circulation at the time. Ideas that originate in one language will diffuse throughout a family of related languages, and then leap suddenly across familial gaps to appear in an entirely different family.
The task is further complicated by the fact that languages can be classified along multiple axes. For example, Java is both an object-oriented language (because it encourages object-oriented organization) and a concurrent language (because it contains built-in constructs for running multiple threads in parallel). Python is an object-oriented scripting language.
In broad strokes, programming languages divide into "programming paradigms" and a classification by "intended domain of use," with general-purpose programming languages distinguished from domain-specific programming languages. Traditionally, programming languages have been regarded as describing computation in terms of imperative sentences, i.e. issuing commands. These are generally called imperative programming languages. A great deal of research in programming languages has been aimed at blurring the distinction between a program as a set of instructions and a program as an assertion about the desired answer, which is the main feature of declarative programming. More refined paradigms include procedural programming, object-oriented programming, functional programming, and logic programming; some languages are hybrids of paradigms or multi-paradigmatic. An assembly language is not so much a paradigm as a direct model of an underlying machine architecture. By purpose, programming languages might be considered general purpose, system programming languages, scripting languages, domain-specific languages, or concurrent/distributed languages (or a combination of these). Some general purpose languages were designed largely with educational goals.
A programming language may also be classified by factors unrelated to programming paradigm. For instance, most programming languages use English language keywords, while a minority do not. Other languages may be classified as being deliberately esoteric or not.

</doc>
<doc id="23019" url="https://en.wikipedia.org/wiki?curid=23019" title="Economy of Poland">
Economy of Poland

The Economy of Poland is the second largest economy in Central Europe, sixth-largest in the EU and the largest among the ex-communist members of the European Union. Before the late-2000s recession its economy grew a yearly growth rate of over 6.0% . According to the Central Statistical Office of Poland, in 2010 the Polish economic growth rate was 3.9%, which was one of the best results in Europe. In Q1 2014 its economy grew by 3.4% and is expected to grow by 3.4% in 2014, 3.7% in 2015 and 3.9% in 2016.
History.
Before 1989.
This article discusses the economy of the current Poland, post-1989. For historical overview of past Polish economies, see:
1990-2009.
The Polish state has steadfastly pursued a policy of economic liberalization throughout the 1990s, with positive results for economic growth but negative results for some sectors of the population. The privatization of small and medium state-owned companies and a liberal law on establishing new firms has encouraged the development of the private business sector, which has been the main drive for Poland's economic growth. The agricultural sector remains handicapped by structural problems, surplus labor, inefficient small farms, and a lack of investment. Restructuring and privatization of "sensitive sectors" (e.g. coal), has also been slow, but recent foreign investments in energy and steel have begun to turn the tide. Recent reforms in health care, education, the pension system, and state administration have resulted in larger than expected fiscal pressures. Improving this account deficit and tightening monetary policy, with focus on inflation, are priorities for the Polish government. Further progress in public finance depends mainly on the reduction of public sector employment, and an overhaul of the tax code to incorporate farmers, who currently pay significantly lower taxes than other people with similar income levels. Despite some continued systemic problems, Poland has made great economic progress over the last decade, and now is ranked 20th worldwide in terms of GDP. The largest component of its economy is the service sector. With the economic reform of 1989 the Polish external debt increased from $42.2 billion in 1989 to $365.2 billion in 2014
Since the 2009 financial crisis.
Since the global recession of 2009, Poland's GDP continued to grow. In 2009, at the high point of the crisis, the GDP for the European Union as a whole dropped by 4.5% while Polish GDP increased by 1.6%. As of November 2013, the size of EU's economy remains below the pre-crisis level, while Poland's economy increased by a cumulative 16%. The major reasons for its success appear to be a large internal market (in terms of population is sixth in EU) and a business friendly political climate. The economic reforms implemented after the fall of communism in the 1990s have also played a role; between 1989 and 2007 Poland's economy grew by 177%, faster than other countries in Eastern and Central Europe, while at the same time millions were left without work.
Another factor which allowed the Polish economy to avoid the financial crisis was its low level of public debt, at about 50% of GDP, below the EU average (around 90%). Strict financial regulation also helped to keep household and corporate debt low. Furthermore, unlike many other European countries, Poland did not implement austerity but rather boosted domestic demand through Keynesian policy of tax cut, and foreign-assistance funded public spending. An additional reason for its success lay in the fact that Poland is outside the Euro zone. The depreciation of the currency, the złoty, increased international competitiveness and boosted the value of Poland's exports (in złotys).
However, the economic fluctuations of the business cycle did have an impact on Poland's unemployment rate, which by early 2013 reached almost 11%. This level was still below European average and has begun falling subsequently. As of February 2014, Poland's unemployment rate stood at 14% according to Polish Central Statistics Office and 9.7% according to Eurostat which stated European average is 10.6% (and 11.9% for the EU18). Unemployment remains a permanent and one of the most important problems of Poland and has been growing since years and Polish unemployment remains one of the highest in EU Warsaw Business Journal remarked that the fact that despite the growing GDP Polish unemployment remained "stubbornly high" casts shadow over claims of economic success; in 2012 the unemployment rate in Poland was 13.3 percent,higher than it was in 1991 (12.2 )after capitalist reforms were initiated Entrenched structural unemployment is especially problematic in Poland, with 46% of the jobless being long term unemployed Lack of employment opportunities, low wages and poverty have led to flight of over 2 million Poles to Western EU in search of better life since 2004; with most being in the young demographic and not intending to return to Poland, this is expected to cause long term problems in Polish economy
According to professor Gavin Rae from Kozminski University most of Polish recent economic growth was based on ability to leverage funding from EU
Labour market and wages.
Despite Polish productivity rising to 2/3 of those in the West, the wages in Poland remained low, at 1/3 of that in the West. This has contributed to the flight of Polish population from the country.
Poland has the highest number of workers in the EU employed on so-called 'junk contracts', i.e. non-fixed, temporary contracts. While the average share in the EU is less than 15%, in Poland it exceeds 27%. This number has increased by more than five times since 2000, when only 5% of workers were employed on 'junk contracts', and particularly affects the young population, among whom over 60% are employed on such terms. This problem is exacerbated by the large number of people (19%) forced into self-employment. Employers are not required to pay social insurance for these workers, meaning that they will receive the lowest level of pension upon their retirement, while also depriving the National Insurance Fund (ZUS) of funds needed to pay ongoing pensions.
Foreign trade and FDI.
With the collapse of the rouble-based COMECON trading bloc in 1991, Poland reoriented its trade. As early as 1996, 70% of its trade was with EU members. Neighboring Germany is Poland's main trading partner today. Poland joined the European Union in May 2004. Before that, it fostered regional integration and trade through the Central European Free Trade Agreement (CEFTA), which included Hungary, the Czech Republic, Slovakia and Slovenia.
Poland is a founding member of the World Trade Organization. As a member of the European Union, it applies the common external tariff to goods from other countries including the United States. Major Poland's imports are capital goods needed for industrial retooling and for manufacturing inputs. The country's exports also include machinery, but are highly diversified. The most successful exports are furniture, foods, motor boats, light planes, hardwood products, casual clothing, shoes and cosmetics. Germany is by far the biggest importer of Poland's exports as of 2013. In the agricultural sector, the biggest money-makers abroad include smoked and fresh fish, fine chocolate, and dairy products, meats and specialty breads, with the exchange rate conducive to export growth. Food exports amounted to 62 billion zloty in 2011, increasing by 17% from 2010. Most Polish exports to the U.S. receive tariff benefits under the Generalized System of Preferences (GSP) program.
Poland is less dependent on external trade than most other Central and Eastern European countries, but its volume of trade with Europe is still substantial. In 2011 the volume of trade (exports plus imports) with the Euro area as share of GDP was 40%, a doubling from the mid 1990s. 30% of Poland's exports are to Germany and another 30% to the rest of Europe. There has been substantial increase in Poland's exports to Russia. However, in August 2014, exports of fruits and vegetables to Russia fell dramatically following its politically motivated ban by Moscow.
Foreign direct investment (FDI) was at 40% of GDP in 2010, a doubling over the level in 2000. Most FDI into Poland comes from France, Germany and Netherlands. Polish firms in turn have foreign investments primarily in Italy and Luxembourg. Most of the internal FDI is in manufacturing, which makes it susceptible to economic fluctuations in the source countries.
The UAE has become Poland's largest trading partner in the Arab world, Roman Chalaczkiewicz, Polish Ambassador to the UAE, told Gulf News.
Polish law is rather favourable to foreign entrepreneurs. The government offers investors various forms of state aid, such as: CIT tax at the level of 19% and investment incentives in 14 Special Economic Zones (among others: income tax exemption, real estate tax exemption, competitive land prices), several industrial and technology parks, the possibility to benefit from the EU structural funds, brownfield and greenfield locations. According to the National Bank of Poland (NBP) the level of FDI inflow into Poland in 2006 amounted to €13.9 billion.
According to an Ernst & Young report, Poland ranks 7th in the world in terms of investment attractiveness. However, Ernst & Young's 2010 European attractiveness survey reported that Poland saw a 52% decrease in FDI job creation and a 42% decrease in number of FDI projects since 2008. According to the OECD (www.oecd.org) report, in 2004 Poles were one of the hardest working nations in Europe. Yet, the ability to establish and conduct business easily has been cause for economic hardship; the 2010 the World Economic Forum ranked Poland near the bottom of OECD countries in terms of the clarity, efficiency and neutrality of the legal framework used by firms to settle disputes.
Sectors.
Primary.
Agriculture.
Agriculture employs 12.7% of the work force but contributes 3.8% to the gross domestic product (GDP), reflecting relatively low productivity. Unlike the industrial sector, Poland's agricultural sector remained largely in private hands during the decades of communist rule. Most of the former state farms are now leased to farmer tenants. Lack of credit is hampering efforts to sell former state farmland. Currently, Poland's 2 million private farms occupy 90% of all farmland and account for roughly the same percentage of total agricultural production. Farms are small—8 hectares on average—and often fragmented. Farms with an area exceeding 15 ha accounted for 9% of the total number of farms but cover 45% of total agricultural area. Over half of all farm households in Poland produce only for their own needs with little, if any, commercial sales.
Poland is a net exporter of processed fruit and vegetables, meat, and dairy products. Processors often rely on imports to supplement domestic supplies of wheat, feed grains, vegetable oil, and protein meals, which are generally insufficient to meet domestic demand. However, Poland is the leading EU producer of potatoes and rye and is one of the world's largest producers of sugar beets and triticale. Poland also is a significant producer of rapeseed, grains, hogs, and cattle. 
Poland is the largest producer and exporter of apples in the entire world, surpassing China.
Mining.
Historically, mining industry in Poland had been extensive, particularly in Silesia.
Secondary.
Production industries.
Before World War II, Poland's industrial base was concentrated in the coal, textile, chemical, machinery, iron, and steel sectors. Today it extends to fertilizers, petrochemicals, machine tools, electrical machinery, electronics, car manufacture and shipbuilding.
Poland's industrial base suffered greatly during World War II, and many resources were directed toward reconstruction. The socialist economic system imposed in the late 1940s created large and unwieldy economic structures<ref name="Poland 11/07"></ref> operated under a tight central command. In part because of this systemic rigidity, the economy performed poorly even in comparison with other economies in Central Europe.
In 1990, the Mazowiecki government began a comprehensive reform programme to replace the centralised command economy with a market-oriented system. While the results overall have been impressive, many large state-owned industrial enterprises, particularly the rail, mining, steel, and defence sectors, have remained resistant to change and the downsizing required to survive in a market-based economy.
Pharmaceutics.
The total value of the Polish pharmacy market in 2008 was PLN 24.1bn, 11.5% more than in 2007.
The non-prescription medicines market, which accounts for about one-third of the total market value, was worth PLN 7.5bn in 2008. This value includes drugs and non-drugs such as dietary supplements, cosmetics, dressings, dental materials, diagnostic tests and medical devices. The prescription medicines market was worth PLN 15.8bn.
Tertiary.
Financial.
The Polish banking sector is regulated by the Polish Financial Supervision Authority (PFSA).
While transforming the country to a market-oriented economy during 1992–97, the government privatized some banks, recapitalized the rest and introduced legal reforms that made the sector competitive. These reforms, and the health and relative stability of the sector, attracted a number of strategic foreign investors. At the beginning of 2009, Poland's banking sector had 51 domestic banks, a network of 578 cooperative banks and 18 branches of foreign-owned banks. In addition, foreign investors had controlling stakes in nearly 40 commercial banks, which made up 68% of the banking capital. Banks in Poland reacted to the financial crisis of 2009 by restraining lending, raising interest rates, and strengthening balance sheets. Subsequently, the sector started lending again, with an increase of more than 4% expected in 2011.
Major Polish companies.
Selection from the list of 500 largest companies in Poland compiled by magazine Polityka.
Data.
Retail sales in Poland
Investment (gross fixed):
18.4% of GDP (2004 est.)
Household income or consumption by percentage share:
Distribution of family income – Gini index:
30.6 (2004)
Agriculture – products:
potatoes, fruits, vegetables, wheat, poultry, eggs, pork
Industrial production growth rate:
17.8% (2006)
Electricity:
Electricity – production by source:
Oil:
Natural gas:
Households with access to fixed and mobile telephone access
Broadband penetration rate
Individuals using computer and internet
Exports – commodities:
machinery and transport equipment 37.8%, intermediate manufactured goods 23.7%, miscellaneous manufactured goods 17.1%, food and live animals 7.6% (2003)
Imports – commodities:
machinery and transport equipment 38%, intermediate manufactured goods 21%, chemicals 14.8%, minerals, fuels, lubricants, and related materials 9.1% (2003)
Currency exchange rates:
Unemployment:
Average gross monthly pay: 3403.07 PLN (~€830) (~$1202) December 2009
Budget and debt.
Polish state budget expenditure by division (2008):
Source: Concise Statistical Yearbook of Poland (2008/9)
Reserves of foreign exchange & gold:
$70.08 billion (2004 est.)
State Treasury Debt – foreign:
$55.4 billion (2008 est.)
Current account balance:
$−6.7 billion [−1.5% of GDP] (2009 est.)
GDP growth in Poland.
Recent GDP growth (comparing to the same quarter of previous year): 
Historical annual data

</doc>
<doc id="23021" url="https://en.wikipedia.org/wiki?curid=23021" title="Telecommunications in Poland">
Telecommunications in Poland

Telecommunications in Poland include radio, television, fixed and mobile telephones, and the Internet.
Telephones.
From the communist era Poland inherited an underdeveloped and outmoded system of telephones, with some areas (e.g. in the extreme South East) being served by manual exchanges. In December 2005 the last analog exchange was shut down. All telephone lines are now served by modern fully computerized exchanges (Siemens EWSD, Alcatel S12, Lucent 5ESS, Alcatel E10). The former state owned telephone monopoly (TPSA) has been mostly privatized, with France Telecom buying the largest share. Various other companies have entered the fixed phone market, but generally aiming for niches (e.g. Sferia with fixed wireless, Netia covering primarily business). Whilst prices have reduced and availability has increased considerably since the introduction of competition, there is little sign of TPSA's market share being seriously reduced.
The long waiting list for fixed line telephones helped in a boom in mobile cellular telephone use and all mobile phone operators in Poland use GSM. There are three competing networks with similar market share, T-Mobile (T-Mobile and Heyah brands), Orange Polska (Orange and POP brands) and Plus (Plus and Sami Swoi brands). The fourth network, Play, owned by Netia and Novator Telecom, started offering UMTS network services in early 2007. All mobile operators have UMTS services in the major cities, with nationwide coverage planned.

</doc>
<doc id="23022" url="https://en.wikipedia.org/wiki?curid=23022" title="Transport in Poland">
Transport in Poland

Transport in Poland involves air traffic, waterways, roads and railroads.
As a country located at the 'cross-roads' of Europe, Poland, with its highly developed economy, is a nation with a large and increasingly modern network of transport infrastructure.
The country's most important waterway is the river Vistula. The largest seaports are the Port of Szczecin and Port of Gdańsk. Air travel is generally used for international travel, with many flights originating at Warsaw Chopin Airport. Railways connect all of Poland's major cities and the state-owned Polish State Railways (PKP) corporation, through its subsidiaries, runs a great number of domestic and international services of varying speed and comfort. In addition to this, five out of sixteen Polish voivodeships have their own provincial rail service providers. Many major Polish cities have rapid transit systems (typically tram networks) and public transport is available in nearly all areas throughout the country.
Roads.
Polish public roads are grouped into categories related to administrative division. Poland has of public roads, of which are unsurfaced (2011):
According to national roads state report by GDDKiA in 2008 1/4 of national roads were capable of handling 11.5 tonnes per axle loads.
In recent years, the network has been improving and government spending on road construction recently saw a huge increase, due to rapid development of the country and the inflow of European Union funds for infrastructure projects.
Motorways and expressways.
Polish motorways and expressways are part of national roads network. As of December 2012, there are of motorways ("autostrady", singular - "autostrada") and of expressways ("drogi ekspresowe", singular - "droga ekspresowa").
 Motorways in Poland, (2012):<br>
A1 | A2 | A4 | A6 | A8 | A18
 Expressways in Poland, (2012):<br>
S1 | S2 | S3 | S5 |
S6 | S7 | S8 | S10 |
S11 | S12 | S14 |
S17 | S19 | S22 |
S51 | S61 | S69 | S74 | S79 | S86
Air transport.
The most important airport in Poland is Warsaw 'Frederic Chopin' International Airport. Warsaw's airport is the main international hub for LOT Polish Airlines. 
In addition to Warsaw Chopin, Wrocław, Gdańsk, Katowice, Kraków and Poznań all have international airports.
In preparation for the Euro 2012 football championships jointly hosted by Poland and Ukraine, a number of airports around the country were renovated and redeveloped. This included the building of new terminals with an increased number of jetways and stands at both Copernicus Airport in Wrocław and Lech Wałęsa Airport in Gdańsk.
Airports.
The Polish airline market was until 2004 a closed market, with bilateral agreements between countries served from the national hub – Warsaw. The regional airports were mostly serving as spokes, and were controlled by PPL, the state-owned airport authority. However, in the 1990s it was decided to deregulate the airport market and abolish the dominant position of PPL. Nearly all local airports (apart from Zielona Góra airport) became separate companies, with local governments involved in their management, which led to the partial decentralisation. Soon after opening of Polish sky for competition, flights “avoiding” the Warsaw hub became more common.
There are twelve passenger airports in operation, and there is also an airport Heringsdorf in German village Garz, 7 kilometers from Polish seaside spa Świnoujście.
International airports.
List of airports in Poland
The following are the largest airports in Poland (In descending order for 2013):
Domestic:
Airports with paved runways:
Total: 84 (2005)
Airports – with unpaved runways:
Total: 39 (2005)
Heliports: 2 (2005)
Marine.
Marine transport in Poland has two main sub-groups, riverine and seaborne. On the Baltic Sea coast, a number of large seaports exist to serve the international freight and passenger trade; these are typically deep water ports and are able to serve very large ships, including the ro-ro ferries of Unity Line, Polferries and Stena Line which operate the Poland – Scandinavia passenger lines.
Riverine services operate on almost all major Polish rivers and canals (such as the Danube–Oder and Elbląg canals) as well as on domestic coastal routes.
Waterways.
Poland has of navigable rivers and canals (as of 2009).
Merchant marine.
Total: 57 ships (1,000 GRT or over) totaling 1,120,165 GRT/
Ships by type:
bulk 50, cargo 2, chemical tanker 2, roll-on/roll-off 1, short-sea passenger 2
Railways.
Poland is served by an extensive network of railways. In most cities the main railway station is located near a city centre and is well connected to the local transportation system. The infrastructure is operated by PKP PLK ( PKP-Polskie Linie Kolejowe : PKP-Polish Rail Lines), part of state-run PKP Group. The rail network is very dense in western and northern Poland, while eastern part of the country is less developed.
The only high-speed rail line (though by most definitions, real high-speed rail only includes speeds over 200 km/h) in central-eastern Europe is the Central Rail Line (Poland), "Centralna Magistrala Kolejowa" (CMK). It has a length of , and was built in 1971–1977; it links Warsaw with Kraków and Katowice. Most trains on the CMK operate at speeds up to , but since December 2014 new Alstom Pendolino ED250 trains operate on a 90 km section of the CMK at , and improvements under way should raise the authorized speed to on most of the line. In test runs on the CMK in November 2013 a new Pendolino ED250 train set a new Polish speed record of .
Other high-speed lines:
"Projects"
The Warsaw–Łódź line is being upgraded to allow speed up to 160 km/h (in order to bind together the Warsaw–Łódź agglomeration).
Plans were made to construct a new high-speed line (350 km/h) from Warsaw to Poznań and Wrocław with forks in Łódź and Kalisz., but the project was cancelled in November 2011 due to its high cost.
The PKP Group is the fourth largest railway throughout Europe. Trains are run by its different subsidiaries.
Passenger transport operators.
The following companies operate in Poland:
Narrow gauge railways.
There are hundreds of kilometres of , , , and narrow gauge lines in Poland.
These railways are mostly in decline, some surviva as a museum or tourist railways.
Freight transport market.
Broad gauge railways.
Except for Linia Hutnicza Szerokotorowa, and a few very short stretches near border crossings, Poland uses the standard gauge for its railways. Therefore, Linia Hutnicza Szerokotorowa (known by its acronym "LHS", English: "Broad gauge steelworks line") in Sławków is the longest broad gauge railway line in Poland. The line runs on a single track for almost from the Polish-Ukrainian border, crossing it just east of Hrubieszów. It is the westernmost broad gauge railway line in Europe that is connected to the broad gauge rail system of the countries of the former Soviet Union.
Rail system.
Total: 
As of December 2002 narrow gauge railways were no longer owned or operated by PKP. They were transferred to regional authorities or became independent companies.
Municipal transport.
Bus.
Most Polish towns and cities have well developed municipal bus services. Typically, a city possesses its own local bus company, however, in some cases they have private competitors operating on certain lines upon the agreement with local authorities.
Until the 1990s, interurban connections were operated by a single, state-owned company PKS. Since then, it has been broken into a number of independent national and municipal enterprises. In addition, several private operators emerged. There are two classes of service distinguished by vehicle length:
While they often use the same bus stops, they tend to use different stations.
Tram.
Bigger cities run dense tram networks, which are the primary mean of public transport. Currently, there are 14 systems serving over 30 cities including Bydgoszcz, Gdańsk, Katowice, Kraków, Łódź, Poznań, Szczecin, Warsaw and Wrocław, with the total track length varying from (Silesian Interurbans) to less than (Tramways in Grudziądz). A new network is being constructed in Olsztyn. See the list: List of town tramway systems in Europe#Poland
Since the 1990s, a number of cities attempts to upgrade certain parts of their networks to the light rail standard (called "szybkie tramwaje", eng. "fast trams"). The most notable investments are Poznań Fast Tram and Kraków Fast Tram with the underground premetro section.
Trolleybus.
Trolleybuses can be found in three cities: Gdynia (with some lines reaching Sopot), Lublin and Tychy.
Metro.
The first and currently the only metro line was opened in Warsaw in 1995. The second line is under construction. There are no official plans to build metro in other cities due to the lack of funds, but there is an ongoing debate whether they should be built, especially in Kraków and Wrocław.
See: Warsaw Metro

</doc>
<doc id="23024" url="https://en.wikipedia.org/wiki?curid=23024" title="Foreign relations of Poland">
Foreign relations of Poland

The Republic of Poland is a Central European country and member of the European Union and NATO, among others. In recent years, Poland has extended its responsibilities and position in European and Western affairs, supporting and establishing friendly foreign relations with both the West and with numerous European countries.
Integration with the West and Europe.
After regaining independence in 1989, Poland has forged ahead on its economic reintegration with the Western world. Poland also has been an active nation in advocating European integration.
In 1994, Poland became an associate member of the European Union (EU) and its defensive arm, the Western European Union (WEU). In 1996, Poland achieved full OECD membership and submitted preliminary documentation for full EU membership. In 1997, Poland was invited in the first wave of NATO policy enlargement at the July 1997 NATO Summit in Madrid, Spain. In March 1999, Poland became a full member of NATO. Poland promoted its NATO candidacy through energetic participation in the Partnership for Peace (PfP) program and through intensified individual dialogue with NATO. Poland formally joined the European Union in May 2004, along with the other members of the Visegrád group.
Poland was a part of the multinational force in Iraq.
Establishing relationships with European countries.
The collapse of the Soviet Union led to the establishment of seven new sovereign states in Poland's immediate neighborhood (Latvia, Lithuania, Estonia, Belarus, Ukraine, and Russia), of which Lithuania, Belarus, Ukraine, and Russia (through the Kaliningrad Oblast) border Poland. Poland has actively pursued good relations with all its neighboring countries, signing friendship treaties replacing links severed by the collapse of the Warsaw Pact. The Poles have forged special relationships with Lithuania and particularly Ukraine in an effort to firmly anchor these states to the West.
Due to its tragic historical experience with a repeating pattern of disloyal allies and simultaneous aggression of powerful neighbors (e.g., Partitions of Poland, Second World War), Polish foreign policy pursues close cooperation with a strong partner, one apt enough to give strong military support in times of critical situations. This creates the background of Poland's tight relations with the USA and their sensitivity in relations towards its partner within the European Union, Germany. At the same time, the equally burdened attitude towards Russia results in very tense diplomatic relations, which have been constantly worsening since Vladimir Putin's rise to power. This is an important factor for the special attention Poland pays to the political emancipation of all its Eastern neighbors: Lithuania, Belarus and Ukraine.

</doc>
<doc id="23028" url="https://en.wikipedia.org/wiki?curid=23028" title="Media of Poland">
Media of Poland

The Media of Poland consist of several different types of communications media including television, radio, cinema, newspapers, magazines, and Internet. Many of the media are controlled by large for-profit corporations who reap revenue from advertising, subscriptions, and sale of copyrighted material.
Media and politics.
During the communist regime in Poland the Stalinist press doctrine dominated and controlled Polish media. This doctrine aimed at getting the support of people and making Polish people "Soviets". The country instituted freedom of press since the fall of communism. However, public TV and radio are still politically controlled, via a state regulatory body called "Krajowa Rada Radiofonii i Telewizji" ("The National Radio and Television Committee"), which is similar to CRTC in Canada. It is said that both public and private media are not impartial, and used as means for political propaganda. Various irregularities have been exposed during the investigation by a special parliamentary committee into the "Lew Rywin affair".
TV stations.
TVP – public broadcaster
Polsat – private
Grupa ITI ("International Trading and Investments Holdings SA Luxembourg")
Polcast Television
Minor players and joint-ventures:
Many major players are also present on the market, among them:
Canal+ Polska, Canal+ Sport, Canal+ Film, Canal+ Sport2, HBO, HBO2, EuroSport, EuroSport2, Discovery Channel, Discovery Travel & Living, Discovery Science, Discovery World, MTV Poland, VIVA Poland, VH1 Poland
Radio stations.
Privately owned stations.
Broker FM group:
Eurozet group:
Agora group:
Time group:
other:

</doc>
<doc id="23033" url="https://en.wikipedia.org/wiki?curid=23033" title="Portugal">
Portugal

Portugal (; ), officially the Portuguese Republic (), is a country on the Iberian Peninsula, in southwestern Europe. It is the westernmost country of mainland Europe, being bordered by the Atlantic Ocean to the west and south and by Spain to the north and east. The Portugal-Spain border is 1,214 km (754 mi) long and considered the longest uninterrupted border within the European Union. The republic also holds sovereignty over the Atlantic archipelagos of the Azores and Madeira, both autonomous regions with their own regional governments. 
The land within the borders of current Portugal has been continuously settled and fought over since prehistoric times. The Celts and the Romans were followed by the Visigothic and the Suebi Germanic peoples, who were themselves later invaded by the Moors. These Muslim peoples were eventually expelled during the Christian "Reconquista" of the peninsula.
By 1139, Portugal had established itself as a kingdom independent from León. In the 15th and 16th centuries, as the result of pioneering the Age of Discovery, Portugal expanded Western influence and established the first global empire, becoming one of the world's major economic, political and military powers.
Portugal lost much of its wealth and status with the destruction of Lisbon in a 1755 earthquake, occupation during the Napoleonic Wars, and the independence of Brazil, its wealthiest colony, in 1822. After the 1910 revolution deposed the monarchy, the democratic but unstable Portuguese First Republic was established, later being superseded by the "Estado Novo" right-wing authoritarian regime. Democracy was restored after the Portuguese Colonial War and the Carnation Revolution in 1974. Shortly after, independence was granted to all its colonies, with the exception of Macau, which was handed over to China in 1999. This marked the end of the longest-lived European colonial empire, leaving a profound cultural and architectural influence across the globe and a legacy of over 250 million Portuguese speakers today.
Portugal maintains a unitary semi-presidential republican form of government and is a developed country with an advanced economy, and very high living standards, having the 18th highest Social Progress in the world, putting it ahead of other western European countries like France, Spain and Italy. It is a member of numerous international organizations, including the United Nations, the European Union, the Eurozone, OECD, NATO and the Community of Portuguese Language Countries. Portugal is also known for having fully decriminalized the usage of all drugs in 2001, the first country in the world to do so.
History.
Early history: Pre-Celts and Celts.
The early history of Portugal is shared with the rest of the Iberian Peninsula located in South Western Europe. The name of Portugal derives from the combined Romano-Celtic name Portus Cale. The region was settled by Pre-Celts and Celts, giving origin to peoples like the Gallaeci, Lusitanians, Celtici and Cynetes, visited by Phoenicians and Carthaginians, incorporated in the Roman Republic dominions as Lusitania and part of Gallaecia, after 45 BC until 298 AD, settled again by Suebi, Buri, and Visigoths, and conquered by Moors. Other influences include some 5th-century vestiges of Alan settlement, which were found in Alenquer (old Germanic "Alankerk", from Alan+kerk; meaning "church of the Alan" (people), Coimbra and Lisbon.
The region of present-day Portugal was inhabited by Neanderthals and then by Homo sapiens, who roamed the border-less region of the northern Iberian peninsula. These were subsistence societies that, although they did not establish prosperous settlements, did establish organized societies. Neolithic Portugal experimented with domestication of herding animals, the raising of some cereal crops and fluvial or marine fishing.
It is believed by some scholars that early in the first millennium BC, several waves of Celts invaded Portugal from Central Europe and inter-married with the local populations, forming different ethnic groups, with many tribes.
Chief among these tribes were the Calaicians or Gallaeci of Northern Portugal, the Lusitanians of central Portugal, the Celtici of Alentejo, and the Cynetes or Conii of the Algarve. Among the lesser tribes or sub-divisions were the Bracari, Coelerni, Equaesi, Grovii, Interamici, Leuni, Luanqui, Limici, Narbasi, Nemetati, Paesuri, Quaquerni, Seurbi, Tamagani, Tapoli, Turduli, Turduli Veteres, Turdulorum Oppida, Turodi, and Zoelae.
There were in the southern part of the country some small, semi-permanent commercial coastal settlements founded by Phoenicians-Carthaginians (such as Tavira, in the Algarve).
Roman Lusitania and Gallaecia.
Romans first invaded the Iberian Peninsula in 219 BC. During the last days of Julius Caesar, almost the entire peninsula had been annexed to the Roman Republic. The Carthaginians, Rome's adversary in the Punic Wars, were expelled from their coastal colonies.
The Roman conquest of what is now part of modern-day Portugal took almost two hundred years and took many lives of young soldiers and
the lives of those who were sentenced to a certain death in the slavery mines when not sold as slaves to other parts of the empire. It suffered a severe setback in 150 BC, when a rebellion began in the north. The Lusitanians and other native tribes, under the leadership of Viriathus, wrested control of all of western Iberia.
Rome sent numerous legions and its best generals to Lusitania to quell the rebellion, but to no avail—the Lusitanians kept conquering territory. The Roman leaders decided to change their strategy. They bribed Viriathus's allies to kill him. In 139 BC, Viriathus was assassinated, and Tautalus became leader.
Rome installed a colonial regime. The complete Romanization of Lusitania only took place in the Visigothic era.
In 27 BC, Lusitania gained the status of Roman province. Later, a northern province of Lusitania was formed, known as Gallaecia, with capital in Bracara Augusta, today's Braga.
There are still many ruins of castros (hill forts) all over modern Portugal and remains of Castro culture.
Numerous Roman sites are scattered around present-day Portugal, some urban remains are quite large, like Conímbriga and Mirobriga. The former, beyond being one of the largest Roman settlements in Portugal, is also classified as a National Monument. Conímbriga lies 16 km from Coimbra which by its turn was the ancient "Aeminium"). The site also has a museum that displays objects found by archaeologists during their excavations.
Several works of engineering, such as baths, temples, bridges, roads, circus, theatres and layman's homes are preserved throughout the country. Coins, some of which coined in Lusitanian land, as well as numerous pieces of ceramics were also found. Contemporary historians include Paulus Orosius (c. 375–418) and Hydatius (c. 400–469), bishop of Aquae Flaviae, who reported on the final years of the Roman rule and arrival of the Germanic tribes.
Germanic invasions.
In the early 5th century, Germanic tribes, namely the Suebi and the Vandals (Silingi and Hasdingi) together with their allies, the Sarmatians and Alans invaded the Iberian Peninsula where they would form their kingdom. The Kingdom of the Suebi was the Germanic post-Roman kingdom, established in the former Roman provinces of Gallaecia-Lusitania.
About 410 and during the 6th century it became a formally declared kingdom, where king Hermeric made a peace treaty with the Gallaecians before passing his domains to Rechila, his son. In 448 Réchila died, leaving the state in expansion to Rechiar.
In the year 500, the Visigothic Kingdom was installed in Iberia, centred on Toledo. The Visigoths eventually conquered the Suebi and its capital city Bracara (modern day Portugal's Braga) in 584–585. 
It maintained its independence until 585, when it was annexed by the Visigoths, and turned into the sixth province of the Visigothic Kingdom of Hispania.
For the next 300 years and by the year 700, the entire Iberian Peninsula was ruled by Visigoths, having survived until 711, when King Roderic (Rodrigo) was killed while opposing an invasion from the south by the Umayyad Muslims.
Moorish Iberia.
Today's modern day continental Portugal, along with a significant part of Spain, was part of the Umayyad Caliphate for approximately five centuries (711 AD - 1249 AD), following the Umayyad Caliphate conquest of the Iberian Peninsula in 711 AD.
After defeating the Visigoths in only a few months, the Umayyad Caliphate started expanding rapidly in the peninsula. Beginning in 711, the land that is now Portugal became part of the vast Umayyad Caliphate's empire of Damascus. Which stretched from the Indus river in the Indian sub-continent (now Pakistan) up to the South of France, until its collapse in 750, a year in which the west of the empire gained its independence under Abd-ar-Rahman I with the creation of the Emirate of Córdoba. After almost two centuries, the Emirate became the Caliphate of Córdoba in 929, until its dissolution a century later in 1031 into no less than 23 small kingdoms, called Taifa kingdoms.
The governors of the taifas each proclaimed themselves Emir of their provinces and established diplomatic relations with the Christian kingdoms of the north. Most of Portugal fell into the hands of the Taifa of Badajoz of the Aftasid Dynasty, and after a short spell of an ephemeral Taifa of Lisbon in 1022, fell under the dominion of the Taifa of Seville of the Abbadids poets. The Taifa period ended with the conquest of the Almoravids who came from Morocco in 1086 winning a decisive victory at the Battle of Sagrajas, followed a century later in 1147, after the second period of Taifa, by the Almohads, also from Marrakesh.
Al-Andalus was divided into different districts called "Kura". Gharb Al-Andalus at its largest was constituted of ten kuras, each with a distinct capital and governor. The main cities of the period in Portugal were Beja, Silves, Alcácer do Sal, Santarém and Lisbon.
The Muslim population of the region consisted mainly of native Iberian converts to Islam (the so-called "Muwallad" or "Muladi") and to a lesser extent Berbers and Arabs. The Arabs were principally noblemen from Oman; and though few in numbers, they constituted the elite of the population. The Berbers were originally from the Atlas mountains and Rif mountains of North Africa and were essentially nomads. 
In Portugal, the Muslim population (or "Moors"), relatively small in numbers, stayed in the Algarve region, and south of the Tagus. Today, there are approximately 800 words in the Portuguese language of Arabic origin. The Muslims were expelled from Portugal 300 years earlier than in neighbouring Spain, which is reflected both in Portuguese culture and the language, which is mostly Celtiberian and Vulgar Latin.
Reconquista.
An Asturian Visigothic noble named Pelayos or Pelagius in 718 AD was elected leader by many of the ousted Visigoth nobles. Pelayos called for the remnant of the Christian Visigothic armies to rebel against the Moors and regroup in the unconquered northern Asturian highlands, better known today as the Cantabrian Mountains, in what is today the small mountain region in North-western Spain, adjacent to the Bay of Biscay.
Pelayos' plan was to use the Cantabrian mountains as a place of refuge and protection from the invading Moors. He then aimed to regroup the Iberian Peninsula's Christian armies and use the Cantabrian mountains as a springboard from which to regain their lands from the Moors. In the process, after defeating the Moors in the Battle of Covadonga in 722 AD, Pelayos was proclaimed king, thus founding the Christian Kingdom of Asturias and starting the war of Christian reconquest known in Portuguese as the "Reconquista Cristã".
At the end of the 9th century, the region of Portugal, between the rivers Minho and Douro, was freed or reconquered from the Moors by Vimara Peres on the orders of King Alfonso III of Asturias. Finding that the region had previously had two major cities—Portus Cale in the coast and Braga in the interior, with many towns that were now deserted—he decided to repopulate and rebuild them with Portuguese and Galician refugees and other Christians.
Thus, it was very easy for Vimara Peres to organize the region and elevate it to the status of County. Vimara Peres named the region he freed from the Moors, the County of Portugal after the region's major port city—"Portus Cale"' or modern Porto. One of the first cities Vimara Peres founded at this time is Vimaranes, known today as Guimarães - the "birthplace of the Portuguese nation" or the "cradle city" (Cidade Berço in Portuguese).
After annexing the County of Portugal into one of the several counties that made up the Kingdom of Asturias, King Alfonso III of Asturias knighted Vimara Peres, in 868 AD, as the First Count of Portus Cale (Portugal). The region became known as "Portucale", "Portugale", and simultaneously "Portugália" — the County of Portugal. Later the Kingdom of Asturias was divided into a number of Christian Kingdoms in Northern Spain due to dynastic divisions of inheritance among the kings offspring. With the forced abdication of Alfonso III "the Great" of Asturias by his sons in 910, the Kingdom of Asturias split into three separate kingdoms of León, Galicia and Asturias. The three kingdoms were eventually reunited in 924 (León and Galicia in 914, Asturias later) under the crown of León.
A year before Alfonso III "the Great" of Asturias death, three of Alfonso's sons rose in rebellion and forced him to abdicate, partitioning the kingdom among them. The eldest son, García, became king of León. The second son, Ordoño, reigned in Galicia, while the third, Fruela, received Asturias with Oviedo as his capital. Alfonso died in Zamora, probably in 910. His former realm would be reunited when first García died childless and León passed to Ordoño. He in turn died when his children were too young to ascend; Fruela became king of a reunited crown. His death the next year initiated a series of internecine struggles that led to unstable succession for over a century. It continued under that name until incorporated into the Kingdom of Castile in 1230, after Ferdinand III became joint king of the two kingdoms. This was done to avoid dynastic feuds and to maintain the Christian Kingdoms strong enough to prevent complete Muslim take over of the Iberian Peninsula and to further the Reconquista of Iberia by Christian armies.
During the century of internecine struggles for dominance among the Northern Christians kingdoms, the County of Portugal, formed the southern portion of the Kingdom of Galicia. At times the Kingdom of Galicia existed independently for short periods, but usually formed an important part of the Kingdom of Leon. Throughout this period, the people of County of Portugal as Galicians found themselves struggling to maintain the autonomy of Galicia with its distinct language and culture (Galician-Portuguese) from the Leonese culture, whenever the status of the Kingdom of Galicia changed in relation to the Kingdom of Leon. As a result of political division, Galician-Portuguese lost its unity when the County of Portugal separated from the Kingdom of Galicia (a dependent kingdom of Leon) to establish the Kingdom of Portugal. The Galician and Portuguese versions of the language then diverged over time as they followed independent evolutionary paths. This began occurring when the Kingdom of Leon and the Kingdom of Castile united and the Castilian Language (known as Spanish) slowly over the centuries began influencing the Galician Language and then trying to replace it. The same thing happened to Astur-Leonese Language to the point where it is greatly reduced or completely replaced by the Castilian (Spanish Language).
During the Reconquista period, Christians reconquered the Iberian Peninsula from Moorish domination. A victory over the Muslims at the Battle of Ourique in 1139 is traditionally taken as the occasion when the County of Portugal as a fief of the Kingdom of León was transformed into the independent Kingdom of Portugal.
Henry, to whom the newly formed county was awarded by Alfonso VI for his role in reconquering the land, based his newly formed county in Bracara Augusta (nowadays Braga), capital city of the ancient Roman province, and also previous capital of several kingdoms over the first millennia.
On 24 June 1128, the Battle of São Mamede occurred near Guimarães. Afonso Henriques, Count of Portugal, defeated his mother Countess Teresa and her lover Fernão Peres de Trava, thereby establishing himself as sole leader. Afonso then turned his arms against the Moors in the south. His campaigns were successful and, on 25 July 1139, he obtained an overwhelming victory in the Battle of Ourique, and straight after was unanimously proclaimed King of Portugal by his soldiers.
Afonso then established the first of the Portuguese Cortes at Lamego, where he was crowned by the Archbishop of Braga, though the validity of the Cortes of Lamego has been disputed and called a myth created during the Portuguese Restoration War. Afonso was recognized in 1143 by King Alfonso VII of León and Castile, and in 1179 by Pope Alexander III.
Afonso Henriques and his successors, aided by military monastic orders, pushed southward to drive out the Moors. At this time Portugal covered about half of its present area. In 1249, the Reconquista ended with the capture of the Algarve and complete expulsion of the last Moorish settlements on the southern coast, giving Portugal its present-day borders, with minor exceptions.
The reigns of Dinis I, Afonso IV, and Pedro I for the most part saw peace with the Christian kingdoms of Iberia, and thus the Portuguese kingdom advanced in prosperity and culture.
In 1348 and 1349 Portugal, like the rest of Europe, was devastated by the Black Death. In 1373, Portugal made an alliance with England, which is the longest-standing alliance in the world. This alliance served both nations' interests throughout history and is regarded by many as the predecessor to NATO. Over time this went way beyond geo-political and military cooperation (protecting both nations' interests in Africa, the Americas and Asia against French, Spanish and Dutch rivals) and maintained strong trade and cultural ties between the two old European allies. Particularly in the Oporto region, there is visible English influence to this day.
In 1383, John I of Castile, husband of Beatrice of Portugal and son-in-law of Ferdinand I of Portugal, claimed the throne of Portugal. A faction of petty noblemen and commoners, led by John of Aviz (later King John I of Portugal) and commanded by General Nuno Álvares Pereira defeated the Castilians in the Battle of Aljubarrota. With this battle, the House of Aviz became the ruling house of Portugal.
Joanine era.
Portugal spearheaded European exploration of the world and the Age of Discovery. Prince Henry the Navigator, son of King João I, became the main sponsor and patron of this endeavour. During this period, Portugal explored the Atlantic Ocean, discovering several Atlantic archipelagos like the Azores, Madeira, and Cape Verde, explored the African coast, colonized selected areas of Africa, discovered an eastern route to India via the Cape of Good Hope, discovered Brazil, explored the Indian Ocean, established trading routes throughout most of southern Asia, and sent the first direct European maritime trade and diplomatic missions to China and Japan.
In 1415, Portugal acquired the first of its overseas colonies by conquering Ceuta, the first prosperous Islamic trade centre in North Africa. There followed the first discoveries in the Atlantic: Madeira and the Azores, which led to the first colonization movements.
Throughout the 15th century, Portuguese explorers sailed the coast of Africa, establishing trading posts for several common types of tradable commodities at the time, ranging from gold to slaves, as they looked for a route to India and its spices, which were coveted in Europe.
The Treaty of Tordesillas, intended to resolve the dispute that had been created following the return of Christopher Columbus, which was made by Pope Alexander VI, the mediator between Portugal and Spain. It was signed on 7 June 1494, and divided the newly discovered lands outside Europe between the two countries along a meridian 370 leagues west of the Cape Verde islands (off the west coast of Africa).
In 1498, Vasco da Gama reached India and brought economic prosperity to Portugal and its population of 1.7 million residents, helping to start the Portuguese Renaissance. In 1500, the Portuguese explorer Gaspar Corte-Real reached what is now Canada and founded the town of Portugal Cove-St. Philip's, Newfoundland and Labrador, long before the French and English in the 17th century, and being just one of many Portuguese Colonizations of the Americas.
In 1500, Pedro Álvares Cabral discovered Brazil and claimed it for Portugal. Ten years later, Afonso de Albuquerque conquered Goa in India, Muscat and Ormuz in the Persian Strait, and Malacca, now a state in Malaysia. Thus, the Portuguese empire held dominion over commerce in the Indian Ocean and South Atlantic. Portuguese sailors set out to reach Eastern Asia by sailing eastward from Europe, landing in such places as Taiwan, Japan, the island of Timor, and in the Moluccas.
Although for a long period it was believed the Dutch were the first Europeans to arrive in Australia, evidence points to the Portuguese discovery of Australia in 1521.
The Treaty of Zaragoza, signed on 22 April 1529 between Portugal and Spain, specified the anti-meridian to the line of demarcation specified in the Treaty of Tordesillas.
All these factors made Portugal one of the world's major economic, military, and political powers from the 15th century until the late 16th century.
Iberian Union and Restoration.
Portugal's sovereignty was interrupted between 1580 and 1640. This occurred because the last two kings of the House of Aviz – King Sebastian, who died in the battle of Alcácer Quibir in Morocco, and his great-uncle and successor, King Henry of Portugal – both died without heirs, resulting in the Portuguese succession crisis of 1580.
Subsequently, Philip II of Spain claimed the throne and so became Philip I of Portugal. Although Portugal did not lose its formal independence, it was governed by the same monarch who governed the Spanish Empire, briefly forming a union of kingdoms. At this time Spain was a geographic territory. The joining of the two crowns deprived Portugal of an independent foreign policy and led to its involvement in the Eighty Years' War between Spain and the Netherlands.
War led to a deterioration of the relations with Portugal's oldest ally, England, and the loss of Hormuz, a strategic trading post located between Iran and Oman. From 1595 to 1663 the Dutch-Portuguese War primarily involved the Dutch companies invading many Portuguese colonies and commercial interests in Brazil, Africa, India and the Far East, resulting in the loss of the Portuguese Indian sea trade monopoly.
In 1640, John IV spearheaded an uprising backed by disgruntled nobles and was proclaimed king. The Portuguese Restoration War between Portugal and the Spanish Empire, in the aftermath of the 1640 revolt, ended the sixty-year period of the Iberian Union under the House of Habsburg. This was the beginning of the House of Braganza, which reigned in Portugal until 1910.
Official estimates – and most estimates made so far – place the number of Portuguese migrants to Colonial Brazil during the gold rush of the 18th century at 600,000. This represented one of the largest movements of European populations to their colonies in the Americas during colonial times.
Early Brigantine and Pombaline era.
In 1738, Sebastião José de Carvalho e Melo, 1st Marquis of Pombal, began a diplomatic career as the Portuguese Ambassador in London and later in Vienna. The Queen consort of Portugal, Archduchess Maria Anne Josefa of Austria, was fond of Melo; and after his first wife died, she arranged the widowed de Melo's second marriage to the daughter of the Austrian Field Marshal Leopold Josef, Count von Daun. King John V of Portugal, however, was not pleased and recalled Melo to Portugal in 1749. John V died the following year and his son, Joseph I of Portugal, was crowned. In contrast to his father, Joseph I was fond of de Melo, and with the Queen Mother's approval, he appointed Melo as Minister of Foreign Affairs.
As the King's confidence in de Melo increased, the King entrusted him with more control of the state. By 1755, Sebastião de Melo was made Prime Minister. Impressed by British economic success that he had witnessed from the Ambassador, he successfully implemented similar economic policies in Portugal. He abolished slavery in Portugal and in the Portuguese colonies in India; reorganized the army and the navy; restructured the University of Coimbra, and ended discrimination against different Christian sects in Portugal.
But Sebastião de Melo's greatest reforms were economic and financial, with the creation of several companies and guilds to regulate every commercial activity. He demarcated the region for production of Port to ensure the wine's quality, and this was the first attempt to control wine quality and production in Europe. He ruled with a strong hand by imposing strict law upon all classes of Portuguese society from the high nobility to the poorest working class, along with a widespread review of the country's tax system. These reforms gained him enemies in the upper classes, especially among the high nobility, who despised him as a social upstart.
Disaster fell upon Portugal in the morning of 1 November 1755, when Lisbon was struck by a violent earthquake with an estimated Richter scale magnitude of 9. The city was razed to the ground by the earthquake and the subsequent tsunami and ensuing fires. Sebastião de Melo survived by a stroke of luck and then immediately embarked on rebuilding the city, with his famous quote: "What now? We bury the dead and take care of the living."
Despite the calamity and huge death toll, Lisbon suffered no epidemics and within less than one year was already being rebuilt. The new city centre of Lisbon was designed to resist subsequent earthquakes. Architectural models were built for tests, and the effects of an earthquake were simulated by marching troops around the models. The buildings and big squares of the Pombaline City Centre still remain as one of Lisbon's tourist attractions. Sebastião de Melo also made an important contribution to the study of seismology by designing an inquiry that was sent to every parish in the country.
Following the earthquake, Joseph I gave his Prime Minister even more power, and Sebastião de Melo became a powerful, progressive dictator. As his power grew, his enemies increased in number, and bitter disputes with the high nobility became frequent. In 1758 Joseph I was wounded in an attempted assassination. The Távora family and the Duke of Aveiro were implicated and executed after a quick trial. The Jesuits were expelled from the country and their assets confiscated by the crown. Sebastião de Melo prosecuted every person involved, even women and children. This was the final stroke that broke the power of the aristocracy. Joseph I made his loyal minister Count of Oeiras in 1759.
In 1762, Spain invaded Portuguese territory as part of the Seven Years' War, but by 1763 the "status quo" between Spain and Portugal before the war had been restored.
Following the Távora affair, the new Count of Oeiras knew no opposition. Made "Marquis of Pombal" in 1770, he effectively ruled Portugal until Joseph I's death in 1779. However, historians also argue that Pombal’s "enlightenment," while far-reaching, was primarily a mechanism for enhancing autocracy at the expense of individual liberty and especially an apparatus for crushing opposition, suppressing criticism, and furthering colonial economic exploitation as well as intensifying book censorship and consolidating personal control and profit.
National and Imperial change.
The new ruler, Queen Maria I of Portugal, disliked the Marquis because of the power he amassed, and never forgave him for the ruthlessness with which he dispatched the Távora family, and upon her accession to the throne, she withdrew all his political offices. Pombal died on his estate at Pombal in 1782.
In the autumn of 1807, Napoleon moved French troops through Spain to invade Portugal. From 1807 to 1811, British-Portuguese forces would successfully fight against the French invasion of Portugal, while the royal family and the Portuguese nobility, including Maria I, relocated to the Portuguese territory of Brazil, at that time a colony of the Portuguese Empire, in South America. This episode is known as the Transfer of the Portuguese Court to Brazil.
With the occupation by Napoleon, Portugal began a slow but inexorable decline that lasted until the 20th century. This decline was hastened by the independence in 1822 of the country's largest colonial possession, Brazil. In 1807, as Napoleon's army closed in on Lisbon, the Prince Regent João VI of Portugal transferred his court to Brazil and established Rio de Janeiro as the capital of the Portuguese Empire. In 1815, Brazil was declared a Kingdom and the Kingdom of Portugal was united with it, forming a pluricontinental State, the United Kingdom of Portugal, Brazil and the Algarves.
As a result of the change in its status and the arrival of the Portuguese royal family, Brazilian administrative, civic, economical, military, educational, and scientific apparatus were expanded and highly modernized. Portuguese and their allied British troops fought against the French Invasion of Portugal and by 1815 the situation in Europe had cooled down sufficiently that João VI would have been able to return safely to Lisbon. However, the King of Portugal remained in Brazil until the Liberal Revolution of 1820, which started in Porto, demanded his return to Lisbon in 1821.
Thus he returned to Portugal but left his son Pedro in charge of Brazil. When the Portuguese Government attempted the following year to return the Kingdom of Brazil to subordinate status, his son Pedro, with the overwhelming support of the Brazilian elites, declared Brazil's independence from Portugal. Cisplatina (today's sovereign state of Uruguay), in the south, was one of the last additions to the territory of Brazil under Portuguese rule.
Colonial restoration.
At the height of European colonialism in the 19th century, Portugal had already lost its territory in South America and all but a few bases in Asia. Luanda, Benguela, Bissau, Lourenço Marques, Porto Amboim and the Island of Mozambique were among the oldest Portuguese-founded port cities in its African territories. During this phase, Portuguese colonialism focused on expanding its outposts in Africa into nation-sized territories to compete with other European powers there.
With the Conference of Berlin of 1884, Portuguese Africa territories had their borders formally established on request of Portugal in order to protect the centuries-long Portuguese interests in the continent from rivalries enticed by the Scramble for Africa. Portuguese Africa's cities and towns like Nova Lisboa, Sá da Bandeira, Silva Porto, Malanje, Tete, Vila Junqueiro, Vila Pery and Vila Cabral were founded or redeveloped inland during this period and beyond. New coastal towns like Beira, Moçâmedes, Lobito, João Belo, Nacala and Porto Amélia were also founded. Even before the turn of the 20th century, railway tracks as the Benguela railway in Angola, and the Beira railway in Mozambique, started to be built to link coastal areas and selected inland regions.
Other episodes during this period of the Portuguese presence in Africa include the 1890 British Ultimatum. This forced the Portuguese military to retreat from the land between the Portuguese colonies of Mozambique and Angola (most of present-day Zimbabwe and Zambia), which had been claimed by Portugal and included in its "Pink Map", which clashed with British aspirations to create a Cape to Cairo Railway.
The Portuguese territories in Africa were Cape Verde, São Tomé and Príncipe, Portuguese Guinea, Angola, and Mozambique. The tiny fortress of São João Baptista de Ajudá on the coast of Dahomey, was also under Portuguese rule. In addition, Portugal still ruled the Asian territories of Portuguese India, Portuguese Timor and Macau.
Republic and turmoil.
On 1 February 1908, the king Dom Carlos I of Portugal and his heir apparent, Prince Royal Dom Luís Filipe, Duke of Braganza, were murdered in Lisbon. Under his rule, Portugal had twice been declared bankrupt – on 14 June 1892, and again on 10 May 1902 – causing social turmoil, economic disturbances, protests, revolts and criticism of the monarchy. Manuel II of Portugal became the new king, but was eventually overthrown by the 5 October 1910 revolution, which abolished the regime and instated republicanism in Portugal. Political instability and economic weaknesses were fertile ground for chaos and unrest during the Portuguese First Republic. These conditions would lead to the failed Monarchy of the North, 28 May 1926 coup d'état, and the creation of the National Dictatorship ("Ditadura Nacional").
This in turn led to the establishment of the right-wing dictatorship of the Estado Novo under António de Oliveira Salazar in 1933. Portugal was one of only five European countries to remain neutral in World War II. From the 1940s to the 1960s, Portugal was a founding member of NATO, OECD and the European Free Trade Association (EFTA). Gradually, new economic development projects and relocation of mainland Portuguese citizens into the overseas provinces in Africa were initiated, with Angola and Mozambique, as the largest and richest overseas territories, being the main targets of those initiatives. These actions were used to affirm Portugal's status as a transcontinental nation and not as a colonial empire.
After India attained independence in 1947, pro-Indian residents of Dadra and Nagar Haveli, with the support of the Indian government and the help of pro-independence organisations, separated the territories of Dadra and Nagar Haveli from Portuguese rule in 1954. In 1961, São João Baptista de Ajudá's annexation by the Republic of Dahomey was the start of a process that led to the final dissolution of the centuries-old Portuguese Empire.
According to the census of 1921 São João Baptista de Ajudá had 5 inhabitants and, at the moment of the ultimatum by the Dahomey Government, it had only 2 inhabitants representing Portuguese Sovereignty. Another forcible retreat from overseas territories occurred in December 1961 when Portugal refused to relinquish the territories of Goa, Daman and Diu. As a result, the Portuguese army and navy were involved in armed conflict in its colony of Portuguese India against the Indian Armed Forces.
The operations resulted in the defeat and surrender of the limited Portuguese defensive garrison, which was forced to surrender to a much larger military force. The outcome was the loss of the remaining Portuguese territories in the Indian subcontinent. The Portuguese regime refused to recognize Indian sovereignty over the annexed territories, which continued to be represented in Portugal's National Assembly until the military coup of 1974.
Also in the early 1960s, independence movements in the Portuguese overseas provinces of Angola, Mozambique and Guinea in Africa, resulted in the Portuguese Colonial War (1961–1974).
Revolution and imperial end.
Throughout the colonial war period Portugal had to deal with increasing dissent, arms embargoes and other punitive sanctions imposed by most of the international community. However, the authoritarian and conservative Estado Novo regime, first installed and governed by António de Oliveira Salazar and from 1968 onwards led by Marcelo Caetano, tried to preserve a vast centuries-long intercontinental empire with a total area of 2,168,071 km2.
The Portuguese government and army successfully resisted the decolonization of its overseas territories until April 1974, when a bloodless left-wing military coup in Lisbon, known as the Carnation Revolution, led the way for the independence of the overseas territories in Africa and Asia, as well as for the restoration of democracy after two years of a transitional period known as PREC ("Processo Revolucionário Em Curso"). This period was characterized by social turmoil and power disputes between left- and right-wing political forces. The retreat from the overseas territories and the acceptance of its independence terms by Portuguese head representatives for overseas negotiations, which would create independent states in 1975, prompted a mass exodus of Portuguese citizens from Portugal's African territories (mostly from Portuguese Angola and Mozambique).
Over one million Portuguese refugees fled the former Portuguese provinces as white settlers were usually not considered part of the new identities of the former Portuguese colonies in Africa and Asia. Mário Soares and António de Almeida Santos were charged with organising the independence of Portugal's overseas territories. By 1975, all the Portuguese African territories were independent and Portugal held its first democratic elections in 50 years.
The country continued to be governed by a Junta de Salvação Nacional until the Portuguese legislative election of 1976. It was won by the Portuguese Socialist Party (PS) and Mário Soares, its leader, became Prime Minister of the 1st Constitutional Government on 23 July. Mário Soares would be Prime Minister from 1976 to 1978 and again from 1983 to 1985. In this capacity Soares tried to resume the economic growth and development record that had been achieved before the Carnation Revolution, during the last decade of the previous regime. He initiated the process of accession to the European Economic Community (EEC) by starting accession negotiations as early as 1977.
The country bounced between socialism and adherence to the neoliberal model. Land reform and nationalizations were enforced; the Portuguese Constitution (approved in 1976) was rewritten in order to accommodate socialist and communist principles. Until the constitutional revisions of 1982 and 1989, the constitution was a highly charged ideological document with numerous references to socialism, the rights of workers, and the desirability of a socialist economy. Portugal's economic situation after its transition to democracy, obliged the government to pursue International Monetary Fund (IMF)-monitored stabilization programs in 1977–78 and 1983–85.
European integration.
In 1986, Portugal joined the European Economic Community (EEC) that later became the European Union (EU). In the following years Portugal's economy progressed considerably as a result of EEC/EU structural and cohesion funds and Portuguese companies' easier access to foreign markets.
Portugal's last overseas territory, Macau, was peacefully handed over to the People's Republic of China (PRC) in 1999, under the 1987 joint declaration that set the terms for Macau's handover from Portugal to the PRC. In 2002, the independence of East Timor (Asia) was formally recognized by Portugal, after an incomplete decolonization process that was started in 1975 because of the Carnation Revolution.
On 26 March 1995, Portugal started to implement Schengen Area rules, eliminating border controls with other Schengen members while simultaneously strengthening border controls with non-member states. In 1996 the country was a co-founder of the Community of Portuguese Language Countries (CPLP) headquartered in Lisbon. Expo '98 took place in Portugal and in 1999 it was one of the founding countries of the Euro and the eurozone.
On 5 July 2004, José Manuel Barroso, then Prime Minister of Portugal, was nominated President of the European Commission, the most powerful office in the European Union. On 1 December 2009, the Treaty of Lisbon entered into force, after it had been signed by the European Union member states on 13 December 2007 in the Jerónimos Monastery, in Lisbon, enhancing the efficiency and democratic legitimacy of the Union and improving the coherence of its action.
Economic disruption and an unsustainable growth in borrowing costs in the wake of the late-2000s financial crisis led the country to negotiate in 2011 with the IMF and the European Union, through the European Financial Stability Mechanism (EFSM) and the European Financial Stability Facility (EFSF), a loan to help the country stabilise its finances.
Geography.
The territory of Portugal includes an area in the Iberian Peninsula (referred to as "the continent" by most Portuguese) and two archipelagos in the Atlantic Ocean: the archipelagos of Madeira and the Azores. It lies between latitudes 32° and 43° N, and longitudes 32° and 6° W.
Mainland Portugal is split by its main river, the Tagus that flows from Spain and disgorges in Tagus Estuary, in Lisbon, before escaping into the Atlantic. The northern landscape is mountainous towards the interior with several plateaus indented by river valleys, whereas the south, that includes the Algarve and the Alentejo regions, is characterized by rolling plains.
Portugal's highest peak is the similarly named Mount Pico on the island of Pico in the Azores. This ancient volcano, which measures is an iconic symbol of the Azores, while the Serra da Estrela on the mainland (the summit being above sea level) is an important seasonal attraction for skiers and winter sports enthusiasts.
The archipelagos of Madeira and the Azores are scattered within the Atlantic Ocean: the Azores straddling the Mid-Atlantic Ridge on a tectonic triple junction, and Madeira along a range formed by in-plate hotspot geology. Geologically, these islands were formed by volcanic and seismic events, although the last terrestrial volcanic eruption occurred in 1957–58 (Capelinhos) and minor earthquakes occur sporadically, usually of low intensity.
Portugal's Exclusive Economic Zone, a sea zone over which the Portuguese have special rights over the exploration and use of marine resources, has 1,727,408 km2. This is the 3rd largest Exclusive Economic Zone of the European Union and the 11th largest in the world.
Climate.
Portugal is defined as a Mediterranean climate ("Csa" in the South, interior, and Douro region; "Csb" in the North, Central Portugal and coastal Alentejo; mixed oceanic climate along the northern half of the coastline and also Semi-arid climate or Steppe climate ("BSk" in certain parts of Beja district far South) according to the Köppen-Geiger Climate Classification), and is one of the warmest European countries: the annual average temperature in mainland Portugal varies from in the mountainous interior north to in the south and on the Guadiana river basin. The Algarve, separated from the Alentejo region by mountains reaching up to in Alto de Fóia, has a climate similar to that of the southern coastal areas of Spain or Southwest Australia.
Annual average rainfall in the mainland varies from just over in the northern mountains to less than in the area of the Massueime River, near Côa, along the Douro river. Mount Pico is recognized as receiving the largest annual rainfall (over per year) in Portugal, according to "Instituto Português do Mar e da Atmosfera " ().
In some areas, such as the Guadiana basin, annual average temperatures can be as high as , and summer highest temperatures may be over . The record high of was recorded in Amareleja, although this might not be the hottest spot in summer, according to satellite readings.
Snowfalls occur regularly in the winter in the interior North and Centre of the country in districts such as Vila Real, Bragança, Viseu and Guarda. In winter temperatures may drop below in particular in Serra da Estrela, Serra do Gerês, Serra do Marão and Serra de Montesinho, and have even been recorded below . In these places snow can fall any time from October to May. In the South of the country snowfalls are rare but still occur in the highest elevations.
The country has around 2500 to 3200 hours of sunshine a year, an average of 4–6 h in winter and 10–12 h in the summer, with higher values in the south-east and lower in the north-west.
The sea surface temperature on the west coast of mainland Portugal varies from in winter to in the summer while on the south coast it ranges from in winter and rises in the summer to about occasionally reaching .
Both the archipelagos of the Azores and Madeira have a subtropical climate, although variations between islands exist, making weather predictions very difficult (owing to rough topography). The Madeira and Azorean archipelagos have a narrower temperature range, with annual average temperatures exceeding along the coast (according to the Portuguese Meteorological Institute). Some islands in Azores do have drier months in the summer. Consequently, the island of the Azores have been identified as having a Mediterranean climate (both "Csa" and "Csb" types), while some islands (such as Flores or Corvo) are classified as Maritime Temperate ("Cfb") and Humid subtropical ("Cfa"), respectively, according to Köppen-Geiger classification.
Porto Santo island in Madeira has a semi-arid steppe climate ("BSh"). The Savage Islands, which are part of the regional territory of Madeira and a nature reserve are unique in being classified as a desert climate ("BWh") with an annual average rainfall of approximately . The sea surface temperature in the archipelagos varies from in winter to in the summer occasionally reaching .
Biodiversity.
Despite the fact that humans occupy the territory of Portugal for thousands of years, something still remains from the original vegetation. Very important florest relicts can be described: in Gerês both climax deciduous and coniferous forests can be found, an extremely rare worldwide mature mediterranean forest remain in some parts of the Arrábida mountain and a subtropical laurissilva forest, dating back to the Tertiary period, covers its largest continuous area in the world in the Madeira main island. Due to the human population decrease and rural exodus, Pyrenean oak and other local native trees, are colonizing many abandoned areas. Boar, iberian red deer, roe deer, iberian wild goat, for example, are reported to be expanding greatly, during the last decades. Boars were found recently roaming even inside big urban areas, like in Setubal, though during the night. Protected areas of Portugal include one national park (), 12 natural parks (), nine natural reserves (), five natural monuments (), and seven protected landscapes (), which include the Parque Nacional da Peneda-Gerês, the Parque Natural da Serra da Estrela and the Paul d'Arzila.
These natural environments are shaped by diverse flora, and include widespread species of pine (especially the "Pinus pinaster" and "Pinus pinea" species), the English oak ("Quercus robur"), the Pyrenean oak ("Quercus pyrenaica") the chestnut ("Castanea sativa"), the cork-oak ("Quercus suber"), the holm oak ("Quercus ilex") or the Portuguese oak ("Quercus faginea"). Due to their economic value, some species of the "Eucalyptus" genus were introduced and are now common, despite their environmental impact.
Laurisilva is a unique type of subtropical rainforest found in few areas of Europe and the world: in the Azores, and in particular on the island of Madeira, there are large forests of endemic "Laurisilva" forests (the latter protected as a natural heritage preserve).
There are several species of diverse mammalian fauna, including the fox, badger, iberian lynx, iberian wolf, wild goat ("Capra pyrenaica"), wild cat ("Felis silvestris"), hare, weasel, polecat, chameleon, mongoose, civet, brown bear (spotted near Rio Minho, close to Peneda-Gerês) and many others. Portugal is an important stopover for migratory birds, in places such as Cape St. Vincent or the Monchique mountains, where thousands of birds cross from Europe to Africa during the autumn or in the spring (return migration).
Most of the avian species congregate along the Iberian Peninsula since it is the closest stopover between Northern Europe and Africa. Six hundred bird species occur in Portugal (either for nesting or during the course of migration), and annually there are new registries of nesting species. The archipelagos of the Azores and Madeira are transient stopover for American, European, and African birds, while continental Portugal mostly encounters European and African bird species.
There are more than 100 freshwater fish species, varying from the giant European catfish (in the Tagus International Natural Park) to some small and endemic species that live only in small lakes (along the western portion of country, for example). Some of these rare and specific species are highly endangered because of habitat loss, pollution and drought. Up-welling along the west coast of Portugal makes the sea extremely rich in nutrients and diverse species of marine fish; the Portuguese marine waters are one of the richest in the world. Marine fish species are more common, and include thousands of species, such as the sardine ("Sardina pilchardus"), tuna and Atlantic mackerel. Bioluminescent species are also well represented (including species in different colour spectrum and forms), like the glowing plankton that are possible to observe in some beaches.
There are many endemic insect species, most only found in certain parts of Portugal, while other species are more widespread like the stag beetle ("Lucanus cervus") and the cicada. The Macaronesian islands (Azores and Madeira) have many endemic species (like birds, reptiles, bats, insects, snails and slugs) that evolved independently from other regions of Portugal. In Madeira, for example, it is possible to observe more than 250 species of land gastropods.
Government and administration.
Portugal has been a semi-presidential constitutional republic since the ratification of the Constitution of 1976, with Lisbon, the nation's largest city, as its capital. The Constitution grants the division or separation of powers among four bodies referred as "organs of Sovereignty": the President of the Republic, the Government, the Assembly of the Republic and the Courts.
The President, who is elected to a five-year term, has a supervisory executive role: the current President is Aníbal Cavaco Silva. The Assembly of the Republic is a single chamber parliament composed of 230 deputies elected for a four-year term. The Government is headed by the Prime Minister (currently António Costa) and includes Ministers and Secretaries of State. The Courts are organized into several levels, among the judicial, administrative and fiscal branches. The Supreme Courts are institutions of last resort/appeal. A thirteen-member Constitutional Court oversees the constitutionality of the laws.
Portugal operates a multi-party system of competitive legislatures/local administrative governments at the national-, regional- and local-levels. The Assembly of the Republic, Regional Assemblies and local municipalities and parishes, are dominated by two political parties, the Socialist Party and the Social Democratic Party, in addition to the Democratic Unity Coalition (Portuguese Communist Party plus Ecologist Party "The Greens"), the Left Bloc and the Democratic and Social Centre – People's Party, which garner between 5 and 15% of the vote regularly.
Chief of State.
The Chief of State of Portugal is the President of the Republic, elected to a five-year term by direct, universal suffrage. He has essentially supervision and reserve powers. These powers are often compared with the "moderator power" that was held by the King in the Portuguese Constitutional Monarchy. Presidential powers include the appointment of the Prime Minister and the other members of the Government (where the President is obligated by the results from Legislative Elections); dismissing the Prime Minister; dissolving the Assembly of the Republic (to call early elections); vetoing legislation (which may be overridden by the Assembly); and declaring a State of War or siege. The President is also the nominal Supreme Commander of the Armed Forces.
The President is advised on issues of importance by the Council of State, which is composed of six senior civilian officers, any former Presidents elected under the 1976 Constitution, five-members chosen by the Assembly, and five selected by the president.
Government.
The Government is headed by the presidentially appointed Prime Minister, also including Vice-Prime-Ministers, Ministers, Secretaries of State and Under-Secretaries of State.
The Government is both the organ of Sovereignty that conducts the general politics of the country and the superior body of the Public Administration.
It has essentially Executive powers, but has also limited Legislative powers. The Government can legislate about its own organization, about areas covered by legislative authorizations conceded by the Assembly of the Republic and about the specific regulation of generalist laws issued by the Assembly.
The Council of Ministers - under the presidency of the Prime Minister and also including the Vice-Prime Minister and the Ministers - acts as the cabinet. Each government is required to define the broad outline of its policies in a program, and present it to the Assembly for a mandatory period of debate. The failure of the Assembly to reject the program by a majority of deputies confirms the government in office.
Parliament.
The Assembly of the Republic is the national parliament of Portugal. It is the main Legislative body, although the Government also has limited legislative powers.
The Assembly of the Republic is a unicameral body composed of up to 230 deputies. Elected by universal suffrage according to a system of proportional representation, deputies serve four-year terms of office, unless the President dissolves the Assembly and calls for new elections.
Law and criminal justice.
The Portuguese legal system is part of the civil law legal system, also called the continental family legal system. The main laws include the Constitution (1976, as amended), the Portuguese Civil Code (1966, as amended) and the Penal Code of Portugal (1982, as amended). Other relevant laws are the "Commercial Code" (1888, as amended) and the "Civil Procedure Code" (1961, as amended).
The supreme national courts are the Supreme Court of Justice and the Constitutional Court. The Public Ministry, headed by the Attorney General of the Republic, constitutes the independent body of public prosecutors.
Portuguese law applied in the former colonies and territories and continues to be the major influence for those countries. Portugal's main police organizations are the "Guarda Nacional Republicana – GNR" (National Republican Guard), a gendarmerie; the "Polícia de Segurança Pública – PSP" (Public Security Police), a civilian police force who work in urban areas; and the "Polícia Judiciária – PJ" (Judicial Police), a highly specialized criminal investigation police that is overseen by the Public Ministry.
Portugal was one of the first countries in the world to abolish the death penalty. Maximum jail sentences are limited to 25 years.
Portugal has arguably the most liberal laws concerning possession of illicit drugs in the Western world. In 2001, Portugal decriminalized possession of effectively all drugs that are still illegal in other developed nations including, but not limited to, cannabis, cocaine, heroin, and LSD. While possession is legal, trafficking and possession of more than "10 days worth of personal use" are still punishable by jail time and fines. People caught with small amounts of any drug are given the choice to go to a rehab facility, and may refuse treatment without consequences. Despite criticism from other European nations, who stated Portugal's drug consumption would tremendously increase, overall drug use has declined along with the number of HIV infection cases, which had dropped 50 percent by 2009. Drug use among 16- to 18-year-olds also declined, however the use of marijuana rose only slightly among that age group.
On 31 May 2010, Portugal became the sixth country in Europe and the eighth country in the world to legally recognize same-sex marriage on the national level. The law came into force on 5 June 2010.
Administrative divisions.
Administratively, Portugal is divided into 308 municipalities
(), which after a reform in 2013 are subdivided into 3,092 civil parishes (). Operationally, the municipality and civil parish, along with the national government, are the only legally identifiable local administrative units identified by the government of Portugal (for example, cities, towns or villages have no standing in law, although may be used as catchment for the defining services). For statistical purposes the Portuguese government also identifies NUTS, inter-municipal communities and informally, the district system, used until European integration (and being phased-out by the national government). Continental Portugal is agglomerated into 18 districts, while the archipelagos of the Azores and Madeira are governed as autonomous regions; the largest units, established since 1976, are either mainland Portugal () and the autonomous regions of Portugal (Azores and Madeira).
The 18 districts of mainland Portugal are: Aveiro, Beja, Braga, Bragança, Castelo Branco, Coimbra, Évora, Faro, Guarda, Leiria, Lisbon, Portalegre, Porto, Santarém, Setúbal, Viana do Castelo, Vila Real and Viseu – each district takes the name of the district capital.
Within the European Union NUTS (Nomenclature of Territorial Units for Statistics) system, Portugal is divided into seven regions: the Azores, Alentejo, Algarve, Centro, Lisboa, Madeira and Norte, and with the exception of the Azores and Madeira, these NUTS areas are subdivided into 28 subregions.
Foreign relations.
A member state of the United Nations since 1955, Portugal is also a founding member of NATO (1949), OECD (1961) and EFTA (1960); it left the latter in 1986 to join the European Economic Community, that would become the European Union in 1993. In 1996 it co-founded the Community of Portuguese Language Countries (CPLP), which seeks to foster closer economic and cultural ties between the world's Lusophone nations.
In addition, Portugal is a full member of the Latin Union (1983) and the Organization of Ibero-American States (1949). It has a friendship alliance and dual citizenship treaty with its former colony, Brazil. Portugal and England (subsequently, the United Kingdom of Great Britain and Northern Ireland) share the world's oldest active military accord through their Anglo-Portuguese Alliance (Treaty of Windsor), which was signed in 1373.
There are two international territorial disputes, both with Spain:
Military.
The armed forces have three branches: Navy, Army and Air Force. They serve primarily as a self-defense force whose mission is to protect the territorial integrity of the country and provide humanitarian assistance and security at home and abroad. As of 2008, the three branches numbered 39,200 active personnel including 7,500 women. Portuguese military expenditure in 2009 was $5.2 billion, representing 2.1 percent of GDP. Military conscription was abolished in 2004. The minimum age for voluntary recruitment is 18 years.
The Army (21,000 personnel) comprises three brigades and other small units. An infantry brigade (mainly equipped with Pandur II APC), a mechanized brigade (mainly equipped with Leopard 2 A6 tanks and M113 APC) and a Rapid Reaction Brigade (consisting of paratroopers, commandos and rangers). The Navy (10,700 personnel, of which 1,580 are marines) has five frigates, seven corvettes, two submarines, and 28 patrol and auxiliary vessels. The Air Force (7,500 personnel) has the Lockheed F-16 Fighting Falcon and the Dassault/Dornier Alpha Jet as the main combat aircraft.
In addition to the three branches of the armed forces, there is the National Republican Guard, a security force subject to military law and organization (gendarmerie) comprising 25,000 personnel. This force is under the authority of both the Defense and the Interior Ministry. It has provided detachments for participation in international operations in Iraq and East Timor.
The United States maintains a military presence with 770 troops in the Lajes Air Base at Terceira Island, in the Azores. The Allied Joint Force Command Lisbon (JFC Lisbon) – one of the three main subdivisions of NATO's Allied Command Operations – it is based in Oeiras, near Lisbon.
In the 20th century, Portugal engaged in two major conflicts: World War I and the Portuguese Colonial War (1961–1974). After the end of the Portuguese Empire in 1975, the Portuguese Armed Forces have participated in peacekeeping missions in East Timor, Bosnia, Kosovo, Afghanistan, Somalia, Iraq (Nasiriyah) and Lebanon. Portugal also conducted several independent unilateral military operations abroad, as were the cases of the interventions of the Portuguese Armed Forces in Angola in 1992 and in Guinea-Bissau in 1998 with the main objectives of protecting and withdrawing of Portuguese and foreign citizens threatened by local civil conflicts.
Government finance.
The Portuguese government is heavily indebted, and received a 78 billion euro bailout from the European Union and the International Monetary Fund in May 2011. The ratio of Portugal’s debt to its overall economy, was 107 percent when it received the bailout. As part of the deal, the country agreed to cut its budget deficit from 9.8 percent of GDP in 2010 to 5.9 percent in 2011, 4.5 percent in 2012 and 3 percent in 2013.
After the bailout was announced, the Portuguese government headed by Pedro Passos Coelho managed to implement measures with the intention of improve the State's financial situation, including tax hikes, a freeze of civil service-related lower-wages and cuts of higher-wages by 14.3%, on top of the government's spending cuts. The Portuguese government also agreed to eliminate its golden share in Portugal Telecom which gave it veto power over vital decisions. In 2012, all public servants had already seen an average wage cut of 20% relative to their 2010 baseline, with cuts reaching 25% for those earning more than 1,500 euro per month.
The IMF, the European Commission (EC) and the European Central Bank (ECB) said in September 2012 that Portugal’s debt would peak at 124 percent of gross domestic product in 2014. The IMF previously said in July 2012 that Portugal’s debt would peak at about 118.5 percent of GDP in 2013. In September 2013, the Portuguese Government reviewed again the public debt of Portugal for 2013 to 127.8 percent, after a peak of 130.9 percent in that month.
A report released in January 2011 by the Diário de Notícias and published in Portugal by Gradiva, had demonstrated that in the period between the Carnation Revolution in 1974 and 2010, the democratic Portuguese Republic governments encouraged over-expenditure and investment bubbles through unclear Public–private partnerships and funding of numerous ineffective and unnecessary external consultancy and advisory of committees and firms.
This allowed considerable slippage in state-managed public works and inflated top management and head officer bonuses and wages. Persistent and lasting recruitment policies boosted the number of redundant public servants. Risky credit, public debt creation, and European structural and cohesion funds were mismanaged across almost four decades.
After the financial crisis of 2007–2008, it was known in 2008–2009 that two Portuguese banks (Banco Português de Negócios (BPN) and Banco Privado Português (BPP)) had been accumulating losses for years due to bad investments, embezzlement and accounting fraud. The case of BPN was particularly serious because of its size, market share, and the political implications - Portugal's then current President, Cavaco Silva, and some of his political allies, maintained personal and business relationships with the bank and its CEO, who was eventually charged and arrested for fraud and other crimes. In the grounds of avoiding a potentially serious financial crisis in the Portuguese economy, the Portuguese government decided to give them a bailout, eventually at a future loss to taxpayers and to the Portuguese people in general.
Economy.
The Portuguese currency is the euro (€), which replaced the Portuguese Escudo, and the country was one of the original member states of the eurozone. Portugal's central bank is the "Banco de Portugal", an integral part of the European System of Central Banks. Most industries, businesses and financial institutions are concentrated in the Lisbon and Porto metropolitan areas—the Setúbal, Aveiro, Braga, Coimbra and Leiria districts are the biggest economic centres outside these two main areas.
According to World Travel Awards, Portugal is the Europe's Leading Golf Destination 2012 and 2013.
Since the Carnation Revolution of 1974, which culminated in the end of one of Portugal's most notable phases of economic expansion (that started in the 1960s), a significant change has occurred in the nation's annual economic growth. After the turmoil of the 1974 revolution and the PREC period, Portugal tried to adapt to a changing modern global economy, a process that continues in 2013. Since the 1990s, Portugal's public consumption-based economic development model has been slowly changing to a system that is focused on exports, private investment and the development of the high-tech sector. Consequently, business services have overtaken more traditional industries such as textiles, clothing, footwear and cork (Portugal is the world's leading cork producer), wood products and beverages.
In the second decade of the 21st century the Portuguese economy suffered its most severe recession since the 1970s resulting in the country having to be bailed out by the European Commission, European Central Bank and International Monetary Fund. The bailout, agreed to in 2011, required Portugal to enter into a range of austerity measures in exchange for funding support of €78 billion. In May 2014 the country exited the bailout but reaffirmed its commitment to maintaining its reformist momentum. At the time of exiting the bailout the economy had contracted by 0.7% in the first quarter of 2014, however unemployment, while still high had fallen to 15.3 percent.
Sectors.
Primary sector.
Agriculture in Portugal is based on small to medium-sized family-owned dispersed units. However, the sector also includes larger scale intensive farming export-oriented agrobusinesses backed by companies (like Grupo RAR's Vitacress, Sovena, Lactogal, Vale da Rosa, Companhia das Lezírias and Valouro). The country produces a wide variety of crops and livestock products, including tomatoes, citrus, green vegetables, rice, corn, barley, olives, oilseeds, nuts, cherries, bilberry, table grapes, edible mushrooms, dairy products, poultry and beef.
Forestry has also played an important economic role among the rural communities and industry (namely paper industry that includes Portucel Soporcel Group, engineered wood that includes Sonae Indústria, and furniture that includes several manufacturing plants in and around Paços de Ferreira, the core of Portugal's major industrial operations of IKEA). In 2001, the gross agricultural product accounted for 4 per cent of the national GDP.
Traditionally a sea-power, Portugal has had a strong tradition in the Portuguese fishing sector and is one of the countries with the highest fish consumption per capita. The main landing sites in Portugal (including Azores and Madeira), according to total landings in weight by year, are the harbours of Matosinhos, Peniche, Olhão, Sesimbra, Figueira da Foz, Sines, Portimão and Madeira. Portuguese processed fish products are exported through several companies, under a number of different brands and registered trademarks, such as Ramirez (the world’s oldest active canned fish producer), Bom Petisco, Nero, Combate, Comur, General, Líder, Manná, Murtosa, Pescador, Pitéu, Tenório, Torreira and Vasco da Gama.
Portugal is a significant European minerals producer and is ranked among Europe's leading copper producers. The nation is also a notable producer of tin, tungsten and uranium. However, the country lacks the potential to conduct hydrocarbon exploration and aluminium, a limitation that has hindered the development of Portugal's mining and metallurgy sectors. Although the country has vast iron and coal reserves—mainly in the north—after the 1974 revolution and the consequent economic globalization, low competitiveness forced a decrease in the extraction activity for these minerals. The Panasqueira and Neves-Corvo mines are among the most recognised Portuguese mines that are still in operation.
Secondary sector.
Industry is diversified, ranging from automotive (Volkswagen Autoeuropa and Peugeot Citroen), aerospace (Embraer and OGMA), electronics and textiles, to food, chemicals, cement and wood pulp. Volkswagen Group's AutoEuropa motor vehicle assembly plant in Palmela is among the largest foreign direct investment projects in Portugal.
Modern non-traditional technology-based industries, such as aerospace, biotechnology and information technology, have been developed in several locations across the country. Alverca, Covilhã, Évora, and Ponte de Sor are the main centres of the Portuguese aerospace industry, which is led by Brazil-based company Embraer and the Portuguese company OGMA. Following the turn of the 21st century, many major biotechnology and information technology industries have been founded, and are concentrated in the metropolitan areas of Lisbon, Porto, Braga, Coimbra and Aveiro.
Tertiary sector.
Travel and tourism continue to be extremely important for Portugal, with visitor numbers forecast to increase significantly in the future. However, the increasing competition from Eastern European destinations continues to develop, with the presence of similar attractions that are often cheaper in countries such as Croatia. Consequently, it has been necessary for the country to focus upon its niche attractions, such as health, nature and rural tourism, to stay ahead of its competitors.
The banking and insurance sectors performed well until the late-2000s financial crisis, and this partly reflected a rapid deepening of the market in Portugal. While sensitive to various types of market and underwriting risks, it has been estimated that overall both the life and non-life sectors will be able to withstand a number of severe shocks, even though the impact on individual insurers varies widely.
State-owned companies.
Major State-owned companies include Águas de Portugal (water), Caixa Geral de Depósitos (banking), Comboios de Portugal (railways), Companhia das Lezírias (agriculture) and RTP (media). Some former state-owned entities are managed by state-run holding company Parpública, which is a shareholder of several public and private companies. Among former State owned companies recently privatized are CTT (postal service), TAP Portugal (airline) and ANA (airports).
Listed companies.
Companies listed on Euronext Lisbon stock exchange like EDP, Galp, Jerónimo Martins, Mota-Engil, Novabase, Semapa, Portucel Soporcel, Portugal Telecom and Sonae, are among the largest corporations of Portugal by number of employees, net income or international market share. The Euronext Lisbon is the major stock exchange of Portugal and is part of the NYSE Euronext, the first global stock exchange. The PSI-20 is Portugal's most selective and widely known stock index.
Performance.
The Global Competitiveness Report for 2014-2015, published by the World Economic Forum, placed Portugal on the 36th position on the economic index. This represents a sharp increase from the 51st position where Portugal appeared in 2013-2014.
The Economist Intelligence Unit's quality of life index placed Portugal as the country with the 19th-best quality of life in the world for 2005, ahead of other economically and technologically advanced countries like France, Germany, the United Kingdom and South Korea, but 9 places behind its only neighbour, Spain. This is despite the fact that Portugal remains one of the countries with the lowest per capita GDP in Western Europe.
The poor performance of the Portuguese economy was explored in April 2007 by The Economist, which described Portugal as "a new sick man of Europe". From 2002 to 2007, the number of unemployed increased by 65% (270,500 unemployed citizens in 2002, 448,600 unemployed citizens in 2007). By early December 2009, the unemployment rate had reached 10.2% – a 23-year record high. In December 2009, ratings agency Standard & Poor's lowered its long-term credit assessment of Portugal to "negative" from "stable," voicing pessimism on the country's structural weaknesses in the economy and weak competitiveness that would hamper growth and the capacity to strengthen its public finances and reduce debt. In July 2011, ratings agency Moody's downgraded its long-term credit assessment of Portugal after warning of deteriorating risk of default in March 2011.
Corruption has become an issue of major political and economic significance for the country. Some cases are well known and were widely reported in the media, such as the affairs in several municipalities that involved local town hall officials, businesspersons, and a number of politicians with wider responsibilities and power. Nevertheless, the 2010 Transparency International report places Portugal in 31st position for perceived corruption, just below Israel and Spain.
According to a 2013 report from the Ernst & Young quoted by the EU Observer Portugal is the most corrupt Country in Western Europe.
Over time, the Portuguese economy converged with EU levels, with the period from 1986 to the early 2000s of particular significance. According to Barry (2003), "what appears to have been crucial in the Portuguese case, relative to Spain at least, is the degree of labour-market flexibility that the economy exhibits... Thus Portuguese convergence has been impressive, even though, consistent with its relatively low human-capital stock, the economy has specialised in low-tech production."
On 6 April 2011, after his proposed "Plan for Stability and Growth IV" (PEC IV) was rejected by the Parliament, Prime Minister José Sócrates announced on national television that the country would request financial assistance from the IMF and the European Financial Stability Facility, as Greece and the Republic of Ireland had done previously. It was the third time that the Portuguese government had requested external financial aid from the IMF—the first occasion occurred in the late 1970s following the Carnation's Revolution. In October 2011, Moody's Investor Services downgraded nine Portuguese banks due to financial weakness.
Public sector.
In 2005, the number of public employees per thousand inhabitants in the Portuguese government (70.8) was above the European Union average (62.4 per thousand inhabitants). By EU and USA standards, Portugal's justice system was internationally known as being slow and inefficient, and by 2011 it was the second slowest in Western Europe (after Italy); conversely, Portugal has one of the highest rates of judges and prosecutors—over 30 per 100,000 people. The entire Portuguese public service has been known for its mismanagement, useless redundancies, waste, excess of bureaucracy and a general lack of productivity in certain sectors, particularly in justice.
In the first week of May 2013, Prime Minister Passos Coelho announced a significant government plan for the public sector, whereby 30,000 jobs will be cut and the number of weekly working hours will be increased from 35 to 40 hours. Coelho reaffirmed the announcement by explaining that austerity measures are necessary if Portugal seeks to avoid another monetary bailout grant from the European Commission, European Central Bank and International Monetary Fund—the overall plan intends to enact further cuts of €4.8 billion over a three-year period.
Ongoing policies, reactions and consequences.
Passos Coelho also announced that the retirement age will be increased from 65 to 66, announced cuts in the pensions, unemployment benefits, health, education and science expenses, abolished the English obligatory classes in Basic Education, but kept the pensions of the judges, diplomats untouched and didn't raise the retirement age of the military and police forces. He has, however, cut meaningfully the politicians salaries.
These policies have led to social unrest and to confrontations between several institutions, namely between the Government and the Constitutional Court. Several individualities belonging to the parties that support the government have also raised their voices against the policies that have been taken in order to try to solve the financial crisis.
Since 2011, the Portuguese economy has already shrunk 4.5% and it's predicted that it will shrink more 2.3% in 2013 (totaling 6.7%). The Portuguese population has been shrinking since 2009 due to emigration caused by the economic crisis. Between 2009 and 2012 the unemployed population rose from 473,000 to 769,000. Meanwhile, the number of people in situation of poverty rose to 2.7 million people.
Labour market.
Portugal is a developed and a high income country. However, its income per capita figure is still one of the lowest among the EU's member states. Portugal's GDP per capita in 2014 was 78% of the EU27 average - increasing from 76% in 2012, but still not achieving the 81% of 2009 and 2010 - making it the eleventh lowest in the Union.
The average wage in Portugal is 910 € per month (net), excluding self-employed individuals and the minimum wage, which is regulated/ref by law, is €505 per month (paid 14 times per annum).
After years of high increase, the unemployment in Portugal has been in a continuous falling trend since the third quarter of 2014, decreasing from a peak of 17.7% achieved in the early 2013 to a rate of 11.9% in the second quarter of 2015. However, it is high still high compared with what was the normal average Portuguese unemployment rate in the past. In the second quarter of 2008 the unemployment rate was 7.3%, but the rate immediately rose the following period. By December 2009, unemployment had surpassed the 10% mark nationwide in the wake of worldwide events, by 2010, the rate was around 11% and in 2011 it was above 12%. The first quarter of 2013 signified a new unemployment rate record for Portugal, as it reached 17.7%— up from 17% in the previous quarter — and the Government has predicted an 18.5% unemployment rate in 2014. However, in the third quarter of the same year, it has surprisingly declined to a rate of 15.6%. From then on, the unemployment downtrend continued, declining to 13.9% in the second semester of 2014 and to 11.9% in the second quarter of 2015.
Tourism.
Portugal is among the 20 most visited countries in the world, receiving an average of 13 million foreign tourists each year. Tourism is playing an increasingly important role in Portugal's economy, contributing to about 5% of its gross domestic product (GDP).
Tourist hotspots in Portugal are Lisbon, Algarve, Madeira and the city of Coimbra, also, between 4-5 million religious pilgrims visit Fátima each year, where apparitions of the Blessed Virgin Mary to three shepherd children reportedly took place in 1917. The Sanctuary of Fátima is one of the largest Roman Catholic shrines in the world. The Portuguese government continues to promote and develop new tourist destinations, such as the Douro Valley, the island of Porto Santo, and Alentejo. Lisbon is the 16th European city which attracts the most tourists (with seven million tourists occupying the city's hotels in 2006, a number that grew 11.8% compared to previous year). Lisbon in recent years surpassed the Algarve as the leading tourist region in Portugal. Porto and Northern Portugal, especially the urban areas north of Douro River valley, was the tourist destination which grew most (11.9%) in 2006, surpassing Madeira (in 2010), as the third most visited destination.
Most tourists in Portugal are British-, French-, Spanish-, Dutch- or German-origin visitors, travel by low cost airliners, and not only seek sun and beaches, but increasingly search for cultural, gastronomic, environmental or nautical experiences (or travel for reasons of business).
In 2014, Portugal was elected "The Best European Country" by the USA Today.
Tourist regions.
The main tourist regions can be broken-down into: the Greater Lisbon (), the Algarve, Greater Porto and Northern Portugal (), the Portuguese Islands (: Madeira and Azores), and Alentejo. Other tourist regions include "Douro Sul", "Templários", "Dão-Lafões", "Costa do Sol", "Costa Azul", "Planície Dourada", that are unknown to many tourists or visitors.
Most of these regions are grouped in tourism reference areas, which continue to be in a state of reorganization and evolution, some based on the traditional regions of Portugal: the "Costa Verde" ("Green Coast"); "Costa da Prata" ("Silver Coast)"; "Costa de Lisboa" ("Lisbon Coast"); "Montanhas" ("Mountains"); "Planícies" ("Plains"); "Algarve"; and the islands of the archipelagos of Madeira and the Azores.
The legend of the Rooster of Barcelos tells the story of a dead rooster's miraculous intervention in proving the innocence of a man who had been falsely accused and sentenced to death. The story is associated with the 17th-century calvary that is part of the collection of the Archeological Museum located in Paço dos Condes, a gothic-style palace in Barcelos, a city in the Braga District of northwest Portugal. The Rooster of Barcelos is bought by many tourists as a souvenir.
Transport.
By the early 1970s Portugal's fast economic growth with increasing consumption and purchase of new automobiles set the priority for improvements in transportation. Again in the 1990s, after joining the European Economic Community, the country built many new motorways. Today, the country has a road network, of which almost are part of system of 44 motorways. Opened in 1944, the first motorway (which linked Lisbon to the National Stadium) was an innovative project that made Portugal among one of the first countries in the world to establish a motorway (this roadway eventually became the Lisbon-Cascais highway, or A5). But, although a few other tracts were created (around 1960 and 1970), it was only after the beginning of the 1980s that large-scale motorway construction was implemented. In 1972, Brisa, the highway concessionaire, was founded to handle the management of many of the regions motorways. On many highways, toll needs to be paid, see Via Verde. Vasco da Gama bridge is the longest bridge in Europe.
Continental Portugal's territory is serviced by four international airports located near the principal cities of Lisbon, Porto, Faro and Beja. Lisbon's geographical position makes it a stopover for many foreign airlines at several airports within the country. The primary flag-carrier is TAP Portugal, although many other domestic airlines provide services within and without the country. The government decided to build a new airport outside Lisbon, in Alcochete, to replace Lisbon Portela Airport, though this plan has been stalled due to the austerity. Currently, the most important airports are in Lisbon, Porto, Faro, Funchal (Madeira), and Ponta Delgada (Azores), managed by the national airport authority group ANA – Aeroportos de Portugal.
A national railway system that extends throughout the country and into Spain, is supported and administered by Comboios de Portugal. Rail transport of passengers and goods is derived using the of railway lines currently in service, of which are electrified and about allow train speeds greater than . The railway network is managed by the REFER while the transport of passengers and goods are the responsibility of Comboios de Portugal (CP), both public companies. In 2006 the CP carried 133 million passengers and of goods.
The major seaports are located in Sines, Lisbon, Leixões, Setúbal, Aveiro, Figueira da Foz, and Faro.
The two largest metropolitan areas have subway systems: Lisbon Metro and "Metro Sul do Tejo" in the Lisbon Metropolitan Area and Porto Metro in the Porto Metropolitan Area, each with more than of lines. In Portugal, Lisbon tram services have been supplied by the "Companhia de Carris de Ferro de Lisboa" (Carris), for over a century. In Porto, a tram network, of which only a tourist line on the shores of the Douro remain, began construction on 12 September 1895 (a first for the Iberian Peninsula). All major cities and towns have their own local urban transport network, as well as taxi services.
Science and technology.
Scientific and technological research activities in Portugal are mainly conducted within a network of R&D units belonging to public universities and state-managed autonomous research institutions like the INETI – Instituto Nacional de Engenharia, Tecnologia e Inovação and the INRB – Instituto Nacional dos Recursos Biológicos. The funding and management of this research system is mainly conducted under the authority of the Ministry of Science, Technology and Higher Education (MCTES) itself and the MCTES's Fundação para a Ciência e Tecnologia (FCT). The largest R&D units of the public universities by volume of research grants and peer-reviewed publications, include biosciences research institutions like the Instituto de Medicina Molecular, the Centre for Neuroscience and Cell Biology, the IPATIMUP, the Instituto de Biologia Molecular e Celular and the Abel Salazar Biomedical Sciences Institute.
Among the largest non-state-run research institutions in Portugal are the Instituto Gulbenkian de Ciência and the Champalimaud Foundation, a neuroscience and oncology research centre, which in addition awards every year one of the highest monetary prizes of any science prize in the world. A number of both national and multinational high-tech and industrial companies, are also responsible for research and development projects. One of the oldest learned societies of Portugal is the Sciences Academy of Lisbon, founded in 1779.
Iberian bilateral state-supported research efforts include the International Iberian Nanotechnology Laboratory and the Ibercivis distributed computing platform, which are joint research programmes of both Portugal and Spain. Portugal is a member of several pan-European scientific organizations. These include the European Space Agency (ESA), the European Laboratory for Particle Physics (CERN), ITER, and the European Southern Observatory (ESO).
Portugal has the largest aquarium in Europe, the Lisbon Oceanarium, and the Portuguese have several other notable organizations focused on science-related exhibits and divulgation, like the state agency "Ciência Viva", a programme of the Portuguese Ministry of Science and Technology to the promotion of a scientific and technological culture among the Portuguese population, the Science Museum of the University of Coimbra, the National Museum of Natural History at the University of Lisbon, and the Visionarium.
With the emergence and growth of several science parks throughout the world that helped create many thousands of scientific, technological and knowledge-based businesses, Portugal started to develop several science parks across the country. These include the Taguspark (in Oeiras), the Coimbra iParque (in Coimbra), the biocant (in Cantanhede), the Madeira Tecnopolo (in Funchal), Sines Tecnopolo (in Sines), Tecmaia (in Maia) and Parkurbis (in Covilhã). Companies locate in the Portuguese science parks to take advantage of a variety of services ranging from financial and legal advice through to marketing and technological support.
Egas Moniz, a Portuguese physician who developed the cerebral angiography and leucotomy, received in 1949 the Nobel Prize in Physiology or Medicine – he is the first Portuguese recipient of a Nobel Prize and the only in the sciences.
The European Innovation Scoreboard 2011, placed Portugal-based innovation in the 15th position, with an impressive increase in innovation expenditure and output.
Energy.
Portugal has considerable resources of wind and river power, the two most cost-effective renewable sources. Since the turn of the 21st century, there has been a trend towards the development of a renewable resource industry and reduction of both consumption and use of fossil fuel resources. In 2006, the world's largest solar power plant at that date, the Moura Photovoltaic Power Station, began operating near Moura, in the south, while the world's first commercial wave power farm, the Aguçadoura Wave Farm, opened in the Norte region (2008). By the end of 2006, 66% of the country's electrical production was from coal and fuel power plants, while 29% were derived from hydroelectric dams, and 6% by wind energy.
In 2008, renewable energy resources were producing 43% of the nation's consumption of electricity, even as hydroelectric production decreased with severe droughts. As of June 2010, electricity exports had outnumbered imports. In the period between January and May 2010, 70% of the national production of energy came from renewable sources.
Portugal’s national energy transmission company, Redes Energéticas Nacionais (REN), uses sophisticated modeling to predict weather, especially wind patterns, and computer programs to calculate energy from the various renewable-energy plants.
Before the solar/wind revolution, Portugal had generated electricity from hydropower plants on its rivers for decades. New programs combine wind and water: wind-driven turbines pump water uphill at night, the most blustery period; then the water flows downhill by day, generating electricity, when consumer demand is highest. Portugal’s distribution system is also now a two-way street. Instead of just delivering electricity, it draws electricity from even the smallest generators, like rooftop solar panels. The government aggressively encouraged such contributions by setting a premium price for those who buy rooftop-generated solar electricity.
Water supply and sanitation.
The Water supply and sanitation services in Portugal have seen
important advances in access to services, technologies used and service
quality over the past decades (1980s–1990s), partially achieved thanks 
to important funds from the European Union.
Nevertheless, sanitation still remains relatively low in mountain rural
areas and some people have their own sources of water controlled by 
municipalities.
During the 1990s Portugal has put in place a modern institutional framework for the sector, which includes a national regulatory agency (ERSAR - The Water and Waste Services Regulation Authority) and multi-municipal water and sanitation companies.
Demographics.
The Statistics Portugal () estimates that, according to the 2011 census, the population was 10,562,178 (of which 52% was female, 48% was male). This population has been relatively homogeneous for most of its history: a single religion (Catholicism) and a single language have contributed to this ethnic and national unity, namely after the expulsion of the Moors and Jews.
A considerable number of Moors and Jews, nevertheless, stayed in Portugal, under the condition that they converted to Catholicism, and afterwards they were known as "Mouriscos" (former Muslims) and "Cristãos Novos" (New Christians or former Jews) some of whom may have continued to observe rabbinic Judaism in secret, as in the case of the secret Jews of Belmonte, who now observe the Jewish faith openly. After 1772 the distinction between Old and New Christians was abolished by decree. Some famous Portuguese New Christians were the mathematician Pedro Nunes and the physician and naturalist Garcia de Orta.
Native Portuguese are an Iberian ethnic group, whose ancestry is very similar to other Western and Southern Europeans and Mediterranean peoples, in particular Spaniards, followed by some regional French and Italians with whom they share a common ancestry, history and cultural proximity.
The most important demographic influence in the modern Portuguese seems to be the oldest one; current interpretation of Y-chromosome and mtDNA data suggests that the Portuguese have their origin in Paleolithic peoples that began arriving to the European continent around 45,000 years ago. All subsequent migrations did leave an impact, genetically and culturally, but the main population source of the Portuguese is still Paleolithic. Genetic studies show Portuguese populations not to be significantly different from other European populations.
The total fertility rate (TFR) as of 2013 was estimated at 1.51 children born/woman, which is below the replacement rate of 2.1. In 2014, 49.3% of births were to unmarried women. Like most Western countries, Portugal has to deal with low fertility levels: the country has experienced a sub-replacement fertility rate since the 1980s.
The structure of Portuguese society is characterized by an increasing inequality which at present (2015) places the country in the lowest third of the Social Justice Index for the European Union.
Metropolitan areas.
There are two Greater Metropolitan Areas (GAMs): Lisbon and Porto.
!align=right| Rank
!align=left| City name
!align=left| MetroArea
!align=left| Population
!align=left| Subregion
!align=left| Population
Immigration.
Portugal's colonial history has long since been a cornerstone of its national identity, as has its geographic position at the south-western corner of Europe, looking out into the Atlantic Ocean. It was one of the last western colonial European powers to give up its overseas territories (among them Angola and Mozambique in 1975), turning over the administration of Macau to the People's Republic of China at the end of 1999. Consequently, it has both influenced and been influenced by cultures from former colonies or dependencies, resulting in immigration from these former territories for both economic and/or personal reasons. Portugal, long a country of emigration (the vast majority of Brazilians have Portuguese ancestry), has now become a country of net immigration, and not just from the last Indian (Portuguese until 1961), African (Portuguese until 1975), and Far East Asian (Portuguese until 1999) overseas territories. An estimated 800,000 Portuguese returned to Portugal as the country's African possessions gained independence in 1975. By 2007, Portugal had 10,617,575 inhabitants of whom about 332,137 were legal immigrants.
Since the 1990s, along with a boom in construction, several new waves of Ukrainian, Brazilian, people from the former Portuguese colonies in Africa and other Africans have settled in the country. Romanian, Moldovans, Kosovar and Chinese have also chosen Portugal as destination. Portugal's Romani population, estimated at about 40,000.
In addition, a number of EU citizens, mostly from the United Kingdom, other northern European or Nordic countries, have become permanent residents in the country (with the British community being mostly composed of retired pensioners and choosing to live in the Algarve and Madeira).
Religion.
According to the 2011 Census, 81.0% of the Portuguese population are Roman Catholic. The country has small Protestant, Latter-day Saint, Muslim, Hindu, Sikh, Eastern Orthodox Church, Jehovah's Witnesses, Baha'i, Buddhist, Jewish and Spiritist communities. Influences from African Traditional Religion and Chinese Traditional Religion are also felt among many people, particularly in fields related with Traditional Chinese Medicine and African Witch Doctors. Some 6.8% of the population declared themselves to be non-religious, and 8.3% did not give any answer about their religion.
In 2012, a study conducted by the Catholic University revealed 79.5% of the Portuguese considered themselves Catholics, and that 18% attended Mass regularly. These figures represent a drop from 86.9% of Catholics in 2001, while during the same period the number of people stating that they had no religion rose from 8.2% to 14.2%.
Many Portuguese holidays, festivals and traditions have a Christian origin or connotation. Although relations between the Portuguese state and the Roman Catholic Church were generally amiable and stable since the earliest years of the Portuguese nation, their relative power fluctuated. In the 13th and 14th centuries, the church enjoyed both riches and power stemming from its role in the reconquest, its close identification with early Portuguese nationalism and the foundation of the Portuguese educational system, including the first university. The growth of the Portuguese overseas empire made its missionaries important agents of colonization, with important roles in the education and evangelization of people from all the inhabited continents. The growth of liberal and nascent republican movements during the eras leading to the formation of the First Portuguese Republic (1910–26) changed the role and importance of organized religion.
Portugal is a secular state: church and state were formally separated during the Portuguese First Republic, and later reiterated in the 1976 Portuguese Constitution. Other than the Constitution, the two most important documents relating to religious freedom in Portugal are: the 1940 Concordata (later amended in 1971) between Portugal and the Holy See, and the 2001 Religious Freedom Act.
On the Flag of Portugal, the Portuguese Arm rests over the armillary sphere. Except during the reign of Afonso I, it is present in every single historical flag, in one form or another. It is the prime Portuguese symbol as well as one of the oldest, with the first elements of today's shield appearing during the reign of Sancho I. The evolution of the Portuguese flag is inherently associated with the evolution of the shield.
Within the white inescutcheon, the five "quinas" (small blue shields) with their five white bezants representing the five wounds of Christ () when crucified and are popularly associated with the "Miracle of Ourique". The story associated with this miracle tells that before the Battle of Ourique (25 July 1139), an old hermit appeared before Count Afonso Henriques (future Afonso I) as a divine messenger. He foretold Afonso's victory and assured him that God was watching over him and his peers. The messenger advised him to walk away from his camp, alone, if he heard a nearby chapel bell tolling, in the following night. In doing so, he witnessed an apparition of Jesus on the cross. Ecstatic, Afonso heard Jesus promising victories for the coming battles, as well as God's wish to act through Afonso, and his descendants, in order to create an empire which would carry His name to unknown lands, thus choosing the Portuguese to perform great tasks.
Languages.
Portuguese is the official language of Portugal. Portuguese is a Romance language that originated in what is now Galicia and Northern Portugal, originating from Galician-Portuguese, which was the common language of the Galician and Portuguese people until the independence of Portugal. Particularly in the North of Portugal, there are still many similarities between the Galician culture and the Portuguese culture. Galicia is a consultative observer of the Community of Portuguese Language Countries. According to the Ethnologue of Languages, Portuguese and Spanish have a lexical similarity of 89% - educated speakers of each language can communicate easily with one another.
The Portuguese language is derived from the Latin spoken by the romanized Pre-Roman peoples of the Iberian Peninsula around 2000 years ago—particularly the Celts, Tartessians, Lusitanians and Iberians. In the 15th and 16th centuries, the language spread worldwide as Portugal established a colonial and commercial empire between 1415 and 1999. Portuguese is now spoken as a native language in five different continents, with Brazil accounting for the largest number of native Portuguese speakers of any country (200 million speakers in 2012).
In 2013 the Portuguese language is the official language spoken in Brazil, Angola, Mozambique, Cape Verde, São Tomé and Príncipe, Guinea-Bissau, Equatorial Guinea, and East Timor. These countries, plus Macau Special Administrative Region (People's Republic of China) where Portuguese is co-official with Cantonese, make up the Lusosphere, a term derived from the ancient Roman province of "Lusitania", which currently matches the Portuguese territory south of the Douro river.
Mirandese is also recognized as a co-official regional language in some municipalities of North-Eastern Portugal. An estimate of between 6,000 and 7,000 Mirandese speakers has been documented for Portugal.
According to International English Proficiency Index, Portugal has a high proficiency level in English, proficiency higher than in countries like Italy, France or Greece.
Education.
The educational system is divided into preschool (for those under age 6), basic education (9 years, in three stages, compulsory), secondary education (3 years, compulsory since 2010), and higher education (subdivided in university and polytechnic education).
The total adult literacy rate is 99 percent. Portuguese primary school enrollments are close to 100 percent. According to the OECD's Programme for International Student Assessment (PISA) 2009, the average Portuguese 15-year-old student, when rated in terms of reading literacy, mathematics and science knowledge, is placed at the same level as those students from the United States, Sweden, Germany, Ireland, France, Denmark, United Kingdom, Hungary and Taipei, with 489 points (493 is the average). Over 35% of college-age citizens (20 years old) attend one of the country's higher education institutions (compared with 50% in the United States and 35% in the OECD countries). In addition to being a destination for international students, Portugal is also among the top places of origin for international students. All higher education students, both domestic and international, totaled 380,937 in 2005.
Portuguese universities have existed since 1290. The oldest Portuguese university was first established in Lisbon before moving to Coimbra. Historically, within the scope of the Portuguese Empire, the Portuguese founded the oldest engineering school of the Americas (the "Real Academia de Artilharia, Fortificação e Desenho" of Rio de Janeiro) in 1792, as well as the oldest medical college in Asia (the "Escola Médico-Cirúrgica" of Goa) in 1842. The largest university in Portugal is the University of Lisbon.
Universities are usually organized into faculties. Institutes and schools are also common designations for autonomous subdivisions of Portuguese higher education institutions.
The Bologna process has been adopted, since 2006, by Portuguese universities and poly-technical institutes. Higher education in state-run educational establishments is provided on a competitive basis, a system of "numerus clausus" is enforced through a national database on student admissions. However, every higher education institution offers also a number of additional vacant places through other extraordinary admission processes for sportsmen, mature applicants (over 23 years old), international students, foreign students from the Lusosphere, degree owners from other institutions, students from other institutions (academic transfer), former students (readmission), and course change, which are subject to specific standards and regulations set by each institution or course department. Most student costs are supported with public money. However, with the increasing tuition fees a student has to pay to attend a Portuguese state-run higher education institution and the attraction of new types of students (many as part-time students or in evening classes) like employees, businessmen, parents, and pensioners, many departments make a substantial profit from every additional student enrolled in courses, with benefits for the college or university's gross tuition revenue and without loss of educational quality (teacher per student, computer per student, classroom size per student, etc.).
Portugal has entered into cooperation agreements with the Massachusetts Institute of Technology and other US institutions to further develop and increase the effectiveness of Portuguese higher education and research.
Health.
According to the latest Human Development Report, the average life expectancy in 2015 was 81.0 years.
Portugal ranks 12th in the best public health systems in the world, ahead of high developed countries like the United Kingdom, Germany or Sweden.
The Portuguese health system is characterized by three coexisting systems: the National Health Service ("Serviço Nacional de Saúde"', SNS), special social health insurance schemes for certain professions (health subsystems) and voluntary private health insurance. The SNS provides universal coverage. In addition, about 25% of the population is covered by the health subsystems, 10% by private insurance schemes and another 7% by mutual funds.
The Ministry of Health is responsible for developing health policy as well as managing the SNS.
Five regional health administrations are in charge of implementing the national health policy objectives, developing guidelines and protocols and supervising health care delivery. Decentralization efforts have aimed at shifting financial and management responsibility to the regional level. In practice, however, the autonomy of regional health administrations over budget setting and spending has been limited to primary care.
The SNS is predominantly funded through general taxation. Employer (including the state) and employee contributions represent the main funding sources of the health subsystems. In addition, direct payments by the patient and voluntary health insurance premiums account for a large proportion of funding.
Similar to the other Eur-A countries, most Portuguese die from noncommunicable diseases. Mortality from cardiovascular diseases (CVD) is higher than in the eurozone, but its two main components, ischaemic heart disease and cerebrovascular disease, display inverse trends compared with the Eur-A, with cerebrovascular disease being the single biggest killer in Portugal (17%). Portuguese people die 12% less often from cancer than in the Eur-A, but mortality is not declining as rapidly as in the Eur-A. Cancer is more frequent among children as well as among women younger than 44 years. Although lung cancer (slowly increasing among women) and breast cancer (decreasing rapidly) are scarcer, cancer of the cervix and the prostate are more frequent.
Portugal has the highest mortality rate for diabetes in the Eur-A, with a sharp increase since the 1980s.
Portugal's infant mortality rate has dropped sharply since the late 1970s, when 24 of 1000 newborns died in the first year of life. It is now around 2 deaths per a 1000 newborns. This improvement was mainly due to the decrease in neonatal mortality, from 15.5 to 2.4 per 1000 live births.
People are usually well informed about their health status, the positive and negative effects of their behaviour on their health and their use of health care services. Yet their perceptions of their health can differ from what administrative and examination-based data show about levels of illness within populations. Thus, survey results based on self-reporting at the household level complement other data on health status and the use of services. Only one third of adults rated their health as good or very good in Portugal (Kasmel et al., 2004). This is the lowest of the Eur-A countries reporting and reflects the relatively adverse situation of the country in terms of mortality and selected morbidity.
Culture.
Portugal has developed a specific culture while being influenced by various civilizations that have crossed the Mediterranean and the European continent, or were introduced when it played an active role during the Age of Discovery. In the 1990s and 2000s (decade), Portugal modernized its public cultural facilities, in addition to the Calouste Gulbenkian Foundation established in 1956 in Lisbon. These include the Belém Cultural Centre in Lisbon, Serralves Foundation and the Casa da Música, both in Porto, as well as new public cultural facilities like municipal libraries and concert halls that were built or renovated in many municipalities across the country.
Portugal is home to fifteen UNESCO World Heritage Sites, ranking it 8th in Europe and 17th in the world.
Architecture.
Traditional architecture is distinctive and include the Manueline, also known as Portuguese late Gothic, a sumptuous, composite Portuguese style of architectural ornamentation of the first decades of the 16th century. A 20th-century interpretation of traditional architecture, Soft Portuguese style, appears extensively in major cities, especially Lisbon. Modern Portugal has given the world renowned architects like Eduardo Souto de Moura, Álvaro Siza Vieira (both Pritzker Prize winners) and Gonçalo Byrne. In Portugal Tomás Taveira is also noteworthy, particularly for stadium design.
Cinema.
Portuguese cinema has a long tradition, reaching back to the birth of the medium in the late 19th century. Portuguese film directors such as Arthur Duarte, António Lopes Ribeiro, António Reis, Pedro Costa, Manoel de Oliveira, João César Monteiro, António-Pedro Vasconcelos, Fernando Lopes, João Botelho and Leonel Vieira, are among those that gained notability. Noted Portuguese film actors include Joaquim de Almeida, Daniela Ruah, Maria de Medeiros, Diogo Infante, Soraia Chaves, Ribeirinho, Lúcia Moniz, and Diogo Morgado.
Literature.
Portuguese literature, one of the earliest Western literatures, developed through text as well as song. Until 1350, the Portuguese-Galician troubadours spread their literary influence to most of the Iberian Peninsula. Gil Vicente (c. 1465–c. 1536), was one of the founders of both Portuguese and Spanish dramatic traditions.
Adventurer and poet Luís de Camões (c. 1524–1580) wrote the epic poem "Os Lusíadas" (The Lusiads), with Virgil's Aeneid as his main influence. Modern Portuguese poetry is rooted in neoclassic and contemporary styles, as exemplified by Fernando Pessoa (1888–1935). Modern Portuguese literature is represented by authors such as Almeida Garrett, Camilo Castelo Branco, Eça de Queiroz, Fernando Pessoa, Sophia de Mello Breyner Andresen, António Lobo Antunes and Miguel Torga. Particularly popular and distinguished is José Saramago, recipient of the 1998 Nobel Prize in Literature.
Cuisine.
 
Portuguese cuisine is diverse. The Portuguese consume a lot of dry cod ("bacalhau" in Portuguese), for which there are hundreds of recipes. There are more than enough "bacalhau" dishes for each day of the year. Two other popular fish recipes are grilled sardines and caldeirada, a potato-based stew that can be made from several types of fish. Typical Portuguese meat recipes, that may be made out of beef, pork, lamb, or chicken, include "cozido à portuguesa", "feijoada", "frango de churrasco", "leitão" (roast suckling pig) and "carne de porco à alentejana". A very popular northern dish is the arroz de sarrabulho (rice stewed in pigs blood) or the arroz de cabidela (rice and chickens meat stewed in chickens blood).
Typical fast food dishes include the Francesinha (Frenchie) from Porto, and "bifanas" (grilled pork) or "prego" (grilled beef) sandwiches, which are well known around the country. The Portuguese art of pastry has its origins in the many medieval Catholic monasteries spread widely across the country. These monasteries, using very few ingredients (mostly almonds, flour, eggs and some liquor), managed to create a spectacular wide range of different pastries, of which pastéis de Belém (or "pastéis de nata") originally from Lisbon, and "ovos moles" from Aveiro are examples. Portuguese cuisine is very diverse, with different regions having their own traditional dishes. The Portuguese have a culture of good food, and throughout the country there are myriads of good restaurants and typical small "tasquinhas".
Portuguese wines have enjoyed international recognition since the times of the Romans, who associated Portugal with their god Bacchus. Today, the country is known by wine lovers and its wines have won several international prizes. Some of the best Portuguese wines are: Vinho Verde, Vinho Alvarinho, Vinho do Douro, Vinho do Alentejo, Vinho do Dão, Vinho da Bairrada and the sweet: Port Wine, Madeira Wine, the Moscatel from Setúbal and Favaios. Port and Madeira are particularly appreciated in a wide range of places around the world.
Music.
Portuguese music encompasses a wide variety of genres. The most renowned is Fado, a melancholy urban music originated in Lisbon, usually associated with the Portuguese guitar and "saudade", or longing. Coimbra fado, a unique type of "serenading" fado, is also noteworthy. Internationally notable performers include Amália Rodrigues, Carlos Paredes, José Afonso, Mariza, Carlos do Carmo, António Chainho, Mísia, and Madredeus.
In addition to Fado and Folk, the Portuguese listen to pop and other types of modern music, particularly from North America and the United Kingdom, as well as a wide range of Portuguese, Caribbean and Brazilian artists and bands. Artists with international recognition include Dulce Pontes, Moonspell, Buraka Som Sistema, Blasted Mechanism and The Gift, with the two latter being nominees for a MTV Europe Music Award.
Portugal has several summer music festivals, such as "Festival Sudoeste" in Zambujeira do Mar, "Festival de Paredes de Coura" in Paredes de Coura, "Festival Vilar de Mouros" near Caminha, Boom Festival in Idanha-a-Nova Municipality, "Optimus Alive!", "Sumol Summer Fest" in Ericeira, "Rock in Rio Lisboa" and "Super Bock Super Rock" in Greater Lisbon. Out of the summer season, Portugal has a large number of festivals, designed more to an urban audience, like Flowfest or Hip Hop Porto. Furthermore, one of the largest international Goa trance festivals takes place in central Portugal every two years, the Boom Festival, that is also the only festival in Portugal to win international awards: European Festival Award 2010 – Green'n'Clean Festival of the Year and the Greener Festival Award Outstanding 2008 and 2010. There is also the student festivals of "Queima das Fitas" are major events in a number of cities across Portugal. In 2005, Portugal held the MTV Europe Music Awards, in Pavilhão Atlântico, Lisbon.
In the classical music domain, Portugal is represented by names as the pianists Artur Pizarro, Maria João Pires, Sequeira Costa, the violinists Carlos Damas, Gerardo Ribeiro and in the past by the great cellist Guilhermina Suggia. Notable composers include José Vianna da Motta, Carlos Seixas, João Domingos Bomtempo, João de Sousa Carvalho, Luís de Freitas Branco and his student Joly Braga Santos, Fernando Lopes-Graça, Emmanuel Nunes and Sérgio Azevedo. Similarly, contemporary composers such as Nuno Malo and Miguel d'Oliveira have achieved some international success writing original music for film and television.
Visual arts.
Portugal has a rich history in painting. The first well-known painters date back to the 15th century – like Nuno Gonçalves – were part of the Gothic painting period.
José Malhoa, known for his work "Fado", and Columbano Bordalo Pinheiro (who painted the portraits of Teófilo Braga and Antero de Quental) were both references in naturalist painting.
The 20th century saw the arrival of Modernism, and along with it came the most prominent Portuguese painters: Amadeo de Souza-Cardoso, who was heavily influenced by French painters, particularly by the Delaunays. Among his best-known works is "Canção Popular a Russa e o Fígaro". Another great modernist painters/writers were Carlos Botelho and Almada Negreiros, friend to the poet Fernando Pessoa, who painted his (Pessoa's) portrait. He was deeply influenced by both Cubist and Futurist trends. Prominent international figures in visual arts nowadays include painters Vieira da Silva, Júlio Pomar, Helena Almeida, Joana Vasconcelos, Julião Sarmento and Paula Rego.
Sport.
Football is the most popular sport in Portugal. There are several football competitions ranging from local amateur to world-class professional level. The legendary Eusébio is still a major symbol of Portuguese football history. FIFA World Player of the Year winners Luís Figo and Cristiano Ronaldo who won the FIFA Ballon d'Or for 2013 and 2014, are among the numerous examples of other world-class football players born in Portugal and noted worldwide. Portuguese football managers are also noteworthy, with José Mourinho, André Villas-Boas, Fernando Santos, Carlos Queiroz and Manuel José among the most renowned.
The Portuguese national football team has titles in the FIFA World Youth Championship and in the UEFA youth championships. The main national team – "Selecção Nacional" – finished second in Euro 2004 (held in Portugal), reached the third place in the 1966 FIFA World Cup, and reached the fourth place in the 2006 FIFA World Cup, their best results in major competitions to date.
SL Benfica, FC Porto, and Sporting CP are the largest sports clubs by popularity and by number of trophies won, often known as "os três grandes" ("the big three"). They have won eight titles in the European UEFA club competitions, were present in many finals and have been regular contenders in the last stages almost every season. Other than football, many Portuguese sports clubs, including the "big three", compete in several other sports events with a varying level of success and popularity, these may include roller hockey, basketball, futsal, handball, and volleyball.
The Portuguese Football Federation (FPF)  – "Federação Portuguesa de Futebol" – annually hosts the Algarve Cup, a prestigious women`s football tournament that has been celebrated in the Algarvian part of Portugal.
Portugal has a successful roller hockey team, with 15 world titles and 20 European titles, making it the country with the most wins in both competitions. The most successful Portuguese roller hockey clubs in the history of European championships are Futebol Clube do Porto, Sport Lisboa e Benfica, Sporting Clube de Portugal and Óquei de Barcelos.
The Portuguese national rugby union team made a dramatic qualification into the 2007 Rugby World Cup and became the first all amateur team to qualify for the World Cup since the dawn of the professional era. The Portuguese national rugby sevens team has performed well, becoming one of the strongest teams in Europe, and proved their status as European champions in several occasions.
In athletics, the Portuguese have won a number of gold, silver and bronze medals in the European, World and Olympic Games competitions. Cycling, with Volta a Portugal being the most important race, is also a popular sports event and include professional cycling teams such as Sport Lisboa e Benfica, Boavista, Clube de Ciclismo de Tavira, and União Ciclista da Maia.
The country has also achieved notable performances in sports like fencing, judo, kitesurf, rowing, sailing, surfing, shooting, triathlon and windsurf, owning several European and world titles. The paralympic athletes have also conquered many medals in sports like swimming, boccia and wrestling.
In motorsport, Portugal is internationally noted for the Rally of Portugal, and the Estoril, Algarve Circuits and the revived Porto Street Circuit which holds a stage of the WTCC every two years, as well as for a number of internationally noted pilots in varied motorsports.
In equestrian sports, Portugal won the only Horseball-Pato World Championship (in 2006), achieved the third position in the First Horseball World Cup (organized in Ponte de Lima, Portugal, in 2008), and has achieved several victories in the European Working Equitation Championship.
In water sports, Portugal has two major sports: swimming and water polo. Northern Portugal has its own original martial art, "Jogo do Pau", in which the fighters use staffs to confront one or several opponents. Other popular sport-related recreational outdoor activities with thousands of enthusiasts nationwide include airsoft, fishing, golf, hiking, hunting and orienteering.

</doc>
<doc id="23034" url="https://en.wikipedia.org/wiki?curid=23034" title="Piano">
Piano

The piano (; an abbreviation of pianoforte ) is a musical instrument played using a keyboard. It is widely employed in classical and jazz music for solo and ensemble performances, accompaniment, and for composing and rehearsal. Although the piano is not portable and often expensive, its versatility and ubiquity have made it one of the world's most familiar musical instruments.
An acoustic piano usually has a protective wooden case surrounding the soundboard and metal strings, and a row of 88 black and white keys (52 white, 36 black). The strings are sounded when the keys are pressed, and silenced when the keys are released. The note can be sustained, even when the keys are released, by the use of pedals.
Pressing a key on the piano's keyboard causes a padded (often with felt) hammer to strike strings. The hammer rebounds, and the strings continue to vibrate at their resonant frequency. These vibrations are transmitted through a bridge to a soundboard that amplifies by more efficiently coupling the acoustic energy to the air. When the key is released, a damper stops the strings' vibration, ending the sound. Although an acoustic piano has strings, it is usually classified as a percussion instrument because the strings are struck rather than plucked (as with a harpsichord or spinet); in the Hornbostel-Sachs system of instrument classification, pianos are considered chordophones. With technological advances, electric, electronic, and digital pianos have also been developed.
The word "piano" is a shortened form of "pianoforte", the Italian term for the instrument, which in turn derives from "gravicembalo col piano e forte" and "fortepiano". The Italian musical terms "piano" and "forte" indicate "soft" and "loud" respectively, in this context referring to the variations in volume produced in response to a pianist's touch on the keys: the greater the velocity of a key press, the greater the force of the hammer hitting the strings, and the louder the sound of the note produced.
History.
The piano was founded on earlier technological innovations. The first string instruments with struck strings were the hammered dulcimers. During the Middle Ages, there were several attempts at creating stringed keyboard instruments with struck strings. By the 17th century, the mechanisms of keyboard instruments such as the clavichord and the harpsichord were well known. In a clavichord, the strings are struck by tangents, while in a harpsichord they are plucked by quills. Centuries of work on the mechanism of the harpsichord in particular had shown the most effective ways to construct the case, soundboard, bridge, and keyboard for a mechanism intended to hammer strings.
Invention.
The invention of the modern piano is credited to Bartolomeo Cristofori (1655–1731) of Padua, Italy, who was employed by Ferdinando de' Medici, Grand Prince of Tuscany, as the Keeper of the Instruments; he was an expert harpsichord maker, and was well acquainted with the body of knowledge on stringed keyboard instruments. It is not known exactly when Cristofori first built a piano. An inventory made by his employers, the Medici family, indicates the existence of a piano by the year 1700; another document of doubtful authenticity indicates a date of 1698. The three Cristofori pianos that survive today date from the 1720s.
Cristofori named the instrument "un cimbalo di cipresso di piano e forte" ("a keyboard of cypress with soft and loud"), abbreviated over time as "pianoforte", "fortepiano", and simply, piano. While the clavichord allowed expressive control of volume and sustain, it was too quiet for large performances. The harpsichord produced a sufficiently loud sound, but offered little expressive control over each note. The piano offered the best of both, combining loudness with dynamic control.
Cristofori's great success was solving, with no prior example, the fundamental mechanical problem of piano design: the hammer must strike the string, but not remain in contact with it (as a tangent remains in contact with a clavichord string) because this would damp the sound. Moreover, the hammer must return to its rest position without bouncing violently, and it must be possible to repeat a note rapidly. Cristofori's piano action was a model for the many approaches to piano actions that followed. Cristofori's early instruments were made with thin strings, and were much quieter than the modern piano, but much louder and with more sustain in comparison to the clavichord—the only previous keyboard instrument capable of dynamic nuance via the keyboard.
The early fortepiano.
Cristofori's new instrument remained relatively unknown until an Italian writer, Scipione Maffei, wrote an enthusiastic article about it in 1711, including a diagram of the mechanism, that was translated into German and widely distributed. Most of the next generation of piano builders started their work due to reading it. One of these builders was Gottfried Silbermann, better known as an organ builder. Silbermann's pianos were virtually direct copies of Cristofori's, with one important addition: Silbermann invented the forerunner of the modern sustain pedal, which lifts all the dampers from the strings simultaneously.
Silbermann showed Johann Sebastian Bach one of his early instruments in the 1730s, but Bach did not like it at that time, claiming that the higher notes were too soft to allow a full dynamic range. Although this earned him some animosity from Silbermann, the criticism was apparently heeded. Bach did approve of a later instrument he saw in 1747, and even served as an agent in selling Silbermann's pianos.
Piano-making flourished during the late 18th century in the Viennese school, which included Johann Andreas Stein (who worked in Augsburg, Germany) and the Viennese makers Nannette Streicher (daughter of Stein) and Anton Walter. Viennese-style pianos were built with wood frames, two strings per note, and had leather-covered hammers. Some of these Viennese pianos had the opposite coloring of modern-day pianos; the natural keys were black and the accidental keys white. It was for such instruments that Wolfgang Amadeus Mozart composed his concertos and sonatas, and replicas of them are built today for use in authentic-instrument performance of his music. The pianos of Mozart's day had a softer, more ethereal tone than today's pianos or English pianos, with less sustaining power. The term "fortepiano" is now used to distinguish these early instruments from later pianos.
The modern piano.
In the period lasting from about 1790 to 1860, the Mozart-era piano underwent tremendous changes that led to the modern form of the instrument. This revolution was in response to a preference by composers and pianists for a more powerful, sustained piano sound, and made possible by the ongoing Industrial Revolution with resources such as high-quality piano wire for strings, and precision casting for the production of iron frames. Over time, the tonal range of the piano was also increased from the five octaves of Mozart's day to the 7-plus range found on modern pianos.
Early technological progress owed much to the firm of Broadwood. John Broadwood joined with another Scot, Robert Stodart, and a Dutchman, Americus Backers, to design a piano in the harpsichord case—the origin of the "grand". They achieved this in about 1777. They quickly gained a reputation for the splendour and powerful tone of their instruments, with Broadwood constructing ones that were progressively larger, louder, and more robustly constructed. They sent pianos to both Joseph Haydn and Ludwig van Beethoven, and were the first firm to build pianos with a range of more than five octaves: five octaves and a fifth (interval) during the 1790s, six octaves by 1810 (Beethoven used the extra notes in his later works), and seven octaves by 1820. The Viennese makers similarly followed these trends; however the two schools used different piano actions: Broadwoods were more robust, Viennese instruments were more sensitive.
By the 1820s, the center of innovation had shifted to Paris, where the Pleyel firm manufactured pianos used by Frédéric Chopin and the Érard firm manufactured those used by Franz Liszt. In 1821, Sébastien Érard invented the double escapement action, which incorporated a "repetition lever" (also called the "balancier") that permitted repeating a note even if the key had not yet risen to its maximum vertical position. This facilitated rapid playing of repeated notes, a musical device exploited by Liszt. When the invention became public, as revised by Henri Herz, the double escapement action gradually became standard in grand pianos, and is still incorporated into all grand pianos currently produced.
Other improvements of the mechanism included the use of felt hammer coverings instead of layered leather or cotton. Felt, which was first introduced by Jean-Henri Pape in 1826, was a more consistent material, permitting wider dynamic ranges as hammer weights and string tension increased. The sostenuto pedal (see below), invented in 1844 by Jean-Louis Boisselot and copied by the Steinway firm in 1874, allowed a wider range of effects.
One innovation that helped create the sound of the modern piano was the use of a strong iron frame. Also called the "plate", the iron frame sits atop the soundboard, and serves as the primary bulwark against the force of string tension that can exceed 20 tons in a modern grand. The single piece cast iron frame was patented in 1825 in Boston by Alpheus Babcock, combining the metal hitch pin plate (1821, claimed by Broadwood on behalf of Samuel Hervé) and resisting bars (Thom and Allen, 1820, but also claimed by Broadwood and Érard). Babcock later worked for the Chickering & Mackays firm who patented the first full iron frame for grand pianos in 1843. Composite forged metal frames were preferred by many European makers until the American system was fully adopted by the early 20th century.
The increased structural integrity of the iron frame allowed the use of thicker, tenser, and more numerous strings. In 1834, the Webster & Horsfal firm of Birmingham brought out a form of piano wire made from cast steel; according to Dolge it was "so superior to the iron wire that the English firm soon had a monopoly." But a better steel wire was soon created in 1840 by the Viennese firm of Martin Miller, and a period of innovation and intense competition ensued, with rival brands of piano wire being tested against one another at international competitions, leading ultimately to the modern form of piano wire.
Other important advances included changes to the way the piano is strung, such as the use of a "choir" of three strings rather than two for all but the lowest notes, and the implementation of an over-strung scale, in which the strings are placed in two separate planes, each with its own bridge height. (This is also called "cross-stringing". Whereas earlier instruments' bass strings were a mere continuation of a single string plane, over-stringing placed the bass bridge behind and to the treble side of the tenor bridge area. This "crossed" the strings, with the bass strings in the higher plane.) This permitted a much narrower cabinet at the "nose" end of the piano, and optimized the transition from unwound tenor strings to the iron or copper-wrapped bass strings. Over-stringing was invented by Pape during the 1820s, and first patented for use in grand pianos in the United States by Henry Steinway, Jr. in 1859.
Some piano makers developed schemes to enhance the tone of each note. Julius Blüthner developed Aliquot stringing in 1893 as well as Pascal Taskin (1788), and Collard & Collard (1821). Each used more distinctly ringing, undamped vibrations to modify tone, except the Blüthner Aliquot stringing, which uses an additional fourth string in the upper two treble sections. While the hitchpins of these separately suspended Aliquot strings are raised slightly above the level of the usual tri-choir strings, they are not struck by the hammers but rather are damped by attachments of the usual dampers. Eager to copy these effects, Theodore Steinway invented "duplex scaling", which used short lengths of non-speaking wire bridged by the aliquot throughout much of upper the range of the piano, always in locations that caused them to vibrate in conformity with their respective overtones—typically in doubled octaves and twelfths.
The mechanical action structure of the upright piano was invented in London, England in 1826 by Robert Wornum, and upright models became the most popular model, also amplifying the sound.
Variations in shape and design.
Some early pianos had shapes and designs that are no longer in use. The square piano (not truly square, but rectangular) was cross strung at an extremely acute angle above the hammers, with the keyboard set along the long side. This design is attributed to Gottfried Silbermann or Christian Ernst Friderici on the continent, and Johannes Zumpe or Harman Vietor in England, and it was improved by changes first introduced by Guillaume-Lebrecht Petzold in France and Alpheus Babcock in the United States. Square pianos were built in great numbers through the 1840s in Europe and the 1890s in the United States, and saw the most visible change of any type of piano: the iron-framed, over-strung squares manufactured by Steinway & Sons were more than two-and-a-half times the size of Zumpe's wood-framed instruments from a century before. Their overwhelming popularity was due to inexpensive construction and price, although their tone and performance were limited by narrow soundboards, simple actions and string spacing that made proper hammer alignment difficult.
The tall, vertically strung upright grand was arranged like a grand set on end, with the soundboard and bridges above the keys, and tuning pins below them. The term was later revived by many manufacturers for advertising purposes. Giraffe, pyramid and lyre pianos were arranged in a somewhat similar fashion in evocatively shaped cases.
The very tall cabinet piano was introduced about 1805 and was built through the 1840s. It had strings arranged vertically on a continuous frame with bridges extended nearly to the floor, behind the keyboard and very large "sticker action". The short cottage upright or "pianino" with vertical stringing, made popular by Robert Wornum around 1815, was built into the 20th century. They are informally called "birdcage pianos" because of their prominent damper mechanism. The oblique upright, popularized in France by Roller & Blanchet during the late 1820s, was diagonally strung throughout its compass. The tiny spinet upright was manufactured from the mid-1930s until recent times. The low position of the hammers required the use of a "drop action" to preserve a reasonable keyboard height.
Modern upright and grand pianos attained their present forms by the end of the 19th century. Improvements have been made in manufacturing processes, and many individual details of the instrument continue to receive attention.
Types.
Modern acoustic pianos have two basic configurations, the grand piano and the upright piano, with various styles of each. There are also specialized and novelty pianos, electric pianos based on electromechanical designs, electronic pianos that synthesize piano-like tones using oscillators, and digital pianos using digital samples of acoustic piano sounds.
Grand.
In grand pianos, the frame and strings are horizontal, with the strings extending away from the keyboard. The action lies beneath the strings, and uses gravity as its means of return to a state of rest.
There are many sizes of grand piano. A rough generalization distinguishes the "concert grand" (between 2.2 and 3 meters long, about –) from the "parlor grand" or "boudoir grand" (1.7 to 2.2 meters long, about –) and the smaller "baby grand" (around ).
All else being equal, longer pianos with longer strings have larger, richer sound and lower inharmonicity of the strings. Inharmonicity is the degree to which the frequencies of overtones (known as partials or harmonics) sound sharp relative to whole multiples of the fundamental frequency. This results from the piano's considerable string stiffness; as a struck string decays its harmonics vibrate, not from their termination, but from a point very slightly toward the center (or more flexible part) of the string. The higher the partial, the further sharp it runs. Pianos with shorter and thicker string (i.e., small pianos with short string scales) have more inharmonicity. The greater the inharmonicity, the more the ear perceives it as harshness of tone.
Inharmonicity requires that octaves be "stretched," or tuned to a lower octave's corresponding sharp overtone rather than to a theoretically correct octave. If octaves are not stretched, single octaves sound in tune, but double—and notably triple—octaves are unacceptably narrow. Stretching a small piano's octaves to match its inherent inharmonicity level creates an imbalance among all the instrument's intervallic relationships, not just its octaves. In a concert grand, however, the octave "stretch" retains harmonic balance, even when aligning treble notes to a harmonic produced from three octaves below. This lets close and widespread octaves sound pure, and produces virtually beatless perfect fifths. This gives the concert grand a brilliant, singing and sustaining tone quality—one of the principal reasons that full-size grands are used in the concert hall. Smaller grands satisfy the space and cost needs of domestic use.
Upright (vertical).
Upright pianos, also called vertical pianos, are more compact because the frame and strings are vertical. The hammers move horizontally, and return to their resting position via springs, which are susceptible to degradation. Upright pianos with unusually tall frames and long strings are sometimes called "upright grand" pianos. Some authors classify modern pianos according to their height and to modifications of the action that are necessary to accommodate the height.
Specialized.
The toy piano, introduced in the 19th century, is a small piano-like instrument, that generally uses round metal rods to produce sound, rather than strings. The US Library of Congress recognizes the toy piano as a unique instrument with the subject designation, Toy Piano Scores: M175 T69.
In 1863, Henri Fourneaux invented the player piano, which plays itself from a piano roll. A machine perforates a performance recording into rolls of paper, and the player piano replays the performance using pneumatic devices. Modern equivalents of the player piano include the Bösendorfer CEUS, Yamaha Disklavier and QRS Pianomation, using solenoids and MIDI rather than pneumatics and rolls.
A silent piano is an acoustic piano having an option to silence the strings by means of an interposing hammer bar. They are designed for private silent practice.
Edward Ryley invented the transposing piano in 1801. It has a lever under the keyboard as to move the keyboard relative to the strings so a pianist can play in a familiar key while the music sounds in a different key.
The minipiano, an instrument patented by the Brasted brothers of the Eavestaff Ltd. piano company, was patented in 1934. This instrument has a braceless back, and a soundboard positioned below the keys—meaning that long metal rods pulled on the levers to make the hammers strike the strings. The first model, known as the "Pianette,"' was unique in that the tuning pins extended through the instrument, so it could be tuned at the front.
The prepared piano, present in some contemporary art music, is a piano with objects placed inside it to alter its sound, or has had its mechanism changed in some other way. The scores for music for prepared piano specify the modifications, for example instructing the pianist to insert pieces of rubber, paper, metal screws, or washers in between the strings. These either mute the strings or alter their timbre. A harpsichord-like sound can be produced by placing or dangling small metal buttons in front of the hammer.
In 1954 a German company exhibited a wire-less piano at the Spring Fair in Frankfurt, Germany that sold for $238. The wires were replaced by metal bars of different alloys that replicated the standard wires when played. A similar concept is used in the electric-acoustic Rhodes piano.
Electric, electronic, and digital.
Electric pianos have conventional strings but use electromagnetic pickups similar to those on an electric guitar. The resulting electrical, analogue signal can then be amplified or electronically manipulated if required. Electric pianos are uncommon.
Electronic pianos are non-acoustic, they do not have strings but are a simple type of synthesizer that simulates piano sounds using oscillators.
Digital pianos are also non-acoustic and do not have strings but use digital sampling technology to reproduce the sound of each piano note. Digital pianos can include pedals, weighted keys, multiple voices, and MIDI interfaces. Early digital pianos tended to lack a full set of pedals but the synthesis software of later models such as the Yamaha Clavinova series synthesised the sympathetic vibration of the other strings and full pedal sets can now be replicated. The processing power of digital pianos has enabled highly realistic pianos using multi-gigabyte piano sample sets with as many as ninety recordings, each lasting many seconds, for each key under different conditions. Additional samples emulate sympathetic resonance, key release, the drop of the dampers, and simulations of techniques such as re-pedalling.
Digital, MIDI compliant, pianos can output a stream of MIDI data, or record and play via a CDROM or USB flash drive using MIDI format files, similar in concept to a pianola. The MIDI file records the physics of a note rather than its resulting sound and recreates the sounds from its physical properties. Computer based software, such as Modartt's 2006 Pianoteq, can be used to manipulate the MIDI stream in real time or subsequently to edit it. This type of software may use no samples but synthesise a sound based on aspects of the physics that went into the creation of a played note.
Construction and components.
Pianos can have upwards of 12,000 individual parts, supporting six functional features: keyboard, hammers, dampers, bridge, soundboard, and strings.
Many parts of a piano are made of materials selected for strength and longevity. This is especially true of the outer rim. It is most commonly made of hardwood, typically hard maple or beech, and its massiveness serves as an essentially immobile object from which the flexible soundboard can best vibrate. According to Harold A. Conklin, the purpose of a sturdy rim is so that, "... the vibrational energy will stay as much as possible in the soundboard instead of dissipating uselessly in the case parts, which are inefficient radiators of sound."
Hardwood rims are commonly made by laminating thin, hence flexible, strips of hardwood, bending them to the desired shape immediately after the application of glue. The bent plywood system was developed by C.F. Theodore Steinway in 1880 to reduce manufacturing time and costs. Previously, the rim was constructed from several pieces of solid wood, joined and veneered, and this method continued to be used in Europe well into the 20th century. A modern exception, Bösendorfer, the Austrian manufacturer of high-quality pianos, constructs their inner rims from solid spruce, the same wood that the soundboard is made from, which is notched to allow it to bend; rather than isolating the rim from vibration, their "resonance case principle" allows the framework to more freely resonate with the soundboard, creating additional coloration and complexity of the overall sound.
The thick wooden posts on the underside (grands) or back (uprights) of the piano stabilize the rim structure, and are made of softwood for stability. The requirement of structural strength, fulfilled by stout hardwood and thick metal, makes a piano heavy. Even a small upright can weigh 136 kg (300 lb), and the Steinway concert grand (Model D) weighs 480 kg (990 lb). The largest piano available on the general market, the Fazioli F308, weighs 570 kg (1257 lb).
The pinblock, which holds the tuning pins in place, is another area where toughness is important. It is made of hardwood (typically hard maple or beech), and is laminated for strength, stability and longevity. Piano strings (also called piano wire), which must endure years of extreme tension and hard blows, are made of high carbon steel. They are manufactured to vary as little as possible in diameter, since all deviations from uniformity introduce tonal distortion. The bass strings of a piano are made of a steel core wrapped with copper wire, to increase their mass whilst retaining flexibility. If all strings throughout the piano's compass were individual (monochord), the massive bass strings would overpower the upper ranges. Makers compensate for this with the use of double (bichord) strings in the tenor and triple (trichord) strings throughout the treble.
The plate (harp), or metal frame, of a piano is usually made of cast iron. A massive plate is advantageous. Since the strings vibrate from the plate at both ends, an insufficiently massive plate would absorb too much of the vibrational energy that should go through the bridge to the soundboard. While some manufacturers use cast steel in their plates, most prefer cast iron. Cast iron is easy to cast and machine, has flexibility sufficient for piano use, is much more resistant to deformation than steel, and is especially tolerant of compression. Plate casting is an art, since dimensions are crucial and the iron shrinks about one percent during cooling.
Including an extremely large piece of metal in a piano is potentially an aesthetic handicap. Piano makers overcome this by polishing, painting, and decorating the plate. Plates often include the manufacturer's ornamental medallion. In an effort to make pianos lighter, Alcoa worked with Winter and Company piano manufacturers to make pianos using an aluminum plate during the 1940s. Aluminum piano plates were not widely accepted, and were discontinued.
The numerous parts of a piano action are generally made from hardwood, such as maple, beech, and hornbeam, however, since World War II, makers have also incorporated plastics. Early plastics used in some pianos in the late 1940s and 1950s, proved disastrous when they lost strength after a few decades of use. Beginning in 1961, the New York branch of the Steinway firm incorporated Teflon, a synthetic material developed by DuPont, for some parts of its Permafree grand action in place of cloth bushings, but abandoned the experiment in 1982 due to excessive friction and a "clicking" that developed over time; Teflon is "humidity stable" whereas the wood adjacent to the Teflon swells and shrinks with humidity changes, causing problems. More recently, the Kawai firm built pianos with action parts made of more modern materials such as carbon fiber reinforced plastic, and the piano parts manufacturer Wessell, Nickel and Gross has launched a new line of carefully engineered composite parts. Thus far these parts have performed reasonably, but it will take decades to know if they equal the longevity of wood.
In all but the poorest pianos the soundboard is made of solid spruce (that is, spruce boards glued together along the side grain). Spruce's high ratio of strength to weight minimizes acoustic impedance while offering strength sufficient to withstand the downward force of the strings. The best piano makers use quarter-sawn, defect-free spruce of close annular grain, carefully seasoning it over a long period before fabricating the soundboards. This is the identical material that is used in quality acoustic guitar soundboards. Cheap pianos often have plywood soundboards.
Keyboard.
In the early years of piano construction, keys were commonly made from sugar pine. Today they are usually made of spruce or basswood. Spruce is typically used in high-quality pianos. Black keys were traditionally made of ebony, and the white keys were covered with strips of ivory. However, since ivory-yielding species are now endangered and protected by treaty, makers use plastics almost exclusively. Also, ivory tends to chip more easily than plastic. Legal ivory can still be obtained in limited quantities. The Yamaha firm invented a plastic called "Ivorite" that they claim mimics the look and feel of ivory. It has since been imitated by other makers.
Almost every modern piano has 52 white keys and 36 black keys for a total of 88 keys (seven octaves plus a minor third, from A0 to C8). Many older pianos only have 85 keys (seven octaves from A0 to A7). Some piano manufacturers extend the range further in one or both directions.
Some Bösendorfer pianos, for example, extend the normal range down to F0, and one of their models which has 97 keys even goes as far as a bottom C0, making a full eight octave range. These extra keys are sometimes hidden under a small hinged lid that can cover the keys to prevent visual disorientation for pianists unfamiliar with the extra keys, or the colors of the extra white keys are reversed (black instead of white).
The extra keys are added primarily for increased resonance from the associated strings; that is, they vibrate sympathetically with other strings whenever the damper pedal is depressed and thus give a fuller tone. Only a very small number of works composed for piano actually use these notes. More recently, the Stuart and Sons company has also manufactured extended-range pianos, with the first 102 key piano. On their instruments, the frequency range extends from C0 to F8, which is the widest practical range for the acoustic piano. The extra keys are the same as the other keys in appearance.
Small studio upright acoustical pianos with only 65 keys have been manufactured for use by roving pianists. Known as "gig" pianos and still containing a cast iron harp (frame), these are comparatively lightweight and can be easily transported to and from engagements by only two people. As their harp is longer than that of a spinet or console piano, they have a stronger bass sound that to some pianists is well worth the trade-off in range that a reduced key-set offers.
The toy piano manufacturer Schoenhut started manufacturing both grands and uprights with only 44 or 49 keys, and shorter distance between the keyboard and the pedals. These pianos are true pianos with action and strings. The pianos were introduced to their product line in response to numerous requests in favor of it.
There is a rare variants of piano that has double keyboards called the "Emánuel Moór Pianoforte". It was invented by Hungarian composer and pianist, Emánuel Moór (19 February 1863 – 20 October 1931). It consisted of two keyboards lying one above each other. The lower keyboard has the usual 88 keys and the upper keyboard has 76 keys. When pressing the upper keyboard the internal mechanism pulls down the corresponding key on the lower keyboard, but an octave higher. This allow pianist to easily reach two octave with one hand which was impossible to do so on a conventional piano. Due to its double keyboard musical work that were originally created for double-manual Harpsichord such as Goldberg Variations by Bach become much easier to play, since playing on a conventional single keyboard piano involve complex and hand-tangling cross-hand movements. The design also featured a special forth pedal which pair the lower keyboard with upper keyboard, so when playing on the lower keyboard the note one octave higher would also be played as if the pianist had also pressed the upper keyboard. Only about 60 Emánuel Moór Pianoforte were made, mostly manufactured by Bösendorfer. Other piano manufactures such as Bechstein, Chickering, and Steinway & Sons had also manufactured a few.
Pianos have been built with alternative keyboard systems, e.g., the Jankó keyboard.
Pedals.
Pianos have had pedals, or some close equivalent, since the earliest days. (In the 18th century, some pianos used levers pressed upward by the player's knee instead of pedals.) Most grand pianos in the US have three pedals: the soft pedal (una corda), sostenuto, and sustain pedal (from left to right, respectively), while in Europe, the standard is two pedals: the soft pedal and the sustain pedal. Most modern upright pianos also have three pedals: soft pedal, practice pedal and sustain pedal, though older or cheaper models may lack the practice pedal. In Europe the standard for upright pianos is two pedals: the soft and the sustain pedals.
The sustain pedal (or, damper pedal) is often simply called "the pedal", since it is the most frequently used. It is placed as the rightmost pedal in the group. It lifts the dampers from all keys, sustaining all played notes. In addition, it alters the overall tone by allowing all strings, including those not directly played, to reverberate.
The soft pedal or "una corda" pedal is placed leftmost in the row of pedals. In grand pianos it shifts the entire action/keyboard assembly to the right (a very few instruments have shifted left) so that the hammers hit two of the three strings for each note. In the earliest pianos whose unisons were bichords rather than trichords, the action shifted so that hammers hit a single string, hence the name "una corda", or 'one string'. The effect is to soften the note as well as change the tone. In uprights this action is not possible; instead the pedal moves the hammers closer to the strings, allowing the hammers to strike with less kinetic energy. This produces a slightly softer sound, but no change in timbre.
On grand pianos, the middle pedal is a sostenuto pedal. This pedal keeps raised any damper already raised at the moment the pedal is depressed. This makes it possible to sustain selected notes (by depressing the sostenuto pedal before those notes are released) while the player's hands are free to play additional notes (which aren't sustained). This can be useful for musical passages with pedal points and other otherwise tricky or impossible situations.
On many upright pianos, the middle pedal is called the "practice" or "celeste" pedal. This drops a piece of felt between the hammers and strings, greatly muting the sounds. This pedal can be shifted while depressed, into a "locking" position.
There are also non-standard variants. On some pianos (grands and verticals), the middle pedal can be a bass sustain pedal: that is, when it is depressed, the dampers lift off the strings only in the bass section. Players use this pedal to sustain a single bass note or chord over many measures, while playing the melody in the treble section. On the Stuart and Sons piano as well as the largest Fazioli piano, there is a fourth pedal to the left of the principal three. This fourth pedal works in the same way as the soft pedal of an upright piano, moving the hammers closer to the strings.
The rare transposing piano (an example of which was owned by Irving Berlin) has a middle pedal that functions as a clutch that disengages the keyboard from the mechanism, so the player can move the keyboard to the left or right with a lever. This shifts the entire piano action so the pianist can play music written in one key so that it sounds in a different key.
Some piano companies have included extra pedals other than the standard two or three. Crown and Schubert Piano Co. produced a four-pedal piano. Fazioli currently offers a fourth pedal that provides a second soft pedal, that works by bringing the keys closer to the strings.
Wing and Son of New York offered a five-pedal piano from approximately 1893 through the 1920s. There is no mention of the company past the 1930s. Labeled left to right, the pedals are Mandolin, Orchestra, Expression, Soft, and Forte (Sustain). The Orchestral pedal produced a sound similar to a tremolo feel by bouncing a set of small beads dangling against the strings, enabling the piano to mimic a mandolin, guitar, banjo, zither and harp, thus the name Orchestral. The Mandolin pedal used a similar approach, lowering a set of felt strips with metal rings in between the hammers and the strings ( aka rinky-tink effect). This extended the life of the hammers when the Orch pedal was used, a good idea for practicing, and created an echo-like sound that mimicked playing in an orchestral hall.
The "pedalier" piano, or pedal piano, is a rare type of piano that includes a pedalboard so players can user their feet to play bass register notes, as on an organ. There are two types of pedal piano. On one, the pedal board is an integral part of the instrument, using the same strings and mechanism as the manual keyboard. The other, rarer type, consists of two independent pianos (each with separate mechanics and strings) placed one above the other—one for the hands and one for the feet. This was developed primarily as a practice instrument for organists, though there is a small repertoire written specifically for the instrument.
Mechanics.
When the key is struck, a chain reaction occurs to produce the sound. First, the key raises the wippen, which forces the jack against the hammer roller (or "knuckle"). The hammer roller then lifts the lever carrying the hammer. The key also raises the damper; and immediately after the hammer strikes the wire it falls back, allowing the wire to resonate. When the key is released the damper falls back onto the strings, stopping the wire from vibrating. The vibrating piano strings themselves are not very loud, but their vibrations are transmitted to a large soundboard that moves air and thus converts the energy to sound.
The irregular shape and off-center placement of the bridge ensure that the soundboard vibrates strongly at all frequencies. (See Piano action for a diagram and detailed description of piano parts.)
There are three factors that influence the pitch of a vibrating wire.
A vibrating wire subdivides itself into many parts vibrating at the same time. Each part produces a pitch of its own, called a partial. A vibrating string has one fundamental and a series of partials. The most pure combination of two pitches is when one is double the frequency of the other.
For a repeating wave, the velocity equals the wavelength times the frequency ,
On the piano string, waves reflect from both ends. The superposition of reflecting waves results in a standing wave pattern, but only for wavelengths , where is the length of the string. Therefore, the only frequencies produced on a single string are . Timbre is largely determined by the content of these harmonics. Different instruments have different harmonic content for the same pitch. A real string vibrates at harmonics that are not perfect multiples of the fundamental. This results in a little inharmonicity, which gives richness to the tone but causes significant tuning challenges throughout the compass of the instrument.
Striking the piano key with greater velocity increases the amplitude of the waves and therefore the volume. From "pianissimo" ("pp") to "fortissimo" ("ff") the hammer velocity changes by almost a factor of a hundred. The hammer contact time with the string shortens from 4 ms at "pp" to less than 2 ms at "ff". If two wires adjusted to the same pitch are struck at the same time, the sound produced by one reinforces the other, and a louder combined sound of shorter duration is produced. If one wire vibrates out of synchronization with the other, they subtract from each other and produce a softer tone of longer duration.
Maintenance.
Pianos are heavy yet delicate instruments. Over the years, professional piano movers have developed special techniques for transporting both grands and uprights, which prevent damage to the case and to the piano's mechanics. Pianos need regular tuning to keep them on pitch. The hammers of pianos are voiced to compensate for gradual hardening, and other parts also need periodic regulation. Aged and worn pianos can be rebuilt or reconditioned. Often, by replacing a great number of their parts, they can perform as well as new pianos.
Tuning.
Piano tuning involves adjusting the tensions of the piano's strings, thereby aligning the intervals among their tones so that the instrument is in tune. The meaning of the term "in tune" in the context of piano tuning is not simply a particular fixed set of pitches. Fine piano tuning carefully assesses the interaction among all notes of the chromatic scale, different for every piano, and thus requires slightly different pitches from any theoretical standard. Pianos are usually tuned to a modified version of the system called equal temperament ("see Piano key frequencies for the theoretical piano tuning"). In all systems of tuning, each pitch is derived from its relationship to a chosen fixed pitch, usually the internationally recognized standard concert pitch of A440.
The relationship between two pitches, called an interval, is the ratio of their absolute frequencies. Two different intervals are perceived as the same when the pairs of pitches involved share the same frequency ratio. The easiest intervals to identify, and the easiest intervals to tune, are those that are just, meaning they have a simple whole-number ratio. The term "temperament" refers to a tuning system that tempers the just intervals (usually the perfect fifth, which has the ratio 3:2) to satisfy another mathematical property; in equal temperament, a fifth is tempered by narrowing it slightly, achieved by flattening its upper pitch slightly, or raising its lower pitch slightly. A temperament system is also known as a set of bearings.
Tempering an interval causes it to beat, which is a fluctuation in perceived sound intensity due to interference between close (but unequal) pitches. The rate of beating is equal to the frequency differences of any harmonics that are present for both pitches and that coincide or nearly coincide.
Playing and technique.
As with any other musical instrument, the piano may be played from written music, by ear, or through improvisation. Piano technique evolved during the transition from harpsichord and clavichord to fortepiano playing, and continued through the development of the modern piano. Changes in musical styles and audience preferences, as well as the emergence of virtuoso performers contributed to this evolution, and to the growth of distinct approaches or schools of piano playing. Although technique is often viewed as only the physical execution of a musical idea, many pedagogues and performers stress the interrelatedness of the physical and mental or emotional aspects of piano playing.
Well-known approaches to piano technique include those by Dorothy Taubman, Edna Golandsky, Fred Karpoff, and Otto Ortmann.
Performance styles.
Many classical music composers, including Haydn, Mozart, and Beethoven, composed for the fortepiano, a rather different instrument than the modern piano. Even composers of the Romantic movement, like Liszt, Chopin, Robert Schumann, Felix Mendelssohn, and Johannes Brahms, wrote for pianos substantially different from modern pianos. Contemporary musicians may adjust their interpretation of historical compositions to account for sound quality differences between old and new instruments.
Starting in Beethoven's later career, the fortepiano evolved into the modern piano as we know it today. Modern pianos were in wide use by the late 19th century. They featured an octave range larger than the earlier fortepiano instrument, adding around 30 more keys to the instrument. Factory mass production of upright pianos made them more affordable for a larger number of people. They appeared in music halls and pubs during the 19th century, providing entertainment through a piano soloist, or in combination with a small band. Pianists began accompanying singers or dancers performing on stage, or patrons dancing on a dance floor.
During the 19th century, American musicians playing for working-class audiences in small pubs and bars, particularly African-American composers, developed new musical genres based on the modern piano. Ragtime music, popularized by composers such as Scott Joplin, reached a broader audience by 1900. The popularity of ragtime music was quickly succeeded by Jazz piano. New techniques and rhythms were invented for the piano, including ostinato for boogie-woogie, and Shearing voicing. George Gershwin's Rhapsody in Blue broke new musical ground by combining American jazz piano with symphonic sounds. Comping, a technique for accompanying jazz vocalists on piano, was exemplified by Duke Ellington's technique. Honky-tonk music, featuring yet another style of piano rhythm, became popular during the same era. Bebop techniques grew out of jazz, with leading composers such as Thelonious Monk and Bud Powell. In the late 20th century, Bill Evans composed pieces combining classical techniques with his jazz experimentation. Herbie Hancock was one of the first jazz pianists to find mainstream popularity working with newer urban music techniques.
Pianos have also been used prominently in rock and roll by entertainers such as Jerry Lee Lewis, Little Richard, Keith Emerson (Emerson, Lake & Palmer), Elton John, Ben Folds, Billy Joel, Nicky Hopkins, and Tori Amos, to name a few.
Modernist styles of music have also appealed to composers writing for the modern grand piano, including John Cage and Philip Glass.
Role.
The piano is a crucial instrument in Western classical music, jazz, film, television, and most other complex western musical genres. A large number of composers are proficient pianists—and because the piano keyboard offers an easy means of complex melodic and harmonic interplay—the piano is often used as a tool for composition.
References.
General.
Most of the information in this article can be found in the following published works:

</doc>
<doc id="23035" url="https://en.wikipedia.org/wiki?curid=23035" title="Pamela Anderson">
Pamela Anderson

Pamela Denise Anderson (born July 1, 1967) is a Canadian-American actress. In addition to her acting career, she is also a model, producer, author, activist and a former showgirl, known for her roles on the television series "Home Improvement", "Baywatch" and "V.I.P.". She was chosen as a Playmate of the Month for "Playboy" magazine in February 1990. For a time, she was known as Pamela Anderson Lee (or Pamela Lee) after marrying Mötley Crüe drummer Tommy Lee. Anderson is a member of the animal rights movement and has conducted campaigns condemning the commercial fur industry and promoting veganism through the animal rights organization People for the Ethical Treatment of Animals (PETA). In 2006, she was inducted into Canada's Walk of Fame.
She maintains dual Canadian and American citizenship.
Early life.
Anderson was born in Ladysmith, British Columbia, the daughter of Barry, a furnace repairman, and Carol (née Grosco) Anderson, a waitress. Her great-grandfather, Juho Hyytiäinen, was Finnish, a native of Saarijärvi, and left the Grand Duchy of Finland (which was a part of the Russian Empire at the time) in 1908. He changed his name to Anderson when he arrived as an immigrant. Anderson also has Russian ancestry on her mother's side.
Anderson got some press coverage right after her birth as the country's "Centennial Baby", having been the first baby born on July 1, 1967, the 100th anniversary of Canada's official founding via the Constitution Act, 1867.
Anderson suffered frequent sexual abuse as a child, a fact she would not reveal publicly until 2014: she was molested by a female babysitter from ages 6 to 10, raped by a 25-year-old man when she was twelve, and gang-raped by her boyfriend and six of his friends when she was 14. She also revealed that her father, though "loving", had been an alcoholic.
Anderson attended Highland Secondary School in Comox, British Columbia. During high school, she played on the volleyball team. She graduated in 1985. In 1988, Anderson moved to Vancouver and worked as a fitness instructor.
Career.
Discovery.
In 1989, Anderson attended a BC Lions Canadian Football League game at the BC Place Stadium in Vancouver, where she was featured on the Jumbotron while wearing a Labatt's Beer t-shirt. The brewing company hired Anderson briefly as a spokesmodel. Inspired by that event, her then-boyfriend Dan Ilicic produced a poster of her image, entitled the "Blue Zone Girl".
"Playboy" magazine career.
Anderson appeared as the cover girl on "Playboy" magazine's October 1989 issue. She moved to Los Angeles to further pursue a modeling career. "Playboy" subsequently chose her as Playmate of the Month in their February 1990 issue, in which she appeared in the centerfold photo. Anderson then elected to have breast implant surgery, increasing her bust size to 34D. She famously increased her bust size again, to 34DD, several years later. Anderson has since appeared in "Playboy" several times in the 1990s and the 2000s.
Anderson's "Playboy" career spans twenty-two years, and she has appeared on more "Playboy" covers than any other model. She has also made appearances in the publication's newsstand specials. Anderson wrote the foreword in the "Playboy" coffee table book "Playboy's Greatest Covers".
Acting and modeling.
After she moved to Los Angeles, she won a minor role as Lisa, the original "Tool Time girl", on the television sitcom, "Home Improvement". She left the show after two seasons and won the role of C. J. Parker on "Baywatch", whom she played for five seasons between 1992 and 1997 making her one of the longest serving cast members. This has been one of her best known roles to date and has gained her a lot of popularity from international viewers. She later reprised her role to return in a reunion movie, "" in 2003 and also to star in commercials for DirecTV in 2007. Anderson was still modeling for "Outdoor Life" and appearing on the cover of the magazine each year. In 1993, Anderson appeared in a music video "Can't Have Your Cake" by Vince Neil to promote his first solo album "Exposed".
In 1994, she was cast in her first starring film role, in "Raw Justice", also known as "Good Cop, Bad Cop," costarring with Stacy Keach, David Keith and Robert Hays. Under the alternate title, the film won the Bronze Award at the Worldfest-Charleston in the category for dramatic theatrical films.
In 1996, she appeared in "Barb Wire" playing Barbara Rose Kopetski, which was later claimed by some sources to be Anderson's real name, although it is not. The movie, a thinly veiled futuristic remake of "Casablanca", was not a commercial success. In April 1997, she guest-hosted "Saturday Night Live". She appeared on one of two covers for the September issue of "Playboy".
In September 1998, Anderson starred as Vallery Irons in the Sony Pictures Entertainment syndicated show "V.I.P." created by J. F. Lawton. Blending action and humor in a fast-paced adventure series, with Anderson often poking fun at her tabloid image, the show explored the exciting and sometimes treacherous lives of the rich and famous. The series lasted through a successful four-year run. In 1999, she appeared as a man-eating giantess in the music video for "Miserable" by California alternative rock band Lit. She appeared on "The Nanny" as Fran's rival, Heather Biblow. Also in 1999, she had her breast implants surgically removed.
In early 2004, Anderson returned to the spotlight. In May, she appeared naked on the cover of "Playboy" magazine. It was the first time she had appeared naked on any magazine cover. Later, she posed naked for "Stuff" and "GQ" magazines. Anderson also graced the cover of the fashion magazine "Elle" Canada.
Anderson became a naturalized citizen of the United States on May 12, 2004, while retaining her Canadian citizenship. She has lived in Southern California since 1989.
In 2004, she released the book "Star", co-written by Eric Shaw Quinn, about a teenager trying to become famous. After this, she began touring the United States, signing autographs for fans at Wal-Mart stores nationwide. Her second book, the sequel "Star Struck", released in 2005, is a thinly veiled look at her life with Tommy Lee and the trials of celebrity life. In April 2005, Anderson starred in a new Fox sitcom "Stacked" as Skyler Dayton, a party girl who goes to work at a bookstore. It was canceled on May 18, 2006, after two seasons, although some episodes were never aired. On August 14, 2005, Comedy Central created the "Roast of Pamela Anderson" to honor the sex symbol for the past decade.
In December 2005, NBC cut off a video of Anderson pole dancing on Elton John's "The Red Piano". NBC said that the footage was inappropriate for prime time. The video was shown on huge screens during the event, while John played "The Bitch is Back". In March 2006, it was announced that Anderson would receive a star on Canada's Walk of Fame thanks to her many years as a model and actress. She is only the second model to receive a star. In April 2006, Anderson hosted Canada's Juno Awards, becoming the first non-singer and model to do so.
She was referenced in the 2006 mockumentary, "", as the title character becomes obsessed with her, and plans to abduct and marry her. She appears as herself at a book signing at the end of the film, confronted by Borat in a staged botched abduction.
She performed on February 13-14, 2008 in a Valentine's Day striptease act at the Crazy Horse cabaret in Paris. Anderson then starred in "", which debuted on August 3, 2008 on E! in the United States.
In December 2009, Anderson guest-starred as "Genie of the Lamp" in the pantomime "Aladdin" at the New Wimbledon Theatre in Wimbledon, south-west London, England. Anderson took over the role from comedienne Ruby Wax, with former EastEnders actress Anita Dobson and comedian Paul O'Grady also booked for the role. In 2010, she appeared in the short film "The Commuter" directed by the McHenry Brothers and shot entirely on the Nokia N8 smartphone as promotion for the phone in the UK. Anderson was featured in a beach-themed editorial, shot by Mario Testino for Brazilian "Vogue"'s June 2013 "Body Issue".
"Big Brother".
On July 9, 2008, Anderson entered the Australian "Big Brother" house for a three-day visit. This was Anderson's first foray into reality television. In November 2010, Anderson appeared on season 4 of "Bigg Boss", the Indian version of the "Big Brother" television franchise. She stayed as a guest in the house for three days for a reported sum of Rs. 2.5 crores (approx US$ 550,000). Furthering her involvement in the franchise, In September 2011, Anderson took part in the 12th series of the UK version of "Big Brother".
On September 9, 2012, it was officially announced that she will enter the House in Bulgaria on September 16, taking part in the fourth season of "VIP Brother", which is the celebrity spin-off of "Big Brother" in Bulgaria.
On Day 12 for the "Promi Big Brother (season 1)" in Germany, she entered the house, as a Special Guest Star on the final day. David Hasselhoff, a former "Baywatch" co-star, was a contestant in Day 1 to Day 5.
"Dancing with the Stars".
Anderson was a contestant on the tenth season of "Dancing with the Stars", partnered with professional dancer Damian Whitewood. The season premiered on Monday, March 22, 2010, and after seven weeks, Anderson was eliminated. She also took part in the 15th season all-star edition in 2012 with Tristan MacManus. Anderson and MacManus were eliminated in the first week of competition.
In 2011, she appeared on the Argentinian version of "Dancing with the Stars", entitled "Bailando por un sueño" (Bailando 2011). She once again danced with Whitewood. She withdrew from the competition after the fourth round.
"Dancing on Ice".
In 2013, Anderson appeared on series 8 of the British reality TV show "Dancing on Ice", partnered with former winner Matt Evers. They became the first couple on that series to be voted off by the judges due to a few stumbles.
Causes.
Animal rights.
One of Anderson's campaigns as a member of PETA has been against the use of fur. In 1999, Anderson received the first Linda McCartney Memorial Award for animal rights protectors, in recognition of her campaign. In 2003, Anderson stripped down for PETA's "I'd Rather Go Naked Than Wear Fur" advertising campaign. On June 28, 2006, Anderson posed naked with other protesters on a window display of the Stella McCartney boutique in London, England. It was a PETA gala event before the PETA Humanitarian Awards. Anderson went inside the boutique and said she would take her clothes off if the event raised enough money for PETA, which it did. She campaigned against Kentucky Fried Chicken. In 2001, Anderson released a letter in support of PETA's campaign against Kentucky Fried Chicken, stating "What KFC does to 750 million chickens each year is not civilized or acceptable." She later made a video about KFC's treatment of chickens. In January 2006, Anderson requested that the Governor of Kentucky remove a bust of Colonel Sanders, the founder of KFC, from display but her request was refused even when she offered her own bust in exchange. In February 2006, Anderson decided to boycott the Kentucky Derby because of its support for Kentucky Fried Chicken.
She has also campaigned against seal hunting in Canada. In March 2006, Anderson asked to speak to Prime Minister Stephen Harper about the annual seal hunt but was refused. In May 2006, she petitioned individuals on the street for their opinion on the Canadian Seal Hunt. In December 2009, Anderson, photographed in a T-shirt with a drawn picture of a seal pup on it, was featured in a new ad campaign for PETA. She appears next to the headline "Save the Seals" in the ad and urges the public to help end "Canada's annual seal slaughter." She joined forces with the organization again in a campaign for the boycott of fruit-juice maker POM. The "Pom Horrible Campaign" has resulted in the company halting animal tests.
Anderson became the center of controversy when she posed in a bikini nearly nude for a PETA ad that was banned in Montreal, Canada on grounds that the ad was sexist. Anderson retorted saying, "In a city that is known for its exotic dancing and for being progressive and edgy, how sad that a woman would be banned from using her own body in a political protest over the suffering of cows and chickens. In some parts of the world, women are forced to cover their whole bodies with burqas – is that next? I didn't think that Canada would be so puritanical." 
She became a company spokesperson for FrogAds, Inc. in March 2012. In February 2014, she stripped for a Valentine’s Day-themed ad for PETA, urging dog lovers to cuddle up with their pets during winter. In July 2015, Anderson wrote an open letter to Russian President Vladimir Putin asking to prevent the passage of the cargo vessel "Winter Bay" with over 1,700 tons of fin whale meat through the Northeast Passage to Japan.
AIDS, cannabis, and other activism.
In March 2005, Anderson became a spokesperson for MAC Cosmetics's MAC AIDS Fund, which helped people affected by AIDS and HIV. After becoming the official spokesmodel, Anderson raised money during events in Toronto, Tokyo, Dublin, and Athens. Anderson became the celebrity spokesperson for the American Liver Foundation, and served as the Grand Marshal of the SOS motorcycle ride fundraiser.
She wrote an open letter to President Barack Obama urging the legalization of cannabis.
She has also shown support to the Friends of the Israel Defense Forces.
Personal life.
Relationships.
In addition to her fame from modelling and acting, Anderson has received a great deal of press attention for her well-publicized personal life. Her relationships have made headlines in gossip magazines for years.
Anderson married Tommy Lee, drummer of Mötley Crüe, on February 19, 1995, after knowing him for 96 hours/4 days. They wed on a beach, with Anderson in a bikini. Anderson's mother did not know, and learned of the marriage from "People" magazine. During this time, she was known professionally as Pamela Anderson Lee. Together they have two sons, Brandon Thomas Lee and Dylan Jagger Lee. Dylan Jagger Lee was named for Anderson's great grandfather, Dale Jagger Grosco who fought in World War II. The couple divorced in 1998. Although divorced, the couple reunited briefly upon Lee's release from prison but eventually split again in 2001. They reconciled and split again in 2008.
In March 2002, Anderson publicly stated that she had contracted Hepatitis C from Lee (supposedly from sharing tattoo needles), and began writing a regular column for "Jane" magazine. In October 2003, Anderson jokingly said on Howard Stern's radio show that she does not expect to live more than 10 or 15 years, but this was misconstrued and taken seriously by many websites and tabloids.
After the 1998 divorce, Anderson became engaged to the model Marcus Schenkenberg; they broke up in 2001. She then became engaged to the singer Kid Rock (Robert J. Ritchie); she broke up with him in 2003. On July 18, 2006, it was announced that she would marry Kid Rock on July 29, 2006, on a yacht near St Tropez, France. "Feels like I've been stuck in a time warp," said Anderson in her blog entry. "Not able to let go of MY family picture ... it's been sad and lonely and frustrating ... I've raised my kids alone in hope of a miracle. Well my miracle came and went. And came back and back because he knew that I'd wake up one day and realize that I was waiting for nothing." "I'm moving on," she declared. "I feel like I'm finally free ... I'm in love." There was extensive unconfirmed media speculation that the marriage was pregnancy-related, but the theory was based only on Anderson's representative's refusal to comment on the question.
On November 10, 2006, it was announced that Anderson had miscarried while in Vancouver shooting a new film, "Blonde and Blonder". Seventeen days later, on November 27, 2006, Anderson filed for divorce in Los Angeles County Superior Court, citing irreconcilable differences. Some news reports have suggested that Kid Rock's outrage during a screening of "", in which Anderson plays a cameo role, led to the filing for divorce two weeks later.
In September 2007, Anderson told talk show host Ellen DeGeneres that she was engaged. On September 29, Anderson and film producer Rick Salomon applied for a marriage license in Las Vegas. On October 6, 2007, Anderson married Salomon in a small wedding ceremony at The Mirage, between her two nightly appearances at the Planet Hollywood Resort and Casino in Hans Klok's magic show. The couple separated on December 13, and on February 22, 2008, Anderson requested through the courts that the marriage be annulled, citing fraud.
In February 2007, Anderson said that she still often had sex with Lee since their divorce. In mid-2008 Lee said that they were going to try again to make things work together.
In October 2013, Anderson said on "The Ellen DeGeneres Show" that she and Salomon were "friends with benefits". In January 2014, she announced that she had remarried Salomon on an unspecified date. Anderson filed for divorce from Salomon in February 2015. The divorce was finalized on April 29, 2015.
Sex tapes controversy.
A sex tape of Anderson and Tommy Lee on their honeymoon was stolen from their home in 1995 and made a huge stir on the Internet. Anderson sued the video distribution company, Internet Entertainment Group. Ultimately, the Lees entered into a confidential settlement agreement with IEG. Thereafter, the company began making the tape available to subscribers to its web sites again, resulting in triple the normal traffic on the sites.
Another tape, which was made before the Tommy Lee tape, involving Anderson and musician Bret Michaels from Poison, was later announced, and an abridged version of less than 60 seconds appeared on the internet. Frames of the video first appeared in "Penthouse" magazine in March 1998. The tape was successfully blocked by Michaels, but a four-minute sex tape is still available on the Internet.
Veganism.
Anderson is a vegan, an advocate for animal rights, and an active member of the animal protection organization People for the Ethical Treatment of Animals (PETA), taking part in several campaigns for animal rights. She became a vegetarian in her early teens when she saw her father cleaning an animal he had hunted.
In popular culture.
Sam Newman's House is a pop architecture building constructed in 2003 in St Kilda, Victoria, Australia, which features a large image of Anderson's face. Sam Newman commissioned local architect Cassandra Fahey to design the building, and used the image with Anderson's permission. Permits were issued retroactively when it became a major local landmark and won the award for Best New Residential Building in the RAIA Victorian Architecture Awards.

</doc>
<doc id="23036" url="https://en.wikipedia.org/wiki?curid=23036" title="Printer (publishing)">
Printer (publishing)

In publishing, printers are both companies providing printing services and individuals who directly operate printing presses.
The profession of printer became established after the invention of the moveable type printing press by Johannes Gutenberg around 1450, and proliferated throughout Europe. Such early printers often were recognizable by individual characteristics in the works they produced, such as type or typography, and since early printed books were made in relatively small quantities they are rare and collectible.
Today's printers include:
An artist who operates a printing press to execute their own works, especially by hand in limited runs, is usually distinguished from other printers by the term printmaker.

</doc>
<doc id="23037" url="https://en.wikipedia.org/wiki?curid=23037" title="Punk rock">
Punk rock

Punk rock (or simply punk) is a rock music genre that developed between 1974 and 1976 in the United States, United Kingdom, and Australia. Rooted in garage rock and other forms of what is now known as protopunk music, punk rock bands eschewed perceived excesses of mainstream 1970s rock. Punk bands typically use short or fast-paced songs, with hard-edged melodies and singing styles, stripped-down instrumentation, and often political, anti-establishment lyrics. Punk embraces a DIY ethic; many bands self-produced recordings and distributed them through informal channels.
The term "punk" was first used in relation to rock music by some American critics in the early 1970s, to describe garage bands and their devotees. By late 1976, bands such as the Sex Pistols, the Clash and the Damned in London, and Television, Patti Smith, and the Ramones in New York City were recognized as the vanguard of a new musical movement. The following year saw punk rock spreading around the world, and it became a major cultural phenomenon in the United Kingdom. For the most part, punk took root in local scenes that tended to reject association with the mainstream. An associated punk subculture emerged, expressing youthful rebellion and characterized by distinctive styles of clothing and adornment (ranging from deliberately offensive T-shirts, leather jackets, spike bands and other studded or spiked jewelry to bondage and S&M clothes) and a variety of anti-authoritarian ideologies.
By the beginning of the 1980s, faster, more aggressive styles such as hardcore (e.g. Black Flag) and Oi! (e.g. Cock Sparrer), as well as crossover thrash (e.g. Suicidal Tendencies), had become the predominant mode of punk rock. Musicians identifying with or inspired by punk also pursued a broad range of other variations, giving rise to post-punk and the alternative rock movement. At the end of the 20th century, punk rock had been adopted by the mainstream, as pop punk and punk rock bands such as Green Day, Rancid, Sublime, the Offspring and Blink-182 brought the genre widespread popularity.
Characteristics.
Philosophy.
The first wave of punk rock was aggressively modern, distancing itself from the bombast and sentimentality of early 1970s rock. According to Ramones drummer Tommy Ramone, "In its initial form, a lot of [1960s] stuff was innovative and exciting. Unfortunately, what happens is that people who could not hold a candle to the likes of Hendrix started noodling away. Soon you had endless solos that went nowhere. By 1973, I knew that what was needed was some pure, stripped down, no bullshit rock 'n' roll." John Holmstrom, founding editor of "Punk" magazine, recalls feeling "punk rock had to come along because the rock scene had become so tame that [acts] like Billy Joel and Simon and Garfunkel were being called rock and roll, when to me and other fans, rock and roll meant this wild and rebellious music." In critic Robert Christgau's description, "It was also a subculture that scornfully rejected the political idealism and Californian flower-power silliness of hippie myth."
Technical accessibility and a DIY spirit are prized in punk rock. In the early days of punk rock, this ethic stood in marked contrast to what those in the scene regarded as the ostentatious musical effects and technological demands of many mainstream rock bands. Musical virtuosity was often looked on with suspicion. According to Holmstrom, punk rock was "rock and roll by people who didn't have very much skills as musicians but still felt the need to express themselves through music". In December 1976, the English fanzine "Sideburns" published a now-famous illustration of three chords, captioned "This is a chord, this is another, this is a third. Now form a band". The title of a 1980 single by the New York punk band Stimulators, "Loud Fast Rules!" inscribed a catchphrase for punk's basic musical approach.
Some of British punk rock's leading figures made a show of rejecting not only contemporary mainstream rock and the broader culture it was associated with, but their own most celebrated predecessors: "No Elvis, Beatles or the Rolling Stones in 1977", declared the Clash song "1977". The previous year, when the punk rock revolution began in Great Britain, was to be both a musical and a cultural "Year Zero". Even as nostalgia was discarded, many in the scene adopted a nihilistic attitude summed up by the Sex Pistols slogan "No Future"; in the later words of one observer, amid the unemployment and social unrest in 1977, "punk's nihilistic swagger was the most thrilling thing in England." While "self-imposed alienation" was common among "drunk punks" and "gutter punks", there was always a tension between their nihilistic outlook and the "radical leftist utopianism" of bands such as Crass, who found positive, liberating meaning in the movement. As a Clash associate describes singer Joe Strummer's outlook, "Punk rock is meant to be our freedom. We're meant to be able to do what we want to do."
The issue of authenticity is important in the punk subculture—the pejorative term "poseur" is applied to those who associate with punk and adopt its stylistic attributes but are deemed not to share or understand the underlying values and philosophy. Scholar Daniel S. Traber argues that "attaining authenticity in the punk identity can be difficult"; as the punk scene matured, he observes, eventually "everyone got called a poseur".
Musical and lyrical elements.
Punk rock bands often emulate the bare musical structures and arrangements of 1960s garage rock. Typical punk rock instrumentation includes one or two electric guitars, an electric bass, and a drum kit, along with vocals. Songs tend to be shorter than those of other popular genres. Most early punk rock songs retained a traditional rock 'n' roll verse-chorus form and 4/4 time signature. However, later bands have often broken from this format. In critic Steven Blush's description, "The Sex Pistols were still rock'n'roll...like the craziest version of Chuck Berry. Hardcore was a radical departure from that. It wasn't verse-chorus rock. It dispelled any notion of what songwriting is supposed to be. It's its own form."
Punk rock vocals sometimes sound nasal, and lyrics are often shouted instead of sung in a conventional sense, particularly in hardcore styles. Shifts in pitch, volume, or intonational style are relatively infrequent. Complicated guitar solos are considered self-indulgent and unnecessary, although basic guitar breaks are common. Guitar parts tend to include highly distorted power chords or barre chords, creating a characteristic sound described by Christgau as a "buzzsaw drone". Some punk rock bands take a surf rock approach with a lighter, twangier guitar tone. Others, such as Robert Quine, lead guitarist of the Voidoids, have employed a wild, "gonzo" attack, a style that stretches back through the Velvet Underground to the 1950s recordings of Ike Turner. Bass guitar lines are often uncomplicated; the quintessential approach is a relentless, repetitive "forced rhythm," although some punk rock bass players—such as Mike Watt of the Minutemen and Firehose—emphasize more technical bass lines. Bassists often use a pick due to the rapid succession of notes, which makes fingerpicking impractical. Drums typically sound heavy and dry, and often have a minimal set-up. Compared to other forms of rock, syncopation is much less the rule. Hardcore drumming tends to be especially fast. Production tends to be minimalistic, with tracks sometimes laid down on home tape recorders or simple four-track portastudios. The typical objective is to have the recording sound unmanipulated and "real," reflecting the commitment and "authenticity" of a live performance.
Punk rock lyrics are typically frank and confrontational; compared to the lyrics of other popular music genres, they frequently comment on social and political issues. Trend-setting songs such as the Clash's "Career Opportunities" and Chelsea's "Right to Work" deal with unemployment and the grim realities of urban life. Especially in early British punk, a central goal was to outrage and shock the mainstream. The Sex Pistols' "Anarchy in the U.K." and "God Save the Queen" openly disparaged the British political system and social mores. Anti-sentimental depictions of relationships and sex are common, as in "Love Comes in Spurts," written by Richard Hell and recorded by him with the Voidoids. Anomie, variously expressed in the poetic terms of Hell's "Blank Generation" and the bluntness of the Ramones' "Now I Wanna Sniff Some Glue," is a common theme. Identifying punk with such topics aligns with the view expressed by V. Vale, founder of San Francisco fanzine "Search and Destroy": "Punk was a total cultural revolt. It was a hardcore confrontation with the black side of history and culture, right-wing imagery, sexual taboos, a delving into it that had never been done before by any generation in such a thorough way".
Visual and other elements.
The classic punk rock look among male American musicians harkens back to the T-shirt, motorcycle jacket, and jeans ensemble favored by American greasers of the 1950s associated with the rockabilly scene and by British rockers of the 1960s. The cover of the Ramones' 1976 debut album, featuring a shot of the band by "Punk" photographer Roberta Bayley, set forth the basic elements of a style that was soon widely emulated by rock musicians both punk and nonpunk. Richard Hell's more androgynous, ragamuffin look—and reputed invention of the safety-pin aesthetic—was a major influence on Sex Pistols impresario Malcolm McLaren and, in turn, British punk style. (John D Morton of Cleveland's Electric Eels may have been the first rock musician to wear a safety-pin-covered jacket.) McLaren's partner, fashion designer Vivienne Westwood, credits Johnny Rotten as the first British punk to rip his shirt, and Sex Pistols bassist Sid Vicious as the first to use safety pins. Early female punk musicians displayed styles ranging from Siouxsie Sioux's bondage gear to Patti Smith's "straight-from-the-gutter androgyny". The former proved much more influential on female fan styles. Over time, tattoos, piercings, and metal-studded and -spiked accessories became increasingly common elements of punk fashion among both musicians and fans, a "style of adornment calculated to disturb and outrage". The typical male punk haircut was originally short and choppy; the Mohawk later emerged as a characteristic style.
The characteristic stage performance style of male punk musicians does not deviate significantly from the macho postures classically associated with rock music. Female punk musicians broke more clearly from earlier styles. Scholar John Strohm suggests that they did so by creating personas of a type conventionally seen as masculine: "They adopted a tough, unladylike pose that borrowed more from the macho swagger of sixties garage bands than from the calculated bad-girl image of bands like the Runaways." Scholar Dave Laing describes how bassist Gaye Advert adopted fashion elements associated with male musicians only to generate a stage persona readily consumed as "sexy". Laing focuses on more innovative and challenging performance styles, seen in the various erotically destabilizing approaches of Siouxsie Sioux, the Slits' Ari Up, and X-Ray Spex' Poly Styrene.
The lack of emphatic syncopation led punk dance to "deviant" forms. The characteristic style was originally the pogo. Sid Vicious, before he became the Sex Pistols' bassist, is credited with initiating the pogo in Britain as an attendee at one of their concerts. Moshing (Slam Dancing) is typical at hardcore shows. The lack of conventional dance rhythms was a central factor in limiting punk's mainstream commercial impact.
Breaking down the distance between performer and audience is central to the punk ethic. Fan participation at concerts is thus important; during the movement's first heyday, it was often provoked in an adversarial manner—apparently perverse, but appropriately "punk". First-wave British punk bands such as the Sex Pistols and the Damned insulted and otherwise goaded the audience into intense reactions. Laing has identified three primary forms of audience physical response to goading: can throwing, stage invasion, and spitting or "gobbing". In the hardcore realm, stage invasion is often a prelude to stage diving. In addition to the numerous fans who have started or joined punk bands, audience members also become important participants via the scene's many amateur periodicals—in England, according to Laing, punk "was the first musical genre to spawn fanzines in any significant numbers".
Pre-history.
Garage rock and British Beat.
In the early to mid-1960s, garage rock bands, often recognized as punk rock's progenitors, began springing up around North America. The Kingsmen, from Portland, Oregon, had a hit with their 1963 cover of "Louie, Louie," considered by some as punk rock's defining "ur-text." After the Beatles’ first appearance on the Ed Sullivan Show, and then with the subsequent string of other successful British acts, the garage band craze would gather even more momentum. The minimalist sound of many garage rock bands was influenced by the harder-edged wing of the British Invasion, exemplified by groups such as the Rolling Stones and the Yardbirds. After 1967, U.S. garage rock began to fall out of favor, but the raw sound and outsider attitude of bands, such as the Sonics, the Seeds, the Remains, the Standells, and the Shadows of Knight predicted the style of later bands such as MC5 and the Stooges. In the early 70s, certain rock critics began to speak of the mid-60s garage bands (as well bands that they considered continuing in their line, such as MC5 and the Stooges) as a genre that they called "punk rock." However, since the advent of New York and London scenes of 1975-1978, and the subculture that grew out of them, the term has become most commonly applied to music emerging after 1974. Sixties garage bands are now typically described as garage rock, or, especially in the case of their immediate successors, protopunk.
From England in 1964, largely under the grip of the mod youth movement and beat group explosion, came the Kinks' hit singles, "You Really Got Me" and "All Day and All of the Night," both influenced by "Louie, Louie". They have been described as "predecessors of the whole three-chord genre." For instance, the Ramones' 1978 'I Don't Want You,' was largely Kink's-influenced. In 1965, the Who progressed from their first single, "I Can't Explain," a virtual Kinks clone, to "My Generation". Though it had little impact on the American charts, the Who's mod anthem pre-figured the kind of "cerebral mix of musical ferocity and rebellious posture" that would characterize much of the later British punk rock of the 1970s. John Reed describes the Clash's emergence as a "tight ball of energy with both an image and rhetoric reminiscent of a young Pete Townshend—speed obsession, pop-art clothing, art school ambition." The Who and fellow mods the Small Faces were among the few rock elders acknowledged by the Sex Pistols. The tougher-sounding British bands of the mid-late 60s are sometimes referred to as Freakbeat.
Protopunk.
Debut albums by two Michigan-based bands that appeared in 1969 are regarded as the central protopunk records. In January, Detroit's MC5 released "Kick Out the Jams". "Musically the group is intentionally crude and aggressively raw...," wrote critic Lester Bangs in "Rolling Stone." "...most of the songs are barely distinguishable from each other in their primitive two-chord structures. You've heard all this before from such notables as the Seeds, Blue Cheer, Question Mark and the Mysterians, and the Kingsmen..."
Los Saicos out of Peru recorded one of the earliest proto-punk tracks in their 1965 track "Demolicion" According to the Black Lips, who cited the Peruvian band as inspiration: "They are the first to play what later became punk. There was no name for that at the time, but the riffs are definitely punk."
That August, the Stooges, from Ann Arbor, premiered with a self-titled album. According to critic Greil Marcus, the band, led by singer Iggy Pop, created "the sound of Chuck Berry's Airmobile—after thieves stripped it for parts". The album was produced by John Cale, a former member of New York's experimental rock group the Velvet Underground. Having earned a "reputation as the first underground rock band," the Velvet Underground inspired, directly or indirectly, many of those involved in the creation of punk rock.
In the early 1970s, the New York Dolls updated the original wildness of 1950's rock 'n' roll in a fashion that later became known as glam punk. The New York duo Suicide played spare, experimental music with a confrontational stage act inspired by that of the Stooges. At the Coventry club in the New York City borough of Queens, the Dictators used rock as a vehicle for wise-ass attitude and humor. In Boston, the Modern Lovers, led by Velvet Underground devotee Jonathan Richman, gained attention with a minimalistic style. In 1974, an updated garage rock scene began to coalesce around the newly opened Rathskeller club in Kenmore Square. Among the leading acts were the Real Kids, founded by former Modern Lover John Felice; Willie Alexander and the Boom Boom Band, whose frontman had been a member of the Velvet Underground for a few months in 1971; and Mickey Clean and the Mezz. In 1974, as well, the Detroit band Death—made up of three African-American brothers—recorded "scorching blasts of feral ur-punk," but couldn't arrange a release deal. In Ohio, a small but influential underground rock scene emerged, led by Devo in Akron and Kent and by Cleveland's Electric Eels, Mirrors and Rocket from the Tombs. In 1975, Rocket from the Tombs split into Pere Ubu and Frankenstein. The Electric Eels and Mirrors both broke up, and the Styrenes emerged from the fallout.
Britain's Deviants, in the late 1960s, played in a range of psychedelic styles with a satiric, anarchic edge and a penchant for situationist-style spectacle presaging the Sex Pistols by almost a decade. In 1970, the act evolved into the Pink Fairies, which carried on in a similar vein. With his Ziggy Stardust persona, David Bowie made artifice and exaggeration central—elements, again, that were picked up by the Sex Pistols and certain other punk acts. The Doctors of Madness built on Bowie's presentation concepts, while moving musically in the direction that would become identified with punk. Bands in London's pub rock scene stripped the music back to its basics, playing hard, R&B-influenced rock 'n' roll. By 1974, the scene's top act, Dr. Feelgood, was paving the way for others such as the Stranglers and Cock Sparrer that would play a role in the punk explosion. Among the pub rock bands that formed that year was the 101ers, whose lead singer would soon adopt the name Joe Strummer.
Bands anticipating the forthcoming movement were appearing as far afield as Düsseldorf, West Germany, where "punk before punk" band NEU! formed in 1971, building on the Krautrock tradition of groups such as Can. In Japan, the anti-establishment Zunō Keisatsu (Brain Police) mixed garage psych and folk. The combo regularly faced censorship challenges, their live act at least once including onstage masturbation. A new generation of Australian garage rock bands, inspired mainly by the Stooges and MC5, was coming even closer to the sound that would soon be called "punk": In Brisbane, the Saints also recalled the raw live sound of the British Pretty Things, who had made a notorious tour of Australia and New Zealand in 1975.
Etymology.
Between the late 16th and the 18th centuries, "punk" was a common, coarse synonym for "prostitute"; William Shakespeare used it with that meaning in "The Merry Wives of Windsor" (1602) and "Measure for Measure" (1623). The term eventually came to describe "a young male hustler, a gangster, a hoodlum, or a ruffian". As Legs McNeil explains, "On TV, if you watched cop shows, "Kojak", "Baretta", when the cops finally catch the mass murderer, they'd say, 'you dirty Punk.' It was what your teachers would call you. It meant that you were the lowest." The first known use of the phrase "punk rock" appeared in the "Chicago Tribune" on March 22, 1970, attributed to Ed Sanders, cofounder of New York's anarcho-prankster band the Fugs. Sanders was quoted describing a solo album of his as "punk rock—redneck sentimentality". In the December 1970 issue of "Creem", Lester Bangs, mocking more mainstream rock musicians, ironically referred to Iggy Pop as "that Stooge punk". Suicide's Alan Vega credits this usage with inspiring his duo to bill its gigs as a "punk mass" for the next couple of years.
Dave Marsh was the first music critic to employ the term "punk rock": In the May 1971 issue of "Creem", he described ? and the Mysterians, one of the most popular 1960s garage rock acts, as giving a "landmark exposition of punk rock". Later in 1971, in his fanzine "Who Put the Bomp", Greg Shaw wrote about "...what I have chosen to call "punkrock" bands—white teenage hard rock of '64-66 (Standells, Kingsmen, Shadows of Knight, etc.)". Robert Christgau writing for the Village Voice in October, 1971 refers to "mid-60's punk" as a historical period of rock-and-roll. Lester Bangs would use the term "punk rock" in several articles written in the early 70s to refer to mid-60s garage acts. In his June, 1971 piece in "Creem," "Psyhotic Reactions and Carburetor Dung," he wrote "...then punk bands started cropping up who were writing their own songs but taking the Yardbirds' sound and reducing it to this kind of goony fuzztone clatter...oh, it was beautiful, it was pure folklore, Old America, and sometimes I think those were the best days ever." In several places in a 1971 article in "Who Put the Bomp," Bangs refers to Britain's the Troggs and bands of their ilk as "punk." In the liner notes of the 1972 anthology LP, "", musician and rock journalist Lenny Kaye, later a member of the Patti Smith Group, used variations of the term in two places: first "punk rock," in the essay liner notes, to describe the genre of 60s garage bands, and then, later, "classic garage-punk," in the track-by-track notes, to describe a song recorded in 1966 by the Shadows of Knight. In June 1972, the fanzine "Flash" included a "Punk Top Ten" of 1960s albums. By that December, the term was in circulation to the extent that "The New Yorker"s Ellen Willis, contrasting her own tastes with those of "Flash" and fellow critic Nick Tosches, wrote, ""Punk-rock" has become the favored term of endearment." In February 1973, Terry Atkinson of the "Los Angeles Times", reviewing the debut album by a hard rock band, Aerosmith, declared that it "achieves all that punk-rock bands strive for but most miss." Three months later, Billy Altman launched the short-lived "punk magazine," which pre-dated the better-known 1975 publication of the same name, but, unlike the later magazine, was more devoted to covering 60s garage and psychedelic acts.
In May 1974, "Los Angeles Times" critic Robert Hilburn reviewed the second New York Dolls album, "Too Much Too Soon". "I told ya the New York Dolls were the real thing," he wrote, describing the album as "perhaps the best example of raw, thumb-your-nose-at-the-world, punk rock since the Rolling Stones' "Exile on Main Street"." Bassist Jeff Jensen of Boston's Real Kids reports of a show that year, "A reviewer for one of the free entertainment magazines of the time caught the act and gave us a great review, calling us a 'punk band.' ... [W]e all sort of looked at each other and said, 'What's punk?'"
By 1975, "punk" was being used to describe acts as diverse as the Patti Smith Group, the Bay City Rollers, and Bruce Springsteen. As the scene at New York's CBGB club attracted notice, a name was sought for the developing sound. Club owner Hilly Kristal called the movement "street rock"; John Holmstrom credits "Aquarian" magazine with using "punk" "to describe what was going on at CBGBs". Holmstrom, McNeil, and Ged Dunn's magazine "Punk", which debuted at the end of 1975, was crucial in codifying the term. "It was pretty obvious that the word was getting very popular", Holmstrom later remarked. "We figured we'd take the name before anyone else claimed it. We wanted to get rid of the bullshit, strip it down to rock 'n' roll. We wanted the fun and liveliness back."
Early history.
North America.
New York City.
The origins of New York's punk rock scene can be traced back to such sources as late 1960s trash culture and an early 1970s underground rock movement centered on the Mercer Arts Center in Greenwich Village, where the New York Dolls performed. In early 1974, a new scene began to develop around the CBGB club, also in lower Manhattan. At its core was Television, described by critic John Walker as "the ultimate garage band with pretensions". Their influences ranged from the Velvet Underground to the staccato guitar work of Dr. Feelgood's Wilko Johnson. The band's bassist/singer, Richard Hell, created a look with cropped, ragged hair, ripped T-shirts, and black leather jackets credited as the basis for punk rock visual style. In April 1974, Patti Smith, a member of the Mercer Arts Center crowd and a friend of Hell's, came to CBGB for the first time to see the band perform. A veteran of independent theater and performance poetry, Smith was developing an intellectual, feminist take on rock 'n' roll. On June 5, she recorded the single "Hey Joe"/"Piss Factory", featuring Television guitarist Tom Verlaine; released on her own Mer Records label, it heralded the scene's do it yourself (DIY) ethic and has often been cited as the first punk rock record. By August, Smith and Television were gigging together at another downtown New York club, Max's Kansas City.
Out in Forest Hills, Queens, several miles from lower Manhattan, the members of a newly formed band adopted a common surname. Drawing on sources ranging from the Stooges to the Beatles and the Beach Boys to Herman's Hermits and 1960s girl groups, the Ramones condensed rock 'n' roll to its primal level: "'1-2-3-4!' bass-player Dee Dee Ramone shouted at the start of every song, as if the group could barely master the rudiments of rhythm." The band played its first gig at CBGB on August 16, 1974, on the same bill as another new act, Angel and the Snake, soon to be renamed Blondie. By the end of the year, the Ramones had performed seventy-four shows, each about seventeen minutes long. "When I first saw the Ramones", critic Mary Harron later remembered, "I couldn't believe people were doing this. The dumb brattiness." The Dictators, with a similar "playing dumb" concept, were recording their debut album. The Dictators' "Go Girl Crazy!" came out in March 1975, mixing absurdist originals such as "Master Race Rock" and loud, straight-faced covers of cheese pop like Sonny & Cher's "I Got You Babe".
That spring, Smith and Television shared a two-month-long weekend residency at CBGB that significantly raised the club's profile. The Television sets included Richard Hell's "Blank Generation", which became the scene's emblematic anthem. Soon after, Hell left Television and founded a band featuring a more stripped-down sound, the Heartbreakers, with former New York Dolls Johnny Thunders and Jerry Nolan. The pairing of Hell and Thunders, in one critical assessment, "inject[ed] a poetic intelligence into mindless self-destruction". A July festival at CBGB featuring over thirty new groups brought the scene its first substantial media coverage. In August, Television—with Fred Smith, former Blondie bassist, replacing Hell—recorded a single, "Little Johnny Jewel", for the tiny Ork label. In the words of John Walker, the record was "a turning point for the whole New York scene" if not quite for the punk rock sound itself—Hell's departure had left the band "significantly reduced in fringe aggression".
Other bands were becoming regulars at CBGB, such as Mink DeVille and Talking Heads, which moved down from Rhode Island. More closely associated with Max's Kansas City were Suicide and the band led by Jayne County, another Mercer Arts Center alumna. The first album to come out of this downtown scene was released in November 1975: Smith's debut, "Horses", produced by John Cale for the major Arista label. The inaugural issue of "Punk" appeared in December. The new magazine tied together earlier artists such as Velvet Underground lead singer Lou Reed, the Stooges, and the New York Dolls with the editors' favorite band, the Dictators, and the array of new acts centered on CBGB and Max's. That winter, Pere Ubu came in from Cleveland and played at both spots.
Early in 1976, Hell left the Heartbreakers; he soon formed a new group that would become known as the Voidoids, "one of the most harshly uncompromising bands" on the scene. That April, the Ramones' debut album was released by Sire Records; the first single was "Blitzkrieg Bop", opening with the rally cry "Hey! Ho! Let's go!" According to a later description, "Like all cultural watersheds, "Ramones" was embraced by a discerning few and slagged off as a bad joke by the uncomprehending majority." At the instigation of Ramones lead singer Joey Ramone, the members of Cleveland's Frankenstein moved east to join the New York scene. Reconstituted as the Dead Boys, they played their first CBGB gig in late July. In August, Ork put out an EP recorded by Hell with his new band that included the first released version of "Blank Generation".
Other New York venues apart from CBGB included the Lismar Lounge (41 First Avenue) and Aztec Lounge (9th Street).
The term "punk" initially referred to the scene in general, rather than a particular sound—the early New York punk bands represented a broad variety of influences. Among them, the Ramones, the Heartbreakers, Richard Hell and the Voidoids, and the Dead Boys were establishing a distinct musical style. Even where they diverged most clearly, in lyrical approach—the Ramones' apparent guilelessness at one extreme, Hell's conscious craft at the other—there was an abrasive attitude in common. Their shared attributes of minimalism and speed, however, had not yet come to define punk rock.
Other U.S. cities.
Chickasha, Oklahoma gave birth to avant garde, glam-punk bands Victoria Vein and the Thunderpunks in 1974 and Debris' in 1975 whose self-released underground classic Static Disposal was released in 1976. The album has been touted as an inspiration by numerous bands including Scream, Nurse With Wound, the Melvins and Sonic Youth.
In 1975, the Suicide Commandos formed in Minneapolis. They were one of the first U.S. bands outside of New York to play in the Ramones-style harder-louder-faster mode that would define punk rock. Detroit's Death self-released one of their 1974 recordings, "Politicians in My Eyes", in 1976. As the punk movement expanded rapidly in the United Kingdom that year, a few bands with similar tastes and attitude appeared around the United States. The first West Coast punk scenes emerged in San Francisco, with the bands Crime and the Nuns, and Seattle, where the Telepaths, Meyce, and the Tupperwares played a groundbreaking show on May 1. Rock critic Richard Meltzer cofounded VOM (short for "vomit") in Los Angeles. In Washington, D.C., raucous roots-rockers the Razz helped along a nascent punk scene featuring Overkill, the Slickee Boys, and the Look. Around the turn of the year, White Boy began giving notoriously crazed performances. In Boston, the scene at the Rathskeller—affectionately known as the Rat—was also turning toward punk, though the defining sound retained a distinct garage rock orientation. Among the city's first new acts to be identified with punk rock was DMZ. In Bloomington, Indiana, the Gizmos played in a jokey, raunchy, Dictators-inspired style later referred to as "frat punk".
Like their garage rock predecessors, these local scenes were facilitated by enthusiastic impresarios who operated nightclubs or organized concerts in venues such as schools, garages, or warehouses, advertised via inexpensively printed flyers and fanzines. In some cases, punk's do it yourself ethic reflected an aversion to commercial success, as well as a desire to maintain creative and financial autonomy. As Joe Harvard, a participant in the Boston scene, describes, it was often a simple necessity—the absence of a local recording industry and well-distributed music magazines left little recourse but DIY.
Australia.
At the same time, a similar music-based subculture was beginning to take shape in various parts of Australia. A scene was developing around Radio Birdman and its main performance venue, the Oxford Tavern (later the Oxford Funhouse), located in Sydney's Darlinghurst suburb. In December 1975, the group won the "RAM (Rock Australia Magazine)"/Levi's Punk Band Thriller competition. By 1976, the Saints were hiring Brisbane local halls to use as venues, or playing in "Club 76", their shared house in the inner suburb of Petrie Terrace. The band soon discovered that musicians were exploring similar paths in other parts of the world. Ed Kuepper, co-founder of the Saints, later recalled:
One thing I remember having had a really depressing effect on me was the first Ramones album. When I heard it [in 1976], I mean it was a great record ... but I hated it because I knew we’d been doing this sort of stuff for years. There was even a chord progression on that album that we used ... and I thought, "Fuck. We’re going to be labeled as influenced by the Ramones", when nothing could have been further from the truth.
On the other side of Australia, in Perth, germinal punk rock act the Cheap Nasties, featuring singer-guitarist Kim Salmon, formed in August. In September 1976, the Saints became the first punk rock band outside the U.S. to release a recording, the single "(I'm) Stranded". As with Patti Smith's debut, the band self-financed, packaged, and distributed the single. "(I'm) Stranded" had limited impact at home, but the British music press recognized it as a groundbreaking record. At the insistence of their superiors in the UK, EMI Australia signed the Saints. Meanwhile, Radio Birdman came out with a self-financed EP, "Burn My Eye", in October. "Trouser Press" critic Ian McCaleb later described the record as the "archetype for the musical explosion that was about to occur".
United Kingdom.
After a brief period unofficially managing the New York Dolls, Briton Malcolm McLaren returned to London in May 1975, inspired by the new scene he had witnessed at CBGB. The Kings Road clothing store he co-owned, recently renamed Sex, was building a reputation with its outrageous "anti-fashion". Among those who frequented the shop were members of a band called the Strand, which McLaren had also been managing. In August, the group was seeking a new lead singer. Another Sex habitué, Johnny Rotten, auditioned for and won the job. Adopting a new name, the group played its first gig as the Sex Pistols on November 6, 1975, at Saint Martin's School of Art and soon attracted a small but ardent following. In February 1976, the band received its first significant press coverage; guitarist Steve Jones declared that the Sex Pistols were not so much into music as they were "chaos". The band often provoked its crowds into near-riots. Rotten announced to one audience, "Bet you don't hate us as much as we hate you!" McLaren envisioned the Sex Pistols as central players in a new youth movement, "hard and tough". As described by critic Jon Savage, the band members "embodied an attitude into which McLaren fed a new set of references: late-sixties radical politics, sexual fetish material, pop history...youth sociology".
Bernard Rhodes, a sometime associate of McLaren and friend of the Sex Pistols, was similarly aiming to make stars of the band London SS. Early in 1976, London SS broke up before ever performing publicly, spinning off two new bands: the Damned and the Clash, which was joined by Joe Strummer, former lead singer of the 101'ers. On June 4, 1976, the Sex Pistols played Manchester's Lesser Free Trade Hall in what came to be regarded as one of the most influential rock shows ever. Among the approximately forty audience members were the two locals who organised the gig—they had formed Buzzcocks after seeing the Sex Pistols in February. Others in the small crowd went on to form Joy Division, the Fall, and—in the 1980s—the Smiths.
In July, the Ramones crossed the Atlantic for two London shows that helped spark the nascent UK punk scene and affected its musical style—"instantly nearly every band speeded up". On July 4, they played with the Flamin' Groovies and the Stranglers before a crowd of 2,000 at the Roundhouse. That same night, the Clash debuted, opening for the Sex Pistols in Sheffield. On July 5, members of both bands attended a Ramones club gig. The following night, the Damned performed their first show, as the Sex Pistols opening act in London. In critic Kurt Loder's description, the Sex Pistols purveyed a "calculated, arty nihilism, [while] the Clash were unabashed idealists, proponents of a radical left-wing social critique of a sort that reached back at least to ... Woody Guthrie in the 1940s". The Damned built a reputation as "punk's party boys". This London scene's first fanzine appeared a week later. Its title, "Sniffin' Glue", derived from a Ramones song. Its subtitle affirmed the connection with what was happening in New York: "+ Other Rock 'n' Roll Habits for Punks!"
Another Sex Pistols gig in Manchester on July 20, with a reorganized version of Buzzcocks debuting in support, gave further impetus to the scene there. In August, the self-described "First European Punk Rock Festival" was held in Mont de Marsan in the southwest of France. Eddie and the Hot Rods, a London pub rock group, headlined. The Sex Pistols, originally scheduled to play, were dropped by the organizers who said the band had gone "too far" in demanding top billing and certain amenities; the Clash backed out in solidarity. The only band from the new punk movement to appear was the Damned.
Over the next several months, many new punk rock bands formed, often directly inspired by the Sex Pistols. In London, women were near the center of the scene—among the initial wave of bands were the female-fronted Siouxsie and the Banshees and X-Ray Spex and the all-female the Slits. There were female bassists Gaye Advert in the Adverts and Shanne Bradley in the Nipple Erectors. Other groups included Subway Sect, Eater, the Subversives, the aptly named London, and Chelsea, which soon spun off Generation X. Farther afield, Sham 69 began practicing in the southeastern town of Hersham. In Durham, there was Penetration, with lead singer Pauline Murray. On September 20–21, the 100 Club Punk Festival in London featured the four primary British groups (London's big three and Buzzcocks), as well as Paris's female-fronted Stinky Toys, arguably the first punk rock band from a non-Anglophone country. Siouxsie and the Banshees and Subway Sect debuted on the festival's first night; that same evening, Eater debuted in Manchester. On the festival's second night, audience member Sid Vicious was arrested, charged with throwing a glass at the Damned that shattered and destroyed a girl's eye. Press coverage of the incident fueled punk's reputation as a social menace.
Some new bands, such as London's Alternative TV, Edinburgh's Rezillos, and Leamington's the Shapes, identified with the scene even as they pursued more experimental music. Others of a comparatively traditional rock 'n' roll bent were also swept up by the movement: the Vibrators, formed as a pub rock–style act in February 1976, soon adopted a punk look and sound. A few even longer-active bands including Surrey neo-mods the Jam and pub rockers the Stranglers and Cock Sparrer also became associated with the punk rock scene. Alongside the musical roots shared with their American counterparts and the calculated confrontationalism of the early Who, the British punks also reflected the influence of glam rock and related bands such as Slade, T.Rex, and Roxy Music. One of the groups openly acknowledging that influence were the Undertones, from Derry in Northern Ireland.
In October, the Damned became the first UK punk rock band to release a single, the romance-themed "New Rose". The Vibrators followed the next month with "We Vibrate" and, backing long-time rocker Chris Spedding, "Pogo Dancing". The latter was hardly a punk song by any stretch, but it was perhaps the first song "about" punk rock. On 26 November, the Sex Pistols' "Anarchy in the U.K." came out—with its debut single the band succeeded in its goal of becoming a "national scandal". Jamie Reid's "anarchy flag" poster and his other design work for the Sex Pistols helped establish a distinctive punk visual aesthetic. On December 1, an incident took place that sealed punk rock's notorious reputation: On "Thames Today", an early evening London TV show, Sex Pistols guitarist Steve Jones was goaded into a verbal altercation by the host, Bill Grundy. Jones called Grundy a "dirty fucker" on live television, triggering a media controversy. Two days later, the Sex Pistols, the Clash, the Damned, and the Heartbreakers set out on the Anarchy Tour, a series of gigs throughout the UK. Many of the shows were cancelled by venue owners in response to the media outrage following the Grundy confrontation.
Second wave.
By 1977, a second wave of the punk rock movement was breaking in the three countries where it had emerged, as well as in many other places. Bands from the same scenes often sounded very different from each other, reflecting the eclectic state of punk music during the era. While punk rock remained largely an underground phenomenon in North America, Australia, and the new spots where it was emerging, in the UK it briefly became a major sensation.
North America.
The California punk scene was in full swing by early 1977. In Los Angeles, there were the Weirdos, the Zeros, Black Randy and the Metrosquad, the Germs, X, the Dickies, Bags, and the relocated Tupperwares, now dubbed the Screamers. San Francisco's second wave included the Avengers, Negative Trend, the Mutants, and the Sleepers. the Dils, from Carlsbad, moved between the two major cities. The Wipers formed in Portland, Oregon. In Seattle, there was the Lewd. Often sharing gigs with the Seattle punks were bands from across the Canadian border. A major scene developed in Vancouver, spearheaded by the Furies and Victoria's all-female Dee Dee and the Dishrags. the Skulls spun off into D.O.A. and the Subhumans. The K-Tels (later known as the Young Canadians) and Pointed Sticks were among the area's other leading punk acts.
In eastern Canada, the Toronto protopunk band Dishes had laid the groundwork for another sizable scene, and a September 1976 concert by the touring Ramones had catalyzed the movement. Early Ontario punk bands included the Diodes, the Viletones, the Battered Wives, the Demics, Forgotten Rebels, Teenage Head, the Poles, and the Ugly. Along with the Dishrags, Toronto's the Curse and B Girls were North America's first all-female punk acts. In July 1977, the Viletones, Diodes, Curse, and Teenage Head headed down to New York City to play "Canada night" at CBGB.
By mid-1977 in downtown New York, punk rock was already ceding its cutting-edge status to the anarchic sound of Teenage Jesus and the Jerks and Mars, spearheads of what became known as no wave, although several original punk bands continued to perform and new ones emerged on the scene. The Cramps, whose core members were from Sacramento, California by way of Akron, had debuted at CBGB in November 1976, opening for the Dead Boys. They were soon playing regularly at Max's Kansas City. The Misfits formed in nearby New Jersey. Still developing what would become their signature B movie–inspired style, later dubbed horror punk, they made their first appearance at CBGB in April 1977.
"Leave Home", the Ramones' second album, had come out in January. The Dead Boys' debut LP, "Young, Loud and Snotty", was released at the end of August. October saw two more debut albums from the scene: Richard Hell and the Voidoids' first full-length, "Blank Generation", and the Heartbreakers' "L.A.M.F." One track on the latter exemplified both the scene's close-knit character and the popularity of heroin within it: "Chinese Rocks"—the title refers to a strong form of the drug—was written by Dee Dee Ramone and Hell, both users, as were the Heartbreakers' Thunders and Nolan. (During the Heartbreakers' 1976 and 1977 tours of Britain, Thunders played a central role in popularizing heroin among the punk crowd there, as well.) The Ramones' third album, "Rocket to Russia", appeared in November 1977.
The Ohio protopunk bands were joined by Cleveland's the Pagans, Akron's Bizarros and Rubber City Rebels, and Kent's Human Switchboard. Bloomington, Indiana, had MX-80 Sound and Detroit had the Sillies. The Suburbs came together in the Twin Cities scene sparked by the Suicide Commandos. The Feederz formed in Arizona. Atlanta had the Fans. In North Carolina, there was Chapel Hill's H-Bombs and Raleigh's Th' Cigaretz. The Chicago scene began not with a band but with a group of DJs transforming a gay bar, La Mere Vipere, into what became known as America's first punk dance club. The Crucified, Tutu and the Pirates and Silver Abuse were among the city's first punk bands. In Boston, the scene at the Rat was joined by the Nervous Eaters, Thrills, and Human Sexual Response. In Washington, D.C., the Controls played their first gig in spring 1977, but the city's second wave really broke the following year with acts such as Urban Verbs, Half Japanese, D'Chumps, Rudements and Shirkers. By early 1978, the D.C. jazz-fusion group Mind Power had transformed into Bad Brains, one of the first bands to be identified with hardcore punk.
United Kingdom.
The Sex Pistols' live TV skirmish with Bill Grundy was the signal moment in British punk's transformation into a major media phenomenon, even as some stores refused to stock the records and radio airplay was hard to come by. Press coverage of punk misbehavior grew intense: On January 4, 1977, "The Evening News" of London ran a front-page story on how the Sex Pistols "vomited and spat their way to an Amsterdam flight". In February 1977, the first album by a British punk band appeared: "Damned Damned Damned" (by the Damned) reached number thirty-six on the UK chart. The EP "Spiral Scratch", self-released by Manchester's Buzzcocks, was a benchmark for both the DIY ethic and regionalism in the country's punk movement. The Clash's self-titled debut album came out two months later and rose to number twelve; the single "White Riot" entered the top forty. In May, the Sex Pistols achieved new heights of controversy (and number two on the singles chart) with "God Save the Queen". The band had recently acquired a new bassist, Sid Vicious, who was seen as exemplifying the punk persona.
Scores of new punk groups formed around the United Kingdom, as far from London as Belfast's Stiff Little Fingers and Dunfermline, Scotland's the Skids. Though most survived only briefly, perhaps recording a small-label single or two, others set off new trends. Crass, from Essex, merged a vehement, straight-ahead punk rock style with a committed anarchist mission, and played a major role in the emerging anarcho-punk movement. Sham 69, London's Menace, and the Angelic Upstarts from South Shields in the Northeast combined a similarly stripped-down sound with populist lyrics, a style that became known as street punk. These expressly working-class bands contrasted with others in the second wave that presaged the post-punk phenomenon. Liverpool's first punk group, Big in Japan, moved in a glam, theatrical direction. The band didn't survive long, but it spun off several well-known post-punk acts. The songs of London's Wire were characterized by sophisticated lyrics, minimalist arrangements, and extreme brevity. By the end of 1977, according to music historian Clinton Heylin, they were "England's arch-exponents of New Musick, and the true heralds of what came next."
Alongside thirteen original songs that would define classic punk rock, the Clash's debut had included a cover of the recent Jamaican reggae hit "Police and Thieves". Other first wave bands such as the Slits and new entrants to the scene like the Ruts and the Police interacted with the reggae and ska subcultures, incorporating their rhythms and production styles. The punk rock phenomenon helped spark a full-fledged ska revival movement known as 2 Tone, centered on bands such as the Specials, the Beat, Madness, and the Selecter.
June 1977 saw the release of another charting punk album: the Vibrators' "Pure Mania". In July, the Sex Pistols' third single, "Pretty Vacant", reached number six and the Saints had a top-forty hit with "This Perfect Day". Recently arrived from Australia, the band was now considered insufficiently "cool" to qualify as punk by much of the British media, though they had been playing a similar brand of music for years. In August, the Adverts entered the top twenty with "Gary Gilmore's Eyes". As punk became a broad-based national phenomenon in the summer of 1977, punk musicians and fans were increasingly subject to violent assaults by Teddy boys, football yobbos, and others. A Ted-aligned band recorded "The Punk Bashing Boogie".
In September, Generation X and the Clash reached the top forty with, respectively, "Your Generation" and "Complete Control". X-Ray Spex' "Oh Bondage Up Yours!" didn't chart, but it became a requisite item for punk fans. In October, the Sex Pistols hit number eight with "Holidays in the Sun", followed by the release of their first and only "official" album, "Never Mind the Bollocks, Here's the Sex Pistols". Inspiring yet another round of controversy, it topped the British charts. In December, one of the first books about punk rock was published: "The Boy Looked at Johnny", by Julie Burchill and Tony Parsons.
Australia.
In February 1977, EMI released the Saints debut album, "(I'm) Stranded", which the band recorded in two days. The Saints had relocated to Sydney; in April, they and Radio Birdman united for a major gig at Paddington Town Hall. Last Words had also formed in the city. The following month, the Saints relocated again, to Great Britain. In June, Radio Birdman released the album "Radios Appear" on its own Trafalgar label.
The Victims became a short-lived leader of the Perth scene, self-releasing the classic "Television Addict". They were joined by the Scientists, Kim Salmon's successor band to the Cheap Nasties. Among the other bands constituting Australia's second wave were Johnny Dole & the Scabs, the Hellcats, and Psychosurgeons (later known as the Lipstick Killers) in Sydney; The Leftovers, the Survivors, and Razar in Brisbane; and La Femme, the Negatives, and the Babeez (later known as the News) in Melbourne. Melbourne's art rock–influenced Boys Next Door featured singer Nick Cave, who would become one of the world's best-known post-punk artists.
Rest of the world.
Meanwhile, punk rock scenes were emerging around the globe. In France, "les punks", a Parisian subculture of Lou Reed fans, had already been around for years. Following the lead of Stinky Toys, Métal Urbain played its first concert in December 1976. In August 1977, Asphalt Jungle played at the second Mont de Marsan punk festival. Stinky Toys' debut single, "Boozy Creed", came out in September. It was perhaps the first non-English-language punk rock record, though as music historian George Gimarc notes, the punk enunciation made that distinction somewhat moot. The following month, Métal Urbain's first 45, "Panik", appeared. After the release of their minimalist punk debut, "Rien à dire", Marie et les Garçons became involved in New York's mutant disco scene. Asphalt Jungle's "Deconnection" and Gasoline's "Killer Man" also came out before the end of the year, and other French punk acts such as Oberkampf and Starshooter soon formed.
1977 also saw the debut album from Hamburg's Big Balls and the Great White Idiot, arguably West Germany's first punk band. Other early German punk acts included the Fred Banana Combo and Pack. Bands primarily inspired by British punk sparked what became known as the Neue Deutsche Welle (NDW) movement. Vanguard NDW acts such as the Nina Hagen Band and S.Y.P.H. featured strident vocals and an emphasis on provocation. Before turning in a mainstream direction in the 1980s, NDW attracted a politically conscious and diverse audience, including both participants of the left-wing alternative scene and neo-Nazi skinheads. These opposing factions were mutually attracted by a view of punk rock as "politically as well as musically...'against the system'."
Scandinavian punk was propelled early on by tour dates by bands such as the Clash and the Ramones (both in Stockholm in May 1977), and the Sex Pistols' tour through Denmark, Sweden and Norway in July the same year. The band Briard jump-started Finnish punk with its November 1977 single "I Really Hate Ya"/"I Want Ya Back"; other early Finnish punk acts included Eppu Normaali and singer Pelle Miljoona. The first Swedish punk single was "Vårdad klädsel"/"Förbjudna ljud" released by Kriminella Gitarrer in February 1978, which started an extensive Swedish punk scene featuring act such as Ebba Grön, KSMB, Rude Kids, Besökarna, Liket Lever, Garbochock, Attentat, and many others. Within a couple of years, hundreds of punk singles were released in Sweden.
In Japan, a punk movement developed around bands playing in an art/noise style such as Friction, and "psych punk" acts like Gaseneta and Kadotani Michio. In New Zealand, Auckland's Scavengers and Suburban Reptiles were followed by the Enemy of Dunedin. I. Punk rock scenes also grew in other countries such as Belgium (the Kids, Chainsaw), the Netherlands (the Suzannes, the Ex), Spain (La Banda Trapera Del Río, Kaka De Luxe), and Switzerland (Nasal Boys, Kleenex).
Indonesia was a part of the largest punk movement in Southeast Asia, heavily influenced by Green Day, Rancid, and the Offspring. Young people created their own underground sub-culture of punk, which over time developed into a style that was completely different to the original movement.
Punk emerged in South Africa as direct opposition to the conservative apartheid government and racial segregation enforcement of the time. Bands like Wild Youth and National Wake led the way in the late 1970s and early 1980s, followed by Powerage and Screaming Foetus from Durban and Toxik Sox in Johannesburg in the mid '80s.
Schism and diversification.
By 1979, the hardcore punk movement was emerging in Southern California. A rivalry developed between adherents of the new sound and the older punk rock crowd. Hardcore, appealing to a younger, more suburban audience, was perceived by some as anti-intellectual, overly violent, and musically limited. In Los Angeles, the opposing factions were often described as "Hollywood punks" and "beach punks", referring to Hollywood's central position in the original L.A. punk rock scene and to hardcore's popularity in the shoreline communities of South Bay and Orange County.
As hardcore became the dominant punk rock style, many bands of the older California punk rock movement split up, although X went on to mainstream success and the Go-Go's, part of the Hollywood punk scene when they formed in 1978, adopted a pop sound and became major stars. Across North America, many other first and second wave punk bands also dissolved, while younger musicians inspired by the movement explored new variations on punk. Some early punk bands transformed into hardcore acts. A few, most notably the Ramones, Richard Hell and the Voidoids, and Johnny Thunders and the Heartbreakers, continued to pursue the style they had helped create. Crossing the lines between "classic" punk, post-punk, and hardcore, San Francisco's Flipper was founded in 1979 by former members of Negative Trend and the Sleepers. They became "the reigning kings of American underground rock, for a few years".
Radio Birdman broke up in June 1978 while touring the UK, where the early unity between bohemian, middle-class punks (many with art school backgrounds) and working-class punks had disintegrated. In contrast to North America, more of the bands from the original British punk movement remained active, sustaining extended careers even as their styles evolved and diverged. Meanwhile, the Oi! and anarcho-punk movements were emerging. Musically in the same aggressive vein as American hardcore, they addressed different constituencies with overlapping but distinct anti-establishment messages. As described by Dave Laing, "The model for self-proclaimed punk after 1978 derived from the Ramones via the eight-to-the-bar rhythms most characteristic of the Vibrators and Clash. ... It became essential to sound one particular way to be recognized as a 'punk band' now." In February 1979, former Sex Pistols bassist Sid Vicious died of a heroin overdose in New York. If the Sex Pistols' breakup the previous year had marked the end of the original UK punk scene and its promise of cultural transformation, for many the death of Vicious signified that it had been doomed from the start.
By the turn of the decade, the punk rock movement had split deeply along cultural and musical lines, leaving a variety of derivative scenes and forms. On one side were new wave and post-punk artists; some adopted more accessible musical styles and gained broad popularity, while some turned in more experimental, less commercial directions. On the other side, hardcore punk, Oi!, and anarcho-punk bands became closely linked with underground cultures and spun off an array of subgenres. Somewhere in between, pop punk groups created blends like that of the ideal record, as defined by Mekons cofounder Kevin Lycett: "a cross between Abba and the Sex Pistols". A range of other styles emerged, many of them fusions with long-established genres. The Clash album "London Calling", released in December 1979, exemplified the breadth of classic punk's legacy. Combining punk rock with reggae, ska, R&B, and rockabilly, it went on to be acclaimed as one of the best rock records ever. At the same time, as observed by Flipper singer Bruce Loose, the relatively restrictive hardcore scenes diminished the variety of music that could once be heard at many punk gigs. If early punk, like most rock scenes, was ultimately male-oriented, the hardcore and Oi! scenes were significantly more so, marked in part by the slam dancing and moshing with which they became identified.
New wave.
In 1976—first in London, then in the United States—"New Wave" was introduced as a complementary label for the formative scenes and groups also known as "punk"; the two terms were essentially interchangeable. "NME" journalist Roy Carr is credited with proposing the term's use (adopted from the cinematic French New Wave of the 1960s) in this context. Over time, "new wave" acquired a distinct meaning: Bands such as Blondie and Talking Heads from the CBGB scene; the Cars, who emerged from the Rat in Boston; the Go-Go's in Los Angeles; and the Police in London that were broadening their instrumental palette, incorporating dance-oriented rhythms, and working with more polished production were specifically designated "new wave" and no longer called "punk". Dave Laing suggests that some punk-identified British acts pursued the new wave label in order to avoid radio censorship and make themselves more palatable to concert bookers.
Bringing elements of punk rock music and fashion into more pop-oriented, less "dangerous" styles, new wave artists became very popular on both sides of the Atlantic. New wave became a catch-all term, encompassing disparate styles such as 2 Tone ska, the mod revival inspired by the Jam, the sophisticated pop-rock of Elvis Costello and XTC, the New Romantic phenomenon typified by Ultravox, synthpop groups like Tubeway Army (which had started out as a straight-ahead punk band) and Human League, and the sui generis subversions of Devo, who had gone "beyond punk before punk even properly existed". New wave became a pop culture sensation with the debut of the cable television network MTV in 1981, which put many new wave videos into regular rotation. However, the music was often derided at the time as being silly and disposable.
Post-punk.
During 1976–77, in the midst of the original UK punk movement, bands emerged such as Manchester's Joy Division, the Fall, and Magazine, Leeds' Gang of Four, and London's the Raincoats that became central post-punk figures. Some bands classified as post-punk, such as Throbbing Gristle and Cabaret Voltaire, had been active well before the punk scene coalesced; others, such as the Slits and Siouxsie and the Banshees, transitioned from punk rock into post-punk. A few months after the Sex Pistols' breakup, John Lydon (no longer "Rotten") cofounded Public Image Ltd. Lora Logic, formerly of X-Ray Spex, founded Essential Logic. Killing Joke formed in 1979. These bands were often musically experimental, like certain new wave acts; defining them as "post-punk" was a sound that tended to be less pop and more dark and abrasive—sometimes verging on the atonal, as with Subway Sect and Wire—and an anti-establishment posture directly related to punk's. Post-punk reflected a range of art rock influences from Captain Beefheart to David Bowie and Roxy Music to Krautrock and, once again, the Velvet Underground.
Post-punk brought together a new fraternity of musicians, journalists, managers, and entrepreneurs; the latter, notably Geoff Travis of Rough Trade and Tony Wilson of Factory, helped to develop the production and distribution infrastructure of the indie music scene that blossomed in the mid-1980s. Smoothing the edges of their style in the direction of new wave, several post-punk bands such as New Order (descended from Joy Division) and the Cure. crossed over to a mainstream U.S. audience. Bauhaus was one of the formative gothic rock bands. Others, like Gang of Four, the Raincoats and Throbbing Gristle, who had little more than cult followings at the time, are seen in retrospect as significant influences on modern popular culture.
A number of U.S. artists were retrospectively defined as post-punk; Television's debut album "Marquee Moon", released in 1977, is frequently cited as a seminal album in the field. The no wave movement that developed in New York in the late 1970s, with artists such as Lydia Lunch and James Chance, is often treated as the phenomenon's U.S. parallel. The later work of Ohio protopunk pioneers Pere Ubu is also commonly described as post-punk. One of the most influential American post-punk bands was Boston's Mission of Burma, who brought abrupt rhythmic shifts derived from hardcore into a highly experimental musical context. In 1980, Australia's Boys Next Door moved to London and changed their name to the Birthday Party, which evolved into Nick Cave and the Bad Seeds. Led by the Primitive Calculators, Melbourne's Little Band scene would further explore the possibilities of post-punk. Later alternative rock musicians found diverse inspiration among these post-punk predecessors, as they did among their new wave contemporaries.
Hardcore.
A distinctive style of punk, characterized by superfast, aggressive beats, screaming vocals, and often politically aware lyrics, began to emerge in 1978 among bands scattered around the United States and Canada. The first major scene of what came to be known as hardcore punk developed in Southern California in 1978–79, initially around such punk bands as the Germs and Fear. The movement soon spread around North America and internationally. According to author Steven Blush, "Hardcore comes from the bleak suburbs of America. Parents moved their kids out of the cities to these horrible suburbs to save them from the 'reality' of the cities and what they ended up with was this new breed of monster".
Among the earliest hardcore bands, regarded as having made the first recordings in the style, were Southern California's Middle Class and Black Flag. Bad Brains—all of whom were black, a rarity in punk of any era—launched the D.C. scene. Austin, Texas's Big Boys, San Francisco's Dead Kennedys, and Vancouver's D.O.A. were among the other initial hardcore groups. They were soon joined by bands such as the Minutemen, Descendents, Circle Jerks, Adolescents, and T.S.O.L. in Southern California; D.C.'s Teen Idles, Minor Threat, and State of Alert; and Austin's MDC and the Dicks. By 1981, hardcore was the dominant punk rock style not only in California, but much of the rest of North America as well. A New York hardcore scene grew, including the relocated Bad Brains, New Jersey's Misfits and Adrenalin O.D., and local acts such as the Nihilistics, the Mob, Reagan Youth, and Agnostic Front. Beastie Boys, who would become famous as a hip-hop group, debuted that year as a hardcore band. They were followed by the Cro-Mags, Murphy's Law, and Leeway. By 1983, St. Paul's Hüsker Dü, Willful Neglect, Chicago's Naked Raygun, Indianapolis's Zero Boys, and D.C.'s the Faith were taking the hardcore sound in experimental and ultimately more melodic directions. Hardcore would constitute the American punk rock standard throughout the decade. The lyrical content of hardcore songs is often critical of commercial culture and middle-class values, as in Dead Kennedys' celebrated "Holiday in Cambodia" (1980).
Straight edge bands like Minor Threat, Boston's SS Decontrol, and Reno, Nevada's 7 Seconds rejected the self-destructive lifestyles of many of their peers, and built a movement based on positivity and abstinence from cigarettes, alcohol, drugs, and casual sex.
Skate punk innovators also pointed in other directions: Big Boys helped establish funkcore, while Venice, California's Suicidal Tendencies had a formative effect on the heavy metal–influenced crossover thrash style. Toward the middle of the decade, D.R.I. spawned the superfast thrashcore genre. Both developed in multiple locations. Sacramento's Tales of Terror, which mixed psychedelic rock into their hardcore sound, were an early influence on the grunge genre. D.C.'s Void was one of the first punk-metal crossover acts and influenced thrash metal.
Oi!
Following the lead of first-wave British punk bands Cock Sparrer and Sham 69, in the late 1970s second-wave units like Cockney Rejects, Angelic Upstarts, the Exploited, Anti-Establishment and the 4-Skins sought to realign punk rock with a working class, street-level following. For that purpose, they believed, the music needed to stay "accessible and unpretentious", in the words of music historian Simon Reynolds. Their style was originally called "real punk" or street punk; "Sounds" journalist Garry Bushell is credited with labelling the genre "Oi!" in 1980. The name is partly derived from the Cockney Rejects' habit of shouting "Oi! Oi! Oi!" before each song, instead of the time-honored "1,2,3,4!"
The Oi! movement was fueled by a sense that many participants in the early punk rock scene were, in the words of the Business guitarist Steve Kent, "trendy university people using long words, trying to be artistic ... and losing touch". According to Bushell, "Punk was meant to be of the voice of the dole queue, and in reality most of them were not. But Oi was the reality of the punk mythology. In the places where [these bands] came from, it was harder and more aggressive and it produced just as much quality music." Lester Bangs described Oi! as "politicized football chants for unemployed louts". One song in particular, the Exploited's "Punks Not Dead", spoke to an international constituency. It was adopted as an anthem by the groups of disaffected Mexican urban youth known in the 1980s as "bandas"; one "banda" named itself PND, after the song's initials.
Although most Oi! bands in the initial wave were apolitical or left wing, many of them began to attract a white power skinhead following. Racist skinheads sometimes disrupted Oi! concerts by shouting fascist slogans and starting fights, but some Oi! bands were reluctant to endorse criticism of their fans from what they perceived as the "middle-class establishment". In the popular imagination, the movement thus became linked to the far right. "Strength Thru Oi!", an album compiled by Bushell and released in May 1981, stirred controversy, especially when it was revealed that the belligerent figure on the cover was a neo-Nazi jailed for racist violence (Bushell claimed ignorance). On July 3, a concert at Hamborough Tavern in Southall featuring the Business, the 4-Skins, and the Last Resort was firebombed by local Asian youths who believed that the event was a neo-Nazi gathering. Following the Southall riot, press coverage increasingly associated Oi! with the extreme right, and the movement soon began to lose momentum.
Anarcho-punk.
Anarcho-punk developed alongside the Oi! and American hardcore movements. Inspired by Crass, its Dial House commune, and its independent Crass Records label, a scene developed around British bands such as Subhumans, Flux of Pink Indians, Conflict, Poison Girls, and the Apostles that was concerned as much with anarchist and DIY principles as it was with music. The acts featured ranting vocals, discordant instrumental sounds, primitive production values, and lyrics filled with political and social content, often addressing issues such as class inequalities and military violence. Anarcho-punk musicians and fans disdained the older punk scene from which theirs had evolved. In historian Tim Gosling's description, they saw "safety pins and Mohicans as little more than ineffectual fashion posturing stimulated by the mainstream media and industry... Whereas the Sex Pistols would proudly display bad manners and opportunism in their dealings with 'the establishment,' the anarcho-punks kept clear of 'the establishment' altogether".
The movement spun off several subgenres of a similar political bent. Discharge, founded back in 1977, established D-beat in the early 1980s. Other groups in the movement, led by Amebix and Antisect, developed the extreme style known as crust punk. Several of these bands rooted in anarcho-punk such as the Varukers, Discharge, and Amebix, along with former Oi! groups such as the Exploited and bands from father afield like Birmingham's Charged GBH, became the leading figures in the UK 82 hardcore movement. The anarcho-punk scene also spawned bands such as Napalm Death, Carcass, and Extreme Noise Terror that in the mid-1980s defined grindcore, incorporating extremely fast tempos and death metal–style guitarwork. Led by Dead Kennedys, a U.S. anarcho-punk scene developed around such bands as Austin's MDC and Southern California's Another Destructive System.
Pop punk.
With their love of the Beach Boys and late 1960s bubblegum pop, the Ramones paved the way to what became known as pop punk. In the late 1970s, UK bands such as Buzzcocks and the Undertones combined pop-style tunes and lyrical themes with punk's speed and chaotic edge. In the early 1980s, some of the leading bands in Southern California's hardcore punk rock scene emphasized a more melodic approach than was typical of their peers. According to music journalist Ben Myers, Bad Religion "layered their pissed off, politicized sound with the smoothest of harmonies"; Descendents "wrote almost surfy, Beach Boys–inspired songs about girls and food and being young(ish)". Epitaph Records, founded by Brett Gurewitz of Bad Religion, was the base for many future pop punk bands. Bands that fused punk with light-hearted pop melodies, such as the Queers and Screeching Weasel, began appearing around the country, in turn influencing bands like Green Day and the Offspring, who brought pop punk wide popularity and major record sales. Bands such as the Vandals and Guttermouth developed a style blending pop melodies with humorous and offensive lyrics. Eventually, the geographically large midwest U.S. punk scene, anchored largely in places like Chicago and Minneapolis, would spawn bands like Dillinger Four who would talk a catchy, hooky pop-punk approach and reinfuse it with some of punk's earlier grit and fury, creating a distinctive punk rock sound with a regional tag. This particular substrate still maintains an identity today. The mainstream pop punk of latter-day bands such as Blink-182 is criticized by many punk rock devotees; in critic Christine Di Bella's words, "It's punk taken to its most accessible point, a point where it barely reflects its lineage at all, except in the three-chord song structures."
Other fusions and directions.
From 1977 on, punk rock crossed lines with many other popular music genres. Los Angeles punk rock bands laid the groundwork for a wide variety of styles: the Flesh Eaters with deathrock; the Plugz with Chicano punk; and Gun Club with punk blues. The Meteors, from South London, and the Cramps, who moved from New York to Los Angeles in 1980, were innovators in the psychobilly fusion style. Milwaukee's Violent Femmes jumpstarted the American folk punk scene, while the Pogues did the same on the other side of the Atlantic, influencing many Celtic punk bands. Hardcore punk was combined with hip hop, creating rapcore.
Other bands pointed punk rock toward future rock styles or its own foundations. New York's Suicide, L.A.'s the Screamers and Nervous Gender, Australia's JAB, and Germany's Deutsch Amerikanische Freundschaft were pioneers of electropunk. The Ex, from the Netherlands, were in the art punk vanguard. Chicago's Big Black was a major influence on noise rock, math rock, and industrial rock. Garage punk bands from all over—such as Medway's Thee Mighty Caesars, Chicago's Dwarves, and Adelaide's Exploding White Mice—pursued a version of punk rock that was close to its roots in 1960s garage rock. Seattle's Mudhoney, one of the central bands in the development of grunge, has been described as "garage punk".
Legacy and later developments.
Alternative rock.
The underground punk rock movement inspired countless bands that either evolved from a punk rock sound or brought its outsider spirit to very different kinds of music. The original punk explosion also had a long-term effect on the music industry, spurring the growth of the independent sector. During the early 1980s, British bands like New Order and the Cure that straddled the lines of post-punk and new wave developed both new musical styles and a distinctive industrial niche. Though commercially successful over an extended period, they maintained an underground-style, subcultural identity. In the United States, bands such as Hüsker Dü and their Minneapolis protégés the Replacements bridged the gap between punk rock genres like hardcore and the more melodic, explorative realm of what was then called "college rock".
A 1985 "Rolling Stone" feature on the Minneapolis scene and innovative California hardcore acts such as Black Flag and Minutemen declared, "Primal punk is passé. The best of the American punk rockers have moved on. They have learned how to play their instruments. They have discovered melody, guitar solos and lyrics that are more than shouted political slogans. Some of them have even discovered the Grateful Dead." By the end of the 1980s, these bands, who had largely eclipsed their punk rock forebears in popularity, were classified broadly as alternative rock. Alternative rock encompasses a diverse set of styles—including gothic rock and grunge, among others—unified by their debt to punk rock and their origins outside of the musical mainstream.
As American alternative bands like Sonic Youth, which had grown out of the no wave scene, and Boston's Pixies started to gain larger audiences, major labels sought to capitalize on the underground market that had been sustained by hardcore punk for years. In 1991, Nirvana emerged from Washington State's grunge scene, achieving huge commercial success with its second album, "Nevermind". The band's members cited punk rock as a key influence on their style. "Punk is musical freedom", wrote singer Kurt Cobain. "It’s saying, doing, and playing what you want." Nirvana's success opened the door to mainstream popularity for a wide range of other "left-of-the-dial" acts, such as Pearl Jam and Red Hot Chili Peppers, and fueled the alternative rock boom of the early and mid-1990s.
Emo.
In its original, mid-1980s incarnation, emo was a less musically restrictive style of punk developed by participants in the Washington, D.C. area hardcore scene. It was originally referred to as "emocore", an abbreviation of "emotive hardcore". Jimmy Eat World took emo in a radio-ready pop punk direction, and had top ten albums in 2004 and 2007.
Queercore.
In the 1990s, the queercore movement developed around a number of punk bands with gay, lesbian, bisexual, or genderqueer members such as Against Me! God Is My Co-Pilot, Pansy Division, Team Dresch, and Sister George. Inspired by openly gay punk musicians of an earlier generation such as Jayne County, Phranc, and Randy Turner, and bands like Nervous Gender, the Screamers, and Coil, queercore embraces a variety of punk and other alternative music styles. Queercore lyrics often treat the themes of prejudice, sexual identity, gender identity, and individual rights. The movement has continued into the 21st century, supported by festivals such as Queeruption.
Riot grrrl.
In 1991, a concert of female-led bands at the International Pop Underground Convention in Olympia, Washington, heralded the emerging riot grrrl phenomenon. Billed as "Love Rock Revolution Girl Style Now", the concert's lineup included Bikini Kill, Bratmobile, Heavens to Betsy, L7, and Mecca Normal. The riot grrrl movement foregrounded feminist concerns and progressive politics in general; the DIY ethic and fanzines were also central elements of the scene. Singer-guitarists Corin Tucker of Heavens to Betsy and Carrie Brownstein of Excuse 17, bands active in both the queercore and riot grrrl scenes, cofounded the indie/punk band Sleater-Kinney in 1994. Bikini Kill's lead singer, Kathleen Hanna, the iconic figure of riot grrrl, moved on to form the art punk group Le Tigre in 1998.
Revival.
By the 1990s, punk rock was sufficiently ingrained in Western culture that punk trappings were often used to market highly commercial bands as "rebels". Marketers capitalized on the style and hipness of punk rock to such an extent that a 1993 ad campaign for an automobile, the Subaru Impreza, claimed that the car was "like punk rock". Along with Nirvana, many of the leading alternative rock artists of the early 1990s acknowledged the influence of earlier punk rock acts. With Nirvana's success, the major record companies once again saw punk bands as potentially profitable.
In 1993, California's Green Day and Bad Religion were both signed to major labels. The next year, Green Day put out "Dookie," which became a huge hit, selling nine million albums in the United States in just over two years. Bad Religion's "Stranger Than Fiction" was certified gold. Other California punk bands on the independent label Epitaph, run by Bad Religion guitarist Brett Gurewitz, also began achieving mainstream popularity. In 1994, Epitaph released "Let's Go" by Rancid, "Punk in Drublic" by NOFX, and "Smash" by the Offspring, each eventually certified gold or better. That June, Green Day's "Longview" reached number one on "Billboard"s Modern Rock Tracks chart and became a top forty airplay hit, arguably the first ever American punk song to do so; just one month later, the Offspring's "Come Out and Play" followed suit. MTV and radio stations such as Los Angeles' KROQ-FM played a major role in these bands' crossover success, though NOFX refused to let MTV air its videos.
Following the lead of Boston's Mighty Mighty Bosstones and two California bands, Anaheim's No Doubt and Long Beach's Sublime, ska punk and ska-core became widely popular in the mid-1990s. By 1996, genre acts such as Reel Big Fish and Less Than Jake were being signed to major labels. The original 2 Tone bands had emerged amid punk rock's second wave, but their music was much closer to its Jamaican roots—"ska at 78 rpm". Ska punk bands in the third wave of ska created a true musical fusion between the genres. "...And Out Come the Wolves", the 1995 album by Rancid—which had evolved out of Operation Ivy—became the first record in this ska revival to be certified gold; Sublime's self-titled 1996 album was certified platinum early in 1997. In Australia, two popular groups, skatecore band Frenzal Rhomb and pop punk act Bodyjar, also established followings in Japan.
Green Day and "Dookie"'s enormous sales paved the way for a host of bankable North American pop punk bands in the following decade. With punk rock's renewed visibility came concerns among some in the punk community that the music was being co-opted by the mainstream. They argued that by signing to major labels and appearing on MTV, punk bands like Green Day were buying into a system that punk was created to challenge. Such controversies have been part of the punk culture since 1977, when the Clash was widely accused of "selling out" for signing with CBS Records. The Vans Warped Tour and the mall chain store Hot Topic brought punk even further into the U.S. mainstream.
In the mainstream.
By early 1998, the punk revival had commercially stalled, but not for long. That November, the Offspring's "Americana" on the major Columbia label debuted at number two on the album chart. A bootleg MP3 of its first single, "Pretty Fly (for a White Guy)", made it onto the Internet and was downloaded a record 22 million times—illegally. The following year, "Enema of the State", the first major-label release by pop punk band Blink-182, reached the top ten and sold four million copies in under twelve months. In January 2000, the album's second single, "All the Small Things", hit the sixth spot on the "Billboard" Hot 100. While they were viewed as Green Day "acolytes", critics also found teen pop acts such as Britney Spears, the Backstreet Boys, and 'N Sync suitable points of comparison for Blink-182's sound and market niche. The band's "Take Off Your Pants and Jacket" (2001) and "Blink-182" (2003) respectively rose to numbers one and three on the album chart. In November 2003, "The New Yorker" described how the "giddily puerile" act had "become massively popular with the mainstream audience, a demographic formerly considered untouchable by punk-rock purists."
Other new North American pop punk bands, though often critically dismissed, also achieved major sales in the first decade of the 2000s. Ontario's Sum 41 reached the Canadian top ten with its 2001 debut album, "All Killer, No Filler", which eventually went platinum in the United States. The record included the number one U.S. Alternative hit "Fat Lip", which incorporated verses of what one critic called "brat rap."
The effect of commercialization on the music became an increasingly contentious issue. As observed by scholar Ross Haenfler, many punk fans "'despise corporate punk rock', typified by bands such as Sum 41 and Blink 182". At the same time, politicized and independent-label punk continued to thrive in the United States. Since 1993, Anti-Flag had been putting progressive politics at the center of its music. The administration of George W. Bush provided them and similarly minded acts eight years of conservative government to excoriate. Rise Against was the most successful of these groups, registering top ten records in 2006 with "The Sufferer & the Witness" and two years later with "Appeal to Reason". Leftist punk band Against Me!'s "New Wave" was named best album of 2007 by "Spin".
Elsewhere around the world, "punkabilly" band the Living End became major stars in Australia with their self-titled 1998 debut.

</doc>
<doc id="23040" url="https://en.wikipedia.org/wiki?curid=23040" title="Political philosophy">
Political philosophy

Political philosophy, or political theory, is the study of topics such as politics, liberty, justice, property, rights, law, and the enforcement of a legal code by authority: what they are, why (or even if) they are needed, what, if anything, makes a government legitimate, what rights and freedoms it should protect and why, what form it should take and why, what the law is, and what duties citizens owe to a legitimate government, if any, and when it may be legitimately overthrown, if ever.
In a vernacular sense, the term "political philosophy" often refers to a general view, or specific ethic, political belief or attitude, about politics, synonymous to the term "political ideology".
Political philosophy is considered by some to be a sub-discipline of political science; however, the name generally attributed to this form of political enquiry is political theory, a discipline which has a closer methodology to the theoretical fields in the social sciences - like economic theory - than to philosophical argumentation - like that of moral philosophy or aesthetics.
History.
Ancient Philosophies.
Ancient China.
Chinese political philosophy dates back to the Spring and Autumn Period, specifically with Confucius in the 6th century BC. Chinese political philosophy was developed as a response to the social and political breakdown of the country characteristic of the Spring and Autumn Period and the Warring States period. The major philosophies during the period, Confucianism, Legalism, Mohism, Agrarianism and Taoism, each had a political aspect to their philosophical schools. Philosophers such as Confucius, Mencius, and Mozi, focused on political unity and political stability as the basis of their political philosophies. Confucianism advocated a hierarchical, meritocratic government based on empathy, loyalty, and interpersonal relationships. Legalism advocated a highly authoritarian government based on draconian punishments and laws. Mohism advocated a communal, decentralized government centered on frugality and ascetism. The Agrarians advocated a peasant utopian communalism and egalitarianism. Taoism advocated a proto-anarchism. Legalism was the dominant political philosophy of the Qin Dynasty, but was replaced by State Confucianism in the Han Dynasty. Prior to China's adoption of communism, State Confucianism remained the dominant political philosophy of China up to the 20th century.
Ancient Greece.
Western political philosophy originates in the philosophy of ancient Greece, where political philosophy dates back to at least Plato. Ancient Greece was dominated by city-states, which experimented with various forms of political organization, grouped by Plato into four categories: timocracy, tyranny, democracy and oligarchy. One of the first, extremely important classical works of political philosophy is Plato's "Republic", which was followed by Aristotle's "Nichomachean Ethics" and "Politics". Roman political philosophy was influenced by the Stoics, including the Roman statesman Cicero.
Ancient India.
Indian political philosophy evolved in ancient times and demarcated a clear distinction between (1) nation and state (2) religion and state. The constitutions of Hindu states evolved over time and were based on political and legal treatises and prevalent social institutions. The institutions of state were broadly divided into governance, administration, defense, law and order. "Mantranga," the principal governing body of these states, consisted of the King, Prime Minister, Commander in chief of army, Chief Priest of the King. The Prime Minister headed the committee of ministers along with head of executive (Maha Amatya).
Chanakya, 4th Century BC Indian political philosopher. The Arthashastra provides an account of the science of politics for a wise ruler, policies for foreign affairs and wars, the system of a spy state and surveillance and economic stability of the state. Chanakya quotes several authorities including Bruhaspati, Ushanas, Prachetasa Manu, Parasara, and Ambi, and described himself as a descendant of a lineage of political philosophers, with his father Chanaka being his immediate predecessor. Another influential extant Indian treatise on political philosophy is the Sukra Neeti. An example of a code of law in ancient India is the Manusmṛti or Laws of Manu.
Medieval Christianity.
Saint Augustine.
The early Christian philosophy of Augustine of Hippo was heavily influenced by Plato. A key change brought about by Christian thought was the moderatation of the Stoicism and theory of justice of the Roman world, as well emphasis on the role of the state in applying mercy as a moral example. Augustine also preached that one was not a member of his or her city, but was either a citizen of the City of God (Civitas Dei) or the City of Man (Civitas Terrena). Augustine's "City of God" is an influential work of this period that attacked the thesis, held by many Christian Romans, that the Christian view could be realized on Earth.
St. Thomas Aquinas.
Thomas Aquinas meticulously dealt with the varieties of law. According to Aquinas, there are four kinds of law:
Aquinas never discusses the nature or categorization of canon law. There is scholarly debate surrounding the place of canon law within the Thomistic jurisprudential framework.
Aquinas was an incredibly influential thinker in the Natural Law tradition.
Islamic Golden Age.
Mutazilite vs. Asharite.
The rise of Islam, based on both the Qur'an and Muhammad strongly altered the power balances and perceptions of origin of power in the Mediterranean region. Early Islamic philosophy emphasized an inexorable link between science and religion, and the process of ijtihad to find truth—in effect "all" philosophy was "political" as it had real implications for governance. This view was challenged by the "rationalist" Mutazilite philosophers, who held a more Hellenic view, reason above revelation, and as such are known to modern scholars as the first speculative theologians of Islam; they were supported by a secular aristocracy who sought freedom of action independent of the Caliphate. By the late ancient period, however, the "traditionalist" Asharite view of Islam had in general triumphed. According to the Asharites, reason must be subordinate to the Quran and the Sunna.
Islamic political philosophy, was, indeed, rooted in the very sources of Islam—i.e., the Qur'an and the Sunnah, the words and practices of Muhammad—thus making it essentially theocratic. However, in the Western thought, it is generally supposed that it was a specific area peculiar merely to the great philosophers of Islam: al-Kindi (Alkindus), al-Farabi (Abunaser), İbn Sina (Avicenna), Ibn Bajjah (Avempace), Ibn Rushd (Averroes), and Ibn Khaldun. The political conceptions of Islam such as kudrah (power), sultan, ummah, cemaa (obligation)-and even the "core" terms of the Qur'an—i.e., ibadah (worship), din (religion), rab (master) and ilah (deity)—is taken as the basis of an analysis. Hence, not only the ideas of the Muslim political philosophers but also many other jurists and ulama posed political ideas and theories. For example, the ideas of the Khawarij in the very early years of Islamic history on Khilafa and Ummah, or that of Shia Islam on the concept of Imamah are considered proofs of political thought. The clashes between the Ehl-i Sunna and Shia in the 7th and 8th centuries had a genuine political character.
Ibn Khaldun.
The 14th century Arab scholar Ibn Khaldun is considered one of the greatest political theorists. The British philosopher-anthropologist Ernest Gellner considered Ibn Khaldun's definition of government, "...an institution which prevents injustice other than such as it commits itself," the best in the history of political theory. For Ibn Khaldun, government should be restrained to a minimum for as a necessary evil, it is the constraint of men by other men.
Medieval Europe.
Medieval political philosophy in Europe was heavily influenced by Christian thinking. It had much in common with the Mutazalite Islamic thinking in that the Roman Catholics though subordinating philosophy to theology did not subject reason to revelation but in the case of contradictions, subordinated reason to faith as the Asharite of Islam. The Scholastics by combining the philosophy of Aristotle with the Christianity of St. Augustine emphasized the potential harmony inherent in reason and revelation. Perhaps the most influential political philosopher of medieval Europe was St. Thomas Aquinas who helped reintroduce Aristotle's works, which had only been transmitted to Catholic Europe through Muslim Spain, along with the commentaries of Averroes. Aquinas's use of them set the agenda, for scholastic political philosophy dominated European thought for centuries even unto the Renaissance.
Medieval political philosophers, such as Aquinas in "Summa Theologica", developed the idea that a king who is a tyrant is no king at all and could be overthrown.
Magna Carta, viewed by many as a cornerstone of Anglo-American political liberty, explicitly proposes the right to revolt against the ruler for justice sake. Other documents similar to Magna Carta are found in other European countries such as Spain and Hungary.
European Renaissance.
During the Renaissance secular political philosophy began to emerge after about a century of theological political thought in Europe. While the Middle Ages did see secular politics in practice under the rule of the Holy Roman Empire, the academic field was wholly scholastic and therefore Christian in nature.
Niccolò Machiavelli.
One of the most influential works during this burgeoning period was Niccolò Machiavelli's "The Prince", written between 1511–12 and published in 1532, after Machiavelli's death. That work, as well as "The Discourses", a rigorous analysis of the classical period, did much to influence modern political thought in the West. A minority (including Jean-Jacques Rousseau) interpreted The Prince as a satire meant to be given to the Medici after their recapture of Florence and their subsequent expulsion of Machiavelli from Florence. Though the work was written for the di Medici family in order to perhaps influence them to free him from exile, Machiavelli supported the Republic of Florence rather than the oligarchy of the di Medici family. At any rate, Machiavelli presents a pragmatic and somewhat consequentialist view of politics, whereby good and evil are mere means used to bring about an end—i.e., the secure and powerful state. Thomas Hobbes, well known for his theory of the social contract, goes on to expand this view at the start of the 17th century during the English Renaissance. Although neither Machiavelli nor Hobbes believed in the divine right of kings, they both believed in the inherent selfishness of the individual. It was necessarily this belief that led them to adopt a strong central power as the only means of preventing the disintegration of the social order.
European Enlightenment.
During the Enlightenment period, new theories about what the human was and is and about the definition of reality and the way it was perceived, along with the discovery of other societies in the Americas, and the changing needs of political societies (especially in the wake of the English Civil War, the American Revolution and the French Revolution) led to new questions and insights by such thinkers as Thomas Hobbes, John Locke, Montesquieu and Jean-Jacques Rousseau.
These theorists were driven by two basic questions: one, by what right or need do people form states; and two, what the best form for a state could be. These fundamental questions involved a conceptual distinction between the concepts of "state" and "government." It was decided that "state" would refer to a set of enduring institutions through which power would be distributed and its use justified. The term "government" would refer to a specific group of people who occupied the institutions of the state, and create the laws and ordinances by which the people, themselves included, would be bound. This conceptual distinction continues to operate in political science, although some political scientists, philosophers, historians and cultural anthropologists have argued that most political action in any given society occurs outside of its state, and that there are societies that are not organized into states that nevertheless must be considered in political terms. As long as the concept of natural order was not introduced, the social sciences could not evolve independently of theistic thinking. Since the cultural revolution of the 17th century in England, which spread to France and the rest of Europe, society has been considered subject to natural laws akin to the physical world.
Political and economic relations were drastically influenced by these theories as the concept of the guild was subordinated to the theory of free trade, and Roman Catholic dominance of theology was increasingly challenged by Protestant churches subordinate to each nation-state, which also (in a fashion the Roman Catholic Church often decried angrily) preached in the vulgar or native language of each region. However, the enlightenment was an outright attack on religion, particularly Christianity. The most outspoken critic of the church in France was François Marie Arouet de Voltaire, a representative figure of the enlightenment. After Voltaire, religion would never be the same again in France.
In the Ottoman Empire, these ideological reforms did not take place and these views did not integrate into common thought until much later. As well, there was no spread of this doctrine within the New World and the advanced civilizations of the Aztec, Maya, Inca, Mohican, Delaware, Huron and especially the Iroquois. The Iroquois philosophy in particular gave much to Christian thought of the time and in many cases actually inspired some of the institutions adopted in the United States: for example, Benjamin Franklin was a great admirer of some of the methods of the Iroquois Confederacy, and much of early American literature emphasized the political philosophy of the natives.
John Locke.
John Locke in particular exemplified this new age of political theory with his work "Two Treatises of Government". In it Locke proposes a state of nature theory that directly complements his conception of how political development occurs and how it can be founded through contractual obligation. Locke stood to refute Sir Robert Filmer's paternally founded political theory in favor of a natural system based on nature in a particular given system. The theory of the divine right of kings became a passing fancy, exposed to the type of ridicule with which John Locke treated it. Unlike Machiavelli and Hobbes but like Aquinas, Locke would accept Aristotle's dictum that man seeks to be happy in a state of social harmony as a social animal. Unlike Aquinas's preponderant view on the salvation of the soul from original sin, Locke believes man's mind comes into this world as tabula rasa. For Locke, knowledge is neither innate, revealed nor based on authority but subject to uncertainty tempered by reason, tolerance and moderation. According to Locke, an absolute ruler as proposed by Hobbes is unnecessary, for natural law is based on reason and seeking peace and survival for man.
Industrialization and the Modern Era.
The Marxist critique of capitalism — developed with Friedrich Engels — was, alongside liberalism and fascism, one of the defining ideological movements of the Twentieth Century. The industrial revolution produced a parallel revolution in political thought. Urbanization and capitalism greatly reshaped society. During this same period, the socialist movement began to form. In the mid-19th century, Marxism was developed, and socialism in general gained increasing popular support, mostly from the urban working class. Without breaking entirely from the past, Marx established principles that would be used by future revolutionaries of the 20th century namely Vladimir Lenin, Mao Zedong, Ho Chi Minh, and Fidel Castro. Though Hegel's philosophy of history is similar to Immanuel Kant's, and Karl Marx's theory of revolution towards the common good is partly based on Kant's view of history—Marx declared that he was turning Hegel's dialectic, which was "standing on its head", "the right side up again". Unlike Marx who believed in historical materialism, Hegel believed in the "Phenomenology of Spirit". By the late 19th century, socialism and trade unions were established members of the political landscape. In addition, the various branches of anarchism, with thinkers such as Mikhail Bakunin, Pierre-Joseph Proudhon or Peter Kropotkin, and syndicalism also gained some prominence. In the Anglo-American world, anti-imperialism and pluralism began gaining currency at the turn of the 20th century.
World War I was a watershed event in human history, changing views of governments and politics. The Russian Revolution of 1917 (and similar, albeit less successful, revolutions in many other European countries) brought communism - and in particular the political theory of Leninism, but also on a smaller level Luxemburgism (gradually) - on the world stage. At the same time, social democratic parties won elections and formed governments for the first time, often as a result of the introduction of universal suffrage. However, a group of central European economists led by Austrian School economists Ludwig von Mises and Friedrich Hayek identified the collectivist underpinnings to the various new socialist and fascist doctrines of government power as being different brands of political totalitarianism.
Contemporary political philosophy.
From the end of World War II until 1971, when John Rawls published "A Theory of Justice", political philosophy declined in the Anglo-American academic world, as analytic philosophers expressed skepticism about the possibility that normative judgments had cognitive content, and political science turned toward statistical methods and behavioralism. In continental Europe, on the other hand, the postwar decades saw a huge blossoming of political philosophy, with Marxism dominating the field. This was the time of Jean-Paul Sartre and Louis Althusser, and the victories of Mao Zedong in China and Fidel Castro in Cuba, as well as the events of May 1968 led to increased interest in revolutionary ideology, especially by the New Left. A number of continental European émigrés to Britain and the United States—including Hannah Arendt, Karl Popper, Friedrich Hayek, Leo Strauss, Isaiah Berlin, Eric Voegelin and Judith Shklar—encouraged continued study in political philosophy in the Anglo-American world, but in the 1950s and 1960s they and their students remained at odds with the analytic establishment.
Communism remained an important focus especially during the 1950s and 1960s. Colonialism and racism were important issues that arose. In general, there was a marked trend towards a pragmatic approach to political issues, rather than a philosophical one. Much academic debate regarded one or both of two pragmatic topics: how (or whether) to apply utilitarianism to problems of political policy, or how (or whether) to apply economic models (such as rational choice theory) to political issues. The rise of feminism, LGBT social movements and the end of colonial rule and of the political exclusion of such minorities as African Americans and sexual minorities in the developed world has led to feminist, postcolonial, and multicultural thought becoming significant. This led to a challenge to the social contract by philosophers Charles W. Mills in his book "The Racial Contract" and Carole Patemen in her book "The Sexual Contract" that the social contract excluded persons of colour and women respectively.
In Anglo-American academic political philosophy, the publication of John Rawls's "A Theory of Justice" in 1971 is considered a milestone. Rawls used a thought experiment, the original position, in which representative parties choose principles of justice for the basic structure of society from behind a veil of ignorance. Rawls also offered a criticism of utilitarian approaches to questions of political justice. Robert Nozick's 1974 book "Anarchy, State, and Utopia", which won a National Book Award, responded to Rawls from a libertarian perspective and gained academic respectability for libertarian viewpoints.
Contemporaneously with the rise of analytic ethics in Anglo-American thought, in Europe several new lines of philosophy directed at critique of existing societies arose between the 1950s and 1980s. Most of these took elements of Marxist economic analysis, but combined them with a more cultural or ideological emphasis. Out of the Frankfurt School, thinkers like Herbert Marcuse, Theodor W. Adorno, Max Horkheimer, and Jürgen Habermas combined Marxian and Freudian perspectives. Along somewhat different lines, a number of other continental thinkers—still largely influenced by Marxism—put new emphases on structuralism and on a "return to Hegel". Within the (post-) structuralist line (though mostly not taking that label) are thinkers such as Gilles Deleuze, Michel Foucault, Claude Lefort, and Jean Baudrillard. The Situationists were more influenced by Hegel; Guy Debord, in particular, moved a Marxist analysis of commodity fetishism to the realm of consumption, and looked at the relation between consumerism and dominant ideology formation.
Another debate developed around the (distinct) criticisms of liberal political theory made by Michael Walzer, Michael Sandel and Charles Taylor. The liberal-communitarian debate is often considered valuable for generating a new set of philosophical problems, rather than a profound and illuminating clash of perspective.These and other communitarians (such as Alasdair MacIntyre and Daniel A. Bell) argue that, contra liberalism, communities are prior to individuals and therefore should be the center of political focus. Communitarians tend to support greater local control as well as economic and social policies which encourage the growth of social capital.
A pair of overlapping political perspectives arising toward the end of the 20th century are republicanism (or neo- or civic-republicanism) and the capability approach. The resurgent republican movement aims to provide an alternate definition of liberty from Isaiah Berlin's positive and negative forms of liberty, namely "liberty as non-domination." Unlike liberals who understand liberty as "non-interference," "non-domination" entails individuals not being subject to the arbitrary will of anyother person. To a liberal, a slave who is not interfered with may be free, yet to a republican the mere status as a slave, regardless of how that slave is treated, is objectionable. Prominent republicans include historian Quentin Skinner, jurist Cass Sunstein, and political philosopher Philip Pettit. The capability approach, pioneered by economists Mahbub ul Haq and Amartya Sen and further developed by legal scholar Martha Nussbaum, understands freedom under allied lines: the real-world ability to act. Both the capability approach and republicanism treat choice as something which must be resourced. In other words, it is not enough to be legally able to do something, but to have the real option of doing it.
Current emphasis on "commoditization of the everyday" has been decried by many contemporary theorists, some of them arguing the full brunt of it would be felt in ten years' time. "Pricing" such ethical categories like personal relations or sex, though always present, pushed by media agenda, is thus seen as crossing boundaries and having adverse societal and philosophical consequences.
Fruitful interaction exists between political philosophers and international relations. The rise of globalization has created the need for an international normative framework, and political theory has moved to fill the gap, with actual politics sadly regressing .
One of the most prominent subjects in recent political philosophy has been the theory of deliberative democracy. The seminal work is by Jurgen Habermas in Germany but the most extensive literature has been in English, led by theorists such as Jane Mansbridge, Joshua Cohen, Amy Gutmann and Dennis Thompson.
Influential political philosophers.
A larger list of political philosophers is intended to be closer to exhaustive. Listed below are some of the most canonical or important thinkers, and especially philosophers whose central focus was in political philosophy and/or who are good representatives of a particular school of thought.

</doc>
<doc id="23041" url="https://en.wikipedia.org/wiki?curid=23041" title="Puerto Rico">
Puerto Rico

Puerto Rico ( or ; ), officially the Commonwealth of Puerto Rico (, literally the "Free Associated State of Puerto Rico"), is a United States territory located in the northeastern Caribbean. Puerto Rico is an archipelago that includes the main island of Puerto Rico and a number of smaller islands. The capital and largest city is San Juan. The territory does not observe daylight saving time, and its official languages are Spanish, which is predominant, and English. The island's population is approximately 3.6 million.
Puerto Rico's rich history, tropical climate, diverse natural scenery, renowned traditional cuisine and attractive tax incentives make it a popular destination for visitors from around the world. Its location in the Caribbean, combined with centuries of colonization and subsequent migration, has made Puerto Rican culture a distinct melting pot of Amerindian, Spanish, African and North American influences.
Originally populated by the aboriginal Taíno people, the island was claimed in 1493 by Christopher Columbus for the Kingdom of Spain, enduring several invasion attempts by the French, Dutch, and British. During the four centuries of Spanish rule, the island's cultural and physical landscape were transformed, with European knowledge, customs, and traditions being introduced, especially Roman Catholicism and the Spanish language. In 1898, following the Spanish American War, Spain ceded the island to the United States under the terms of the Treaty of Paris.
Puerto Ricans are natural-born citizens of the United States. The territory operates under a local constitution, allowing its citizens to elect a governor. Puerto Rico's residents are prohibited by federal law from voting for the U.S. Congress, which has full jurisdiction over the territory under the Puerto Rico Federal Relations Act of 1950. As a U.S. territory, Puerto Rico's residents are also prohibited from voting for the President of the United States. A 2012 referendum showed a majority (54% of the electorate) disagreed with "the present form of territorial status," with full statehood as the preferred option among those who voted for a change of status. Following this vote, the Legislative Assembly of Puerto Rico enacted a concurrent resolution to request the President and the Congress of the United States to end the current status and to begin the process to admit Puerto Rico to the Union as a State. As of 2015, Puerto Rico remains an unincorporated U.S. territory.
Etymology.
Puerto Ricans often call the island "Borinquen" - a derivation of "Borikén", its indigenous Taíno name, which means "Land of the Valiant Lord". The terms "boricua" and "borincano" derive from "Borikén" and "Borinquen" respectively, and are commonly used to identify someone of Puerto Rican heritage. The island is also popularly known in Spanish as "la isla del encanto", meaning "the island of enchantment".
Columbus named the island "San Juan Bautista," in honor of the Catholic Saint John the Baptist, while the capital city was named "Ciudad de Puerto Rico" (). Eventually traders and other maritime visitors came to refer to the entire island as Puerto Rico, while San Juan became the name used for the main trading/shipping port and the capital city.
History.
Pre-Columbian era.
The ancient history of the archipelago known today as Puerto Rico is not well known. Unlike other larger, more advanced indigenous communities in the New World (Aztec and Inca) whose people left behind abundant archeological and physical evidence of their societies, the indigenous population of Puerto Rico left scant artifacts and evidence. The scarce archaeological findings and early Spanish scholarly accounts from the colonial era constitute the basis of knowledge about them. The first comprehensive book on the history of Puerto Rico was written by Fray Íñigo Abbad y Lasierra in 1786, almost three centuries after the first Spaniards arrived on the island.
The first settlers were the Ortoiroid people, an Archaic Period culture of Amerindian hunters and fishermen who migrated from the South American mainland. Some scholars suggest that their settlement dates back 4000 years. An archeological dig at the island of Vieques in 1990 found the remains of a man, named the "Puerto Ferro Man", which was dated to around 2000 BC. The Ortoiroid were displaced by the Saladoid, a culture from the same region that arrived on the island between 430 and 250 BC.
The Igneri tribe migrated to Puerto Rico between 120 and 400 AD from the region of the Orinoco river in northern South America. The Arcaico and Igneri co-existed on the island between the 4th and 10th centuries.
Between the 7th and 11th centuries, the Taíno culture developed on the island. By approximately 1000 AD, it had become dominant. At the time of Columbus' arrival, an estimated 30,000 to 60,000 Taíno Amerindians, led by the "cacique" (chief) Agüeybaná, inhabited the island. They called it "Boriken", meaning "the great land of the valiant and noble Lord." The natives lived in small villages, each led by a cacique. They subsisted by hunting and fishing, done generally by men, as well as by the women's gathering and processing of indigenous cassava root and fruit. This lasted until Columbus arrived in 1493.
Spanish colony (1493–1898).
When Columbus arrived in Puerto Rico during his second voyage in , 1493, the island was inhabited by the Taíno. They called it "Borikén" ("Borinquen" in Spanish transliteration). Columbus then renamed it San Juan Bautista, after John The Baptist. Having reported the findings of his first travel, Columbus brought with him this time a letter from King Ferdinand empowered by a papal bull that authorized any course of action necessary for the expansion of the Spanish Empire and the Christian faith. Columbus named the island San Juan Bautista, in honor of the Catholic saint, John the Baptist. Juan Ponce de León, a lieutenant under Columbus, founded the first Spanish settlement, Caparra, on August 8, 1508. He later served as the first governor of the island. Eventually, traders and other maritime visitors came to refer to the entire island as Puerto Rico, and San Juan became the name of the main trading/shipping port.
In the beginning of the 16th century, the Spanish people began to colonize the island. Despite the Laws of Burgos of 1512 and other decrees for the protection of the indigenous population, some Taíno Indians were forced into an encomienda system of forced labor in the early years of colonization. The population suffered extremely high fatalities from epidemics of European infectious diseases.
In 1520, King Charles I of Spain issued a royal decree collectively emancipating the remaining Taíno population. By that time, the Taíno people were few in number. The Spanish began to import slaves from sub-Saharan Africa to have sufficient laborers to develop agriculture and settlements. The number of slaves on the island was smaller than on Cuba, Saint-Domingue and Guadeloupe, where Spanish and French developed large sugar plantations based on slave labor.
African slaves were used primarily in the coastal ports and cities where the island's population was concentrated. The interior of the island continued to be essentially unexplored and undeveloped. Puerto Rico soon became an important stronghold and a significant port for the Spanish Main colonial expansion. They built various forts and walls, such as La Fortaleza, Castillo San Felipe del Morro and Castillo San Cristóbal, to protect the strategic port of San Juan from numerous European raids and invasion attempts. San Juan served as an important port-of-call for ships of all European nations, who needed to take on water, food and other commercial provisions and mercantile exchange as part of the Atlantic trade. Regular convoys of the West Indies Fleet linked the island to Spain, sailing between Cádiz and the Spanish West Indies every year.
During the late 17th and early 18th centuries, Spain concentrated its colonial efforts on the more prosperous mainland North, Central, and South American colonies. The island of Puerto Rico was left virtually unexplored, undeveloped, and (excepting coastal outposts) largely unsettled before the 19th century. As independence movements in the larger Spanish colonies gained success, Spain began to pay attention to Puerto Rico as one of its last remaining maritime colonies.
In 1809, to secure its political bond with the island and in the midst of the European Peninsular War, the Supreme Central Junta based in Cádiz recognized Puerto Rico as an overseas province of Spain. It gave the island residents the right to elect representatives to the recently convened Spanish parliament (Cádiz Cortes), with equal representation to mainland Iberian, Mediterranean (Balearic Islands) and Atlantic maritime Spanish provinces (Canary Islands).
Ramón Power y Giralt, the first Spanish parliamentary representative from the island of Puerto Rico, died after serving a three-year term in the Cortes. These parliamentary and constitutional reforms were in force from 1810 to 1814, and again from 1820 to 1823. They were twice reversed during the restoration of the traditional monarchy by Ferdinand VII. Immigration and commercial trade reforms in the 19th century increased the island's ethnic European population and economy, and expanded Spanish cultural and social imprint on the local character of the island.
Minor slave revolts had occurred on the island throughout the years, with the revolt planned and organized by Marcos Xiorro in 1821 being the most important. Even though the conspiracy was unsuccessful, Xiorro achieved legendary status and is part of Puerto Rico's folklore.
In the early 19th century, Puerto Rico had an independence movement which, due to harsh persecution by the Spanish authorities, convened in the island of St. Thomas. The movement was largely inspired by the ideals of Simón Bolívar in establishing a United Provinces of New Granada, which included Puerto Rico and Cuba. Among the influential members of this movement were Brigadier General Antonio Valero de Bernabé and María de las Mercedes Barbudo. The movement was discovered and Governor Miguel de la Torre had its members imprisoned or exiled.
With the increasingly rapid growth of independent former Spanish colonies in the South and Central American states in the first part of the 19th century, the Spanish Crown considered Puerto Rico and Cuba of strategic importance. To increase its hold on its last two New World colonies, the Spanish Crown revived the Royal Decree of Graces of 1815. Printed in three languages: Spanish, English and French, it was intended to attract non-Spanish Europeans, with the hope that the independence movements would lose their popularity if new settlers had stronger ties to the Crown. Hundreds of families, mainly from Corsica, France, Germany, Ireland, Italy and Scotland, immigrated to the island.
Free land was offered as an incentive to those who wanted to populate the two islands, on the condition that they swear their loyalty to the Spanish Crown and allegiance to the Roman Catholic Church. It was very successful and European immigration continued even after 1898. Puerto Rico today still receives Spanish and European immigration.
Poverty and political estrangement with Spain led to a small but significant uprising in 1868 known as "Grito de Lares." It began in the rural town of Lares, but was subdued when rebels moved to the neighboring town of San Sebastián.
Leaders of this independence movement included Ramón Emeterio Betances, considered the "father" of the Puerto Rican independence movement, and other political figures such as Segundo Ruiz Belvis. Slavery in Puerto Rico was abolished in 1873.
Leaders of "El Grito de Lares" went into exile in New York City. Many joined the Puerto Rican Revolutionary Committee, founded on December 8, 1895, and continued their quest for Puerto Rican independence. In 1897, Antonio Mattei Lluberas and the local leaders of the independence movement in Yauco organized another uprising, which became known as the "Intentona de Yauco". They raised what they called the Puerto Rican flag, which was adopted as the national flag. The local conservative political factions opposed independence. Rumors of the planned event spread to the local Spanish authorities who acted swiftly and put an end to what would be the last major uprising in the island to Spanish colonial rule.
In 1897, Luis Muñoz Rivera and others persuaded the liberal Spanish government to agree to grant limited self-government to the island by royal decree in the Autonomic Charter, including a bicameral legislature. In 1898, Puerto Rico's first, but short-lived, quasi-autonomous government was organized as an "overseas province" of Spain. This bilaterally agreed-upon charter maintained a governor appointed by the King of Spain - who held the power to annul any legislative decision - and a partially elected parliamentary structure. In February, Governor-General Manuel Macías inaugurated the new government under the Autonomic Charter. General elections were held in March and the new government began to function on , 1898.
United States territory.
In around 1890, Captain Alfred Thayer Mahan, a member of the Navy War Board and leading U.S. strategic thinker, wrote a book titled "The Influence of Sea Power upon History" in which he argued for the establishment of a large and powerful navy modeled after the British Royal Navy. Part of his strategy called for the acquisition of colonies in the Caribbean, which would serve as coaling and naval stations. They would serve as strategic points of defense with the construction of a canal through the Isthmus of Panama, to allow easier passage of ships between the Atlantic and Pacific oceans.
William H. Seward, the former Secretary of State under presidents Abraham Lincoln and Ulysses Grant, had also stressed the importance of building a canal in Honduras, Nicaragua or Panama. He suggested that the United States annex the Dominican Republic and purchase Puerto Rico and Cuba. The U.S. Senate did not approve his annexation proposal, and Spain rejected the U.S. offer of dollars for Puerto Rico and Cuba.
Since 1894, the United States Naval War College had been developing contingency plans for a war with Spain. By 1896, the U.S. Office of Naval Intelligence had prepared a plan that included military operations in Puerto Rican waters. Except for one 1895 plan, which recommended annexation of the island then named "Isle of Pines" (later renamed as Isla de la Juventud), a recommendation dropped in later planning, plans developed for attacks on Spanish territories were intended as support operations against Spain's forces in and around Cuba. Recent research suggests that the U.S. did consider Puerto Rico valuable as a naval station, and recognized that it and Cuba generated lucrative crops of sugar – a valuable commercial commodity which the United States lacked.
On July 25, 1898, during the Spanish–American War, the U.S. invaded Puerto Rico with a landing at Guánica. As an outcome of the war, Spain ceded Puerto Rico, along with the Philippines and Guam, then under Spanish sovereignty, to the U.S. under the Treaty of Paris. Spain relinquished sovereignty over Cuba, but did not cede it to the U.S.
The United States and Puerto Rico began a long-standing metropolis-colony relationship. In the early 20th century, Puerto Rico was ruled by the military, with officials including the governor appointed by the President of the United States. The Foraker Act of 1900 gave Puerto Rico a certain amount of civilian popular government, including a popularly elected House of Representatives. The upper house and governor were appointed by the United States. At the time, the US did not have popular election of senators. Until passage of the Seventeenth Amendment in 1913, most US senators were elected by their respective state legislatures.
Its judicial system was constructed to follow the American legal system; a Puerto Rico Supreme Court and a United State District Court for the territory were established. It was authorized a non-voting member of Congress, by the title of "Resident Commissioner", who was appointed. In addition, this Act extended all U.S. laws "not locally inapplicable" to Puerto Rico, specifying, in particular, exemption from U.S. Internal Revenue laws.
The Act empowered the civil government to legislate on "all matters of legislative character not locally inapplicable," including the power to modify and repeal any laws then in existence in Puerto Rico, though the U.S. Congress retained the power to annul acts of the Puerto Rico legislature. During an address to the Puerto Rican legislature in 1906, President Theodore Roosevelt recommended that Puerto Ricans become U.S. citizens.
In 1914, the Puerto Rican House of Delegates voted unanimously in favor of independence from the United States, but this was rejected by the U.S. Congress as "unconstitutional," and in violation of the 1900 Foraker Act.
U.S. citizenship & Puerto Rican citizenship.
In 1917, the U.S. Congress passed the Jones–Shafroth Act, popularly called the Jones Act, which granted Puerto Ricans U.S. citizenship. Opponents, who included all of the Puerto Rican House of Delegates, which voted unanimously against it, said that the US imposed citizenship in order to draft Puerto Rican men into the army as American entry into World War I became likely.
The same Act provided for a popularly elected Senate to complete a bicameral Legislative Assembly, as well as a bill of rights. It authorized the popular election of the Resident Commissioner to a four-year term.
Natural disasters, including a major earthquake and tsunami in 1918, and several hurricanes, and the Great Depression impoverished the island during the first few decades under U.S. rule. Some political leaders, such as Pedro Albizu Campos, who led the Puerto Rican Nationalist Party, demanded change in relations with the United States. He organized a protest at the University of Puerto Rico in 1935, in which four were killed by police.
In 1936, US Senator Millard Tydings introduced a bill supporting independence for Puerto Rico, but it was opposed by Luis Muñoz Marín of the Liberal Party of Puerto Rico. (Tydings had co-sponsored the Tydings–McDuffie Act, which provided independence to the Philippines after a 10-year transition under a limited autonomy.) All the Puerto Rican parties supported the bill, but Muñoz Marín opposed it. Tydings did not gain passage of the bill.
In 1937, Albizu Campos' party organized a protest in which numerous people were killed by police in Ponce. The Insular Police, resembling the National Guard, opened fire upon unarmed cadets and bystanders alike. The attack on unarmed protesters was reported by the U.S. Congressman Vito Marcantonio and confirmed by the report of the Hays Commission, which investigated the events. The commission was led by Arthur Garfield Hays, counsel to the American Civil Liberties Union.
Nineteen persons were killed and over 200 were badly wounded, many in their backs while running away. The Hays Commission declared it a massacre and police mob action, and it has since been known as the Ponce massacre. In the aftermath, on April 2, 1943, Tydings introduced a bill in Congress calling for independence for Puerto Rico. This bill ultimately was defeated.
During the latter years of the Roosevelt–Truman administrations, the internal governance was changed in a compromise reached with Luis Muñoz Marín and other Puerto Rican leaders. In 1946, President Truman appointed the first Puerto Rican-born governor, Jesús T. Piñero.
Since 2007, the Puerto Rico State Department has developed a protocol to issue certificates of Puerto Rican citizenship to Puerto Ricans. In order to be eligible, applicants must have been born in Puerto Rico; born outside of Puerto Rico to a Puerto Rican-born parent; or be an American citizen with at least one year residence in Puerto Rico. The citizenship is internationally recognized by Spain, which considers Puerto Rico to be an Ibero-American nation. Therefore, Puerto Rican citizens have the ability to apply for Spanish citizenship after only two years residency in Spain (instead of the standard 10 years).
Commonwealth (1952–).
In 1947, the U.S. granted Puerto Ricans the right to democratically elect their own governor. In 1948, Luis Muñoz Marín became the first popularly elected governor of Puerto Rico.
A bill was introduced before the Puerto Rican Senate which would restrain the rights of the independence and nationalist movements in the island. The Senate at the time was controlled by the Popular Democratic Party (PPD), and was presided over by Luis Muñoz Marín. The bill, also known as the Gag Law ("Ley de la Mordaza" in Spanish), was approved by the legislature on May 21, 1948. It made it illegal to display a Puerto Rican flag, to sing a pro-independence tune, to talk of independence, or to campaign for independence.
The bill, which resembled the Smith Act passed in the United States, was signed and made into law on June 10, 1948, by the U.S. appointed governor of Puerto Rico, Jesús T. Piñero, and became known as "Law 53" ("Ley 53" in Spanish).
In accordance with this law, it would be a crime to print, publish, sell, exhibit, organize or help anyone organize any society, group or assembly of people whose intentions are to paralyze or destroy the insular government. Anyone accused and found guilty of disobeying the law could be sentenced to ten years of prison, be fined $10,000 dollars (US), or both. According to Dr. Leopoldo Figueroa, a member of the Puerto Rico House of Representatives, the law was repressive and in violation of the First Amendment of the US Constitution, which guarantees Freedom of Speech. He asserted that the law as such was a violation of the civil rights of the people of Puerto Rico. The infamous law was repealed in 1957.
In 1950, the U.S. Congress approved Public Law 600 (P.L. 81-600), which allowed for a democratic referendum in Puerto Rico to determine whether Puerto Ricans desired to draft their own local constitution. This Act was meant to be adopted in the "nature of a compact". It required congressional approval of the Puerto Rico Constitution before it could go into effect, and repealed certain sections of the Organic Act of 1917. The sections of this statute left in force were entitled the "Puerto Rican Federal Relations Act". U.S. Secretary of the Interior Oscar L. Chapman, under whose Department resided responsibility of Puerto Rican affairs, clarified the new commonwealth status in this manner:
The bill (to permit Puerto Rico to write its own constitution) merely authorizes the people of Puerto Rico to adopt their own constitution and to organize a local government...The bill under consideration would not change Puerto Rico's political, social, and economic relationship to the United States.
On October 30, 1950, Pedro Albizu Campos and other nationalists led a 3-day revolt against the United States in various cities and towns of Puerto Rico, in what is known as the Puerto Rican Nationalist Party Revolts of the 1950s. The most notable occurred in Jayuya and Utuado. In the Jayuya revolt, known as the Jayuya Uprising, the Puerto Rican governor declared martial law, and attacked the insurgents in Jayuya with infantry, artillery and bombers under control of the Puerto Rican commander. The Utuado Uprising culminated in what is known as the Utuado massacre.
On , 1950, Puerto Rican nationalists from New York City, Griselio Torresola and Oscar Collazo, attempted to assassinate President Harry S Truman at his temporary residence of Blair House. Torresola was killed during the attack, but Collazo was wounded and captured. He was convicted of murder and sentenced to death, but President Truman commuted his sentence to life. After Collazo served 29 years in a federal prison, President Jimmy Carter commuted his sentence to times served and he was released in 1979.
Don Pedro Albizu Campos served many years in a federal prison in Atlanta, for seditious conspiracy to overthrow the U.S. government in Puerto Rico.
The Constitution of Puerto Rico was approved by a Constitutional Convention on , 1952, and 82% of the voters in a March referendum. It was modified and ratified by the U.S. Congress, approved by President Truman on of that year, and proclaimed by Gov. Muñoz Marín on , 1952. This was the anniversary of the , 1898, landing of U.S. troops in the Puerto Rican Campaign of the Spanish–American War, until then celebrated as an annual Puerto Rico holiday.
Puerto Rico adopted the name of "Estado Libre Asociado de Puerto Rico" (literally "Associated Free State of Puerto Rico"), officially translated into English as Commonwealth, for its body politic. "The United States Congress legislates over many fundamental aspects of Puerto Rican life, including citizenship, the currency, the postal service, foreign policy, military defense, communications, labor relations, the environment, commerce, finance, health and welfare, and many others."
During the 1950s, Puerto Rico experienced rapid industrialization, due in large part to "Operación Manos a la Obra" ("Operation Bootstrap"), an offshoot of FDR's New Deal. It was intended to transform Puerto Rico's economy from agriculture-based to manufacturing-based to provide more jobs. Puerto Rico has become a major tourist destination, as well as a global center for pharmaceutical manufacturing.
Four plebiscites have been held since the late 20th century to resolve the political status. The most recent, in 2012, showed a majority (54% of the voters) in favor of a change in status, with full statehood the preferred option, but it was highly controversial: many ballots were left blank and the results were criticized by several parties. Support for the pro-statehood party, Partido Nuevo Progresista (PNP), and the pro-commonwealth party, Partido Popular Democrático (PPD), remains about equal. The only registered pro-independence party, the Puerto Rican Independence Party (PIP), usually receives 3–5% of the electoral votes.
Geography.
Puerto Rico consists of the main island of Puerto Rico and various smaller islands, including Vieques, Culebra, Mona, Desecheo, and Caja de Muertos. Of these last five, only Culebra and Vieques are inhabited year-round. Culebra, which is only 18 miles away from the mainland, is home to Flamenco Beach, one of the top ten beaches in the world. Mona is uninhabited most of the year except for employees of the Puerto Rico Department of Natural Resources. There are also many other smaller islands, including Monito and "La Isleta de San Juan," which includes Old San Juan and Puerta de Tierra, and is connected to the main island by bridges.
The Commonwealth of Puerto Rico has an area of , of which is land and is water. The maximum length of the main island from east to west is , and the maximum width from north to south is . Puerto Rico is the smallest of the Greater Antilles. It is 80% of the size of Jamaica, just over 18% of the size of Hispaniola and 8% of the size of Cuba, the largest of the Greater Antilles.
The island is mostly mountainous with large coastal areas in the north and south. The main mountain range is called "La Cordillera Central" (The Central Range). The highest elevation in Puerto Rico, Cerro de Punta , is located in this range.
Another important peak is El Yunque, one of the highest in the "Sierra de Luquillo" at the El Yunque National Forest, with an elevation of .
Puerto Rico has 17 lakes, all man-made, and more than 50 rivers, most originating in the Cordillera Central. Rivers in the northern region of the island are typically longer and of higher water flow rates than those of the south, since the south receives less rain than the central and northern regions.
Puerto Rico is composed of Cretaceous to Eocene volcanic and plutonic rocks, overlain by younger Oligocene and more recent carbonates and other sedimentary rocks. Most of the caverns and karst topography on the island occurs in the northern region in the carbonates. The oldest rocks are approximately years old (Jurassic) and are located at Sierra Bermeja in the southwest part of the island. They may represent part of the oceanic crust and are believed to come from the Pacific Ocean realm.
Puerto Rico lies at the boundary between the Caribbean and North American plates and is being deformed by the tectonic stresses caused by their interaction. These stresses may cause earthquakes and tsunamis. These seismic events, along with landslides, represent some of the most dangerous geologic hazards in the island and in the northeastern Caribbean.
The most recent major earthquake occurred on , 1918, and had an estimated magnitude of 7.5 on the Richter scale. It originated off the coast of Aguadilla, several kilometers off the northern coast, and was accompanied by a tsunami. It caused extensive property damage and widespread losses, damaging infrastructure, especially bridges. It resulted in an estimated 116 deaths and $4 million in property damage. The failure of the government to move rapidly to provide for the general welfare contributed to political activism by opponents and eventually to the rise of the Puerto Rican Nationalist Party.
The Puerto Rico Trench, the largest and deepest trench in the Atlantic, is located about north of Puerto Rico at the boundary between the Caribbean and North American plates. It is long. At its deepest point, named the Milwaukee Deep, it is almost deep.
Climate.
Located in the tropics, Puerto Rico has a rainy season which stretches from April into November. The mountains of the Cordillera Central are the main cause of the variations in the temperature and rainfall that occur over very short distances. The mountains can also cause wide variation in local wind speed and direction due to their sheltering and channeling effects adding to the climatic variation. About a quarter of the annual rainfall for Puerto Rico, on average, occurs during tropical cyclones, which are more frequent during La Niña events.
The island has an average temperature of throughout the year, with an average minimum temperature of and maximum of . Temperatures do not change drastically throughout the seasons. The temperature in the south is usually a few degrees higher than the north and temperatures in the central interior mountains are always cooler than those on the rest of the island.
Between winter and summer, there is a temperature change of around . This is mainly due to the warm waters of the tropical Atlantic ocean which significantly modify cooler air moving in from the north and northwest. Coastal waters temperatures around the years are about 75 °F in February to 85 °F in August. The highest temperature ever recorded was at Arecibo, while the lowest temperature ever recorded was at Adjuntas, Aibonito, and Corozal. The average yearly precipitation is .
Puerto Rico experiences the Atlantic hurricane season, similar to the remainder of the Caribbean Sea and North Atlantic oceans. On average, a quarter of its annual rainfall is contributed from tropical cyclones, which are more prevalent during periods of La Niña than El Niño. A cyclone of tropical storm strength passes near Puerto Rico, on average, every five years. A hurricane passes in the vicinity of the island, on average, every seven years. Only one Category 5 hurricane has struck the island since 1851, the Lake Okeechobee Hurricane of September 1928.
Biodiversity.
Species endemic to the archipelago number 239 plants, 16 birds and 39 amphibians/reptiles, recognized as of 1998. Most of these (234, 12 and 33 respectively) are found on the main island. The most recognizable endemic species and a symbol of Puerto Rican pride is the "coquí", a small frog easily identified by the sound of its call, from which it gets its name. Most "coquí" species (13 of 17) live in the El Yunque National Forest, a tropical rainforest in the northeast of the island previously known as the Caribbean National Forest. El Yunque is home to more than 240 plants, 26 of which are endemic to the island. It is also home to 50 bird species, including the critically endangered Puerto Rican amazon.
Across the island in the southwest, the of dry land at the Guánica Commonwealth Forest Reserve contain over 600 uncommon species of plants and animals, including 48 endangered species and 16 endemic to Puerto Rico.
Government and politics.
Puerto Rico has 8 senatorial districts, 40 representative districts and 78 municipalities. It has a republican form of government with separation of powers subject to the jurisdiction and sovereignty of the United States. Its current powers are all delegated by the United States Congress and lack full protection under the United States Constitution. Puerto Rico's head of state is the President of the United States.
The government of Puerto Rico, based on the formal republican system, is composed of three branches: the executive, legislative, and judicial branch. The executive branch is headed by the governor, currently Alejandro García Padilla. The legislative branch consists of a bicameral legislature called the Legislative Assembly, made up of a Senate as its upper chamber and a House of Representatives as its lower chamber. The Senate is headed by the President of the Senate, currently Eduardo Bhatia, while the House of Representatives is headed by the Speaker of the House, currently Jaime Perelló. The governor and legislators are elected by popular vote every four years with the last election held in November 2012.
The judicial branch is headed by the Chief Justice of the Supreme Court of Puerto Rico, currently Liana Fiol Matta. Members of the judicial branch are appointed by the governor with the advice and consent of the Senate.
Puerto Rico is represented in the United States Congress by a nonvoting delegate, the Resident Commissioner, currently Pedro Pierluisi. Current congressional rules have removed the Commissioner's power to vote in the Committee of the Whole, but the Commissioner can vote in committee.
Puerto Rican elections are governed by the Federal Election Commission and the State Elections Commission of Puerto Rico. While residing in Puerto Rico, Puerto Ricans cannot vote in U.S. presidential elections, but they can vote in primaries. Puerto Ricans who become residents of a U.S. state can vote in presidential elections.
Puerto Rico hosts consulates from 41 countries, mainly from the Americas and Europe, with most located in San Juan. As an unincorporated territory of the United States, Puerto Rico does not have any first-order administrative divisions as defined by the U.S. government, but has 78 municipalities at the second level. Mona Island is not a municipality, but part of the municipality of Mayagüez.
Municipalities are subdivided into wards or barrios, and those into sectors. Each municipality has a mayor and a municipal legislature elected for a four-year term. The municipality of San Juan (previously called "town"), was founded first, in 1521, San Germán in 1570, Coamo in 1579, Arecibo in 1614, Aguada in 1692 and Ponce in 1692. An increase of settlement saw the founding of 30 municipalities in the 18th century and 34 in the 19th. Six were founded in the 20th century; the last was Florida in 1971.
Political culture.
Since 1952, Puerto Rico has had three main political parties: the Popular Democratic Party (PPD), the New Progressive Party (PNP) and the Puerto Rican Independence Party (PIP). These three parties stood for three distinct future political status scenarios: the PPD seeks to maintain the island's "association" status with the U.S. as a commonwealth, and has won a plurality vote in referendums on the island's status held over the last six decades, the PNP seeks to have Puerto Rico become a U.S. state, and the PIP seeks the establishment of a sovereign and independent republic.
In 2007, the Puerto Ricans for Puerto Rico Party (PPR) was registered. The PPR claims that it seeks to address the islands' problems from a status-neutral platform. It ceased to remain a registered political party when it failed to obtain the requisite number of votes in the 2008 general election. Other non-registered parties include the Puerto Rican Nationalist Party, the Socialist Workers Movement, and the Hostosian National Independence Movement.
Law.
The insular legal system is a blend of civil law and the common law systems.
Puerto Rico is the only current U.S. possession whose legal system operates primarily in a language other than American English: namely, Spanish. Because the U.S. federal government operates primarily in English, all Puerto Rican attorneys must be bilingual in order to litigate in English in U.S. federal courts and to litigate federal preemption issues in Puerto Rican courts.
Title 48 of the United States Code outlines the role of the United States Code to United States territories and insular areas such as Puerto Rico. After the U.S. government assumed control of Puerto Rico in 1901, it initiated legal reforms resulting in the adoption of codes of criminal law, criminal procedure, and civil procedure modeled after those then in effect in California. Although Puerto Rico has since followed the federal example of transferring criminal and civil procedure from statutory law to rules promulgated by the judiciary, several portions of its criminal law still reflect the influence of the California Penal Code.
The judicial branch is headed by the Chief Justice of the Puerto Rico Supreme Court, which is the only appellate court required by the Constitution. All other courts are created by the Legislative Assembly of Puerto Rico. There is also a Federal District Court for Puerto Rico.
Someone accused of a criminal act at the federal level may not be accused for the same act in a Commonwealth court, unlike a state court, since Puerto Rico as a territory lacks sovereignty separate from Congress as a state does. Such a parallel accusation would constitute double jeopardy.
Political status.
The nature of Puerto Rico's political relationship with the U.S. is the subject of ongoing debate in Puerto Rico, the United States Congress, and the United Nations. Specifically, the basic question is whether Puerto Rico should remain a U.S. territory, become a U.S. state, or become an independent country.
"Estado Libre Asociado".
In 1950, the U.S. Congress granted Puerto Ricans the right to organize a constitutional convention via a referendum that gave them the option of voting their preference, "yes" or "no", on a proposed U.S. law that would organize Puerto Rico as a "commonwealth" that would continue United States sovereignty over Puerto Rico and its people. Puerto Rico's electorate expressed its support for this measure in 1951 with a second referendum to ratify the constitution. The Constitution of Puerto Rico was formally adopted on , 1952. The Constitutional Convention specified the name by which the body politic would be known.
On February 4, 1952, the convention approved Resolution 22 which chose in English the word "Commonwealth", meaning a "politically organized community" or "state", which is simultaneously connected by a compact or treaty to another political system. Puerto Rico officially designates itself with the term "Commonwealth of Puerto Rico" in its constitution, as a translation into English of the term to "Estado Libre Asociado" (ELA).
In 1967 Puerto Rico's Legislative Assembly polled the political preferences of the Puerto Rican electorate by passing a plebiscite act that provided for a vote on the status of Puerto Rico. This constituted the first plebiscite by the Legislature for a choice among three status options (commonwealth, statehood, and independence). In subsequent plebiscites organized by Puerto Rico held in 1993 and 1998 (without any formal commitment on the part of the U.S. Government to honor the results), the current political status failed to receive majority support. In 1993, Commonwealth status won by a plurality of votes (48.6% versus 46.3% for statehood), while the "none of the above" option, which was the Popular Democratic Party-sponsored choice, won in 1998 with 50.3% of the votes (versus 46.5% for statehood). Disputes arose as to the definition of each of the ballot alternatives, and Commonwealth advocates, among others, reportedly urged a vote for "none of the above".
Within the United States.
Constitutionally, Puerto Rico is subject to the plenary powers of the United States Congress under the territorial clause of Article IV of the U.S. Constitution. Laws enacted at the federal level in the United States apply to Puerto Rico as well, regardless of its political status. Their residents do not have voting representation in the U.S. Congress. Like the different states of the United States, Puerto Rico lacks "the full sovereignty of an independent nation", for example, the power to manage its "external relations with other nations", which is held by the U.S. federal government. The Supreme Court of the United States has indicated that once the U.S. Constitution has been extended to an area (by Congress or the courts), its coverage is irrevocable. To hold that the political branches may switch the Constitution on or off at will would lead to a regime in which they, not this Court, say "what the law is.".
Puerto Ricans "were collectively made U.S. citizens" in 1917 as a result of the Jones-Shafroth Act. U.S. citizens residing in Puerto Rico cannot vote for the U.S. president, though both major parties, Republican and Democrat, run primary elections in Puerto Rico to send delegates to vote on a presidential candidate. Since Puerto Rico is an unincorporated territory (see above) and not a U.S. state, the United States Constitution does not fully enfranchise US citizens residing in Puerto Rico. ("See also:" "Voting rights in Puerto Rico").
Despite their American citizenship, only the "fundamental rights" under the federal constitution apply to Puerto Ricans. Various other U.S Supreme Court decisions have held which rights apply in Puerto Rico and which ones do not. Puerto Ricans have a long history of service in the U.S. armed forces and, since 1917, they have been included in the U.S. compulsory draft whenever it has been in effect.
Though the Commonwealth government has its own tax laws, Puerto Ricans are also required to pay many kinds of U.S. federal taxes, not including the federal personal income tax for Puerto Rico-sourced income, but only under certain circumstances. In 2009, Puerto Rico paid into the US Treasury. Residents of Puerto Rico pay into Social Security, and are thus eligible for Social Security benefits upon retirement. They are excluded from the Supplemental Security Income (SSI), and the island actually receives a small fraction of the Medicaid funding it would receive if it were a U.S. state. Also, Medicare providers receive less-than-full state-like reimbursements for services rendered to beneficiaries in Puerto Rico, even though the latter paid fully into the system.
While a state may try an individual for the same crime he/she was tried in federal court since a federated state's separate sovereignty protects it from double jeopardy, Puerto Rico's authority to enact a criminal code derives from the sovereignty of Congress which, as a territory, it lacks. Thus, such a parallel accusation would constitute double jeopardy and is constitutionally impermissible.
In 1992, President George H. W. Bush issued a memorandum to heads of executive departments and agencies establishing the current administrative relationship between the federal government and the Commonwealth of Puerto Rico. This memorandum directs all federal departments, agencies, and officials to treat Puerto Rico administratively as if it were a state, insofar as doing so would not disrupt federal programs or operations.
Many federal executive branch agencies have significant presence in Puerto Rico, just as in any state, including the Federal Bureau of Investigation, Federal Emergency Management Agency, Transportation Security Administration, Social Security Administration, and others. While Puerto Rico has its own Commonwealth judicial system similar to that of a U.S. state, there is also a U.S federal district court in Puerto Rico, and Puerto Ricans have served as judges in that Court and in other federal courts on the U.S. mainland regardless of their residency status at the time of their appointment. Sonia Sotomayor, a New Yorker of Puerto Rican descent, serves as an Associate Justice of the Supreme Court of the United States. Puerto Ricans have also been frequently appointed to high-level federal positions, including serving as United States Ambassadors to other nations.
International status.
On November 27, 1953, shortly after the establishment of the Commonwealth, the General Assembly of the United Nations approved Resolution 748, removing Puerto Rico's classification as a non-self-governing territory. The General Assembly did not apply the full list of criteria which was enunciated in 1960 when it took favorable note of the cessation of transmission of information regarding the non-self-governing status of Puerto Rico.
According to the White House Task Force on Puerto Rico's Political Status in its , 2007 report, the U.S., in its written submission to the UN in 1953, never represented that Congress could not change its relationship with Puerto Rico without the territory's consent. It stated that the U.S. Justice Department in 1959 reiterated that Congress held power over Puerto Rico pursuant to the Territorial Clause of the U.S. Constitution.
In 1993 the United States Court of Appeals for the Eleventh Circuit stated that Congress may unilaterally repeal the Puerto Rican Constitution or the Puerto Rican Federal Relations Act and replace them with any rules or regulations of its choice. In a 1996 report on a Puerto Rico status political bill, the U.S. House Committee on Resources stated, "Puerto Rico's current status does not meet the criteria for any of the options for full self-government under Resolution 1541" (the three established forms of full self-government being stated in the report as (1) national independence, (2) free association based on separate sovereignty, or (3) full integration with another nation on the basis of equality). The report concluded that Puerto Rico "... remains an unincorporated colony and does not have the status of 'free association' with the United States as that status is defined under United States law or international practice", that the establishment of local self-government with the consent of the people can be unilaterally revoked by the U.S. Congress, and that U.S. Congress can also withdraw the U.S. citizenship of Puerto Rican residents of Puerto Rico at any time, for a legitimate Federal purpose. The application of the U.S. Constitution to Puerto Rico is limited by the Insular Cases.
In 2006, 2007, 2009, 2010, and 2011 the United Nations Special Committee on Decolonization passed resolutions calling on the United States to expedite a process "that would allow Puerto Ricans to fully exercise their inalienable right to self-determination and independence," and to release all Puerto Rican political prisoners in U.S. prisons, to clean up, decontaminate and return the lands in the islands of Vieques and Culebra to the people of Puerto Rico, to perform a probe into U.S. human rights violations on the island and a probe into the killing by the FBI of pro-independence leader Filiberto Ojeda Rios.
Recent developments.
On June 15, 2009, the United Nations Special Committee on Decolonization approved a draft resolution calling on the Government of the United States to expedite a process that would allow the Puerto Rican people to exercise fully their inalienable right to self-determination and independence.
On April 29, 2010, the U.S. House voted 223–169 to approve a measure for a federally sanctioned process for Puerto Rico's self-determination, allowing Puerto Rico to set a new referendum on whether to continue its present form of commonwealth, or to have a different political status. If Puerto Ricans voted to continue as a commonwealth, the Government of Puerto Rico was authorized to conduct additional plebiscites at intervals of every eight years from the date on which the results of the prior plebiscite were certified; if Puerto Ricans voted to have a different political status, a second referendum would determine whether Puerto Rico would become a U.S. state, an independent country, or a sovereign nation associated with the U.S. that would not be subject to the Territorial Clause of the United States Constitution. During the House debate, a fourth option, to retain its present form of commonwealth (sometimes referred to as "the status quo") political status, was added as an option in the second plebiscite.
Immediately following U.S. House passage, H.R. 2499 was sent to the U.S. Senate, where it was given two formal readings and referred to the Senate Committee on Energy and Natural Resources. On December 22, 2010, the 111th United States Congress adjourned without any Senate vote on H.R.2499, killing the bill.
The latest Task Force report was released on March 11, 2011. The report suggested a two-plebiscite process, including a "first plebiscite that requires the people of Puerto Rico to choose whether they wish to be part of the United States (either via Statehood or Commonwealth) or wish to be independent (via Independence or Free Association). If continuing to be part of the United States were chosen in the first plebiscite, a second vote would be taken between Statehood and Commonwealth."
On June 14, 2011, President Barack Obama "promised to support "a clear decision" by the people of Puerto Rico on statehood". That same month, the United Nations Special Committee on Decolonization passed a resolution and adopted a consensus text introduced by Cuba's delegate on June 20, 2011, calling on the United States to expedite a process "that would allow Puerto Ricans to fully exercise their inalienable right to self-determination and independence."
On November 6, 2012, a two-question referendum took place, simultaneous with the general elections. The first question asked voters whether they wanted to maintain the current status under the territorial clause of the U.S. Constitution. The second question posed three alternate status options if the first question was approved: statehood, independence or free association. For the first question, 54 percent voted against the current Commonwealth status. For the second question, 61.16% voted for statehood, 33.34% for a sovereign free associated state, and 5.49% for independence.
There were also 515,348 blank and invalidated ballots, which are not reflected in the final tally, as they are not considered cast votes under Puerto Rico law. On December 11, 2012, Puerto Rico's Legislature passed a concurrent resolution to request to the President and the U.S. Congress action on the November 6, 2012 plebiscite results. But on April 10, 2013, with the issue still being widely debated, the White House announced that it will seek $2.5 million to hold another referendum, this next one being the first Puerto Rican status referendum to be financed by the U.S. Federal government.
Foreign and intergovernmental relations.
Puerto Rico is subject to the Commerce and Territorial Clause of the Constitution of the United States and, therefore, is restricted on how it can engage with other nations, sharing most of the opportunities and limitations that state governments have albeit not being one. As is the case with state governments, regardless, it has established several trade agreements with other nations, particularly with Hispanic American countries such as Colombia and Panamá.
It has also established trade promotion offices in many foreign countries and within the United States itself, which now include Spain, the Dominican Republic, Panama, Colombia, Washington, D.C. and Florida, and has included in the past offices in Chile, Costa Rica, and Mexico. Such agreements require permission from the U.S. Department of State or the U.S. Congress itself; most, however, are simply allowed by existent laws or trade agreements between the United States and other nations which supersede the trade agreement pursued by Puerto Rico.
At the local level, Puerto Rico established by law that its international relations must be handled by the Department of State of Puerto Rico, an executive department. The Puerto Rico Federal Affairs Administration, along with the Office of the Resident Commissioner, manage all its intergovernmental affairs before entities of or in the United States (including the federal government of the United States, local and state governments of the United States, and public or private entities in the United States).
Both entities frequently assist the Department of State of Puerto Rico in engaging with Washington, D.C.-based ambassadors and federal agencies that handle Puerto Rico's foreign affairs, such as the U.S. Department of State, the Agency for International Development, and others. The current Secretary of State is David Bernier from the Popular Democratic Party and member of the Democratic Party of the United States, while the current Director of the Puerto Rico Federal Affairs Administration is Juan Eugenio Hernández Mayoral also from the Popular Democratic and member of the Democratic Party.
The Resident Commissioner of Puerto Rico, the delegate elected by Puerto Ricans to represent them before the federal government, including the U.S. Congress, sits in the United States House of Representatives, serves on congressional committees, and functions in every respect as a legislator except being denied a vote on the final disposition of legislation on the House floor, also engages in foreign affairs to the same extent as other members of Congress. The current Resident Commissioner is Pedro Pierluisi from the New Progressive Party and member of the Democratic Party of the United States.
The U.S. has had Puerto Rican ambassadors to different nations, mostly but not exclusively in Latin America. For example, Maricarmen Aponte, the current U.S. ambassador to El Salvador, is Puerto Rican.
Military.
As it is a territory of the United States of America, the defense of Puerto Rico is provided by the United States as part of the Treaty of Paris with the President of the United States as commander-in-chief. Puerto Rico has its own Puerto Rico National Guard, and its own state defense force, the Puerto Rico State Guard, which by local law is under the authority of the Puerto Rico National Guard.
The commander-in-chief of both local forces is the governor of Puerto Rico who delegates his authority to the Puerto Rico Adjutant General, currently Colonel Marta Carcana. The Adjutant General, in turn, delegates the authority over the State Guard to another officer but retains the authority over the Puerto Rico National Guard as a whole.
U.S. military installations in Puerto Rico were part of the U.S. Atlantic Command (LANTCOM after 1993 USACOM), which had authority over all US military operations that took place throughout the Atlantic. Puerto Rico had been seen as crucial in supporting LANTCOM's mission until 1999, when U.S. Atlantic Command was renamed and given a new mission as United States Joint Forces Command, Puerto Rico is currently the responsibility of United States Northern Command.
Both the Naval Forces Caribbean (NFC) and the Fleet Air Caribbean (FAIR) were formerly based at the Roosevelt Roads Naval Station. The NFC had authority over all US Naval activity in the waters of the Caribbean while FAIR had authority over all US military flights and air operations over the Caribbean. With the closing of the Roosevelt Roads and Vieques Island training facilities, the US Navy has basically exited from Puerto Rico, except for the ships that steam by, and the only significant military presence in the island is the U.S. Army at Ft Buchanan, the Puerto Rican Army and Air National Guards, and the U.S. Coast Guard.
A branch of the U.S. Army National Guard is stationed in Puerto Rico —known as the Puerto Rico Army National Guard— which performs missions equivalent to those of the Army National Guards of the different states of the United States, including ground defense, disaster relief, and control of civil unrest. The local National Guard also incorporates a branch of the U.S. Air National Guard —known as the Puerto Rico Air National Guard— which performs missions equivalent to those of the Air National Guards of the U.S. states.
At different times in the 20th century, the U.S. had about 25 military or naval installations in Puerto Rico, some very small ones, as well as large installations. The largest of these installations were the former Roosevelt Roads Naval Station in Ceiba, the Atlantic Fleet Weapons Training Facility (AFWTF) on Vieques, the National Guard training facility at Camp Santiago in Salinas, Fort Allen in Juana Diaz, the Army's Fort Buchanan in San Juan, the former U.S. Air Force Ramey Air Force Base in Aguadilla, and the Puerto Rico Air National Guard at Muñiz Air Force base in San Juan.
The former U.S. Navy facilities at Roosevelt Roads, Vieques, and Sabana Seca have been deactivated and partially turned over to the local government. Other than U.S. Coast Guard and Puerto Rico National Guard facilities, there are only two remaining military installations in Puerto Rico, the U.S. Army's small Ft. Buchanan (supporting local veterans and reserve units) and the PRANG(Puerto Rico Air National Guard) Muñiz Air Base (the C-130 Fleet). In recent years, the U.S. Congress has considered their deactivations, but these have been opposed by diverse public and private entities in Puerto Rico - such as retired military who rely on Ft. Buchanan for the services available there.
Puerto Ricans have participated in many of the military conflicts in which the United States has been involved. For example, they participated in the American Revolution, when volunteers from Puerto Rico, Cuba, and Mexico fought the British in 1779 under the command of General Bernardo de Gálvez (1746–1786), and have continued to participate up to the present-day conflicts in Iraq and Afghanistan.
A significant number of Puerto Ricans participate as members and work for the U.S. Armed Services, largely as National Guard members and civilian employees. The size of the overall military-related community in Puerto Rico is estimated to be 100,000 individuals. This includes retired personnel. Fort Buchanan has about 4,000 military and civilian personnel. In addition, approximately 17,000 people are members of the Puerto Rico Army and Air National Guards, or the U.S. Reserve forces. Puerto Rican soldiers have served in every US military conflict from World War I to the current military engagement known by the United States and its allies as the War against Terrorism.
The 65th Infantry Regiment, nicknamed "The Borinqueneers" from the original Taíno name of the island (Borinquen), is a Puerto Rican regiment of the United States Army. The regiments motto is "Honor et Fidelitas", Latin for "Honor and Fidelity". The 65th Infantry Regiment participated in World War I, World War II, the Korean War, and the War on Terror and in 2014 was awarded the Congressional Gold Medal by President Barack Obama for its heroism during the Korean Conflict.
Administrative divisions.
As an unincorporated territory of the United States, Puerto Rico does not have any first order administrative divisions as defined by the U.S. Government, but there are 78 municipalities at the secondary level which function as counties. Municipalities are further subdivided into "barrios", and those into sectors. Each municipality has a mayor and a municipal legislature elected to four-year terms.
Economy.
The economy of Puerto Rico is classified as a high income economy by the World Bank and as the most competitive economy in Latin America by the World Economic Forum but Puerto Rico currently has a public debt of $72.204 billion (equivalent to 103% of GNP), a government deficit of 2.5 billion US dollars. According to World Bank, gross national income per capita of Puerto Rico in 2013 is $23,830 (PPP,International Dollars), ranked as 63rd among all sovereign entities in the world. Its economy is mainly driven by manufacturing (primarily pharmaceuticals, textiles, petrochemicals and electronics) followed by the service industry (primarily finance, insurance, real estate and tourism).
The geography of Puerto Rico and its political status are both determining factors on its economic prosperity, primarily due to its relatively small size as an island; its lack of natural resources used to produce raw materials , and, consequently, its dependence on imports; as well as its suzerainty to the United States which controls its foreign policy while exerting trading restrictions, particularly in its shipping industry.
Puerto Rico experienced a recession from 2006 to 2011, interrupted by 4 quarters of economic growth, and entered into recession again in 2013, following growing fiscal imbalance and the expiration of the IRS Section 936 corporate incentives that the U.S. Internal Revenue Code had applied to Puerto Rico. This IRS section was critical to the economy, as it established tax exemptions for U.S. corporations that settled in Puerto Rico, and allowed their insular subsidiaries to send their earnings to the parent corporation at any time, without paying federal tax on corporate income. Puerto Rico has surprisingly been able to maintain a relatively low inflation in the past decade while maintaining a purchasing power parity per capita higher than 80% of the rest of the world.
Academically, most of Puerto Rico's economic woes stem from federal regulations that expired, have been repealed, or no longer apply to Puerto Rico; its inability to become self-sufficient and self-sustainable throughout history; its highly politicized public policy which tends to change whenever a political party gains power; as well as its highly inefficient local government which has accrued a public debt equal to 68% of its gross domestic product throughout time.
In comparison to the different states of the United States, Puerto Rico is poorer than Mississippi (the poorest state of the U.S.) with 41% of its population below the poverty line. When compared to Latin America, Puerto Rico has the highest GDP per capita in the region. Its main trading partners are the United States itself, Ireland, and Japan, with most products coming from East Asia, mainly from China, Hong Kong, and Taiwan. At a global scale, Puerto Rico's dependency on oil for transportation and electricity generation, as well as its dependency on food imports and raw materials, makes Puerto Rico volatile and highly reactive to changes in the world economy and climate.
Infrastructure.
Cities and towns in Puerto Rico are interconnected by a system of roads, freeways, expressways, and highways maintained by the Highways and Transportation Authority under the jurisdiction of the U.S. Department of Transportation, and patrolled by the Puerto Rico Police Department. The island's metropolitan area is served by a public bus transit system and a metro system called "Tren Urbano" (in English: Urban Train). Other forms of public transportation include seaborne ferries (that serve Puerto Rico's archipelago) as well as "Carros Públicos" (private mini buses).
Puerto Rico has three international airports, the Luis Muñoz Marín International Airport in Carolina, Mercedita Airport in Ponce, and the Rafael Hernández Airport in Aguadilla, and 27 local airports. The Luis Muñoz Marín International Airport is the largest aerial transportation hub in the Caribbean.
Puerto Rico has nine ports in different cities across the main island. The San Juan Port is the largest in Puerto Rico, and the busiest port in the Caribbean and the 10th busiest in the United States in terms of commercial activity and cargo movement, respectively. The second largest port is the Port of the Americas in Ponce, currently under expansion to increase cargo capacity to twenty-foot containers (TEUs) per year.
The Puerto Rico Electric Power Authority (PREPA) —Spanish: "Autoridad de Energía Eléctrica " (AEE)— is an electric power company and the government-owned corporation of Puerto Rico responsible for electricity generation, power transmission, and power distribution in Puerto Rico. PREPA is the only entity authorized to conduct such business in Puerto Rico, effectively making it a government monopoly. The Authority is ruled by a Governing Board appointed by the Governor with the advice and consent of the Senate of Puerto Rico, and is run by an Executive Director.
Telecommunications in Puerto Rico includes radio, television, fixed and mobile telephones, and the Internet. Broadcasting in Puerto Rico is regulated by the US Federal Communications Commission (FCC). As of 2007, there were 30 TV stations, 125 radio stations and roughly 1 million TV sets on the island. Cable TV subscription services are available and the US Armed Forces Radio and Television Service also broadcast on the island.
Public finances.
Puerto Rico has an operating budget of about $9.8 billion USD with expenses at about $10.4 billion; creating a structural deficit of $775 million (about 7.9% of the budget). The practice of approving budgets with a structural deficit has been done for consecutive years starting in 2000. Throughout those years, including present time, all budgets contemplated issuing bonds to cover said projected deficits rather than make proper adjustments. This practice eroded Puerto Rico's treasury as the government had already been issuing bonds to balance its actual budget for four decades since 1973.
Projected deficits added substantial burdens to an already indebted nation which accrued a public debt of $71B or about 70% of Puerto Rico's gross domestic product. This sparked an ongoing government-debt crisis after Puerto Rico's general obligation bonds were downgraded to speculative non-investment grade ("junk status") by three credit rating agencies. In terms of financial control, almost 9.6% —or about $1.5 billion— of Puerto Rico's central government budget expenses for FY2014 is expected to be spent on debt service. Harsher budget cuts are expected as Puerto Rico must now repay larger chunks of debts in the following years.
For practical reasons the budget is divided into two aspects: a "general budget" which comprises the assignments funded exclusively by the Department of Treasury of Puerto Rico, and the "consolidated budget" which comprises the assignments funded by the general budget, by Puerto Rico's government-owned corporations, by revenue expected from loans, by the sale of government bonds, by subsidies extended by the federal government of the United States, and by other funds.
Both budgets contrast each other drastically, with the consolidated budget being usually thrice the size of the general budget; currently $29B and $9.0B respectively. Almost one out of every four dollars in the consolidated budget comes from U.S. federal subsidies while government-owned corporations compose more than 31% of the consolidated budget.
The critical aspects come from the sale of bonds, which comprise 7% of the consolidated budget; a ratio that increased annually due to the government's inability to prepare a balanced budget in addition to being incapable of generating enough income to cover all its expenses. In particular, the government-owned corporations add a heavy burden to the overall budget and public debt as not a single one is self-sufficient, all of them carrying extremely inefficient operations. For example, in FY2011 the government-owned corporations reported aggregated losses of more than $1.3B with the Puerto Rico Highways and Transportation Authority (PRHTA) reporting losses of $409M, the Puerto Rico Electric Power Authority (PREPA; the government monopoly that controls all electricity on the island) reporting losses of $272M, while the Puerto Rico Aqueducts and Sewers Authority (PRASA; the government monopoly that controls all water utilities on the island) reported losses of $112M. All these losses were defrayed through the issuance of bonds compounding more than 40% of Puerto Rico's entire public debt today. Holistically, from FY2000–FY2010 Puerto Rico's debt grew at a compound annual growth rate (CAGR) of 9% while GDP remained stagnant.
In terms of protocol, the governor, together with the Puerto Rico Office of Management and Budget (OGP in Spanish), formulates the budget he believes is required to operate all government branches for the ensuing fiscal year. He then submits this formulation as a budget request to the Puerto Rican legislature before July 1, the date established by law as the beginning of Puerto Rico's fiscal year. While the constitution establishes that the request must be submitted "at the beginning of each regular session", the request is typically submitted during the first week of May as the regular sessions of the legislature begin in January and it would be unpractical to submit a request so far ahead. Once submitted the budget is then approved by the legislature, typically with amendments, through a joint resolution and referred back to the governor for his approval. The governor then either approves it or vetoes it. If vetoed the legislature can then either refer it back with amendments for the governor's approval, or approve it without the governor's consent by two thirds of the bodies of each chamber.
Once approved the Department of Treasury disburses funds to the Office of Management and Budget which in turn disburses the funds to the respective agencies, all while the Puerto Rico Government Development Bank (the government's intergovernmental bank) manages all related banking affairs including those related to the government-owned corporations.
Cost of living.
The cost of living in Puerto Rico is high and has increased over the past decade. San Juan's in particular is higher than Atlanta, Dallas, and Seattle but lower than Boston, Chicago, and New York City. One factor is housing prices which are comparable to Miami and Los Angeles, although property taxes are considerably lower than most places in the United States.
Statistics used for cost of living sometimes do not take into account certain costs, such as the high cost of electricity, which has hovered in the 24¢ to 30¢ range per kilowatt/hour, two to three times the national average, increased travel costs for longer flights, additional shipping fees, and the loss of promotional participation opportunities for customers "outside the continental United States." While some online stores do offer free shipping on orders to Puerto Rico, many merchants exclude Hawaii, Alaska, Puerto Rico and other United States territories.
The median home value in Puerto Rico ranges from $100,000 USD to $214,000 USD, while the national median home value sits at $119,600.
One of the most cited contributors to the high cost of living in Puerto Rico is the Merchant Marine Act of 1920, also known as the Jones Act, which prevents foreign-flagged ships from carrying cargo between two American ports, a practice known as cabotage. Because of the Jones Act, foreign ships inbound with goods from Central and South America, Western Europe, and Africa cannot stop in Puerto Rico, offload Puerto Rico-bound goods, load mainland-bound Puerto Rico-manufactured goods, and continue to U.S. ports. Instead, they must proceed directly to U.S. ports, where distributors break bulk and send Puerto Rico-bound manufactured goods to Puerto Rico across the ocean by U.S.-flagged ships.
However, a 2013 GAO Study reported that, "Shippers doing business in Puerto Rico that GAO contacted reported that the freight rates are often—although not always—lower for foreign carriers going to and from Puerto Rico and foreign locations than the rates shippers pay to ship similar cargo to and from the United States, despite longer distances. However, data were not available to allow us to validate the examples given or verify the extent to which this difference occurred."
The local government of Puerto Rico has requested several times to the U.S. Congress to exclude Puerto Rico from the Jones Act restrictions without success. The most recent measure has been taken by the 17th Legislative Assembly of Puerto Rico through R. Conc. del S. 21. These measures have always received support from all the major local political parties. In 2013 the Government Accountability Office published a report which concluded that "repealing or amending the Jones Act cabotage law might cut Puerto Rico shipping costs" and that "shippers believed that opening the trade to non-U.S.-flag competition could lower costs."
The report, however, concluded that the effects of modifying the application of the Jones Act for Puerto Rico are highly uncertain for both Puerto Rico and the United States, particularly for the U.S. shipping industry and the military preparedness of the United States.
Demographics.
The population of Puerto Rico has been shaped by Amerindian settlement, European colonization, slavery, economic migration, and Puerto Rico's status as unincorporated territory of the United States.
Population and racial makeup.
Continuous European immigration helped the population of Puerto Rico grow from 155,426 in 1800, to almost a million by the close of the 19th century.
A census conducted by royal decree on , 1858 gave the following totals of the Puerto Rican population at that time: 341,015 were Free colored; 300,430 identified as Whites; and 41,736 were slaves.
During the 19th century hundreds of Corsican, French, Lebanese, Chinese, and Portuguese families arrived in Puerto Rico, along with large numbers of immigrants from Spain (mainly from Catalonia, Asturias, Galicia, the Balearic Islands, Andalusia, and the Canary Islands) and numerous Spanish loyalists from Spain's former colonies in South America. Other settlers included Irish, Scots, Germans, Italians and thousands of others who were granted land by Spain during the "Real Cedula de Gracias de 1815" ("Royal Decree of Graces of 1815"), which allowed European Catholics to settle in the island with land allotments in the interior of the island, provided they paid taxes and continued to support the Catholic Church.
Between 1960 and 1990 the census questionnaire in Puerto Rico did not ask about race or ethnicity. The 2000 United States Census included a racial self-identification question in Puerto Rico. According to the census, most Puerto Ricans identified as White and Hispanic; few identified as Black or some other race.
The population of Puerto Rico was 3,548,397 on July 1, 2014, a -4.76% decrease since the 2010 United States Census. From 2000 to 2010, the population decreased, the first such decrease in census history for Puerto Rico. It went from the 3,808,610 residents registered in the 2000 Census to 3,725,789 in the 2010 Census.
A declining and aging population presents additional problems for the society. The Census Bureau has noted that "76,218 people residing in the U.S. last year lived in Puerto Rico one year earlier."
Population genetics.
A recent population genetics study conducted in Puerto Rico suggests that between 52.6% and 84% of the population possess some degree of Amerindian mitochondrial DNA (mtDNA) in their maternal ancestry, usually in a combination with other ancestries. In addition, these DNA studies show Amerindian ancestry in addition to the Taíno.
One genetic study on the racial makeup of Puerto Ricans found them to be roughly around 61% West Eurasian (overwhelmingly of Spanish provenance), 27% Sub-Saharan African and 11% Native American. Another genetic study from 2007, claimed that "the average genomewide individual (ie. Puerto Rican) ancestry proportions have been estimated as 66%, 18%, and 16%, for European, West African, and Native American, respectively." Other study estimates 63.7% European, 21.2% (Sub-Saharan) African, and 15.2% Native American; European ancestry is more prevalent in the West and in Central Puerto Rico, African in Eastern Puerto Rico, and Native American in Northern Puerto Rico.
According to data provided by the DNA Tribes company, as of 2013 the genetic admixture of Puerto Ricans was, on average, 72.2% West Eurasian (49% European, 18.3% Saharan-Arabian, 4.9% West Asian), 12.7% Native American, 12.5% Sub-Saharan African, and 1.4% Northeast African.
Immigration and emigration.
Puerto Rico has recently become the permanent home of over 100,000 legal residents. The vast majority of recent immigrants, both legal and illegal, come from the Dominican Republic and Haiti. Other sources sending in significant numbers of recent immigrants include Cuba, Mexico, Colombia, Panama, Jamaica, Venezuela, Spain, and Nigeria. Also, there are many non-Puerto Rican US citizens settling in Puerto Rico, from the mainland United States and the US Virgin Islands, as well as Nuyoricans (stateside Puerto Ricans) coming back to Puerto Rico. Most recent immigrants settle areas in and around San Juan.
Emigration is a major part of contemporary Puerto Rican history. Starting soon after World War II, poverty, cheap airfares, and promotion by the island government caused waves of Puerto Ricans to move to the United States, particularly to the Northeastern states, and Florida. This trend continued even as Puerto Rico's economy improved and its birth rate declined. Puerto Ricans continue to follow a pattern of "circular migration", with some migrants returning to the island. In recent years, the population has declined markedly, falling nearly 1% in 2012 and an additional 1% (36,000 people) in 2013 due to a falling birthrate and emigration.
Population distribution.
The most populous city is the capital, San Juan, with approximately 395,326 people. Other major cities include Bayamón, Carolina, Ponce, and Caguas. Of the ten most populous cities on the island, eight are located within what is considered San Juan's metropolitan area, while the other two are located in the south (Ponce) and west (Mayagüez) of the island.
Languages.
The official languages of the executive branch of government of Puerto Rico were Spanish and English, with Spanish being the primary language. Spanish is, and has been, the only official language of the entire Commonwealth judiciary system, despite a 1902 English-only language law. All official business of the U.S. District Court for the District of Puerto Rico is conducted in English. English is spoken by a small minority – less than 10% of the population. Spanish is the dominant language of business, education and daily life on the island, spoken by over 95% of the population.
Public school instruction in Puerto Rico is conducted almost entirely in Spanish. There are pilot programs in about a dozen of the over 1,400 public schools aimed at conducting instruction in English only. English is taught as a second language and is a compulsory subject from elementary levels to high school. The languages of the deaf community are American Sign Language and its local variant, Puerto Rican Sign Language.
The Spanish of Puerto Rico has evolved into having many idiosyncrasies in vocabulary and syntax that differentiate it from the Spanish spoken elsewhere. While the Spanish spoken in all Iberian, Mediterranean and Atlantic Spanish Maritime Provinces was brought to the island over the centuries, the most profound regional influence on the Spanish spoken in Puerto Rico has been from that spoken in the present-day Canary Islands. The Spanish of Puerto Rico also includes occasional Taíno words, typically in the context of vegetation, natural phenomena or primitive musical instruments. Similarly, words attributed to primarily West African languages were adopted in the contexts of foods, music or dances, particularly in coastal towns with concentrations of descendants of Sub-Saharan Africans.
According to a study by the University of Puerto Rico, nine of every ten Puerto Ricans residing in Puerto Rico do not speak English at an advanced level. More recently, according to the "2005–2009 Population and Housing Narrative Profile for Puerto Rico", among people at least five years old living in Puerto Rico in 2005–2009, 95 percent spoke a language other than English at home. Of those speaking a language other than English at home, 100 percent spoke Spanish and less than 0.5 percent spoke some other language; 85 percent reported that they did not speak English "very well."
Spanish became the official language of the island in 2015.
Religion.
The Roman Catholic Church was brought by Spanish colonists and gradually became the dominant religion in Puerto Rico. The first dioceses in the Americas, including that of Puerto Rico, were authorized by Pope Julius II in 1511. One Pope, John Paul II, visited Puerto Rico in October 1984. All municipalities in Puerto Rico have at least one Catholic church, most of which are located at the town center or "plaza". African slaves brought and maintained various ethnic African religious practices associated with different peoples; in particular, the Yoruba beliefs of Santería and/or Ifá, and the Kongo-derived Palo Mayombe. Some aspects were absorbed into syncretic Christianity.
Protestantism, which was suppressed under the Spanish Catholic regime, has slightly reemerged under United States rule, making modern Puerto Rico more interconfessional although Catholicism continues to be the dominant religion. The first Protestant church, Holy Trinity Church in Ponce, was established by the Anglican diocese of Antigua in 1872. German settlers in Ponce founded the Iglesia Santísima Trinidad, an Anglican Church, the first non-Roman Catholic Church in the entire Spanish Empire in the Americas.
Growth has occurred among Pentecostals. Estimates of the Protestant population vary greatly. Pollster Pablo Ramos reported in 1998 that the population was 38% Catholic, 28% Pentecostals, 4% Baptist, and 18% members of independent churches; Protestants collectively numbered almost two million of an island population of 3.6 million. "The conclusion is that Puerto Rico is no longer predominantly Catholic." ("The San Juan Star," April 12, 1998: "Study reflects growing numbers of churchgoers").
Another researcher gave a more conservative assessment of the proportion of Protestants:
Puerto Rico, by virtue of its long political association with the United States, is the most Protestant of Latin American countries, with a Protestant population of approximately 33 to 38 percent, the majority of whom are Pentecostal. David Stoll calculates that if we extrapolate the growth rates of evangelical churches from 1960-1985 for another twenty-five years Puerto Rico will become 75 percent evangelical. (Ana Adams: "Brincando el Charco..." in "Power, Politics and Pentecostals in Latin America," Edward Cleary, ed., 1997. p. 164).
An Eastern Orthodox community, the Dormition of the Most Holy Theotokos / St. Spyridon's Church is located in Trujillo Alto, and serves the small Orthodox community. The congregation represents Greeks, Russians, Serbians, Bulgarians, Americans, Moldavians, and Puerto Ricans.
In 1940, Juanita García Peraza founded the Mita Congregation, the first religion of Puerto Rican origin. Taíno religious practices have been rediscovered/reinvented to a degree by a handful of advocates. Similarly, some aspects of African religious traditions have been kept by some adherents.
In 1952, a handful of American Jews established the island's first synagogue in the former residence of William Korber, a wealthy Puerto Rican of Jewish German descent. It was designed and built by the Czech architect Antonin Nechodoma. The synagogue, called "Sha'are Zedeck," hired its first rabbi in 1954. Puerto Rico has the largest Jewish community in the Caribbean, numbering 3,000, and is the only Caribbean island in which the Conservative, Reform and Orthodox Jewish movements all are represented.
In 2007, there were about 5,000 Muslims in Puerto Rico, representing about 0.13% of the population. Eight mosques are located throughout the island, with most Muslims living in Río Piedras.
In 2011, the 26,546 Jehovah's Witnesses represented about 0.72% of the population, with 329 congregations.
The Padmasambhava Buddhist Center, whose followers practice Tibetan Buddhism, has a branch in Puerto Rico.
Education.
The first school in Puerto Rico was the "Escuela de Gramática" (Grammar School). It was established by Bishop Alonso Manso in 1513, in the area where the Cathedral of San Juan was to be constructed. The school was free of charge and the courses taught were Latin language, literature, history, science, art, philosophy and theology.
Education in Puerto Rico is divided in three levels—Primary (elementary school grades 1–6), Secondary (intermediate and high school grades 7–12), and Higher Level (undergraduate and graduate studies). As of 2002, the literacy rate of the Puerto Rican population was 94.1%; by gender, it was 93.9% for males and 94.4% for females. According to the 2000 Census, 60.0% of the population attained a high school degree or higher level of education, and 18.3% has a bachelor's degree or higher.
Instruction at the primary school level is compulsory and enforced by the state between the ages of 5 and 18. The Constitution of Puerto Rico grants the right to an education to every citizen on the island. To this end, public schools in Puerto Rico provide free and non-sectarian education at the elementary and secondary levels. At any of the three levels, students may attend either public or private schools. As of 1999, there were 1532 public schools and 569 private schools in the island.
The largest and oldest university system is the public University of Puerto Rico (UPR) with 11 campuses. The largest private university systems on the island are the Sistema Universitario Ana G. Mendez which operates the Universidad del Turabo, Metropolitan University and Universidad del Este, the multi-campus Inter American University, the Pontifical Catholic University, and the Universidad del Sagrado Corazón. Puerto Rico has four schools of Medicine and three ABA-approved Law Schools.
Health.
As of 2015 medical care in Puerto Rico had been heavily impacted by immigration of doctors to the mainland and underfunding of the Medicare and Medicaid programs which serve 60% of the island's population. Affordable medical insurance under the Affordable Care Act is not available in Puerto Rico as, since Puerto Ricans pay no income tax, no subsidies are available.
The city of San Juan has a system of triage, hospital, and preventive care health services. The municipal government sponsors regular health fairs in different areas of the city focusing on health care for the elderly and the disabled.
There are twenty hospitals in San Juan, half of which are operated by the government. The largest hospital is the "Centro Médico de Río Piedras" (the Río Piedras Medical Center). Founded in 1956, it is operated by the Medical Services Administration of the Department of Health of Puerto Rico, and is actually a network of eight hospitals:
The city of San Juan operates nine other hospitals. Of these, eight are Diagnostic and Treatment Centers located in communities throughout San Juan. These nine hospitals are:
There are also ten private hospitals in San Juan. These are:
The city of Ponce is served by several clinics and hospitals. There are four comprehensive care hospitals: Hospital Dr. Pila, Hospital San Cristobal, Hospital San Lucas, and Hospital de Damas. In addition, Hospital Oncológico Andrés Grillasca specializes in the treatment of cancer, and Hospital Siquiátrico specializes in mental disorders. There is also a U.S. Department of Veterans Affairs Outpatient Clinic that provides health services to U.S. veterans. The U.S. Veterans Administration will build a new hospital in the city to satisfy regional needs. Hospital de Damas is listed in the U.S. News & World Report as one of the best hospitals under the U.S. flag. Ponce has the highest concentration of medical infrastructure per inhabitant of any municipality in Puerto Rico.
On the island of Culebra, there is a small hospital in the island called "Hospital de Culebra". It also offers pharmacy services to residents and visitors. For emergencies, patients are transported by plane to Fajardo on the main island.
The town of Caguas has three hospitals: Hospital Hima San Pablo, Menonita Caguas Regional Hospital, and the San Juan Bautista Medical Center.
The town of Cayey is served by the "Hospital Menonita de Cayey", and the "Hospital Municipal de Cayey."
"Reforma de Salud de Puerto Rico" (Puerto Rico Health Reform) - locally referred to as "La Reforma" (The Reform) - is a government-run program which provides medical and health care services to the indigent and impoverished, by means of contracting private health insurance companies, rather than employing government-owned hospitals and emergency centers. The Reform is administered by the Puerto Rico Health Insurance Administration.
Culture.
Modern Puerto Rican culture is a unique mix of cultural antecedents: including Taíno (Amerindians), European (mainly Spanish), African, and, more recently, North American.
From the Spanish, Puerto Rico received the Spanish language, the Catholic religion and the vast majority of their cultural and moral values and traditions. The United States added English language influence, the university system and the adoption of some holidays and practices. On , 1903, the University of Puerto Rico was officially founded, branching out from the "Escuela Normal Industrial", a smaller organism that was founded in Fajardo three years before.
Much of Puerto Rican culture centers on the influence of music and has been shaped by other cultures combining with local and traditional rhythms. Early in the history of Puerto Rican music, the influences of Spanish and African traditions were most noticeable. The cultural movements across the Caribbean and North America have played a vital role in the more recent musical influences that have reached Puerto Rico.
The official symbols of Puerto Rico are the "reinita mora" or Puerto Rican spindalis (a type of bird), the "flor de maga" (a type of flower), and the "ceiba" or kapok (a type of tree). The unofficial animal and a symbol of Puerto Rican pride is the coquí, a small frog. Other popular symbols of Puerto Rico are the "jíbaro" (the "countryman"), and the carite.
Architecture.
 
The architecture of Puerto Rico demonstrates a broad variety of traditions, styles and national influences accumulated over four centuries of Spanish rule, and a century of American rule. Spanish colonial architecture, Moorish, art deco, post-modern, and many other architectural forms are visible throughout the island. From town to town, there are also many regional distinctions.
Old San Juan is one of the two "barrios", in addition to Santurce, that made up the municipality of San Juan from 1864 to 1951, at which time the former independent municipality of Río Piedras was annexed. With its abundance of shops, historic places, museums, open air cafés, restaurants, gracious homes, tree-shaded plazas, and its old beauty and architectonical peculiarity, Old San Juan is a main spot for local and internal tourism. The district is also characterized by numerous public plazas and churches including San José Church and the Cathedral of San Juan Bautista, which contains the tomb of the Spanish explorer Juan Ponce de León. It also houses the oldest Catholic school for elementary education in Puerto Rico, the Colegio de Párvulos, built in 1865.
The oldest parts of the district of Old San Juan remain partly enclosed by massive walls. Several defensive structures and notable forts, such as the emblematic Fort San Felipe del Morro, Fort San Cristóbal, and El Palacio de Santa Catalina, also known as La Fortaleza, acted as the primary defenses of the settlement which was subjected to numerous attacks. La Fortaleza continues to serve also as the executive mansion for the Governor of Puerto Rico. Many of the historic fortifications are part of San Juan National Historic Site.
During the 1940s, sections of Old San Juan fell into disrepair, and many renovation plans were suggested. There was even a strong push to develop Old San Juan as a "small Manhattan." However, strict remodeling codes were implemented to prevent new constructions from affecting the common colonial Spanish architectural themes of the old city. When a project proposal suggested that the old Carmelite Convent in San Juan be demolished to erect a new hotel, the Institute had the building declared as a historic building, and then asked that it be converted to a hotel in a renewed facility. This was what became the "Hotel El Convento" in Old San Juan. The paradigm to reconstruct and renovate the old city and revitalize it has been followed by other cities in the Americas, particularly Havana, Lima and Cartagena de Indias.
Ponce Creole is an architectural style created in Ponce, Puerto Rico, in the late 19th and early 20th centuries. This style of Puerto Rican buildings is found predominantly in residential homes in Ponce that developed between 1895 and 1920. Ponce Creole architecture borrows heavily from the traditions of the French, the Spaniards, and the Caribbean to create houses that were especially built to withstand the hot and dry climate of the region, and to take advantage of the sun and sea breezes characteristic of the southern Puerto Rico's Caribbean Sea coast. It is a blend of wood and masonry, incorporating architectural elements of other styles, from Classical revival and Spanish Revival to Victorian.
Arts.
Puerto Rican art reflects many influences, much from its ethnically diverse background. A form of folk art, called "santos" evolved from the Catholic Church's use of sculptures to convert indigenous Puerto Ricans to Christianity. "Santos" depict figures of saints and other religious icons and are made from native wood, clay, and stone. After shaping simple effigies, they are often finished by painting them in vivid colors. "Santos" vary in size, with the smallest examples around eight inches tall and the largest about twenty inches tall. Traditionally, santos were seen as messengers between the earth and Heaven. As such, they occupied a special place on household altars, where people prayed to them, asked for help, or tried to summon their protection.
Also popular, "caretas" are masks worn during carnivals. Similar masks signifying evil spirits were used in both Spain and Africa, though for different purposes. The Spanish used their masks to frighten lapsed Christians into returning to the church, while tribal Africans used them as protection from the evil spirits they represented. True to their historic origins Puerto Rican "caretas" always bear at least several horns and fangs. While usually constructed of papier-mâché, coconut shells and fine metal screening are sometimes used as well. Red and black were the typical colors for "caretas" but their palette has expanded to include a wide variety of bright hues and patterns.
Literature.
Puerto Rican literature evolved from the art of oral story telling to its present-day status. Written works by the native islanders of Puerto Rico were prohibited and repressed by the Spanish colonial government. Only those who were commissioned by the Spanish Crown to document the chronological history of the island, were allowed to write.
Diego de Torres Vargas was allowed to circumvent this strict prohibition for three reasons: 1) he was a priest, 2) he came from a prosperous Spanish family, 3) his father was a Sergeant Major in the Spanish Army, who died while defending Puerto Rico from an invasion by the Dutch armada. In 1647, Torres Vargas wrote "Descripción de la Ciudad e Isla de Puerto Rico" ("Description of the Island and City of Puerto Rico"). This historical book was the first to make a detailed geographic description of the island.
The book described all the fruits and commercial establishments of the time, mostly centered in the towns of San Juan and Ponce. The book also listed and described every mine, church, and hospital in the island at the time. The book contained notices on the State and Capital, plus an extensive and erudite bibliography. "Descripción de la Ciudad e Isla de Puerto Rico" was the first successful attempt at writing a comprehensive history of Puerto Rico.
Some of Puerto Rico's earliest writers were influenced by the teachings of Rafael Cordero. Among these was Dr. Manuel A. Alonso, the first Puerto Rican writer of notable importance. In 1849 he published "El Gíbaro", a collection of verses whose main themes were the poor Puerto Rican country farmer. Eugenio María de Hostos wrote "La peregrinación de Bayoán" in 1863, which used Bartolomé de las Casas as a spring board to reflect on Caribbean identity. After this first novel, Hostos abandoned fiction in favor of the essay which he saw as offering greater possibilities for inspiring social change.
In the late 19th century, with the arrival of the first printing press and the founding of the Royal Academy of Belles Letters, Puerto Rican literature began to flourish. The first writers to express their political views in regard to Spanish colonial rule of the island were journalists. After the United States invaded Puerto Rico during the Spanish–American War and the island was ceded to the Americans as a condition of the Treaty of Paris of 1898, writers and poets began to express their opposition of the new colonial rule by writing about patriotic themes.
Alejandro Tapia y Rivera also known as the Father of Puerto Rican Literature, ushered in a new age of historiography with the publication of "The Historical Library of Puerto Rico". Cayetano Coll y Toste was a Puerto Rican historian and writer. His work "The Indo-Antillano Vocabulary" is valuable in understanding the way the Taínos lived. Dr. Manuel Zeno Gandía in 1894 wrote "La Charca" and told about the harsh life in the remote and mountainous coffee regions in Puerto Rico. Dr. Antonio S. Pedreira, described in his work "Insularismo" the cultural survival of the Puerto Rican identity after the American invasion.
With the Puerto Rican diaspora of the 1940s, Puerto Rican literature was greatly influenced by a phenomenon known as the Nuyorican Movement. Puerto Rican literature continued to flourish and many Puerto Ricans have distinguished themselves as authors, journalists, poets, novelists, playwrights, screenwriters, essayists and other literary fields. The influence of Puerto Rican literature has transcended the boundaries of the island to the United States and the rest of the world. Over the past fifty years, significant writers include Ed Vega, Luis Rafael Sánchez, Piri Thomas , Giannina Braschi, and Miguel Piñero. Esmeralda Santiago has written an autobiographical trilogy about growing up in modern Puerto Rico as well as an historical novel, "Conquistadora", about life on a sugar plantation during the mid-19th century.
Media.
The media in Puerto Rico includes local radio stations, television stations and newspapers, the majority of which are conducted in Spanish. There are also three stations of the US Armed Forces Radio and Television Service. Newspapers with daily distribution are El Nuevo Dia, El Vocero and Primera Hora and the Puerto Rico Daily Sun.
Newspapers distributed on a weekly or regional basis include Claridad and La Estrella Norte, among others. Several television channels provide local content in the island. These include Super Siete, Telemundo, Univision Puerto Rico, WAPA-TV, and WKAQ-TV.
Music.
The music of Puerto Rico has evolved as a heterogeneous and dynamic product of diverse cultural resources. The most conspicuous musical sources have been Spain and West Africa, although many aspects of Puerto Rican music reflect origins elsewhere in Europe and the Caribbean and, over the last century, from the U.S.A. Puerto Rican music culture today comprises a wide and rich variety of genres, ranging from indigenous genres like bomba y plena, aguinaldo and danza, to recent hybrids like reggaeton.
In the realm of classical music, the island hosts two main orchestras, the Orquesta Sinfónica de Puerto Rico and the Orquesta Filarmónica de Puerto Rico. The Casals Festival takes place annually in San Juan, drawing in classical musicians from around the world.
With respect to opera, the legendary Puerto Rican tenor Antonio Paoli was so celebrated, that he performed private recitals for Pope Pius X and the Czar of Russia Nicholas II. In 1907, Paoli was the first operatic artist in world history to record an entire opera - when he participated in a performance of "Pagliacci" by Ruggiero Leoncavallo in Milan, Italy.
Over the past fifty years, Puerto Rican artists such as Jorge Emmanuelli, Yomo Toro, Ramito, Jose Feliciano, Bobby Capo, Tito Puente, Eddie Palmieri, Ray Barreto, Dave Valentin, Omar Rodríguez-López, Hector Lavoe and Marc Anthony have thrilled audiences around the world.
Cuisine.
Puerto Rican cuisine has its roots in the cooking traditions and practices of Europe (Spain), Africa and the native Taínos. In the latter part of the 19th century, the cuisine of Puerto Rico was greatly influenced by the United States in the ingredients used in its preparation. Puerto Rican cuisine has transcended the boundaries of the island, and can be found in several countries outside the archipelago. Basic ingredients include grains and legumes, herbs and spices, starchy tropical tubers, vegetables, meat and poultry, seafood and shellfish, and fruits. Main dishes include "mofongo", "arroz con gandules", "pasteles", and pig roast. Beverages include "maví" and "piña colada". Desserts include "arroz con dulce" (sweet rice pudding), "piraguas", "brazo gitanos", "tembleque", "polvorones", and "dulce de leche".
Locals call their cuisine cocina criolla. The traditional Puerto Rican cuisine was well established by the end of the 19th century. By 1848 the first restaurant, La Mallorquina, opened in Old San Juan. "El Cocinero Puertorriqueño", the island's first cookbook was published in 1849.
From the diet of the Taíno people come many tropical roots and tubers like "yautía" (taro) and especially "Yuca" (cassava), from which thin cracker-like "casabe" bread is made. Ajicito or cachucha pepper, a slightly hot habanero pepper, "recao/culantro" (spiny leaf), "achiote" (annatto), "peppers", "ají caballero" (the hottest pepper native to Puerto Rico), peanuts, guavas, pineapples, "jicacos" (cocoplum), "quenepas" (mamoncillo), "lerenes" (Guinea arrowroot), "calabazas" (tropical pumpkins), and "guanabanas" (soursops) are all Taíno foods. The Taínos also grew varieties of beans and some "maíz" (corn/maize), but "maíz" was not as dominant in their cooking as it was for the peoples living on the mainland of Mesoamerica. This is due to the frequent hurricanes that Puerto Rico experiences, which destroy crops of "maíz", leaving more safeguarded plants like "conucos" (hills of "yuca" grown together).
Spanish / European influence is also seen in Puerto Rican cuisine. Wheat, chickpeas (garbanzos), capers, olives, olive oil, black pepper, onions, garlic, "cilantrillo" (cilantro), oregano, basil, sugarcane, citrus fruit, eggplant, ham, lard, chicken, beef, pork, and cheese all came to Borikén (Puerto Rico's native Taino name) from Spain. The tradition of cooking complex stews and rice dishes in pots such as rice and beans are also thought to be originally European (much like Italians, Spaniards, and the British). Early Dutch, French, Italian, and Chinese immigrants influenced not only the culture but Puerto Rican cooking as well. This great variety of traditions came together to form La Cocina Criolla.
Coconuts, coffee (brought by the Arabs and Corsos to Yauco from Kafa, Ethiopia), okra, yams, sesame seeds, "gandules" (pigeon peas in English) sweet bananas, plantains, other root vegetables and Guinea hen, all come to Puerto Rico from Africa.
Puerto Rico has been commemorated on four U.S. postal stamps and four personalities have been featured. Insular Territories were commemorated in 1937, the third stamp honored Puerto Rico featuring 'La Fortaleza', the Spanish Governor's Palace. The first free election for governor of the US colony of Puerto Rico was honored on April 27, 1949, at San Juan, Puerto Rico. 'Inauguration' on the 3-cent stamp refers to the election of Luis Munoz Marin, the first democratically elected governor of Puerto Rico. San Juan, Puerto Rico was commemorated with an 8-cent stamp on its 450th anniversary issued September 12, 1971, featuring a sentry box from Castillo San Felipe del Morro. In the "Flags of our nation series" 2008-2012, of the fifty-five, five territorial flags were featured. Forever stamps included the Puerto Rico Flag illustrated by a bird issued 2011.
Four Puerto Rican personalities have been featured on U.S. postage stamps. These include Roberto Clemente in 1984 as an individual and in the Legends of Baseball series issued in 2000., Luis Muñoz Marín in the Great Americans series, on February 18, 1990., Julia de Burgos in the Literary Arts series, issued 2010., and José Ferrer in the Distinguished American series, issued 2012.
Sports.
Baseball was one of the first sports to gain widespread popularity in Puerto Rico. The Puerto Rico Baseball League serves as the only active professional league, operating as a winter league. No Major League Baseball franchise or affiliate plays in Puerto Rico, however, San Juan hosted the Montreal Expos for several series in 2003 and 2004 before they moved to Washington, D.C. and became the Washington Nationals.
The Puerto Rico national baseball team has participated in the World Cup of Baseball winning one gold (1951), four silver and four bronze medals, the Caribbean Series (winning fourteen times) and the World Baseball Classic. On , San Juan's Hiram Bithorn Stadium hosted the opening round as well as the second round of the newly formed World Baseball Classic. Famous Puerto Rican baseball players include Hall of Famers Roberto Clemente, Orlando Cepeda and Roberto Alomar, enshrined in 1973, 1999, and 2011 respectively.
Boxing, basketball, and volleyball are considered popular sports as well. Wilfredo Gómez and McWilliams Arroyo have won their respective divisions at the World Amateur Boxing Championships. Other medalists include José Pedraza, who holds a silver medal, and three boxers who finished in third place, José Luis Vellón, Nelson Dieppa and McJoe Arroyo. In the professional circuit, Puerto Rico has the third-most boxing world champions and it is the global leader in champions per capita. These include Miguel Cotto, Félix Trinidad, Wilfred Benítez and Gómez among others.
The Yasuri Jamileth joined the International Basketball Federation in 1957. Since then, it has won more than 30 medals in international competitions, including gold in three FIBA Americas Championships and the 1994 Goodwill Games. , 2004, became a landmark date for the team when it became the first team to defeat the United States in an Olympic tournament since the integration of National Basketball Association players. Winning the inaugural game with scores of 92–73 as part of the 2004 Summer Olympics organized in Athens, Greece. Baloncesto Superior Nacional acts as the top-level professional basketball league in Puerto Rico, and has experienced success since its beginning in 1930.
Puerto Rico is also a member of FIFA and CONCACAF. In 2008, the archipelago's first unified league, the Puerto Rico Soccer League, was established.
Other sports include professional wrestling, road running and basketball. The World Wrestling Council and International Wrestling Association are the largest wrestling promotions in the main island. The World's Best 10K, held annually in San Juan, has been ranked among the 20 most competitive races globally. The "Puerto Rico All Stars" team, which has won twelve world championships in unicycle basketball.
Organized Streetball has gathered some exposition, with teams like "Puerto Rico Street Ball" competing against established organizations including the Capitanes de Arecibo and AND1's Mixtape Tour Team. Six years after the first visit, AND1 returned as part of their renamed Live Tour, losing to the Puerto Rico Streetballers. Consequently, practitioners of this style have earned participation in international teams, including Orlando "El Gato" Meléndez, who became the first Puerto Rican born athlete to play for the Harlem Globetrotters. Orlando Antigua, whose mother is Puerto Rican, in 1995 became the first Hispanic and the first non-black in 52 years to play for the Harlem Globetrotters.
Puerto Rico has representation in all international competitions including the Summer and Winter Olympics, the Pan American Games, the Caribbean World Series, and the Central American and Caribbean Games. Puerto Rican athletes have won seven medals (two silver, five bronze) in Olympic competition, the first one in 1948 by boxer Juan Evangelista Venegas. The Central American and Caribbean Games were held in 1993 in Ponce and in 2010 in Mayagüez.

</doc>
<doc id="23042" url="https://en.wikipedia.org/wiki?curid=23042" title="Republic (disambiguation)">
Republic (disambiguation)

A republic is a type of government where the citizens choose the leaders of their country.
Republic or The Republic may also refer to:

</doc>
<doc id="23046" url="https://en.wikipedia.org/wiki?curid=23046" title="Placebo effect (disambiguation)">
Placebo effect (disambiguation)

Placebo effect may refer to:

</doc>
<doc id="23047" url="https://en.wikipedia.org/wiki?curid=23047" title="Pseudoscience">
Pseudoscience

Pseudoscience is a claim, belief or practice presented as scientific, but which does not adhere to the scientific method. A field, practice, or body of knowledge can reasonably be called pseudoscientific when it is presented as consistent with the norms of scientific research, but it demonstrably fails to meet these norms.
Pseudoscience is often characterized by the following: a use of vague, contradictory, exaggerated or unprovable claims; an over-reliance on confirmation rather than rigorous attempts at refutation; a lack of openness to evaluation by other experts in the field; and a general absence of systematic practices when rationally developing theories. The term "pseudoscience" is often considered inherently pejorative, because it suggests something is being inaccurately or even deceptively portrayed as science. Accordingly, those labeled as practicing or advocating pseudoscience usually dispute the characterization.
Science is distinguishable from revelation, theology, or spirituality in that it offers insight into the physical world obtained by empirical research and testing. Commonly held beliefs in popular science may not meet the criteria of science. "Pop science" may blur the divide between science and pseudoscience among the general public, and may also involve science fiction. Pseudoscientific beliefs are widespread, even among state school science teachers and newspaper reporters.
The demarcation problem between science and pseudoscience has ethical political implications, as well as philosophical and scientific issues. Differentiating science from pseudoscience has practical implications in the case of health care, expert testimony, environmental policies, and science education. Distinguishing scientific facts and theories from pseudoscientific beliefs such as those found in astrology, alchemy, medical quackery, and occult beliefs combined with scientific concepts, is part of science education and scientific literacy.
Etymology.
The word "pseudoscience" is derived from the Greek root "pseudo" meaning false and the English word "science". Although the term has been in use since at least the late 18th century (e.g. used in 1796 in reference to alchemy) the concept of pseudoscience as distinct from real or proper science appears to have emerged in the mid-19th century. Among the first recorded uses of the word "pseudo-science" was in 1844 in the "Northern Journal of Medicine", I 387: "That opposite kind of innovation which pronounces what has been recognized as a branch of science, to have been a pseudo-science, composed merely of so-called facts, connected together by misapprehensions under the disguise of principles". An earlier recorded use of the term was in 1843 by the French physiologist François Magendie. During the 20th century, the word was used as a pejorative to describe explanations of phenomena which were claimed to be scientific, but which were not in fact supported by reliable experimental evidence. From time to time, though, the usage of the word occurred in a more formal, technical manner around a perceived threat to individual and institutional security in a social and cultural setting.
Overview.
Scientific methodology.
While the standards for determining whether a body of knowledge, methodology, or practice is scientific can vary from field to field, a number of basic principles are widely agreed upon by scientists. The basic notion is that all experimental results should be reproducible, and able to be verified by other individuals. These principles aim to ensure experiments can be measurably reproduced under the same conditions, allowing further investigation to determine whether a hypothesis or theory related to given phenomena is both valid and reliable. Standards require the scientific method to be applied throughout, and bias will be controlled for or eliminated through randomization, fair sampling procedures, blinding of studies, and other methods. All gathered data, including the experimental or environmental conditions, are expected to be documented for scrutiny and made available for peer review, allowing further experiments or studies to be conducted to confirm or falsify results. Statistical quantification of significance, confidence, and error are also important tools for the scientific method.
Falsifiability.
In the mid-20th century, Karl Popper put forth the criterion of falsifiability to distinguish science from nonscience. Falsifiability means a result can be disproved. For example, a statement such as "God exists" may be true or false, but no tests can be devised that could prove it either way; it simply lies outside the reach of science. Popper used astrology and psychoanalysis as examples of pseudoscience and Einstein's theory of relativity as an example of science. He subdivided nonscience into philosophical, mathematical, mythological, religious and metaphysical formulations on one hand, and pseudoscientific formulations on the other, though he did not provide clear criteria for the differences.
Another example which shows the distinct need for a claim to be falsifiable was put forth in Carl Sagan's "The Demon-Haunted World" when he talks about an invisible dragon that he has in his garage. The point is made that there is no physical test to refute the claim of the presence of this dragon. No matter what test you think you can come up with, there is then a reason why this does not apply to the invisible dragon, so one can never prove that the initial claim is wrong. Sagan concludes; "Now, what's the difference between an invisible, incorporeal, floating dragon who spits heatless fire and no dragon at all?". He states that "your inability to invalidate my hypothesis is not at all the same thing as proving it true", once again explaining that even if such a claim were true, it would lie outside the realm of scientific inquiry.
Merton's norms.
In 1942, Robert K. Merton identified a set of five "norms" which he characterized as what makes a real science. If any of the norms were violated, Merton considered the enterprise to be nonscience. These are not broadly accepted in the scientific community. His norms were:
Refusal to acknowledge problems.
In 1978, Paul Thagard proposed that pseudoscience is primarily distinguishable from science when it is less progressive than alternative theories over a long period of time, and its proponents fail to acknowledge or address problems with the theory. In 1983, Mario Bunge has suggested the categories of "belief fields" and "research fields" to help distinguish between pseudoscience and science, where the former is primarily personal and subjective and the latter involves a certain systematic approach.
Criticism of the term.
Philosophers of science such as Paul Feyerabend argued that a distinction between science and nonscience is neither possible nor desirable. Among the issues which can make the distinction difficult is variable rates of evolution among the theories and methodologies of science in response to new data. In addition, specific standards applicable to one field of science may not be applicable in other fields.
Larry Laudan has suggested pseudoscience has no scientific meaning and is mostly used to describe our emotions: "If we would stand up and be counted on the side of reason, we ought to drop terms like 'pseudo-science' and 'unscientific' from our vocabulary; they are just hollow phrases which do only emotive work for us". Likewise, Richard McNally states, "The term 'pseudoscience' has become little more than an inflammatory buzzword for quickly dismissing one's opponents in media sound-bites" and "When therapeutic entrepreneurs make claims on behalf of their interventions, we should not waste our time trying to determine whether their interventions qualify as pseudoscientific. Rather, we should ask them: How do you know that your intervention works? What is your evidence?"
History.
The history of pseudoscience is the study of pseudoscientific theories over time. A pseudoscience is a set of ideas that presents itself as science, while it does not meet the criteria to properly be called such.
Distinguishing between proper science and pseudoscience is sometimes difficult. One proposal for demarcation between the two is the falsification criterion, most notably attributed to the philosopher Karl Popper. In the history of science and "history of pseudoscience" it can be especially hard to separate the two, because some sciences developed from pseudosciences. An example of this is the science chemistry, which traces its origins to pseudoscientific alchemy.
The vast diversity in pseudosciences further complicates the history of science. Some modern pseudosciences, such as astrology and acupuncture, originated before the scientific era. Others developed as part of an ideology, such as Lysenkoism, or as a response to perceived threats to an ideology. Examples are creation science and intelligent design, which were developed in response to the scientific theory of evolution.
Despite failing to meet proper scientific standards, many pseudosciences survive. This is usually due to a persistent core of devotees who refuse to accept scientific criticism of their beliefs, or due to popular misconceptions. Sheer popularity is also a factor, as is attested by astrology, which remains popular despite being rejected by a large majority of scientists.
Identifying pseudoscience.
A field, practice, or body of knowledge might reasonably be called pseudoscientific when it is presented as consistent with the norms of scientific research, but it demonstrably fails to meet these norms.
Karl Popper stated it is insufficient to distinguish science from pseudoscience, or from metaphysics, by the criterion of rigorous adherence to the empirical method, which is essentially inductive, based on observation or experimentation. He proposed a method to distinguish between genuine empirical, nonempirical or even pseudoempirical methods. The latter case was exemplified by astrology, which appeals to observation and experimentation. While it had astonishing empirical evidence based on observation, on horoscopes and biographies, it crucially failed to adhere to acceptable scientific standards. Popper proposed falsifiability as an important criterion in distinguishing science from pseudoscience.
To demonstrate this point, Popper gave two cases of human behavior and typical explanations from Freud and Adler's theories: "that of a man who pushes a child into the water with the intention of drowning it; and that of a man who sacrifices his life in an attempt to save the child." From Freud's perspective, the first man would have suffered from psychological repression, probably originating from an Oedipus complex, whereas the second had attained sublimation. From Adler's perspective, the first and second man suffered from feelings of inferiority and had to prove himself which drove him to commit the crime or, in the second case, rescue the child. Popper was not able to find any counterexamples of human behavior in which the behavior could not be explained in the terms of Adler's or Freud's theory. Popper argued it was that the observation always fitted or confirmed the theory which, rather than being its strength, was actually its weakness.
In contrast, Popper gave the example of Einstein's gravitational theory, which predicted "light must be attracted by heavy bodies (such as the sun), precisely as material bodies were attracted." Following from this, stars closer to the sun would appear to have moved a small distance away from the sun, and away from each other. This prediction was particularly striking to Popper because it involved considerable risk. The brightness of the sun prevented this effect from being observed under normal circumstances, so photographs had to be taken during an eclipse and compared to photographs taken at night. Popper states, "If observation shows that the predicted effect is definitely absent, then the theory is simply refuted." Popper summed up his criterion for the scientific status of a theory as depending on its falsifiability, refutability, or testability.
Paul R. Thagard used astrology as a case study to distinguish science from pseudoscience and proposed principles and criteria to delineate them. First, astrology has not progressed in that it has not been updated nor added any explanatory power since Ptolemy. Second, it has ignored outstanding problems such as the precession of equinoxes in astronomy. Third, alternative theories of personality and behavior have grown progressively to encompass explanations of phenomena which astrology statically attributes to heavenly forces. Fourth, astrologers have remained uninterested in furthering the theory to deal with outstanding problems or in critically evaluating the theory in relation to other theories. Thagard intended this criterion to be extended to areas other than astrology. He believed it would delineate as pseudoscientific such practices as witchcraft and pyramidology, while leaving physics, chemistry and biology in the realm of science. Biorhythms, which like astrology relied uncritically on birth dates, did not meet the criterion of pseudoscience at the time because there were no alternative explanations for the same observations. The use of this criterion has the consequence that a theory can at one time be scientific and at a later time pseudoscientific.
Science is also distinguishable from revelation, theology, or spirituality in that it offers insight into the physical world obtained by empirical research and testing. For this reason, the teaching of creation science and intelligent design has been strongly condemned in position statements from scientific organisations. The most notable disputes concern the evolution of living organisms, the idea of common descent, the geologic history of the Earth, the formation of the solar system, and the origin of the universe. Systems of belief that derive from divine or inspired knowledge are not considered pseudoscience if they do not claim either to be scientific or to overturn well-established science. Moreover, some specific religious claims, such as the power of intercessory prayer to heal the sick, although they may be based on untestable beliefs, can be tested by the scientific method.
Some statements and commonly held beliefs in popular science may not meet the criteria of science. "Pop" science may blur the divide between science and pseudoscience among the general public, and may also involve science fiction. Indeed, pop science is disseminated to, and can also easily emanate from, persons not accountable to scientific methodology and expert peer review.
If the claims of a given field can be experimentally tested and methodological standards are upheld, it is not "pseudoscience", however odd, astonishing, or counterintuitive. If claims made are inconsistent with existing experimental results or established theory, but the methodology is sound, caution should be used; science consists of testing hypotheses which may turn out to be false. In such a case, the work may be better described as ideas that are "not yet generally accepted". Protoscience is a term sometimes used to describe a hypothesis that has not yet been adequately tested by the scientific method, but which is otherwise consistent with existing science or which, where inconsistent, offers reasonable account of the inconsistency. It may also describe the transition from a body of practical knowledge into a scientific field.
Pseudoscientific concepts.
Examples of pseudoscience concepts, proposed as scientific when they are not scientific, include acupuncture, alchemy, ancient astronauts, applied kinesiology, astrology, Ayurvedic medicine, Vastu shastra, biorhythms, cellular memory, cold fusion, craniometry, creation science, Scientology founder L. Ron Hubbard's engram theory, enneagrams, esoteric healing, eugenics according to Edwin Black, extrasensory perception (ESP), facilitated communication, graphology, homeopathy, intelligent design, iridology, "kundalini", Lysenkoism, metoposcopy, N-rays, naturopathy, orgone energy, paranormal plant perception, phrenology, physiognomy, polygraph, qi, New Age psychotherapies (e.g., rebirthing therapy), reflexology, remote viewing, neuro-linguistic programming (NLP), reiki, Rolfing, therapeutic touch, and the revised history of the solar system proposed by Immanuel Velikovsky.
Robert T. Carroll stated, in part, "Pseudoscientists claim to base their theories on empirical evidence, and they may even use some scientific methods, though often their understanding of a controlled experiment is inadequate. Many pseudoscientists relish being able to point out the consistency of their ideas with known facts or with predicted consequences, but they do not recognize that such consistency is not proof of anything. It is a necessary condition but not a sufficient condition that a good scientific theory be consistent with the facts."
In 2006, the U.S. National Science Foundation (NSF) issued an executive summary of a paper on science and engineering which briefly discussed the prevalence of pseudoscience in modern times. It said, "belief in pseudoscience is widespread" and, referencing a Gallup Poll, stated that belief in the 10 commonly believed examples of paranormal phenomena listed in the poll were "pseudoscientific beliefs". The items were "extrasensory perception (ESP), that houses can be haunted, ghosts, telepathy, clairvoyance, astrology, that people can communicate mentally with someone who has died, witches, reincarnation, and channelling". Such beliefs in pseudoscience reflect a lack of knowledge of how science works. The scientific community may aim to communicate information about science out of concern for the public's susceptibility to unproven claims.
The following are some of the indicators of the possible presence of pseudoscience.
Demographics.
In his book "The Demon-Haunted World" Carl Sagan discusses the government of China and the Chinese Communist Party concern about Western pseudoscience developments and certain ancient Chinese practices in China. He sees pseudoscience occurring in the U.S. as part of a worldwide trend and suggests its causes, dangers, diagnosis and treatment may be universal.
The National Science Foundation stated that pseudoscientific beliefs in the U.S. became more widespread during the 1990s, peaked near 2001, and declined slightly since with pseudoscientific beliefs remaining common. According to the NSF report, there is a lack of knowledge of pseudoscientific issues in society and pseudoscientific practices are commonly followed. Surveys indicate about a third of all adult Americans consider astrology to be scientific.
A large percentage of the United States population lacks scientific literacy, not adequately understanding scientific principles and methodology. In the Journal of College Science Teaching, Art Hobson writes, "Pseudoscientific beliefs are surprisingly widespread in our culture even among public school science teachers and newspaper editors, and are closely related to scientific illiteracy." However, a 10,000 student study in the same journal concluded there was no strong correlation between science knowledge and belief in pseudoscience.
Explanations.
In a report Singer and Benassi (1981) wrote that pseudoscientific beliefs have their origin from at least four sources.
Another American study (Eve and Dunn, 1990) supported the findings of Singer and Benassi and found sufficient levels of pseudoscientific belief being promoted by high school life science and biology teachers.
Psychology.
The psychology of pseudoscience aims to explore and analyze pseudoscientific thinking by means of thorough clarification on making the distinction of what is considered scientific vs. pseudoscientific. The human proclivity for seeking confirmation rather than refutation (confirmation bias), the tendency to hold comforting beliefs, and the tendency to overgeneralize have been proposed as reasons for the common adherence to pseudoscientific thinking. According to Beyerstein (1991), humans are prone to associations based on resemblances only, and often prone to misattribution in cause-effect thinking.
Michael Shermer's theory of belief-dependent realism is driven by the belief that the brain is essentially a "belief engine," which scans data perceived by the senses and looks for patterns and meaning. There is also the tendency for the brain to create cognitive biases, as a result of inferences and assumptions made without logic and based on instinct — usually resulting in patterns in cognition. These tendencies of patternicity and agenticity are also driven "by a meta-bias called the bias blind spot, or the tendency to recognize the power of cognitive biases in other people but to be blind to their influence on our own beliefs." 
Lindeman states that social motives (i.e., "to comprehend self and the world, to have a sense of control over outcomes, to belong, to find the world benevolent and to maintain one's self-esteem") are often "more easily" fulfilled by pseudoscience than by scientific information. Furthermore, pseudoscientific explanations are generally not analyzed rationally, but instead experientially. Operating within a different set of rules compared to rational thinking, experiential thinking regards an explanation as valid if the explanation is "personally functional, satisfying and sufficient", offering a description of the world that may be more personal than can be provided by science and reducing the amount of potential work involved in understanding complex events and outcomes.
Some people believe the prevalence of pseudoscientific beliefs is due to widespread "scientific illiteracy". The individuals lacking scientific literacy are more susceptible to wishful thinking, since they are likely to turn to immediate gratification powered by System 1, our default operating system which requires little to no effort. This system encourages one to accept the conclusions they believe, and reject the ones they don't. Further analysis of complex pseudoscientific phenomena require System 2, which follows rules, compares objects along multiple dimensions, and weighs options. These two systems have several other differences which are further discussed in the dual-process theory. The scientific and secular systems of morality and meaning are generally unsatisfying to most people. Humans are, by nature, a forward-minded species pursuing greater avenues of happiness and satisfaction, but we are all too frequently willing to grasp at unrealistic promises of a better life.
Psychology has much to discuss about pseudoscience thinking, as it is the illusory perceptions of causality and effectiveness of numerous individuals that needs to be illuminated. Research suggests that illusionary thinking happens in most people when exposed to certain circumstances such as reading a book, an advertisement or the testimony of others are the basis of pseudoscience beliefs. It is assumed that illusions are not unusual, and given the right conditions, illusions are able to occur systematically even in normal emotional situations. One of the things pseudoscience believers quibble most about is that academic science usually treats them as fools. Minimizing these illusions in the real world is not simple. To this aim, designing evidence-based educational programs can be effective to help people identify and reduce their own illusions.
Boundaries between science and pseudoscience.
In the philosophy and history of science, Imre Lakatos stresses the social and political importance of the demarcation problem, the normative methodological problem of distinguishing between science and pseudoscience. His distinctive historical analysis of scientific methodology based on research programmes suggests: "scientists regard the successful theoretical prediction of stunning novel facts – such as the return of Halley's comet or the gravitational bending of light rays – as what demarcates good scientific theories from pseudo-scientific and degenerate theories, and in spite of all scientific theories being forever confronted by 'an ocean of counterexamples'". Lakatos offers a "novel fallibilist analysis of the development of Newton's celestial dynamics, [his] favourite historical example of his methodology" and argues in light of this historical turn, that his account answers for certain inadequacies in those of Sir Karl Popper and Thomas Kuhn. "Nonetheless, Lakatos did recognize the force of Kuhn's historical criticism of Popper – all important theories have been surrounded by an 'ocean of anomalies', which on a falsiﬁcationist view would require the rejection of the theory outright... Lakatos sought to reconcile the rationalism of Popperian falsificationism with what seemed to be its own refutation by history".
The boundary lines between science and pseudoscience are disputed and difficult to determine analytically, even after more than a century of dialogue among philosophers of science and scientists in varied fields, and despite some basic agreements on the fundaments of scientific methodology. The concept of pseudoscience rests on an understanding that scientific methodology has been misrepresented or misapplied with respect to a given theory, but many philosophers of science maintain that different kinds of methods are held as appropriate across different fields and different eras of human history. According to Lakatos, the typical descriptive unit of great scientific achievements is not an isolated hypothesis but "a powerful problem-solving machinery, which, with the help of sophisticated mathematical techniques, digests anomalies and even turns them into positive evidence."
 Laudan maintained that the demarcation between science and non-science was a pseudo-problem, preferring to focus on the more general distinction between reliable and unreliable knowledge.
Politics, health, and education.
Political implications.
The demarcation problem between science and pseudoscience brings up debate in the realms of science, philosophy and politics. Imre Lakatos, for instance, points out that the Communist Party of the Soviet Union at one point declared that Mendelian genetics was pseudoscientific and had its advocates, including well-established scientists such as Nikolai Vavilov, sent to a Gulag and that the "liberal Establishment of the West" denies freedom of speech to topics it regards as pseudoscience, particularly where they run up against social mores.
It becomes pseudoscientific when science cannot be separated from ideology, scientists misrepresent scientific findings to promote or draw attention for publicity, when politicians, journalists and a nation's intellectual elite distort the facts of science for short-term political gain, when powerful individuals in the public conflate causation and cofactors (for example, in the causes of HIV/AIDS) through a mixture of clever wordplay, or when science is being used by the powerful to promote ignorance rather than tackle ignorance. These ideas reduce the authority, value, integrity and independence of science in society.
Health and education implications.
Distinguishing science from pseudoscience has practical implications in the case of health care, expert testimony, environmental policies, and science education. Treatments with a patina of scientific authority which have not actually been subjected to actual scientific testing may be ineffective, expensive, and dangerous to patients, and confuse health providers, insurers, government decision makers, and the public as to what treatments are appropriate. Claims advanced by pseudoscience may result in government officials and educators making poor decisions in selecting curricula; for example, creation science may replace evolution in studies of biology.
The extent to which students acquire a range of social and cognitive thinking skills related to the proper usage of science and technology determines whether they are scientifically literate. Education in the sciences encounters new dimensions with the changing landscape of science and technology, a fast-changing culture, and a knowledge-driven era. A reinvention of the school science curriculum is one that shapes students to contend with its changing influence on human welfare. Scientific literacy, which allows a person to distinguish science from pseudosciences such as astrology, is among the attributes that enable students to adapt to the changing world. Its characteristics are embedded in a curriculum where students are engaged in resolving problems, conducting investigations, or developing projects.
Scientists do not want to get involved to counter pseudoscience for various reasons. For example, pseudoscientific beliefs are irrational and impossible to combat with rational arguments, and even agreeing to talk about pseudoscience indicates acceptance as a credible discipline. Pseudoscience harbors a continuous and an increasing threat to our society. It is impossible to determine the irreversible harm that will happen in the long term. In a time when the public science literacy has declined and the danger of pseudoscience has increased, revising the conventional science course to address current science through the prism of pseudoscience could help improve science literacy and help society to eliminate misconceptions and assault growing trends (remote viewing, psychic readings, etc.) that may harm (financially or otherwise) trusting citizens.
Pseudosciences such as homeopathy, even if generally benign, are magnets for charlatans. This poses a serious issue because it enables incompetent practitioners to administer health care. True-believing zealots may pose a more serious threat than typical con men because of their affection to homeopathy's ideology. Irrational health care is not harmless, and it is careless to create patient confidence in pseudomedicine.
References.
Bibliography

</doc>